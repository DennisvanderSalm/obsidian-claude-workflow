# Zeskoppige start-up kraakt 'onmogelijke' AI-test + Sam Altman haalt GPT-5.2 naar voren + MCP gaat...

**Source:** [YouTube](https://www.youtube.com/watch?v=y-oXYf8SX5o)
**Video ID:** y-oXYf8SX5o
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie, waar we uitzoeken welke invloed AI heeft op ons werk, ons leven en de samenleving met deze week. Er is een enorme sprong op de belangrijkste test die meet hoever we zijn in de ontwikkeling van AI. En dat is dus het idee dat computers 95% van het kenniswerk kunnen overnemen. Op die test dat meten ehm gebeurt normaal een grote sprong naar voren als er een nieuw groot model van een AI bedrijf uitkomt, zoals we recent zagen met eh Gemini 3 Pro van Google. Maar er is deze week ook zo'n enorme sprong gemaakt. En dit keer komt het niet van een groot AI bedrijf, maar van een start-up van zes nerds. Daar gaan we het over hebben. Natuurlijk blijven nieuwe modellen wel gewoon uitkomen. We verwachten deze week GPT 5.2 [muziek] in chat GPT. En Wietze is bij voorbaad al kritisch. Nou, dat gaan je dadelijk horen. En we tippen een geweldige AI tool die je nu al kunt inzetten om delen van je werk te automatiseren. Ik heb hem geprobeerd. Het is fantastisch. Dat en meer in airport. Veel plezier. [muziek] Ik volg dus op LinkedIn heel veel van die marketing mensen en die van reclamebureaus en die delen nu deze week allemaal stuk voor stuk achter elkaar hun [muziek] kerstcommercials. Dat schijnt een ding te zijn inmiddels bij marketing waar zij aan meegewerkt hebben die uit hun stal komen zeg maar. Ja, precies. En dat zijn dit jaar voorspelbaar genoeg veel met AI gegenereerde kerstcommercials. En gaat het dan met trots? of juist een beetje verstopt. Eh nee, daar zit wel daar zit enige mate van trots in. Ja. Eh we zagen het bij Coca-Cola als eerste natuurlijk. Eh dat was internationaal, maar ook in Nederland heeft McDonald's voor Nederland een met AI gemaakt kerstcommercial gemaakt. En wat ik en dat is niet de enige. Er zijn er meer. Dit is dus een trend zou je kunnen zeggen met AI CS commercials maken. En ik vind het dat grappig hoe ze erover praten op LinkedIn, want dat wordt toch een beetje met omhalen wordt er dan bij gezegd. soort van ja, we experimenteren en belangrijk om eh te innoveren. Dus er worden wel wat kanttekeningen bij geplaatst zeg maar. Da de kritiek is natuurlijk ook voorspelbaar, maar wat tegelijkertijd gebeurde was dat ik weer een andere klein bureau zag die heel erg juist trots eh ging doen met het tegenovergestelde. Namelijk wij hebben de hele commercial gemaakt met klei en stop motion. Ja. Wallaas and Gromit van die iedere keer een klein fotootje en het klein dingetje een klein beetje aanpassen en als je het allemaal achter elkaar plakt dan beweegt het. Ja. En dat kun je natuurlijk niet loszien van de tijdsgeest en die andere reclambureaus die allemaal AI gegenereerde commercie aan het maken. Maar dat je dus je kontooit en dat je daarmee ook iets probeert te zeggen. Soort van kijk ons eens. Heel moeilijk gedaan hebben. En ik vind het een grappig grappig moment in het tijdsgewricht want die kerstcommercials die zijn allemaal zijn wel oké. Eh ik denk niet echt dat eh soort van we over 20 jaar aan terug gaan denken. Denk nou dat was een leuke commercie die McDonald's maakt voor de kerst. Maar het is ook weer niet slecht. En het je zit er als kijker toch naar te kijken en denk je oké het is met AI gemaakt zie ik zelf ook wel. Het wordt steeds beter. Snap ik ook wel. Het is een beetje een raar moment dat dat dus met de hand dingen nu maken nu op é of andere manier ook betekenis hebben. Het heeft zeggen. Ja. En het is natuurlijk ook nog dat ik denk dat vanuit marketing, dat is volgens mij wat Coca-Cola deed, want dit is hun tweede of derde al volgens mij met AI gemaakt. Hij wordt dan ieder jaar een beetje beter qua output, qua kwaliteit. Ja. Eh maar daar zit ook een beetje in van AI is nu het ding. Als we het met AI maken, dan is het nieuws dat het met AI gemaakt is, hè. Dus beetje beetje het is gewoon marketing, zeg maar. Precies. Mensen gaan erover praten daardoor. Ja. Dus whatever the engagement is, engagement is engagement om het eventjes eh ja op marketing niveau te zeggen. Ik vind het wel Ik ben ben dus wel benieuwd in hoeverre dat dan dat trucje gaat op een gegeven moment niet meer werken. En hè als het is gewoon niet meer interessant dat het met e Nee, want dat is nu interessant omdat het zo'n onderwerp is. Ja, en het nog wel een beetje moeilijk is om een kan nog trots zeggen van moet je kijken wat ons desondanks de matige kwaliteit van de output toch gelukt is om te maken als een soort trots op met mindere middelen toch iets te doen. En het is AI en dat creëert die engagement waar aan ik ben wel benieuwd dat is niet houdbaar. Nee. Eh in hoeverre de minder enthousiaste engagement hieromheen op een gegeven moment niet een soort van de eh hoe zeg je dat? de weegschalwal een beetje doet doet draaien weer. Kijk, nu kan je zeggen ook al is er best wel een vokale groep mensen die zegt: "Ik doe liever kijken naar een eh reclame van eh kleipoppetjes hè, want dat is artis beter. Daar word je in je hart iets warmer van dan het idee dat er GPU cycles hebben staan draaien. Het is echt een heel mooi contrast tussen die twee." Ehm of dan niet de ja de het antisentiment richting die AI gegenereerde reclames op een gegeven moment zwaarder gaat wegen omdat de novelty, de nieuwheid, de innovatie voorspelling van volgend jaar. Volgend jaar zijn er geen AI commercials. Nou, wacht even, dat weet ik niet. Maar ik kan me wel voorstellen dat ik als je nu bij Coca-Cola zit, dan zitten daar ook mensen aan tafel die zeggen: "Moeten we dit niet juist niet doen?" Ja. En waar een andere is wat die kleikermersche is. Ik kan er niet anders iets niet iets anders inzien dan een statement. Statement. Absoluut statement. Ja, maar dan is de vraag volgend jaar als we VO4 hebben en die reclembureaus allemaal weer voor diezelfde taak zitten, we moeten een kerstcommercie hebben waar mensen over gaan praten, gaan we dan nog de moeite nemen om die klei reclame met de hand te maken of is het het feit dat het dan geen verschil meer zichtbaar is? Even voorspellende dat het geval gaat zijn. Eh is dat dan eh is het dan nog de moeite waard om met de hand een kleburch te maken als je het verschil echt niet meer ziet? Nou ja, dan zou je nog de moeite waard kunnen zijn dat de making off video dat is ook een beetje hoe je hebt allemaal van die meta content tegenwoordig. Ik merk het bij mezelf ook dat ik het vaak dit was vroeger al met DVD specials en extended director cuts dat je het ik in ieder geval leuk vond om te luister de film nog een keer te kijken terwijl de de de director meekletst hè. Dus die meta content dat was altijd al een ding. Maar ik kan me voorstellen dit zie je nu ook bij al die robot video's. Dan zijn er allemaal robot video's en dan moeten de video's gemaakt worden van de making off. En ik heb er laatst één gezien. Dat was de video van de making off making off. [gelach] Nee. Ja, serieus. Want dat het ging erover dat volgens mij ging een robot ging iemand in elkaar schoppen ofzo. Best wel intens beeld. Alsin als eh reclame. Toen werd er een video uitgebracht die lag al klaar van de making off omdat ze al dachten: "Dit gaat niemand geloven zeg maar." Dat was om te laten zien dat je een soort bokser de vechtende robot had. En toen lag er ook alweer een video klaar van het maken van de making off. En ik denk ik kan me wel voorstellen dat als er volgend jaar twee commercials uitkomen allebei met kleipoppetjes. De ene is VO4 en de andere hebben mensen 4000 uur ingestoken ofzo. Of in ieder geval 400 minimaal. Dat dan bij die tweede er een making off en de making off van de making off bij moet om die weer gewicht te geven. Het blijft boeiend hoe we AI in onze cultuur gaan opnemen. Dat is een eh dat is een groot thema. Daar gaan we ongetwijfeld volgend jaar nog heel veel over praten. Dit jaar was AI Report opnieuw de best beluisterde podcast over AI van Nederland. Gefeliciteerd Wietsen. Ja, jij ook. Eh daar zijn we heel trots op en het geeft ons ook energie om nieuwe plannen te maken voor volgend jaar. We hebben ruimte voor nieuwe sponsoren die zich willen verbinden aan onze podcast en aan onze luisteraars. En dat zijn, weten we uit ervaring, veel al beslissers uit het bedrijfsleven. Als je daar interesse in hebt in dus sponsor worden van deze podcast, dan kun je de link checken in de omschrijving en dan videobellen wij snel. We gaan naar het nieuwsen, want in strijd met Google parkeert Open AI de nieuwste snufjes en focust het weer op wat ertoe doet. De volgende update van grote modellen. En er komt nu eerst een kleine update als tussenversie. De GPT 5.2 kun je verwachten. En die wordt waarschijnlijk naar voren gehaald. Zo gaan de geruchten op oorspronkelijk gepland voor eind december, maar nu waarschijnlijk al deze week. Misschien zelfs wel als je dit luistert. Openheid testte recent reclame in chat GPT. Dat is dus een gebrek aan focus eh denkt Sam Altman nu. Eh betaalende gebruikers gingen gelijk klagen en die functie is daarop uitgezegd uitgezet. En dat valt allemaal een beetje samen met die intern afgekondigde code rood bij Open AI in verband met de strijd met Google. Dat betekent dus ook dat die advertentieplannen in ChatPt eh naar de lange baan zijn geschoven tot de basis eerst op orde is. Cloud code komt naar Slack. Dat is een eh Cloud Code is een vibe coding tool gebouwd op het razend populaire AI model cloud. En vibecoding betekent natuurlijk dat je samen met AI kunt programmeren door gewoon te beschrijven wat je wil in plaats van dat je per se moet kunnen programmeren. En nu komt er dus deze functionaliteit naar een programma dat heel veel mensen gebruiken op hun werk. Je kunt in een chat met een collega dan zeggen dat je iets wilt debuggen en dan clot erbij taggen, zoals je normaal een collega tagt. En dan pakt het model dat voor je op. En dat is misschien belangrijker dan dat het klinkt, want het toont hoe AI integreert in onze alledaagse programma's. Andere populaire tools zoals Cursor en GitHub, Copilot bieden ook al Slack integraties. En de strijd gaat hier niet meer over welk model het beste is, maar wie het beste en het diepst integreert in de workflow die je al gebruikt. Een zeskoppig bedrijf genaamd Poetic is als eerste ter wereld door de 50% grens gebroken op de Arc AGI 2 Challenge. Dat is een test die binnen de AI wereld geldt als de ultieme lakmoesproef voor menselijk eh intelligentie eh niveau. De test meet waar AI slecht in is en waar mensen juist goed in zijn. nieuwe onbekende problemen oplossen zonder terug te vallen op voorbeelden waar wat het ding eerder heeft kunnen zien. 6 maanden geleden scoorden de beste modellen nog onder de 5% en mensen halen daar ondertussen dus moeiteloos 60%. Voor mensen is het makkelijk, voor AI is het moeilijk. Maar het bijzondere is dat Poetic geen eigen model bouwde en toch de boel versloeg. Ze gebruikte Google's eh Gemini 3 Pro en maakte daar slimme software omheen. En het resultaat is dat het beter scoort op die belangrijke test dan Google's eigen topvariant voor ook nog eens de helft van de kosten. En dat laat zien dat vooruitgang op dit moment niet alleen komt van bedrijven die miljarden uitgeven aan het trainen van nieuwe modellen, maar ook door dit soort slimme zetten van kleine groepjes nerds. We gaan het er straks uitgebreid over hebben. Entropic, Open AI en block bundelen hun krachten voor open AI standaarden. Zo maakte Enhropic deze week bekend. Het bedrijf doneert het Model Context Protocol. Dat is een universele standaard waarmee AI applicaties met elkaar of externe systemen kunnen communiceren aan een foundation. Een stichting die valt onder de L eh de Linux Foundation. Dat is een nonprofit die open source projecten beheert en zorgt dat geen enkel bedrijf de controle krijgt. Het is allemaal heel eh ehm gezellig. En de cijfers tonen aan waarom dit relevant is. Meer dan 10.000 actieve MCP service hebben op dit moment. Het is een standaard die is geadopteerd door eigenlijk alle grote eh makers van taalmodellen. En er worden ontzettend onwaarschijnlijk veel MCP calls gedaan. Het is inmiddels een nou ja belangrijke bouwsteen voor hoe AI systemen met externe software werken. En ook Google, Microsoft, ABS en Cloudfare, allemaal grote partijen, steunen dit initiatief. Dit is best wel cool ietsen. Ja, best wel snel gegaan, want onze MCP aflevering is denk ik een jaar oud nu, Max. Ja, toch nog even. Wat is MCP? Nou, je zou het HTTP kunnen noemen van zeg jij: "Wat is HTTP?" Precies. Het maakt niet beter. Taala tussen partijen, zodat je in dezelfde taal data naar elkaar kunt sturen. Ja, het is een koppeling zodat je zodat je bij bijvoorbeeld in chatpt met notion kan praten als je notion gebruikt of money do allemaal maar op. En eigenlijk is het we hadden dit al in de vorm van API's. Alleen API's waren bedacht voor ontwikkelaars om met externe systemen te praten. En hier gaat het om AI agents of AI systemen die met externe systemen praten. En dan heb je ook nog wat meer veiligheid nodig. En het is gewoon prettig als je een beetje van elkaar weet hoe je dat doet, want dan kan je voor de eind eindgebruiker wat makkelijker die hele plugin directory maken. Namelijk dat jij in chat GPT kan zeggen: "Ik wil mijn Google Drive, ik wil mijn Canva, ik wil mijn dingetjes, mijn Figma, ik wil icoontjes koppelen als een soort klinkt allemaal heel ingewikkeld, maar het heeft hele praktische eh gevolgen, want daardoor kun je dus in je ChatBT letterlijk vragen om de verwarming harder te zetten als je die koppeling maakt." Nou, dit was een protocol wat is bedacht door Anthropic. Ja, die hebben dus eh ja, die zijn ermee begonnen. Dat is heel snel overgenomen door grote concurrent OPDI en Google. Ja. Ja. Toen eigenlijk volgens mij eh was Google eerst, maar toen uiteindelijk één grote speler ook meedeed, dan op een gegeven moment is het eerst het tweede schaap over de dam zou je moeten zeggen en dan gaat het hard. Ja. En dan gaat het nu ook nog eens in een open source foundation. Ik vind het verdacht eh ja op het is goed opzien barend dat deze grote commerciële bedrijven nu iets een zo'n belangrijke standaard in een nonprofit parkeren. Nou, misschien is goed goede achtergrond informatie is dat het A2A protocol, namelijk agents to agent, wat door Google bedacht is, dat is weer bedacht om agents met elkaar te laten praten, dat dat ook al in de in de community gegooid was, zeg maar, of gezet was. Oké, dus in essentie kan je zou je kunnen zeggen dat als Google dat schaakstuk naar voren schuift dat Antropic eigenlijk mee moet gaan schuiven. Dus eh maar waarom doen ze dit? Nou, uiteindelijk is het in ieders voordeel eh het is hè d is dus je zou het een soort van positieve eh collusion kunnen noemen en het is een soort van eh eh samenwerken eh voor de markt omdat als jij elkaarsprotocollen ondersteunt zorgt dat ervoor dat de portabaliteit dus het mee kunnen nemen van het é het andere eh binnen het systeem groter wordt. En dat opent dan eigenlijk hè normaal dwingt de Europese Unie dit soort dingen af hè. Dus ik denk dat jij ook een beetje verbaasd bent dat ze zichzelf aan het opleggen zijn. Eh ik bedoel ik denk dat het dat de voordelen om samen te werken tussen alle partijen en hun agents en hun developers en hun eh groter is dan als ze het allemaal voor zichzelf nadelen over. Dus ik bedoel er zit een enorme lockin neiging bij die grote partijen, hè om te zeggen eh je hebt het eh nou laten we voor het gemak Google nemen die A2A agent to agent maakt helemaal beheert en dan als je mee wil doen moet je naar Google luisteren zeg maar. Dat is in hun voordeel maar het is om het te laten adopteren door de industrie in hun nadeel. Ja, merkt dat voor jou concurrenten om mee te doen aan jouw plan dat in een nonprofit stoppen en in dit geval zelfs onder een derde partij te leggen die best wel gewend is. De Linux Foundation bestaat al best wel lang om ja, een soort sheppering hè, een soort headder te zijn van dit soort eh afspraken. Z Ja, Linux Foundation beheert de ik neem aan de code achter Linux onder andere en heel veel standaarden daarin. Het gaat vooral om protocollen eigenlijk. Dus je heb kijk uiteindelijk is het implementaties, dat is code. Dat mag je redelijk zelf weten hoe je het implementeert. Er zijn ook wel een beetje regels over, maar het is vooral hoe wat kunnen we van jou verwachten als we met jou praten, wat zeg je dan terug? En als we deze 20 dingen aan jou vragen, verwachten we het ook in dit formaat terug? Nou, het is bijna hardverwarmend hoe deze bedrijven bij elkaar gekomen zijn rond kerstdagen om te zeggen: "Weet je wat, we hebben hier iets heel waardevols in handen. We stoppen het in een nonprofit." Luister, het hele internet is gebouwd op dat soort standaarden en die zijn vaak ook spontaan ontstaan en later eh in een werkgroep gegooid. Alleen werkgroepen krijgen mensen vaak zenuwachtig van omdat ze dan denken: "Nou, daar gaat MCP als in dit staat nu voor altijd stil." Terwijl er zijn hè als in als het eenmaal een soort bureaucratisch eh democratisch proces is binnen een stichting, kan MCP dan nog doorgroeien? Hè? Want toen alleen Antropic heten deed waren het misschien vijf mensen bij Antropic hè. Dat gaat een stuk harder. Ja. Ja, nu moeten ze hem overleggen. Ja, maar je zou ook kunnen zeggen als je eenmaal op de 1.0 bent hè, dus alle de foundations, de fundamenten liggen, dan is er een moment dat je het overdraagt. Nou, er is nog meer hartverwarmends, namelijk Marianne Lucas van Dept. Hi, heermarketing en het tech echtbureau Dept. Elke week bespreken we hoe wij merken helpen in de wonderenwereld van AI. Deze week gaan we het hebben over AI guard trails om consumenteninput te controleren op niet toegestaan inhoud, zodat we AI veilig kunnen gebruiken in hun merkervaring. Lucas, vertel. Ja, nee, je moet natuurlij denken dat iemand bijvoorbeeld met je chatbot begint te praten eh en daar zijn eh politieke voorkeur begint te vinden en jouw chatbot een vrolijk respect daarover begint. Nou, om die reden hebben we voor een wereldwijdg merk een oplossing gebouwd die ervoor zorgt dat AI consumenten één op één kan helpen, maar wel allemaal binnen de veilige merkconforme grenzen. Interessant, want het gaat best wel vaak fout nog toch? Ja, je we kennen allemaal de voorbeelden van AI die begint te hallucineren of eh eh iets te ver meegaan met iemands eh eh politieke mening bijvoorbeeld. Eh en dat is niet gek, want je hebt gewoon weinig controle natuurlijk over wat consumenten allemaal kunnen invoeren. Denk bijvoorbeeldwoorden, gevoerdige data of politieke statements die we net al noemden. En die wil je gewoon niet in je merkervaring hebben. Ehm daarom hebben we AI Guardels ontwikkeld. Eigenlijk is het een laag van slimme controles die je over het inputveld legt en die kijkt realtime of wat er gezegd wordt eh eh wel of niet binnen de eh de guard wheels valt. En pas als die het zijn veilig heeft, gaat de rest van de AI aan de slag met het eh formuleren van het antwoord waardoor we ervoor kunnen zorgen dat het supermenselijk is. Één op één, maar ook veilig. Check. Hyé. En kunnen merken dit makkelijk toepassen ook? Ja, het vraagt ook altijd wat werk hè te beginnen met dat je moet bepalen wat wel of niet mag. Nou, ik denk dat 90% eh logisch is wat niet mag, maar is altijd die laatste 10% denk aan welke concurrent je wel of niet wil meenemen et cetera. Ehm dan ontwikkelen we of trainen we het model. Dat moeten we een aantal keer testen. Eh maar het goede is de tech is volwassen en ook heel goed te trainen. Dus ja, eigenlijk elk merk dat AI wil inzetten in klantinctie of service of campagnes eh kan dit gaan toepassen. En het maakt niet alleen veiliger, maar ook vaak consistenter omdat je beter traint op je merk eh en daarmee ook schaalbaarder. Yes. Kortom, niet afwachten maar doen. Wil je weten hoe jij AI interacties kunt opschalen zonder risico voor je merk? Kijk dan naar deagency.com/aai reports. Tot volgende week. Je hoort het net in de intro al even. Een zeskoppig bedrijf genaamd Poetic met een Q is als eerste door de 50% grens gebroken van de Arc AGI2 challenge. Dat is een test die binnen de AI wereld geldt als de ultieme meetlat voor AGI eh algemene kunstmatige intelligentie. Dat is groot nieuws. Laten we eerst even opfrissen wat die ark test ook weer is. Dat is een test die is bedacht door ene François Colet Col volgens mij. Dat is een AI onderzoeker. En die vindt dat we veel te makkelijk roepen dat AI intelligent is. En daarom ontwerp hij puzzels die meten waar AI slecht in is en waar mensen goed in zijn. Dat zijn dus nieuwe onbekende problemen die opgelost moeten worden door die AI eh zonder dat ze kunnen terugvallen op eerder gezien voorbeelden. Het zijn dus geheim geheime testen voor een deel. Eh vaak visuele puzzeltjes waarbij je moet ontdekken welke logica er achter een patroon zit. En die moet je dan vervolgens toepassen op een nieuwe situatie. Dat zijn dat klinkt allemaal heel abstract, maar dat zijn gewoon testjes die voor mensen te doen zijn. Maar als je luistert en denkt waar gaat het over dan kan en je hebt bij de kerst. Nou, dit is nou een leuk ding. Sommige mensen doen de IVD kerstpuzzel, maar er zijn ook mensen doen de Ark 2 challenge. Misschien is dat iets wat wij kunnen doen onder de booms. [gelach] Jij eerst, ik hoor het wel van je. Vorig jaar werd de eerste versie eh van die test, de Arc AGI One, verslagen door Open I redeneer model O1, weet je nog? Eh dat haalde ruim 75% in de zuinige modus en zelfs 85% met meer rekenkracht, met extended thinking, zoals dat tegenwoordig heeft. Een experts riep eh op een gegeven moment dat die test was gekraakt, maar eh Colet zat als stilletjes te broeden op een nieuwe veel moeilijkere versie en dit voorjaar lanceerde hij dus de versie nummer twee. En de resultaten zetten de AI wereld weer met beide benen op de grond. Want mensen scoren gemiddeld 60% op die test. Maar een panel van en een panel van experts dus echt gewoon de echt slimme mensen eh haalt 100%. Dus gemiddelde mensen 60% en echte slimme mensen 100%. Open is het beste model O3 op dat moment kwam niet verder dan 4% en dat kostte $200 per taak om dat ding te laten broeden. En gewone taalmodellen op dat moment zoals GPT4,5 scoorden 0%. Nou 9 maanden lang bleef die kloon bestaan. Geen enkel model kwam ook maar in de buurt van die menselijke scores. En voordat we naar poetic gaan, want die hebben dus weer een belangrijke slag geslagen. Waarom wietsen is deze test zo moeilijk voor AI? Nou, wat je eigenlijk wat het idee de is van van François Colet de is dat taalmodellen omdat het statistische modellen zijn ze echt goed in het gokken op iets wat ze al eerder hebben gezien. Maar wat onderdeel is van intelligentie in ieder geval dat is het hele debat is kan je ook dingen die je hebt geleerd op A toepassen op B. Ja. Leren van die pogingen en eigenlijk in het moment uitvinden door experimenteren wat bijvoorbeeld kinderen doen. Gewoon een beetje rommelen ermee. Iets nieuws leren in het moment. Wat je eigenlijk doet is je hebt al een stukje bestaande kennis op een eh ander binnen een ander domein bijvoorbeeld of je hebt een eerdere versie van een puzzel gezien die er een beetje op lijkt. Maar kan je dan ook de stap maken om te denken: "Maar wacht even, als ik hier een beetje mee ga rommelen, krijg ik het dan niet voor elkaar om al mijn eerder geleerde dingen plus de nieuwe dingen die ik leer tijdens het puzzelen toch die puzzel te kraken?" En wat tot nu toe de eerdere modellen, of ze nou multimodaal zijn, hè, dus dat ze mee kunnen kijken visueel of alleen maar tekstvoorspellen, hè. Soms werden de puzzels eerst omgezet in tekst, dan gegokt in tekst en dan weer terug. Of de spullen ging beschrijven wat de puzzel was om hem dan op te lossen. Ja, want die kon niet kijken, zeg maar. Hij kon niet echt Hij kon wel kijken om het te beschrijven, maar hij kon niet kijken om te denken. Kijk, precies. Bizar. Precies. Inmiddels hebben natuurlijn modellen of die multimodale modellen. En toen gingen die scores van Arc AGI 2 dus ook heel erg omhoog, want je kon eigenlijk een soort bredere tussen aanstekens intelligentie inzetten. Het was minder compressed ook. Ja. En je hoeft precies en het niet alles kijk die puzzeltjes zijn zo ontworpen eigenlijk expres. Ja, het is het is alsof jij ehm een student in je klas hebt zitten als docent die ontzettend goed antwoord geeft waardoor heel waardoor heel de klas tegen hem of haar opkijkt, maar jij eigenlijk denkt: "Volgens mij weet je helemaal niks, man. Volgens mij zit jij gewoon heel slim net op tijd te bluffen." En jij bluft omdat je eigenlijk al alle vragen van mij al een keer hebt gezien, hè. Je bent vorig jaar al in mijn lessen geweest, hè. Dus maar als je dan als je dat dan weet en je hebt die theorie kan je natuurlijk vragen gaan verzinnen waardoor die student door de mand valt. En dit is wat de Arc AGI challenge is. Hoe laat je een LM door de mand vallen? En wetenschappelijk gezien is dat heel mooi, want volgens mij is wetenschap juist het falsificeren. Dus je wilt constant eigenlijk jezelf uitdagen om te zeggen: "Ik heb iets gebouwd hè." Want ze zijn allemaal best enthousiast bij Arc eh eh over AI modellen, maar ook te zeggen: "Kunnen we niet puzzels maken waarop mensen heel goed zijn en AI's direct door de mand vallen?" En dat gebeurde ook. Ja. Ja. Nou, en daar is nu dus Poetic. Eh dat is een team van zes mensen eh die als eerste door die eh 50% grens breekt van dit eh dit model wat dus eerder dit jaar is uitgekomen. Deze deze test moet ik zeggen, die test die eerder dit jaar is uitgekomen. Ja. is de Arc AGI2 challenge waarop dus O3 high hè wat het summum was van reasoning eh nog z maanden geleden. Ja. Eh ja niet% scoorden. En ik bedoel en Gemini eh 3 Pro zelf hè van Google het model van een maand geleden, maakte ook al een leuke sprong op Arc AGI 2, maar niet een spectaculaire sprong. Juist. Nee, wat nu dus nieuws is, is dat er een clubje is die niet een eigen model hebben gemaakt, toch door die grenzen zijn heen gebroken. Dan ook nog eens best goedkoop $30 per opgave aan dat ding dus moet denken en wat je aan API credits moet betalen aan eh aan Google in dit geval. Ehm dit is zijn geen eh sukkels. Het zijn best wel slimme mensen. Deze zal ex deep mind ex Google. [gelach] Ja, dus die hebben gewerkt met de mensen die eh Google Deep Mind of sorry Google Gemini ontwikkeld hebben. Ik wil er wel meteen bij zeggen, je kan natuurlijk denken ehm want even in een aantal stappen, het poetic team heeft met zijn zessen een harnas of scaffold gemaakt, hè. Een soort exoskeleton om Gemini heen, hè. Dus ja, zij gebruiken Gemini 3 Pro. Ja, in het winnen van deze score, zeg maar, het behalen van deze score is een combinatie van de vanille Gemini 3 Pro, oftewel die jij kunt gebruiken in de Gemini app. Niets a niets aan aangepast. Maar je zou kunnen zeggen door heel slim te prompten, ik ga straks uitleggen wat ik daarmee bedoel, want dat doet het een beetje tekort, maar te zeggen: "Geef ons dan maar gewoon wat iedereen krijgt in Gemini." En wij gaan zo slim om met Gemini dat wij een veel hogere score kunnen halen dan Google zelf met hun eigen model lukt op Arc AGI 2. En dat is best wel bizar. En dat dat heeft dus een aantal implementaties waardoor ik dacht: "Dit is dit nieuws mag toch wel wat groter uitgemeten worden." Dus we gaan nu best. Daar hebben we het erover. Maar wat hebben zij gedaan? Wat ze eigenlijk hebben gedaan is in eerste instantie nog zonder dat Gemini 3 Pro uit was. En dit maakt het heel boeiend, want zij zeiden: "Als poetic zijnde, willen wij eigenlijk eh model scaffolds maken, hè. Dus eh scaffolding is net als dat je een steiger om een huis heen zet, hè. Dus je hebt het huis zelf, dat is het model en de steiger staat daaromheen als extra, zeg maar. Dus je bent om het model heen extra features aan het bouwen. Je hangt als het ware ballen in de kerstboom, hè. Dus je doet er iets bij. Hm hm. Dat je zegt: "Vor alle modellen willen we een scaffold maken waardoor alle modellen sterker worden op hun eigen manier." Dus wat zijn ze gaan doen? Ze hebben JP GPT 120BEN, dus het open source model van Open eh van Open AI eh Clod maar ook eh Gemini 2.5 destijds hebben ze een scaffold omheen gebouwd die werkt voor al die modellen. Ja. Dus het is een soort superheldenpak dat iedereen aan kan trekken. En wat en wat hebben ze wat doen ze dan ab? Maar in dat superheldenpak zitten een aantal onderdelen. Ehm wat heel belangrijk is, is dat wat we nu eigenlijk niet goed hebben is testtime compute. Dus dat houdt in je hebt training pretraining compute. Dus dat is alle computerkracht in datacenters die je inzet om de modellen te trainen, om ze te bakken. Hè, dat is het bakproces van het model. Dat kost heel veel water, energie, noem het allemaal maar op. En data en uiteindelijk komt daar dan Gemini 3 Pro uit. Daar gaat dit allemaal niet over. Absoluut niet. Dat hebben ze ook eigenlijk een beetje afgesproken om te zeggen: "Daar gaan wij niet aan zitten. Laat dat de grote laps maar doen." Want wij krijgen eigenlijk het model als af eh aangeleverd en wij gaan het dan nog hè we gaan nog een camperdak bouwen op dat busje zeg maar. Geef ons maar dat busje, wij gaan er nog even mee door. En eh de testtime compute is eigenlijk dat je zegt op het moment dat je met het model aan het praten bent hè, dan kun je ook nog computerkracht inzetten om het model wat al af is eigenlijk nog extra kracht te geven. Wacht op het Ja, dus even voor jouw beeld ehm je hebt trainen en je hebt inference. Ja, dat snap ik. Ja. En de inference is dus testtime compute. Dat is het moment dat het model wat eigenlijk statisch is op dat moment, je kan het niet meer aanpassen, dat je het model nog de mogelijkheid geeft om na te denken, hè. En dat dat denken dat kost eh uiteindelijk computerkracht. Dus dat ja, dus dat knopje met extended thinking. Ja. En testing is eigenlijk is eigenlijk wanneer je kunt oefenen thuis voor de toets en je hebt het modeling examen. Ja, het modeling examen is testtime compute. Als in hoe lang krijg jij van die docent om na te denken over je antwoord? Ja, maar je mag niet meer je boeken erbij pakken. Ik bedoel, dat is nog een beetje, het is een beetje maff metor, maar ga er maar vanuit. Je bent al voorbereid, je hebt je prep al gedaan. Je mag trouwens nog wel je boeken erbij pakken, maar dan moet je wel donders goed weten wa naar welke pagina je toe moet bladeren, want je hebt maar 5 minuten. Ja. En het allerbelangrijkste is wat om even terug te haken op eh die puzzeltjes, want daar gaat het uiteindelijk over. Nu is het zo geweest dat Gemini 3 Pro krijgt die puzzel te zien en die heeft dan eigenlijk twee shots. Dus die heeft twee pogingen om die puzzel te maken en dan krijg je je cijfer. Dat is hoe dit deze test werkt. Je mag twee keer proberen. Oké. Ehm maar eh dan eigen en dan krijg je daarna het volgende puzzeltje. Hm hm. Maar wat je geleerd hebt bij het eerste puzzeltje is weg, want het is een nieuw gesprek voor het tweede puzzeltje. Dus één van de eerste dingen die zij zijn gaan doen is zeggen: "Oké, wacht even. Als jij puzzels maakt en je ontdekt daar terwijl je ze aan het maken bent nieuwe inzichten, dan ga je die inzichten opschrijven en krijg je daarmee ehm Juist. Ja. En er zijn ook nog eens je bent niet in je eentje puzzels aan het oplossen, maar met heel veel Geminis tegelijk die ook nog eens met elkaar hun inzichten delen. Ah. En ook nog eens, want ik ga nu even stapelen. Ze hebben iets van 12 innovaties gedaan. Eh in die in dat Superman pak, in dat superhero pak zitten 12 trucjes op zijn minst. Ik weet niet of ze alle 12 uit mijn hoofd zou zeggen, maar ik ga de belangrijkste langs. Dus ehm jij geeft de initiële prompt van hun is al een goede prompt hè. Daar zat een dus dat de laat zeggen als als een soort prompt engineers hebben ze al een goede prompt gemaakt om puzzels op te lossen. Dat is één. Dan zit er in die prompt ook die prompt is vloeibaar als je een puzzel hebt gemaakt dan heb je ervan geleerd wat je verkeerd hebt gedaan. Want we hebben jou ook dankzij die hele goede prompt eh een manier gegeven om beter te snappen wat je verkeerd hebt gedaan. Dus eh iedere test die faalt is informatie. Ja, want het is niet alleen maar kijk het enige wat Arc AGI tegen jou zegt is fout. Is dit niet wat een zeg maar als ik naar als ik aan Google's eh Gemini iets vraag en ik klap dan vervolgens die redeneer trand open dat je kan zien welke stappen die allemaal maakt bij het nadenken. Dan zie ik hem regelmatig zichzelf op fouten betrappen en dan eigenlijk een nieuwe route inslaan. Dus leren van die fout. Wa wat je nu beschrijft klinkt alsof dit al gebeurt. Ja. En het gebeurt alleen heel slecht. Oké. Dat blijkt, want de scores zijn veel lager op Arc. Ja, hij is niet goed in van zichzelf van zijn eigen fouten leren ofzo. En hij loopt heel vaak eh in cirkels en vast, zeg maar. Dus even voor de mensen die al langer deze eh podcast luisteren, dat zijn velen van jullie denk ik. We hebben het er al eens over gehad dat heel veel van de sprongen die nu door de modellen anzie gemaakt worden zijn omdat die een deel van dat Superman pak inmiddels toegevoegd is aan het model zelf hè. Dat dat als het ware het pak zit vastgeplakt als huid aan het model om een beetje maffe te voor. Maar goed, ehm wat we bij Poetic zeiden is: "Oké, luister, we hebben een aantal innovaties gedaan. Daar kunnen alle laps van leren en een deel daarvan kunnen ze ook in de modellen gaan stoppen." Maar wat zegt Poetic? Volgens mij moet hier een scheiding gaan ontstaan waarin wij een paken dat op alle modellen werkt. En ik denk als ik hier zelf naar kijk, sta ik even een paar stapjes over alvast richting een soort eh conclusie, maar dan hebben we die alvast staan. In eh engineering, hardware en software heb je zoiets als separation of concerns. Dat houdt in dat eh jij hebt eh op een op jouw server staat een e-mail server, die kan email ontvangen en die maakt een mailboxje aan. Er zat ook een DNS server die doet eh namen omzetten naar IP-adressen. Dat zijn twee verschillende services met twee verschillende rollen. Hun de concerns zijn separated in die twee services. Wat we wat we nu aan het ontdekken zijn met elkaar, lms zijn nog best wel jong, is hoeveel moet er nou in die base model zitten en hoeveel moet er zitten in testtime? En moet je die scaffold dan testtime bedoel jij dus mee het daadwerkelijk gebruiken van het model. Ja, precies. Testtime. En precies dus ja, dat woord test is een beetje stom misschien, maar misschien gewoon wanneer je het gebruikt. Juist. Ja. [gelach] Ja, dat is gewoon nog beter toch? Ja. Tijdens het mondeling. Eh want dan heb je niet meer kan je niet meer zoveel fixen hè. Je bent erin. Want eh tijdens de opname van AI Report. Dit is testtime compute waar je nu mee praten. Helder. Ik zal voorttaan dit [gelach] taalgebruik overnemen. Ja. Ja, je wilt eigenlijk ehm wat blijkt is dat je kunt proberen om alles in de training te doen, want dat scheelt natuurlijk een hoop testtime computer, want die is best wel duur hè, en de eindgebruiker moet ook wachten. Dus die laps zijn ook een beetje aan het duwen van laat het alsjeblieft maar erin zitten. Maar wat blijkt? Die Franis Colet die is puzzels aan het maken waardoor dat wat er al in zit niet meer werkt. Juist. En dat is een kat en muisspel wat je de hele tijd kan proberen blijven inhalen. Maar misschien moet je dus iets veranderen aan ehm welke rol je taalmodel geeft en welke rol je geeft aan de software waarin het taalmodel draait. Wat wij als gebruiker gewoon gebruiken. Ja. En dat een beetje die separation of concern is dat het mogelijk is een betere architectuur voor AI. Ja, oké. Snap ik. Ja, want en wat voor trucks doen ze dan? Nou, je hebt bijvoorbeeld ehm we hebben het vorige keer voor mij ook wel eens gehad over vloeibare modellen. Dus het zijn eigenlijk modellen die wel eh aangepast kunnen worden terwijl ze getest worden, hè. Dus heel veel mensen hebben de misvatting dat de AI die je vandaag de dag gebruikt, dat die soort van op jou aangepast wordt. Ja, er wordt wel een blokje memory gemaakt waarin die leert dat jij Alexander Clubing bent, maar dat is alleen voor jou. Staat alleen maar in jouw account, niet? onderliggende model blij blijft misschien wel een jaar lang of nog langer hetzelfde. Precies. En daarom hebben ze ook versienummers, zodat je ook een beetje op kan vertrouwen dat hij hetzelfde blijft. Dus dat is waarschijnlijk ook gewoon een goed idee. Ja. Maar waar je kunt zeggen: "Wacht even, is het niet handiger dat Gemini 3 Pro in dit geval al puzzelend leert, die leerlessen meteen onthoudt. Die gaan niet terug in de basemdel, maar die blijven er tussenin hangen in dat Superman pak zeg maar. en eigenlijk al puzzelend steeds slimmer aan het worden is. Eh en dat is dan nu eigenlijk de truc hè, dat dat wat ze dan eh recurring learning noemen is dat ze recurring learning tijdens je testtime computer. Ja. Dus je hebt een loop, een cirkel waarin je draait. Ja. Je doet een puzzel, je krijgt terug fout, maar je hebt ook gezorgd dat je prompt ervoor zorgt dat je niet alleen maar fout terugkrijgt, maar ook weet wat je fout gedaan hebt. Dan verzin je een nieuwe hypothese als model. Probeer het nog een keer, want je mag het best wel vaak proberen. Sterker nog, je probeert het met 100 tegelijk en je gaat ook nog met elkaar communiceren over wat je geleerd hebt. Dan heb je ook nog een eh democratische stemronde, wat eigenlijk inhoudt democratische stemronde van modellen. Ja. Dus je Gemini 3 Pro draait zeg maar multi, dus met meerdere hoofdjes tegelijk naast elkaar die lessen met elkaar delen. Kopieën van Gemini 3. Ja. Allemaal agents zou je ze kunnen noemen. Oké. Die gaan daarna in in conclaaf van oké luister het is niemand gelukt om die puzzel op te lossen. Maar wat hebben we eigenlijk allemaal geleerd? zo zullen we een nieuwe hypothese maken en het dan weer proberen en dan op een gegeven moment brood force je als het ware die puzzel. Maar je hebt maar een maximaal aantal pogingen volgens Ark. Dus je moet ook nog heel slim inplannen. Ja. Eigenlijk in je eerste poging wil je gebruiken even een ehm hoe zeg je dat? Een eh iets toe te geven op in deze podcast. Ik zit nu toch niet meer op eh op school. Ik deed dit een beetje op mijn eigen een beetje suffet manier. Mijn mijn trucje was mijn scaffold hoe ik dat inrichtte was ik ging naar de toets zonder te leren en ik deed altijd de herkansing zodat ik alvast wist wat er gevraagd werd ongeveer. Dus het was ik bedoel de herkansing is nooit dezelfde toets hè. Laat dat duidelijk zijn. Als het goed is soms wel. Nee, ik ik val stil omdat ik eh dat ik de d is een opzienbarend moment. Nou ja, het punt is dat ik jij ging zonder te leren naar de eerste toets. Ja. Dan weet je alvast wat de gevraagd word ongeveer ongeveer weet al hoe dit ongeveer gaat. Ja. En dan doe je ging je dat uit je hoofd leren of dan dacht je een beetje oh ze ze pakken het zo aan. Nee, ik wilde vooral weten niet eh wat er gevraagd met maar hoe er gevraagd werd. Zo moet ik het zeggen. En je hebt dus op Arc AGI om even de brug te maken waarom ik dit vertel. Op Arc AGI heb je twee pogingen. Jij bent een soort eh dieselgate. Ja. Jij optimaliseerde je je leren voor de test. Ja. Nee, maar dit heb ik ook. Ik heb ook heel vaak gezegd over in de basis eh een student die goed is, een student die goede eh cijfers haalt, zou in essentie eh kan je vooral van zeggen dat ze goed zijn in de toets maken. Ja. Ja. Eh dus en bij mij deed ik was heel vaak wel benieuwd van oké, ik kan nu de hele het hele boek uit mijn hoofd gaan leren, maar ik kan beter even kijken waarop ze gaan prikken. Ja. Nou, dat doet eigenlijk deze deze eh poetic scaffold ook, want die doet een eerste poging, een goede poging. Juist, maakt het generaliseerbaarder. Ja. En dan leert hij van de eerste poging en daarmee doet hij de tweede poging en niet alleen maar met meerdere tegelijk. Nou, ondertussen is de volgende test van of de volgende versie van deze test dus alweer in ontwikkeling. En dat blijkt dus ook nodig te zijn met deze eh vooruitgang van deze zes eh ex Deep Mind mensen. Ehm de volgende test zal waarschijnlijk gaan niet meer over staatiepuzzels, maar interactieve game omgevingen. AI agents moeten daarin waarnemen, beslissen en handelen over meerdere stappen zonder voorafgaande de puzzel gaat veranderen terwijl je ermee bezig bent, hè. in plaats van dat hij op je zou de arc kunnen uitprinten als het ware. Ja, nu kan je hem nog uitprinten, maar straks wordt het een game waar je puzzel in moet doen. Ja, dat zijn interactive reasoning benchmarks. Jezus Christus. Eh ze testen een breder scale aan vaardigheden, exploratie, planning, geheugen en doelen begrijpen. Ik begin wel op het moment te komen dat ik denk: "Why would we care?" Nou, oké. Dat dat is wel een hele belangrijke omdat in het hele leuk die nerds met hun puzzels, maar nou in het hele eh brede debat rondom AI en wat is dit nou eigenlijk? Zijn taalmodellen een vorm van intelligentie? Eh en zo ja, kan dat dan doorschalen naar iets wat dan lijkt op wat wij doen? Op zo'n manier? Ja. dat 95% van het kenniswerk eh vervangen kan worden door agents. Om het Hoe help het doen van een spelletje daarbij? Nou, dat nu ehm de scepty en dat is allemaal eh de Gary Marcuses van deze wereld voor de mensen die dat interessant vinden om te lezen, die claimen leuke truc die taalmodellen, leuke truc het voorspellen van pixels en video's en alles. Maar dat heeft gewoon weinig te doen met wat wij als mensen kunnen. Nog even los van wat wij als mensen zijn, hè. Dat is een hele filosofische discussie. Maar vooral dat schaalt niet naar een niveau. Je kunt niet zeggen met wat trucjes en wat tweakjes en wat super hero pakken. Kunnen wij van een GPT een een tekstvoorspeller en een beetje beeld voorspellen komen tot iets wat 95% van het kenniswerk gaat doen. Als dat even de definitie van AGI is. Om daar wel te komen moeten we terug naar de drawing board. We moeten een hele nieuwe vormen van AI gaan uitvinden. Wat ik vorige week zei eh omdat ik die optie openhou is wat op het moment dat je een soort hè ik had het toen over zo'n compound ei hè, dus dat een insect heeft 1000 een oog wat bestaat uit 1000 stukjes. Zijn het niet straks 1000 AI'tjes die met elkaar samenwerken in een soort team en wordt dat team dan a? H nou eigenlijk zou je kunnen zeggen dat wat Poetic doet dat die groep mensen die bij Deepmind vandaan komt die zegt het team van AJI's Ja of van AI bedoel ik. Ja, die ja, die eigenlijk zegt ja eh inderdaad één band member, een soloartiest is niet genoeg. En eigenlijk want ja, maar eigenlijk als ik je goed begrijp zegt Carry Marcus dus als één van de eh sceptici zegt: "Menselijk kenniswerk is zo ingewikkeld, een AI model gaat dat nooit in zijn eentje kunnen." En dan zeg jij zelfs als dat waar is, doet het er niet toe. Want een ensemble zou het kunnen dat het er niet toe doet, want een ensemble van AI scoort elke keer weer beter op tests. En dat zijn nu gewoon testjes ehm waar je nog misschien om kan lachen, maar als het straks testjes zijn die wel heel erg lijken op wat wij doen als wij werk doen, dan is het niet zo grappig meer. Nou, ik denk dat het belangrijk is ja, precies wat jij zegt. Belangrijk is dat ensemble verhaal, dus het combineren van verschillende in een soort knowledge of the crowds, hè. Dus je zegt de groep weet meer dan het individu is één van de stapjes van poetic. Ja, ze hebben meer ideeën. Die hebben ze ook ze hebben een deel open source gemaakt zodat ze zeiden voor andere partijen ga je hier eens naar kijken. Want we denken dat we wat fundamentele dingen hebben uitgevonden. Een deel ze zijn ook vis funded dus houden wat dingen geheim. Ja. En we even voor jouw punt waarom is het ehm eh gaan we Waarom gaan we het hier nog veel meer over hebben in de toekomst? Wat Poetic nu zegt is ten eerste het Superman pak wat we hebben gemaakt kan je om alle modellen heen doen. En dat is waar. Ze hebben niet alleen maar Arc AGI 2 getest met eh Gemini 3 Pro. Die kwam er als best uit, hè. Dus Gemini 3 Pro plus Superman pak van Poetic heeft nu die hoge score gehaald. Ze hebben ook alle scores gepubliceerd voor andere modellen. Die zijn ook allemaal hoger dan het model alleen. Exact. Niet een pakje voor Gemini. Dat is al supervet. Allein dat is gaaf, want dat is generaliseerbaar. Het woord generaliseerbaar is waar we het komende jaar over gaan hebben. Is het generaliseerbaar? Ten tweede hebben ze gezegd eh aankondiging op hun blog. Ik ben heel benieuwd. We hebben niet alleen maar Arc2 geprobeerd met dit harnas. We zijn alle andere benchmarks ook aan het afgaan. Dus verwacht de komende maanden enorm Nou ja, we hebben een hele lijst van eh de Humanity's Last Exam bijvoorbeeld, hè. De hele hele belangrijke benchmark wordt dan Humanity's Last Exam genoemd, hè. Dus ons laatste examen. Heel dramatisch. Nieuwe, maar ja, maar goed. Nee, maar ik bedoel [gelach] ook daar komt dan waarschijnlijk weer een versie 2 en versie 3 van. Kijk, hier zit maar bijvoorbeeld ook voor programmeren. Absoluut. Juist. En ju en dan wordt het wezenlijk. Ja, want wat ik nu zelf kijk, ik zie poetic. Ik zie het wel als een soort poetic moment dat ik denk: "Oké, wauw, wat zij nu bewezen hebben, mogelijk, zeer mogelijk, h is dat er nog ontzettend veel te halen is." Ja. Zonder dat je de base models hoeft aan te passen, zonder die al die GPU cycles bij het trainen van het basism. Ja, je gaat de GPU cycles gebruiken bij het testen, hè. Dat bedoel op een andere plek, maar dan nog. Ja, juist. En het laat mij zien dat, kijk, uiteindelijk eh jouw smartphone, jouw computer, jouw tablet, die apparaten zijn ook een hele lage constructie. Daarmee bedoel ik er zit een computer CPU in. die kan eigenlijk alleen maar ene en nullen optellen en eh vermenigvuldigen. Dat is een gewoon een basis eh eh math processor plus nog wat dingen eromheen. Daaroverheen is allemaal software gebouwd op dat basisprincipe van eigenlijk zeg je eigenlijk tegen die processor: "Luister, als jij gewoon heel goed bent in dat manipuleren, je hoeft niet te weten wat het is, maar als jij gewoon heel goed bent in datamanipulatie, dan gaan wij daar abstractielagen overheen bouwen waardoor daar uiteindelijk een computergame op gaat draaien." Op CPU niveau heb je daar helemaal geen zicht op. Dat is alleen maar het heen en weer gaan van nullen en enen. Maar uiteindelijk is de eindgebruiker een computerspel aan het spelen. Mijn punt is dat de modellen zoals Gemini waarschijnlijk de rol zullen gaan vervullen van een fundamentele schakel in zo'n AGI ensembleachtige scaffold. Dus er gaan lagen over de GPT's en de Geminis van deze wereld heen gebouwd worden. Niet door de Googles van deze wereld, maar door andere partijen die eigenlijk als brein, een deel van het brein, eh die modellen gebruiken, maar de rest komt door alle laagjes eroverheen. En dat is een andere architectuur. En daardoor wat mij betreft de discussie LM's of Geminis kunnen niet a worden. Dan zou ik zeggen oké fair. Dan kan je terug naar de tekentafel of zeggen ze worden onderdeel van een samenwerking tussen allerlei laagjes. Ja, ondertussen komen er nog steeds basismodellen uit, zoals dus 5.2 van eh ja, JGBT zou je kunnen zeggen. Wat eh ik zei in het begin, jij bent hier kritisch over. Waarom ben je hier eigenlijk kritisch over? Nou, ik vind in de Dit gaat waarschijnlijk gebeuren deze week of is al gebeurd als je nu luistert. De eh open hij speelt een beetje paniekvoetbal op dit moment. Zo voelt het voor mij. Eh dus je hebt als jij een roadmap roadmap hebt waarop je bepaalt wat je het komende jaar gaat doen of het komende half jaar en je past die roadmap aan aan de hand van wat je concurrenten doen. Een paar weken hè, laten we wel wezen. Ja. Nou ja, goed. De ehm ik ben kritisch omdat ik ja, dit is ik zit nog in het voorgeval en dat sluit hier ook op aan. Wij, het is een beetje een ingewikkeld ding aan het worden omdat wat GPT5 was ook al een deel Superman pak is. Het is ook al een model plus dingen eromheen. En dan kunnen wij zeggen hoeveel van het pak zit inmiddels in het model versus weet je, het doet er uiteindelijk even niet toe. Het komt erop neer dat er eh het steeds moeilijker aan het worden is om een soort van eenvoudig zonder allerlei eh metaforen en moeilijke lage modellen van eh processors enzo erbij te halen te praten over wie heeft nou de beste AI. Die vraag is legitiem, die kan je ook stellen, maar dan vraag je eigenlijk wie heeft de beste modellen plus models carefolding in de beste UI waardoor een eindgebruiker denkt: "Ik wil Gemini gebruiken in de App Store." Hè? En dat doet die eindgebruiker er ook niet toe. Die heeft gewoon vragen en die heeft gewoon puzzels hè met de hoofdletter P en die moeten opgelost worden. Puzzels in PowerPoint Excel. En ik denk wel dat ehm wat om toch nog even op GPT 5.2 te komen waar Open en jij nu mee zit is dat ze eigenlijk in die scaffold om die modellen heen allerlei trucjes aan het doen zijn hè. Kiezen voor denken of niet denken. Eh eh de tone of voice heel erg aan het aanpassen zijn. Kies maar je eigen Ton Voice. Het voelt allemaal best wel. Ik kreeg vanochtend een pop-up in chat GPT die zei: "Hoe wil je eigenlijk dat we tegen je praten?" Dat ik dacht: "Ja, ik heb dit bij Gemini nooit hoeven zeggen en dat gaat prima." Eh als ik het voelde voor mij dat ik een beetje dacht: "Hebben jullie het nog een beetje onder controle of of ben je een beetje heen en weer aan het springen?" Ja, en dit is niet helemaal mijn mening, want ik heb ook veel Dit zijn de vibes. Ik lees ook veel van mensen die zeggen: "Het voelt alsof eh binnen open en jij en dit kan met een maand anders zijn als eh als een als een ander team wat scherper zet hoor. Dus eh wie weet eh verandert de koers nog." maar heel snel hebben gebouwd, iedereen voor wilde blijven, daardoor alle trucjes uit de kast hebben gepakt om er maar overheen te bouwen. Om maar overheen te bouwen. Eh dan maar vlucht weer de systeempt aanpassen, want dit ging mis. Dan maar een router ervoor, want denken gaat mis. Maar uiteindelijk zijn dat niet soort dieper als je als je dat is niet een een soort duurzame eh strategie. Ja. waar Gemini vanaf de grond opnieuw is opgebouwd, zie jij in Open AIGPT vooral een soort van eh met duct tape aan elkaar getaped onderdelen. Ja, ik zit al een tijdje in software. Ja, daar word je boos van. Wat kunnen ze nu doen om jou positief te verbazen bij 5.2? Ehm niet zoveel zo te horen. Nou, ik bedoel kijk als als de 5.2 eh soort de rommelopruime release is, hè. Dus we zijn een beetje te hard gegaan bij vi en vi 5.1 was ook al een beetje een rommel opruimen. Ja. Van we beginnen er beter door te krijgen wat we eigenlijk hebben gemaakt met vijf nu die in de wereld is en mensen er ook kritisch over zijn. 5.2 lost een lijst van 20 problemen op. Het gaat mij uit dan niet zozeer om benchmarks Hm hm. Maar vooral om merk ik zelf dat ik weer terug ga grijpen naar chat GPT. Dat is wel mijn eigen benchmark. Ik wissel een beetje tussen die modellen aan de hand van wat ze voor me kunnen doen, wat hoe ze mijn problemen kunnen oplossen of eh dromen kunnen waarmaken zeg maar. En ik merk dat ik mijn als eindgebruiker begin te voelen met mijn technische achtergrond dat ik bij Open AI zoiets heb. Ik mis focus en die focus die mist in het diepst van het bedrijf voel ik in het eindproduct. Namelijk jullie zijn pleisteres aan het plakken overal op. En het kan prima zo zijn dat er nu een team GPT 5.5 of 6 naastloopt waartegen gezegd is: "Ik geef jullie even een paar maanden de tijd. Ruim het op en breng alsjeblieft iets uit wat niet doorbouwt op de rommel die we hiervoor hebben gemaakt." Hè, zo werkt het vaak een beetje binnen software bedrijven. Ja. En dan het oplossen. Eh maar ik vind gewoon de eh die 5.2 en de beetje de de media daaromheen voelt heel erg als een vrij eh rommelige eh paniekvoetballer reactieve eh actie zeg maar. Oké. Maar ik wou ik ik wil nog wel even terugkomen op eh wat er bij wat er bij poetic gebeurt, want jij hebt het over welke trucjes zit het er allemaal in? Eh misschien toch nog even goed om te benadrukken dat dit precies eh de kritiek die eh Col heeft op ehm alle eerdere modellen is dat ze niet kunnen leren terwijl ze aan het puzzelen zijn. En wat Poetic gebouwd heeft is precies wat Col zegt dat erin moet zitten. Kan je leren terwijl jij antwoord aan het geven bent. En ik denk dat eh we misschien gedacht hadden dat dat in de basismodellen gezet moest worden, maar dat kan blijkbaar prima in het Superman pak gestopt worden. Ja. Ja. Wat zomaar eens een fundamentele stap zou kunnen zijn in hoe we over een jaar ehm over AI praten. Dat het zelflerend wordt. Nou ja, precies. En in dat opzicht zou je kunnen zeggen een laag erop. Ja. Ja. als precies in een andere laag dat we moeten naar een andere laag gaan kijken. En je zou kunnen zeggen ik ben dus heel benieuwd of we de komende maanden allerlei benchmarks gaan krijgen waar ineens weer 10 of 15% op het eh grafiekje erbij komt. Puur en alleen maar doordat ze dat Superman pak hebben aangetrokken. Ja, je kan af en toe het idee krijgen soort van hoe snel gaat het nou eigenlijk allemaal? Maar dit is echt een prima manier om te kijken hoe [&nbsp;__&nbsp;] snel het gaat. de snelheid waarmee ze nieuwe test moeten maken. Goed, weten, we komen weer terug naar aarde, [muziek] want iedere week testen we een tool eh die je kan gebruiken in je leven of in je werk. En deze week is dat Tasklin. Je komt 's ochtends op kantoor en je inbox bevat al een overzicht van het belangrijkste nieuws uit jouw vakgebied. Je agendaafspraken zijn automatisch voorzien van achtergrondinformatie over de mensen die je spreekt. En die wekelijkse statusupdate die je normaal naar je team stuurt, die is al verstuurd zonder dat je het vroeg. Deze week testen we Tasklet. Dat is een platform waarmee je dit soort AI agents maakt in gewone mensentaal. Je hoeft niet te programmeren of met blokjes te slepen. Je bouwt gewoon eh of je beschrijft eigenlijk gewoon in het Nederlands wat je wil en dan probeert die AIRS te regelen. Het belangrijkste wat dat ding doet is verbindingen maken met die MCP's waar we het eer eerder over hadden. Dus hij kan op met groot gemak kan hij allerlei tooltjes aan elkaar koppelen. Je hoeft niets meer te vragen dan eh maak inderdaad die ehm eh maak een overzicht van het belangrijkste nieuws in mijn vakgebied. En dan begrijpt dat ding dat hij jou moet mailen en dat hij daarvoor een Gmail connectie moet hebben. Ik noem maar een voorbeeld. En dan is dus één keer vragen verbind met Gmail genoeg om die koppeling te maken. Dat is verder helemaal geen technisch werk wat je daarvoor hoeft te doen. Onze redacteur Shank test het met die dagelijkse AI news briefing. Dus een briefing over jouw vakgebied in ons geval AI. En binnen 2 minuten stond alles. Zit niet gewoon concurrentie voor onze eigen nieuwsbriefiets. Heel heftig. schema, e-mailadres, bronnen en de volgende dag lag er een keurig gestructureerd overzicht in haar eh inbox opgedeeld in categorieën als doorbraken, investeringen en beleid. Het mooie is, je kan dit instellen door gewoon te chatten met die agent om dingen aan te passen. Dus die eerste briefing die zij kreeg bevatte bijvoorbeeld geen linkjes. Je wilde dat wel. En alle volgende e-mails werden vervolgens automatisch eh werkende links gestuurd. De kanttekening is dat task niet goedkoop is eh en gratis eh gebruik beperkt is. Je loopt wel best wel snel tegen grenzen aan. Betaalde abonnementen beginnen bij $35 per maand. Dus het is niet goedkoop. Maar als je dagelijks handmatige informatie bij elkaar sporkelt of onderzoek doet dat eigenlijk best voorspelbaar is qua stappen, dan verdient het zich misschien wel terug. Eh als je wil weten hoe je alles uit die tool haalt, dan kun je onze nieuwsbrief checken via Airport.nl. Ik las nog een grappig ding witsen. Namelijk dat AI datacenters steeds meer industriële capaciteit opslokken. Dat zien we al een tijdje bij Bitcoin Miners. Dat is inmiddels een matig bedrijfsmodel geworden eh om geld te verdienen met Bitcoin koersen. Kijk maar naar de aandelenkoersen van die eh Bitcoin mining bedrijven. Maar zij hebben één ding wat al die AI bedrijven graag willen en dat is betrouwbare stroomaansluitingen. Want voor Bitcoin mining moet je heel veel stroom uitgeven en datzelfde geldt voor AI bedrijven. En op dit moment is die stroom zo schaars dat AI bedrijven gretig eh Bitcoin eh miners aan het opkopen zijn. En dat zegt iets over hoe de economie nu werkt. namelijk dat er heel veel onderdelen van de industrie in de brede zin van het woord eigenlijk hun werk nu aanpassen om meer energie voor iedrijven te leveren. En dat gaat best ver, want zelfs boem, dat is een bedrijf wat een supers sonisch passagiervliegtuig wil maken, eigenlijk een beetje de opvolger van de Concorde. Gaat gasturbines van 42 MW verkopen aan datacentra. Dus die parkeren hun werk in het maken van supersonische vliegtuigen omdat zij ontdekten dat hun straalmotoren waarmee zij dus eh die vliegtuigen laten vliegen ook stroom kunnen opwerken. Dat vliegtuigproject gaat weliswaar door, maar dit gaat dan volgens het verhaal cruciale cashflow leveren om sneller superzonisch vliegtuig te maken. Het zijn letterlijk jet engines hè, dus in containers in die dan naast de datacenters geplaatst worden waar kerosine ingaat aan één kant dan heel voor herri en dan klappen daar allemaal kilowas uit aan de andere kant. Ik denk dat de mensen die debatteren rondom vliegschaamte en hi schaamte nu makkelijker uit kunnen leggen hoe vliegschaamte gekoppeld is aan schaamte op het moment dat letterlijk de motoren uit vliegtuigen op de grond liggen naast datacenters. Daar liggen te blazen om elektriciteit op te wekken. Dit is dus niet een metafoor. Dit is letterlijk wat boem met hun eh boem super. Maar jij zegt dit met enig cynisme als ik goed als ik het goed begrijp. Ehm ja, vliegtuigmotoren op de grond gaan leggen naast datacenters waar je kerosine in doet en dan blaast aan allemaal CO2 uit. Word ik natuurlijk niet vrolijk van. Nee. Nou ja, liever dit dan kolencentrales toch? Eh ja, ik ken daar de berekening niet van. Ik zou zeggen zet het allemaal. lijkt me iets beter voor het milieu. Zet het allemaal bij stuwmeren zou ik zeggen. Ja, ga niet hard genoeg hè. Ja, goed. Waarom zo snel? Econom crowding out. Wanneer één sector zoveel kapitaal op opslokt dat andere projecten in de snel in de knel komen. En dat is hier dus aan het gebeuren. Even door de economische bril bekeken. Elektriciteit, arbeid en dus industriële capaciteit. In dit geval dus van het maken van vliegtuigen naar stroomgasturbines maken voor datacentra. Alles stroomt richting AI. Het is het soms dan zou ik willen dat ik soort van even een jaartje of tw jaar vooruit kijken dat dat ik zo 5 seconden in de toekomst kan zijn maar één vraag kan stellen. Namelijk is de bubbel al gebarsten? Dat ik nam alleen maar ja of nee kan horen. Dat ik weet waar ik aan toe ben. Nou ja en ik zou dan nog om even de genische pad op te zetten hebben we er al wat aan. Want ik bedoel op heel veel punten in mijn leven vogt het best wel toe hè, de verschillende AI tooling. Maar ik kan me eh samenlevingsbreed wel voorstellen. Kijk, het is Mensen denken dat duurt wel lang allemaal. Nou, en ik moet zeggen dat die eh Kijk, als jij als er letterlijk een eh een jet engine eh 200 me van jouw achtertuin ligt te blazen omdat daar een datacenter is waarin blijkbaar eh Sora 2 videos gemaakt moet worden. Ik maak hem even heel concreet nu hè. Dus jij zit in je achtertuin. Je kinderen zijn verslaafd geraakt aan synthetische content. Die zitten te tiktoker terwijl je op de achtergrond een herri hoort en dan vraagt: "Wat is dat?" Dat is om die filmpjes te maken die met de straalmotor. Om de filmpjes te maken op de telefoon van je kinderen. Ja. Oké. Ik z maak even de cirkel rond. Ehm als dat het als dat het enige AI verhaal is, dan dan vind ik de podcast maken wel moeilijker. Ja, dat is niet het enige AI verhaal hè. Dat kan je zeggen: "Ja, Wiets, dat hou jij jezelf voor." Nee, dat is niet het enige AI verhaal. Maar de verhouding moet wel een beetje blijven kloppen tussen jet engine slop versus eh doorbraak op een medisch veld en eh nou noem het allemaal maar op. Ja, doe mij maar doorbraken medisch bij Steelmeren en niet Jet Engines voor Sora 2 AI TikTok lop. Oké. Nou, punt gemaakt. Eh deze week eh tenslotte maakte ik een grappig dingetje mee met een research tool van Entropic die een week online heeft staat en nu alweer offline is. Oh, waarom? Ik zeg er maar, ik zeg het er maar gelijk bij voordat je het wil proberen. Weet je waarom die offline is? Het was een test. Waarschijnlijk gaan ze hem nog wel online zetten, maar het was een test. Wat Anthropic de hele tijd doet is allemaal onderzoek de wereld inbrengen. Zij zijn best wel scheutig met het delen van ook wel gevoelige eh resultaten van hun testen, testen die over veiligheid gaan, maar ook over impact op onze economie. En zij wilden naast dat ze natuurlijk allerlei onderzoek kunnen doen uit het gebruik van hun AI tooling om de impact te meten op verschillende sectoren. Zij kunnen platgezegd gewoon zien hoeveel wordt clot met Excel gebruikt. Nou, dan kunnen we daar wat meer op gaan optimaliseren. Willen ze ook kwalitatief onderzoek doen. Namelijk mensen vragen naar hun gevoelens bij hoe zij AI gebruiken en hoe ze Cloud gebruiken en hoe AI past in hun leven. wat ze positief eraan vinden, wat ze negatief eraan vinden. En zo'n eh onderzoeksproject op schaal doen is natuurlijk eh ja, arbeidsintensief. Je moet mensen gaan bellen en dan moet je ze vragen om iets eh te vertellen en dan schrijf je dat allemaal op en dan moet je dat weer gaan analyseren. En nou ja, je je weet dat het veel tijd kost. Antropic heeft dat geprobeerd voor zichzelf makkelijker te maken door een tool te maken, een chatbot te maken waarmee je dat gesprek kan voeren. Dus een chatbot die vraagt: "Wat vind je van de rol van AI in je werk?" Waar ze snel achter kwamen is dat als je dat met een standaard chatbot doet, dat mensen niet echt graag antwoord geven op die vragen, want het is gewoon best wel saai om met een chatbot te vragen te praten die alleen maar vragen stelt. En eh ja, het is gewoon niet motiverend voor mensen. Ze kwamen erachter: "Dit gebruiken mensen in de praktijk niet." En dan kunnen we ons doel niet bereiken, want dan kunnen we niet genoeg onderzoek doen. Dus toen dachten ze: "Wat maakt nou dat mensen graag praten met eh iemand anders over dit soort ja, abstracte en emotionele ideeën bij hun werk?" Nou, een plek bijvoorbeeld waar dat goed werkt is als jij naar een conferentie toe gaat en je vindt iemand uit jouw vakgebied die je niet kent, maar die wel uit jouw vakgebied is en die ongeleer ongeveer hetzelfde eh kennisniveau heeft als jij h waarmee je op hoog niveau kan praten over je werk, dan zijn mensen een stuk meer geneigd om te gaan babbelen. En dit is geprobeerd dit is wat ze geprobeerd hebben te emuleren in een research project. Een inhoudelijk gesprek. Een inhoudelijk gesprek. niveau van op jouw niveau. Je wordt ontmoet op jouw niveau niveel. Je wordt ontmoet op jouw niveau door een chatbot. Wat een heel ander type gesprek is dan hoe een chatbot normaal tegen je praat. Namelijk je stelt een vraag en je krijgt een antwoord. Dit ding is er niet op uit om eh soort van resolution te bieden. Dit ding is erop uit om het gesprek gaande te houden. En wat was dit voor je? Ik bedoel, ik heb het nooit gezien. Hoe zag dit er in die week uit dan? Wel een chat interess. Ja, het ziet er gewoon uit als clot op het web, maar dan net een beetje anders. En dat ding praat tegen jou in plaats van dat jij dat ding activeert. De rollen zijn ja, de rollen zijn omgedraaid. En dat ding stelt dus een aantal vragen. En ik was hier eh ja, ik dacht van tevor ik dacht van tevoren: "Oké, het staat een week online, dus ik ga het wel proberen, maar ik verwacht er niet al te veel van." Maar ik viel dus best wel in verbazing over dat ik best wel een leuke avond heb [gelach] gehad met dit ding. Maar kan help me even, want ik heb hier dus niks van gezien, dus ik ga het allemaal even aan jou moeten vragen. Je opent dit, je opent met een vraag en die gaat proberen zo snel mogelijk jou te ontmoeten, want die weet nog niet wie je bent, toch? Precies. Ja, hij zegt gewoon: "Hoe gebruik jij AI in je werk?" Of de eerste vraag was volgens mij: "Wat is het laatste keer dat je AI in je werk hebt gebruikt?" Dus ik een beetje babbelen. Dan vraagt hij dus nou dus hij zei al nou dit ga ik gebruik ik soort van je antwoord ga ik gebruiken om eh om te leren. En eh hoe meer tij me geeft, hoe beter. Ik als je computer zo'n spraakfunctie heeft, dan zal ik die zeker nu even gebruiken. Zoiets stond er ook bij. Het was best grappig. Het was zoals een mens inderdaad. Heb je dat gedaan ook spraak of? Nee, ik heb het allemaal typend, want er waren meer mensen in de kamer. En je zat met elkaar een kerstfilm te kijken. Het was toch ongemakkelijk. Ik ga hier verder niet op in. In ieder geval ik zat leuk te kletsen met mijn chatbosvriend en dat ding vroeg ik dus wanneer heb je voor het laatst uitgebraakt? Nou, ik heb daar een beetje antwoord op geven en toen begon hij wat meer details uit te vragen. Maar het was de manier waarop hij de details uitvroeg dat ik bleef praten en hoe meer ik blijf praten, hoe leuker dat gesprek werd. En ik merkte dus dat ik best wel serieus antwoord aan het geven was omdat ik dacht: "Ja, dit ding begrijpt mij. Dat gevoel gaf het." Het werd echt alleen maar beter. En toen was het klaar. Hij was ook de hele tijd aan het hinten naar nou laatste vraag eh vertel praat vooral verder als je zin in hebt. Maar hij was het soort van aan het Ik vind dat dus op congres altijd heel chill als mensen die je niet kent bijkomen en zeggen: "Ik heb één ik heb één vraag." Eigenlijk geven ze je daarmee toestemming om het gesprek ieder moment te onderbreken is gewoon best wel prettig. Hoe dan ook. Dat ding deed dat bij mij. En eh toen merkte ik dus dat ik zei: "Ja, maar ik eh ik zei: "Ik had eerlijk gezegd verwacht dat ik ook nog wel wat zou leren van jou." Dus ik had een gesprek gehad. Ik had verteld, Hij vroeg waar ik me het meest zorgen over maakte met gewoon AI in de brede zin van het woord. Hij heeft heel veel gehaald bij jou in dat interview eigenlijk, want is een interviewtechniek. Maar jij voelde je ook een beetje? Ja, ik dacht wel ik Ja, dus dat zei ik letterlijk. Ik zei: "Ik heb jou net verteld wat ik eng vind aan de wereld." Namelijk ik denk dat ik zelf best wel flexibel ben en ook ondernemend ben en het idee heb dat ik snel kan omschakelen en dat ik ook technisch wel veel snap. Dus dat ik sneller dan andere mensen me kan aanpassen aan deze revolutie. Dus voor mezelf maak ik me niet zoveel zorgen, maar dat kan niet iedereen. Dat was een beetje mijn punt van waar ben je bang voor? Toen zei: "Nou, dankjewel. Eh heb je nog vragen?" Toen zei ik: "Nou, eerlijk gezegd, ik hoopte van dit ding ook wel wat van jou te leren, zeg maar. Ja, dat vind ik heel goed dat je dat zegt en eh dat kan ik ook heel goed begrijpen. Nou, hier zijn drie redenen waarom jouw manier van denken wat je daar wel tegenover kan zetten. En toen toen verschenen dus die drie blokjes tekst op mijn scherm. En ik heb echt even 5 seconden naar het scherm zitten staren. Zo van [&nbsp;__&nbsp;] Het hij kwam echt met eh ik snap wat je zegt over dat je denkt dat je je snel kan aanpassen, maar als we iets hebben gezien met eerdere technische revoluties, dan is het heel onvoorspelbaar waar hoe mensen zich aanpassen, waarom mensen zich aanpassen en hoe dat precies gaat. Hij zei eigenlijk, er was een soort zinnetje bij waarin die zonder het zo te zeggen, maar dat zat er wel onder, dat hij eigenlijk zei: "Het is beet, het zit tikie uit de hoogte hoe jij redeneert over dat jij hoe slim jij zelf denkt met AI in technologische verandering te zijn versus andere mensen. Want dat is niet hoe dit dat is niet hoeffusie werkt dat je eh je flexibel kan opstellen per se." Zij was de hele tijd een soort van combinatie van spelde prikjes aan het leveren waardoor ik het nog meer serieus ging nemen en eh gewoon vet goede inhoudelijke repliek dat ik echt even zat wat wat gebeurt hier en wat is waarom voelt dit zo het ik kan niet anders het beschrijven dan vibes. Waarom voelt dit zo anders dan met een gewone chatbot praten? Precies. En ik ben dus heel erg gefascineerd. Ik ga toch even die verbinding maken weer met het puntje hiervoor van poetic is heeft ehm kijk ik ben inmiddels van de school prompte is software schrijven en daarmee bedoel ik niet je kunt met AI software maken. Nee, de prompt die jij levert is als een stuk software. En eh net als dat als jij eh als er een nieuw Nintendo spel uitkomt, dan kan jouw Nintendo Switch een heel ander apparaat voelen omdat het software makers gelukt is op precies dezelfde console. Niemand heeft iets aan hoeven passen aan jouw Switch. Zulke slimme programmeercode dat jij ineens Mario Kart aan het spelen bent. Precies dezelfde Switch. Het bestond nog niet daarvoor en niks aangepast aan je Switch. Als jij de prompt ziet als Mario Kart, namelijk alsof je een spelletje in de AI stopt en die hele AI verandert ineens in wat anders. Dus dan hebben we het niet meer over ja, prompt is wel chill, want dan kan je een klein beetje sturen. Hm hm. Je kunt nieuwe AI maken met prompt. heeft dan hieropic eh is was dit eh cloud 4.6? Heb jij eigenlijk al met een beter model zitten praten? Kan hè? Was dit Cloud 4.5 Opus met een fantastisch zieke scaffold? Dus stiekem een combinatie van agents. Jij praatte met zeven AI's tegelijk zonder dat je het door hebt die aan het gokken waren op de achtergrond wie antwoord mocht geven. Of was het enkel en alleen een prompt? Was het alleen maar een system prompt? En dan hè als ik terugkom op promware schrijven zou het kunnen dat je zonder een ander model, zonder een superman pak gewoon door een mega goede prompt eh dat hebt kunnen doen. Nou en en potentieel dus zelfs al is het het eerste namelijk gewoon of het laatste bedoel ik gewoon een simpel prompt dan zeg maar dit de dit was zo'n belangrijke ervaring voor mij want niet alleen praatte ik voor het eerst eigenlijk met een taalmodel best wel een moment ik praatte voor het eerst met een taalmodel waarbij ik aan het chatten was doorhad ik ben dit aan het doen. Ik ben zo iemand nu die met een AI aan het chat is, zoals al die gekkies die verliefd worden op hun AI. Ehm dit ben ik nu aan het doen. Ik ben er de bewust van en het is toch alsnog heel erg leuk. En tweede dacht ik: "Jeetje, maar dit is natuurlijk hoe onderzoek gaat werken. Dit is de telefonische enquête on steroids. En dit is de weet je, ieder iedere werkgever wil de hele tijd feedback van zijn van zijn personeel eh over of iemand eh nog tevreden is in in het werk of iedere krant wil weten of ze nog betrouwbaar gevonden worden door de lezers." En dit stiekem gebeurt het natuurlijk de hele tijd. En ik dacht: "Ja, dit is hoe het gaat zijn. Dit is dit motiveert mij om jou de waarheid te vertellen over hoe ik echt denk in plaats van hoe tot nu toe dingen gaan. Namelijk eigenlijk praat met eigenlijk hoe marketzoek nu wordt gedaan is natuurlijk dat je praat met een soort robotachtig mens. Namelijk iemand die een vragenlijst afwerkt. Helemaal niet leuk. Terwijl hier praten we met een mensachtige robot en het is veel leuker. Ik ben veel eerlijker. Nou ja, dat en ik denk dat misschien nog een eh een laatste om het eh eh Trek jij eens een strik omheen? Nou, ik had ook nog wel een grappig moment. Ik ga het proberen kort te houden, maar ik was met Walter Living aan het praten. Walter Living was voorheen, je bent op zoek naar een huis, typ even typ ja de website. Typ je adres in of de de link van de Funda advertentie van je woning. Ja. En je krijgt een gaaf, mooi uitziend PDF rapport met daarin wat een goe goed bedrag is om te bieden, dingen waar je op moet letten. Best wel tof. Dat doen ze al een paar een paar jaar. Het is een soort dienst die jou helpt om een aankoopmakelaar die jou helpt met informatieverzameling. Ja. En dan draai je heel tijd gewoon lekker rapportjes uit van allerlei woningen die je interessant vindt en dan doen ze wat informatie bij Ja. Ja. of de prijs eigenlijk goed is wat je onderhandelruimte zijn. Ja. Dan kijken ze natuurlijk ook in het kadaster wat er allemaal verkocht is in de laatste maanden om een beetje Ja, je ziet hem voor je. Maar die hebben nu een beetje geforceerd vind ik hè, mochten jullie luisteren een beetje geforceerd een chatbot toegevoegd en ik dacht me laat me gewoon die PDF's maken, man. Ik ben ik ben 39. Ik wil gewoon PDF's. Ik wil niet met een chatbot praten. Maar op een gegeven moment werd hij zo in mijn neus geduwd dat ik dacht, want ik denk dat ding is matig. Dat kan niet goed zijn, zeg maar. Dat ik dacht: "Oké, weet je wat?" Want het knopje met eh download je PDF werd op een gegeven moment weggehaald. Dus ik moest dan aan die chat vragen: "Geef me die PDF." En toen raakte ik in gesprek en toen merkte ik: "Oeh, oh, dit is echt niet alleen maar even een system prompt. Hier zitten allerlei MCP's achter die met Funda en het kadaster kunnen praten. Oeh, dit hebben ze nice gedaan." Dus ik zei op een gegeven moment: "Oké, deze woning daar en daar help me out." Dat zei ik gewoon gewoon. En dat ding. Oké, ik ben nu dat aan het uitlezen op de achter. Je ziet ook helemaal mooi visueel wat hij allemaal aan het doen is. Het is gewoon een een grounded agent die op de achtergrond al die data kan ophalen. Revante data kan ophalen. Je bent in gesprek met chat GPT die wel alle koppelingen heeft die je eigenlijk wil dat hij nodig heeft om dit eigenlijk zoals het kadaster wat nu gewoon niet kan met chatg. Nee, precies. En of je moet Nee, dat kan niet en anders zou je heel veel moeten betalen en dat gaat zit daar natuurlijk allemaal mooi in. En toen begon hij zo'n beetje te praten. Zei hij van oké ik heb het thuis gezien. Ja, ik vind wel die prijs die nu op Funda staat is echt een lokkertjesprijs. Dus ik zou een beetje opletten en toen dacht ik [&nbsp;__&nbsp;] weet [gelach] ik zo lokkertjesprijs. Ja, dit en dat en eh dus ik zei: "Oké, maar kan weet je dan ook huizen waar je van zegt dat die prijs wat eerlijker is?" Ja hoor, ik zal even in omgeving zoeken. En ik ik was dus ik werd een beetje gegrepen en ik daarom ik kom hierop omdat ik uit jouw verhaal ook haal dat je eigenlijk weet wat de gogelaar doet hè. We zitten hier zo te lang al en te diep in jij en ik dat je het eigenlijk al bijna niet meer kan zien hè. Je ziet de technologie teveel, maar te weinig nog wat er aan de achterkant of aan de voorkant gebeurt. En jij bent eigenlijk in jouw gesprek met cloud research in een soort interview terechtgekomen wat jou een beetje gegrepen heeft. En er kwam zelfs best wel feedback uit naar jouzelf toe dat je dacht: "Jeetje, wat is dit nou?" En ik zat dus een beetje met die eh Walter Living bot te praten en ik merkte van dit is nieuw. Ja. En dit is ook best wel best wel nice zeg maar van als eh die combinatie van data, gewoon goede data waar zij natuurlijk dealtjes voor gemaakt hebben plus een prompt die daarbij bedacht is waar zij heel goed van begrijpen hoe hoe dit systeem eigenlijk gebruikt wordt. Eh werd was voelde voor mij wel als we hebben een beetje de we zitten nu nog in heel erg in ik wil AI binnen mijn website hè. Ik ben ik ben een klant. Ik wil AI zet maar een bolletje in de hoek dan kan je praten met de website. Vind ik een beetje makkelijk. Daar dat is nog de meeste AI die ik nu zie. Naar de volgende stap is op maatgemaakte echt tailored zeg maar mooi op maat gemaakte interacties die voor mij als eindgebruiker voelen: "Oh, dit heb ik nu eigenlijk liever nog dan die PDF." Ja, eigenlijk was die PDF altijd een soort matig middel middenpunt. Nou, en de de wat we wat we nu waarschijnlijk gaan zien is dat je dus allemaal AI ervaringen hebt die ingebouwd zijn in tooling die je al gebruikt, zoals in dit geval deze huizenzoeksite die qua databronnen gewoon helemaal geoptimaliseerd zijn voor het concrete probleem wat jij hebt. En ik moet ik ik denk dit ook vaak over wat ik zou willen van uitgevers, dus van een krantabonnement. Nu is het zo dat als je een abonnement hebt op de volkskrant krijg je er ook het parool en weet ik veel trouw en al die kranten bij. Dat hoort dan bij abonnement. Maar het zijn allemaal losse silo's die eigenlijk een interface hebben die geoptimaliseerd is voor het nieuws van vandaag. Dus dat is wat de krant is. Dit is het nieuws van vandaag. En er zat wel een zoekbalk bij, maar dan kun je bij één krant zoeken en je kan ja, het is een soort van random ranking en dan moet ik losse artikelen in om data op te halen. Terwijl ik zou eigenlijk wat ik nu vraag aan chat, namelijk leg mij eens uit hoe het nou eigenlijk zit met die stikstofcrisis, dan krijg ik eigenlijk een antwoord gebaseerd op gratis journalistiek. Terwijl wat ik wil is dat dat ding de archieven van de volkskrant en van de trouw en dan zelf bedenkt: "Nou, hier pak ik die primeur van de trouw of die hebben hier iemand gesproken, een wetenschapper die eh precies iets zegt wat tegengesteld is en wat dit in dit artikel in de Voxant gezegd wordt. dat dat die eigenlijk de de het de tekst die onder water beschikbaar is voor in dit geval DPG, maar dat kunnen ook andere uitgevers zijn, dat de bron wordt van de kennis die ik vraag. En daar wil ik ook best voor betalen, eerlijk gezegd. Zoals ik voor water living ook betaal of zoals je voor water living ook betaalt als je een huis gaat zoeken, precies. wil ik dit eigenlijk ook voor mijn kijk research is een veel te zwaar woord. Ik heb gewoon soms vragen over het leven waarvan ik denk de noem het de desk research. Ik bedoel, je zit een beetje op je bureau door wat ding heen. Nee, maar zit het is ook gewoon het is ook help me met kiezen of help me met jij wilt gewoon dat hij ook even door kwalitatieve informatie als bron kunnen gebruiken. Ook de consumentenbond er gewoon bij kan pakken. Precies. Precies. Ik heb er zo'n zin in. Ja. En dan en dan is het misschien uiteindelijk hè als het dan lukt binnen dat consortium van MCP wat dan nu blijkbaar een protocol is geworden onder eh ster gaat nu omheen gooien. Klar zit ook iets van authenticatie in. Wil je niet gewoon uiteindelijk kunnen zeggen: "Ik heb een abonnement op de consumentenbond. Ik betaal voor de volkskrant. Ik wil ook nog wel betalen voor het volkhands archiefabonnement. Laat mij nou laat nou mijn AI MCB calls doen naar die en ik ik heb daar gewoon abonnement op. En weet je wat? Desnoods zijn het zeven micransactions. Tel ze maar op. Ik klik op Molly en ik betaal €17. Bedrijf moeten maken om per artikel te betalen. Top. We danken Sam Hengeveld voor de edit. Pankra voor de vormgeving. Als je een lezing wil van Neer Hagen of van mij dan kan dat. Mailans op lezing@arreport. Wil je tips en [muziek] trucs krijgen om AI te gebruiken, het nieuws te krijgen twee weeken per week en recensies van de beste AI tools, dan abonneer je op onze nieuwsbriefje Airport. En wil je vandaag beginnen met AI binnen jouw bedrijf, dan ga je naar deagency.com/aai report, dan helpen zij je verder. Dank voor [muziek] het luisteren en tot volgende week. Tot volgende week. [muziek]

---

## Notes


## Key Takeaways
-

## Related
-
