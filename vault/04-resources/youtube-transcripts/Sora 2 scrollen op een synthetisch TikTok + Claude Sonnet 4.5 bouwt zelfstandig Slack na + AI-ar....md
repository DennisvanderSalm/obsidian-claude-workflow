# Sora 2: scrollen op een synthetisch TikTok + Claude Sonnet 4.5 bouwt zelfstandig Slack na + AI-ar...

**Source:** [YouTube](https://www.youtube.com/watch?v=YULg4vMdULo)
**Video ID:** YULg4vMdULo
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie, waar we uitzoeken welke invloed AI heeft op ons werk, ons leven en de samenleving. Tegenover mij zit Wiets Hagen en ik ben Alexander Clubing. Deze week heeft Open AI Sora 2 gelanceerd en het verschil met de vorige versie is verbijsterend. Voor het eerst begrijpt een AI videomodel hoe de zwaartekracht werkt bijvoorbeeld. En Tropic kom met clots on het 4.5, een model dat 30 uur aan één stuk kan doorwerken zonder menselijke tussenkomst. En het bouwde bijvoorbeeld een complete kopie van slack in één ruk door. En we duiken in een experimentele functie die laat zien waar AI ontwikkeling naartoe gaat. Imagine with clot waarbij software zichzelf schrijft terwijl je het gebruikt. Er is heel veel om over te praten deze week. Heel veel plezier. [Muziek] [Applaus] [Muziek] Wie wat een week Open heeft dit jaar zijn rekenkracht al negen keer zo groot gemaakt, heb ik gelezen. En dat is nog maar het begin. Uit interne slebericht van Sam Alman blijkt dat opening tegen 2033 zijn capaciteit nog eens met een factor 125 wil vergroten. Dat zou het energieverbruik trouwens ook boven dat van heel India uiten. Een land met 1.4 miljard inwoners. En Nvidia blijft ondertussen steeds efficiëntere chips maken. Dus die 125 meer capaciteit komt op de praktijk wel uit op veel meer dan dat misschien. En dan roept dat de vraag op: "Waarom denken zij dat ze zoveel rekenkracht nodig hebben?" Nou, deze week eh kwam eh iets bijzonders uit, namelijk Sora 2, de opvolger van hun AI videoel. Anderhalf jaar geleden liet Opener ons voor het eerst kennismaken met ja, het eerste videomodel wat zo echt leek dat we een beetje begonnen te twijfelen aan eh ja, wanneer is iets echt en wanneer is iets nep. Er waren nog wel wat probleempjes, want in die eerste versie van Sora klopte de fysica vooral voor geen meter. Basketballen bleven in de lucht zweven als je prompte dat er een basketbal gegooid moest worden. Of mensen die liepen door muren of watergolven die halverwege omhoog keren. Maar juist dat soort dingen zijn in Sora 2 gefixt. Voor het eerst lijkt die AI te begrijpen hoe de werkelijkheid daadwerkelijk werkt. Dus als je een basketbal shot mist, dan kaatst de bal nu realistisch terug van het boord. in plaats van dat hij spontaan naar de basket teleporteert. Dat was nog wel eens iets wat gebeurde in de eerste versie van Sora. Het model genereert nu ook gesynchroniseerd geluid bij de beelden zoals we dat kennen van VO3 van Google. Dialogen worden, kun je horen. Omgevingsgeluiden, geluidseffecten zijn allemaal te horen. En het kan complexe bewegingen zoals eh gymnastiek trucs of schaatsprongen nabootsen zonder dat opeens je ernaar zit te kijken en denken: "Dit is duidelijk, AI, dit is fake." Open heeft vergelijkt de oorspronkelijke Sora met GPT1. Dat was een beetje het eerste bewijs dat de technologie zou werken. Eh dus dat voor chatgept voor de helderheid eh gewoon een eerste proefversie. En Sora 2 zou dan in vergelijking het GPT 3,5 moment zijn. Dat is de technologie die achter ChatPT zat en in het begin. En dat is dus het punt waarop de technologie echt bruikbaar werd. En bij Open AI ging ChatPT natuurlijk toen pas echt eh toen ging het allemaal echt heel hard opeens. Wij vonden destijds Sora 1 zo gestoord dat we een noord noodflevering over opname wietsen. Ehm en nu we filmpje na filmpje bekijken van Sora 2. We hebben het hier nu niet over gehad buiten de opname, maar de rillingen lopen redelijk over mijn lijf. Eh de meest populaire video die nu in de Sora app circuleert is Sam Oldtman die betrapt wordt met bewakingscamera als hij grafische kaarten probeert te stelen uit een winkel. En dan roept hij tegen de camera: "Alsjeblieft, ik heb dit echt nodig voor inference." Dat vond ik heel grappig. Jij hebt de wiets, jij hebt ongeteld heel veel video's gezien. Wat wat vind je van de sprong die gemaakt is? Nou, ik vind het wat ik eigenlijk niet had aanzien komen is de soort eh drietrapsraket. Want in essentie is het Sora 2 het videomodel hè, daar gaan we het zo over hebben. Dan de Sora app in de App Store, in ieder geval in de US. En daarmee dus ook het Sora Social Network wat nu gemaakt is. Dus in essentie heeft Open eigenlijk een nieuw videomodel aangekocht eh aangekondigd. Daarnaast een app aangekondigd in de App Store en daarnaast de ambitie om dan ook een soort TikTok netwerk op te gaan zetten. Dus ik denk dat we ze ik bedoel alle drie op een bepaalde manier moeten bespreken omdat ja wat bedoel je precies met Sora is een beetje een ingewikkeldere geworden. Maar laten we bij het model beginnen. Laten we bij het model beginnen. Wat wat is hier opgevallen? Nou, wat eh wat je al zei hè, de er is een soort sprong gemaakt van zes vingers eh Will Smith spaghetti zeg maar hè. Dus iedereen wijst dan steeds naar video en beelden die door eigen gegenereerd zijn en zegt dan kijk je ziet dit een zesde vinger of kijk eh die die paal gaat ineens door de muur heen of stuit het weer terug de verkeerde kant op. En dat geeft dat zijn de standaard giveaways van dit is een generated eh video of een generated afbeelding en schijnbaar zitten die partijen daar bovenop en hebben die een soort checklist gemaakt van oké dat zijn dus blijkbaar de giveaways waar we aan moeten werken. Dan komt Sora 2 uit en dan demoen ze ook allemaal scenario's die vroeger misgingen. Vooral gymnastiek omdat je dan eigenlijk de hele fysiek van de mens spiergroepen nou ja, op een bepaalde manier de fysica moet begrijpen. Doe nu airquotes. Het is het is gescoord. even iets zo makkelijk. Maar ja, wat er eigenlijk allemaal in dat model moet zitten om dat allemaal maar goed te gokken is bizar. Eh en dat stelt ook de vraag: worden deze modellen nu niet steeds ehm meer geschikt om in veel bredere domeinen in te zetten? bijvoorbeeld fluer dynamics wanneer je een auto ontwerpt of hoe je de onderkant van een schip moet ontwerpen of eh veiligheidstest doen met auto's in video's voordat je de automodellen daadwerkelijk tegen de muur aanrijdt. Ik moet zeggen, je kan je je kan zo'n videomodel zien als gewoon vermaak en zo kondig ik het net ook een beetje aan, maar je kunt ook je heel goed voorstellen hoe zo'n model gebruikt kan worden voor veel serieuzere simulaties. Ja, je zou ik bedoel eh VO3 eh en eh Sora 2 zijn op hun manier reality simulators, hè, realiteitssimulatoren in de breedste zin dat we ze ooit hebben gezien. En eh dit soort simulaties waren er al heel erg in expert settings voor schepen hè om crash test te doen. En iedereen had daar zijn eigen software en zijn eigen modellen waar ze jaren aan gewerkt hebben, miljoenen geïnvesteerd. En deze modellen doordat we ze vragen om het volgende beeld te voorspellen in een video, moeten daarvoor zoveel weten tussen aanradingstekens dat ze stiekem eigenlijk gewoon geschikt worden voor veel meer domeinen dan alleen maar social media waar ze nu eigenlijk voor heb je een idee van hoe ze dit gedaan hebben ten opzichte van de eerste versie van Sora? Is hier iets fundamenteel anders gegaan of is het gewoon er meer energie tegenaan? Oh, dit wat sowieso opvalt bij deze hele eh release van zeg maar de hele drietrapsraket Sora eh is best wel brutaal. Wat bedoel ik daarmee? Eh ik gebruik dat woord niet zomaar. Ik zit op het puntje van mijn stoel nu. Zou Almen denk ik ook. Nou ja, op een aantal manieren brutaal vind ik. Omdat je als jij nu vraagt doen mij Super Mario eh die in Super Mario rondrent en daarna uit een billboard springt New York inrent en dan op auto's gaat springen, dan komt daar een perfecte Super Mario uit. Als jij Disney copyright vraagt, komen daar allerlei. Dus brutaal als in de eerste Sora werd nog op alle manieren gezorgd dat er niets in terecht kwam wat ook maar leek op toen kregen we op bestaand intellectueel eigendom. Ja, exact. Ja. En eh toen kregen we daarna eh het beeldmodel die Giebli kon doen. Dat was ook toch wel brutaal. Ja, is mijn mening, maar ik vond het vrij brutaal dat ze zeiden: "Wil je Gibli doen?" Oh, dan gaan we Gibly ook echt doen. Ja, je hebt het nu over het plaatjesgenator in Chatb iedereen foto's ging namaken in Studio Gibbly stijle. Dat is natuurlijk een ja, een bekende stijl. Daarom is het leuk om te doen. En over het algemeen eh tot nu toe eh kwam die stijl alleen maar uit dat ene Japanse bedrijf. Die hadden het alleenrecht daarop. En opeens is dat ge ziel de ziel van zo'n eh van zo'n maker eigenlijk. En dat vind ik dan persoonlijk brutaal. Dat vond ik dus al een brutale actie. Maar dat je zag dat met het beeldmodel, voor de duidelijkheid destijds met eh de Gibbly is dat het enorm werkt. Werkt voor viralit, werkt voor aandacht. Ja. Als er als er een herkenning met merken die in het echte leven voorkomen zijn, dan is het dan gaat het beeld viraler. Ja. Ja. Interessant. En nu lijkt het nou lijkt het dat is volgens mij gewoon zo is dat er gezegd is jongens wat daar toen gebeurde ons giebli moment dat gaan we nu nog een keer doen maar dan voor video en we kijken wel wie er ons aanklaagt en wie er gaat klagen. En je kan eigenlijk alle IP zeg maar dus dat intellectueel eigendom van al die studio's nu maken. En eh waarom zodat het dus ook die virale kwaliteit krijgt. Ja, ik snap wel waarom je het woord brutaal gebruikt, want het is dus ze hadden die beveiliging redelijk op orde en hebben hem gewoon waarschijnlijk nou ja, hoogstwaarschijnlijk expres eraf gesloopt om om en dan normaal terwijl er een spotlight op alles ligt wat met intellectueel eigendomsending te maken heeft. Als het gaat over AI dan is dit inderdaad wel een gedurfde keuze. Ja. En ik wat ik merk, want ik ben veel interviews gaan lezen met mensen van buiten open jij in Open en jij om een beetje een soort eh ja vibe check te doen van hoe word hoe landt dat nu dan? in de andere laps die vooral zeggen zo: "Dit is brutaal, want dit zouden wij nooit doen." En ja, nu krijgen ze wel allemaal aandacht, maar er is ook een soort smet op de industrie. Hm. Want is dat dan is open jij de hele AI industrie? Voor sommige wel. Ehm wat ik ook heel erg interessant vond is blijkbaar is het zo dat in de system card, dat is de soort saaie PDF in tijd New Roman, die vaak wordt gereleased naast de model, hè. Dus als eh Antropic een nieuw model uitbrengt of Open AI of noem ze allemaal maar op, Deep Seek. Dan zit daar vaak een research paper bij en dan kan je een beetje meelezen: "Joh, wat hebben we uitgevonden? Wat is hier nieuw aan? Eh waar moet je op letten?" Niet alles staat erin, want dan geef je het weg aan je concurrenten, maar het is vaak iets heel interessants om te lezen. Wat staat er in de system kaart van eh Sora 2? Is dat er eigenlijk gezegd is binnen openi, omdat er zoveel mensen binnen open waren die hier vraagtekens bij hadden. Dat intellectueel eigendom aspect. Onder andere eigenlijk de hele drietrapsraket Sora. Dus het feit wat het kan maken, waar het voor gebruikt kan worden, dat het al in een app gestopt wordt en dat er een TikTok gebouwd wordt, een synthetische TikTok door open en jij. Alles wat ik nu zeg is zojuist gebeurd, hè. Dus niet toep. over die laatste ding gaan we het zo hebben. Zeker, zeker. En dat ze daar eigenlijk in hebben gezegd omdat er zoveel mensen waren binnen jij die dus vraagtekens hebben bij één van deze of al deze stappen. De brutaliteit op stap A of de brutaliteit op stap C of de risico's. Dus misschien moet ik dat woord gebruiken op SAPC voor de samenleving. Dat mocht het zo zijn na evaluatie over 6 maanden dat deze applicatie en dit platform eigenlijk eh meer slecht doet dan goed, dan zijn ze bereid om de app terug te trekken uit de store. Nou, als deze, ik bedoel, jij kijkt dan met een vrij cynisch gezicht naar mij, daar heb je gelijk in denk ik. Maar het feit dat deze zin daarin gezet moest worden, dat betekent volgens mij, en ik nu ben ik, het is allemaal al redelijk complotterig, maar ik wil ik ga nog wat aannames doen. Ik heb het idee dat Sam Altman het heel erg prettig vindt als er heel veel aandacht is, viraliteit en cloud rondom eh Open AI en hun apps. Hij vindt het heel ongemakkelijk, heb ik het idee, dat het podium gestolen wordt door andere partijen. Dus als Google of Anropic iets uitbrengt, zijn ze binnen van 48 uur staan ze klaar met een compleet geprept eh pressverhaal. Ehm en dat er voorheen al een best een groep mensen binnen weg is gegaan. Hij is een tijdje ontslagen geweest. Ik denk met de reden dat hij andere belangen heeft en andere wensen heeft voor wat open is qua product company dan veel van de researchers die daar werkten en dat er nu nog een groep over is daar die alsnog hebben gezegd: "Als wij ons eigen synthetische sociaal netwerk gaan bouwen op basis van een model waar je mee nagenoeg de realiteit kan simuleren, wil ik wel dat we de mogelijkheid hebben om dat weer terug te trekken de wereld uit. Zoveel zorgen maken wij ons als onderzoekers over dit drietraapstraak." Nou, laten we dan maar eens even uitwerken hoe die dat sociale netwerk eruit ziet. Inderdaad, Open Open AI heeft dus een eigen sociale netwerk geïntroduceerd, ik zeg er gelijk bij in de Verenigde Staten en Canada en alleen maar op uitnodigingsbasis. Dus we gaan nu over iets praten waar je in de praktijk niet bij kan. Maar toch even. Het is een iOS app die verdacht veel lijkt op TikTok. Een feed met allerlei short video's, maar ook met profielpagina's, volgers en zelfs DM's. En alle video's die in die feit te zien zijn gegenereerd. En de hoe ze het een beetje voorstellen is dat je ehm dat ze één ding een beetje anders doen dan TikTok. Namelijk dat iedere video die je ziet kun je meteen remixen. Dus als je een ander ziet die een video heeft gemaakt die jij grappig vindt eigenlijk dus een video geprompt heeft. Want zo maak je video's. Je prompt ehm wat je ongeveer wil gaan zien en dan maakt dat ding dat. dan kun je dat hergebruiken. En omdat er een cameofunctie in zit, kun je ook nog eens je eigen eh gezicht erin gebruiken. Dus hoe dat werkt is dat je eenmalige korte videoopname van jezelf kan invoegen in dus iedere scène die je tegenkomt in die eh in die feed. En dan kun je je gezicht, je stem en je manier van bewegen laten oppikken door dat algoritme. Vervolgens, of ik zeg algoritme, dat is het natuurlijk niet. Het is een een door die app. Vervolgens kan je het laten verschijnen op de manier die jij net hebt gezien. Dus het is alsof je een video ziet, een TikTok video die je grappig vindt waar naar iemand randoms in te zien is. En dan kun je zeggen: "Oké, dit maar dan nu met mijn gezicht en mijn stem." En die video kun je dan vervolgens weer delen. Opening medewerkers hebben hier overduidelijk de grootste lol mee. Eh Sam Oldman heeft zijn eigen gezicht helemaal vrijgegeven voor iedereen. Dus er is een lawine aan allerlei deep fakes van Sam Altman die hele rare dingen doet. En eh ja, dat is dus eigenlijk nu vrijgesteld. Ehm dat geldt niet voor als jij je eigen gezicht uploadt, dan kunt alleen jij eh kiezen wie jouw gezicht mag gebruiken. Dus dat zou ook kunnen betekenen dat je bijvoorbeeld alleen jouw vrienden jouw gezicht mogen gebruiken. Dat kun je instellen. Openheid benadrukt dat ze niet dezelfde valkuilen willen nou veroorzaken als andere sociale platforms. Een beetje ehm wat jij net zei Wietsen. Die feed is zoals Openerij zegt niet geoptimaliseerd voor maximale schermtijd. Oftewel een algoritme wat je heel erg verslaafd maakt, maar om inspiratie op te doen voor je eigen creaties. Dit hoe ze het pitchen. En ze hebben ook gelijk limieten voor tieners ingebouwd over de hoeveelheid video's die ze per dag kunnen kijken. En ouders kunnen via chatpt gelijk allerlei instellingen beheren. Dus laten we zeggen dat ze wel leren. Of dat in de praktijk werkt moeten we nog maar zien. Maar het is in ieder geval een poging om dit te doen. Dit is natuurlijk heel interessant, want eh er zijn heel veel dingen hier om uit te pakken, maar het feit dat Open AI zijn eigen AI TikTok lanceert is eh echt een flinke stap meer dan dat ze hadden hoeven doen. Namelijk gewoon een videogeneratie appje maken. Dan hadden mensen het ook leuk gevonden. Maar dit is zo het voelt als zo'n koepoging eh in een controversiële sector, namelijk de social media sector. En eh ja, het voelt ook een beetje als de Moet ook weer denken aan eh was dat Ping of zoiets van Apple. Die heeft dat ook geprobeerd. Apple heeft ooit ooit een sociaal netwerk in iTunes proberen te bouwen. Dat heette ping. Heb je nog nooit gebruikt. Nee, dat bestond een soort ping maar dan ping. In ieder geval de aantal dingen die ik wel interessant vind is wij hebben jij en ik en dit is niet een soort van kijk ons nou een school zijn ding. Eh wat ik hiermee bedoel is jij en ik hebben het hierover gehad. Wij voelden dit een beetje aankomen. Wij voelden niet aankomen dat open en jij dit ging doen. Ik niet in ieder geval. Maar met dit bedoel je de opkomst van video's? Ja, synthetische TikTok. Wij wij nou ja, je zou natuurlijk waarschuwen kunnen noemen of in ieder geval wijzen mensen er al een tijd op van joh, reken erop dat er een grote kans is dat een x% van jouw video feeds gaat bestaan uit synthetische content hè. En ik moet zeggen dat eh dit effect heeft science fiction ook. Daar zal vast een naam voor zijn. Het effect dat science fiction heeft. Dus science fiction films eh waarin allerlei eh ruimteschepen zitten, black mirror waarin eh drones zitten, et cetera, heeft het effect ergens al op voorbereid bent terwijl het er nog niet is. En als het er dan komt dat je een soort van minder onder de indruk bent, omdat je denkt ergens diep van binnen, dit was er toch al. Ik heb het idee dat ons onze psyche, ons brein niet zo heel goed snapt wat er al was in de film en wat er al was in het echt. J ik merk dus nu bij mezelf, dat heb ik dus vanochtend echt even gedaan, dan ging ik op de bank zitten, dacht ik even ademhalen. Er is nu een 100% AI gedreven synthetische TikTok concurrent gelanceerd door Open J zonder blikken of blozen. Ik wil er toch even bij stilstaan, want nou een beetje blozen als je zegt ik als als het te populair wordt, haal hem weer uit de App Store. Dat dat is blozen. Bl. Maar hoe hoe zit jij erin? zeg maar jij eh Sora werd eh gelanceerd 48 uur geleden voor mijn gevoel 36. Hoe zit jij er nu bij zeg maar? Wat is jouw reactie hierop toen je dat las van het is ook een app, ook een platform? Nou ja, hoe het tot mij komt is Twitter, want dat is natuurlijk een beetje raar nu. We zitten nu over een platform te gebruiken wat wij zelf niet kunnen gebruiken. Dus hoe het tot je komt zijn mensen die video's exporteren en dan zie je het in andere eh social media. Dus dit is wel echt een andere ervaring. Dus die Sora app die open je met het idee dat je alleen maar naar AI gegenereerde video's zit te kijken. En ik kijk diezelfde video's nu op andere algoritmische platforms die niet alleen bestaan uit AI gegenereerde video's, maar ook uit de echte wereld. En wat echt spacend is, is dat je dus naar allerlei video's zit te kijken. Ik Sam Altman heeft dus zijn gezicht zeg maar vrij beschikbaar gemaakt voor iedereen die filmpje van hem wil maken. En dat is dus echt je ziet de gekste voorbij komen. Sam Altman die een soort huilend vlog aan het opnemen is over eh dat hij dat hij te weinig ehm computerkracht heeft. dat hij een door een deurbellcamera bij Nvidia waarin die aan het dreigen is dat als hij geen chips krijgt dat eh hem huilend bij een doodskist waar VO3 op staat, het is echt het meest wegrennend bij een datacenter dat alles uitgezegd moet worden, want er zitten een hoorde mensen achter hem aan. Bizar. Echt hele gekke Echt hele gekke Maar dat wordt gewoon afgewisseld met dezelfde soort video's van Zelenski die daadwerkelijk een serieus verhaal aan het houden is over dat ze aan de voorwaard aan de voorwaarde hebben voldan om toe te treden tot de Europese Unie. En het is zo'n mindfuck dat die twee door die laatste is dus echt en dat gaat dwars door elkaar in diezelfde el Musk feed als de video's die gegenereerd zijn. Ik vind dat zo'n mindfuck en je bent de hele tijd je hoofd aan het herkalibreren. Is dit echt? Ik kan mensen echt aanraden eh wat ik laatst heb gedaan is een Spotify playlist gemaakt met doelbewust om en om hè. Dus muziek waar ik van weet AI generated afgewisseld met muziek waar ik van weet dat het echt is. En dan gewoon een middag lang die playlist luisteren. Het doet iets met je. Het is vaag. Want je hebt een soort van synthetische modus als mens. Dat je toch denkt: "Ik ben hier naar iets anders aan het kijken." Waardoor je anders er naar kijkt. Maar door die door mekaar heen te mixen zeg maar ga je op een gegeven moment het veel moeilijker vinden. En ga je naar iets echts kijken met een blik van synthetisch en naar synthetisch kijken met een blik van echt. Ik moet zeggen dat bij mij puur subjectief wat er eigenlijk gebeurt is dat alles nep wordt. Hm hm. Dat vind ik eigenlijk een beetje ja beangstigend is een beetje zwaar. gaat aan alles twijfelen. Ja, eigenlijk wordt alles minder echt en dat die soort van vreemde afstand tot en met alles wat er op een scherm gebeurt, daar kunnen daar zullen wij niet de enige in zijn. Ja, het is ook wat wat mij ook elke keer te binnen schiet is allemaal prima dat dingen heel realistisch lijken. En op é of andere manier deel ik die conclusie wel van ja dat als je genoeg science fiction hebt gelezen of je bent genoeg in een glaas bol aan het staren zoals we de hele dag aan het doen zijn. Dat je er dat je er wel vanuit gaat dat video op een bepaald moment niet van echt te onderscheiden is. En dat moment nu heel dichtbij of misschien zijn we er gewoon. Maar uiteindelijk valt of staat de mate waarin je er naar gaat kijken bij hoe vermakelijk het is ehm of in in hoeverre het een emotie oproept. En eigenlijk schik ik daar het meest van. De mate waarin het erin slaagt om mij te vermaken met rare Sam Oldman video's. En dit is weet je gemaakt voor ons als doelgroep. Twee nerds van middelbare leeftijd die niks beters te doen hebben dan op Twitter te gaan kijken naar z video's. Jouw woorden vriend. Maar dit geldt natuurlijk voor, kijk, nu is dit zo voor Sam Oldman, maar in in Nederland breekt het nu nog niet zo door. Maar dit gaat natuurlijk gebeuren met Dik Schoof en dit gaat gebeuren met eh als het op tijd komt voor onze verkiezingen eh nog dat er dat er genoeg accounts beschikbaar komen voor Nederlanders, dan ga je dus allerlei ja, video's van Geert Wilders of van eh Caroline of van wie dan ook eh zien, positief of negatief. Ehm ehm waarbij eh nou waarschijnlijk positief, want ze moeten natuurlijk zelf een filmpje in eh in ja, als we er vanuit gaan dat we Sora gebruiken, dan is het als het goed is allemaal met consent gegaan. Want ik wilde nog even toevoegen aan jouw verhaal net. Als je dus jezelf wil laten inlezen in die app, te bizar. Je laat eigenlijk is een digital twinning vorm van visual cloning. Dan moet je een soort getallenreeks oplezen alsof je een bank app installeert. Ja, precies. Waarom doen ze dat? en om jou te klonen en om je consent te veriferen in één. Precies. Zodat zodat niet eh Rob Jette de video's van Geert Wilders kan maken, maar Geert Wilders wel video's van Geert Wilders kan maken en en dat kan gaan delen. En het is natuurlijk ja, het feit dat je jezelf nu zijn budgetten voor verkiezingsvideo's zijn gewoon heel laag. Het soort van partijen werken met heel weinig geld om video's te maken. En daarom eh gaan er ook helemaal niet zo heel veel video's rond in in Nederland tijdens de verkiezingen. In Amerika veel meer, want er is veel meer geld beschikbaar. Dus dan zijn er veel meer video's die viable gaan, die met politiek te maken hebben. Maar maar op het moment dat die kosten lager worden, kun je er ook op rekenen dat iedereen dat vervolgens gaat gebruiken om je campagne boodschapkracht bij te zetten door er een heel grappige video van te maken of juist heel erg emotieopwekkende video van te maken. En ja, gaan we dat deze verkiezing nog meemaken? Dat is wat er door mijn hoofd poookt. Maar ja, dat is ook heel erg korte termijn, want dit gaat natuurlijk over ja, dit zeg maar dit is hetzelfde ding wat jij zegt over dat intellectueel eigendom. gaat ook over de mensen die je kent. Video's kijken van mensen die je kent is een stuk leuker dan video's kijken met mensen die je niet kent en die wel heel knap gemaakt zijn, maar vervolgens niet resoneren. Er moet iets van een verbinding zijn met ja, meer dan de realiteit. Het moet ook nog gaan over de concepten in de realiteit, de de merken, de mensen waar we emotionele binding mee hebben. En dat is nu wel heel ja, dat ligt nu in het in het in het voorland waardoor ik denk dat de impact, de culturele impact veel groter gaat zijn deze keer dan dat het met Sora 1 was. Daar daar waren wij nerds gewoon de hele tijd soort van: "Oh, wat knap allemaal." Eh en nu kun je kunnen we dat alsnog doen over dat ze de fysica beter doen, maar de echte truc zit hem, realiseer ik me nu ik dit gesprek met jou voer, zit hem in de culturele relevantie die het heeft. Ja, absoluut. En ik denk ook dat het meerdere aspecten heeft, hè, want je hebt het daar eh ik wil mensen toch even die wat later inschakelen op onze podcast. Ik bedoel niet vandaag in deze aflevering. Zit niet bij BNR. Hoi, bent u net Wacht even. Schakelt net over van Slam FM naar dit. Ik moet een soort van hele vreemde dingen doen tijdens deze podcast, zodat we de randomness hebben die synthetische shows nog niet hebben. Ja, oké. Dat is wat hier gebeurt. We glitchen even deze show bewust van authenticiteit. Nou, we zijn er weer bij. Ja, mocht je nou eh later naar deze afleveringen zijn gaan luisteren, wij hebben al een heel filosofisch eh aspect bekeken over synthetische content, autit, blablabla. Ik wil er toch even op teruggrijpen. Ik ga het even recyclen, want ik vind het wel heel erg relevant met wat er nu gebeurt. Kijk, Pixar films, volledig 3D gegenereerde films met karakters erin die niet bestaan, die je nooit kan ontmoeten. Ja, in plastic bij Disney, maar daar blijft het erbij. Mario leeft niet. Eh en de hele getekende eh van Gibbly tot en met de Disney Studio's en DreamWorks cartoons waren al fake. Er zijn kinderen en ik ook als volwassenen die huilen om tekenfilms en huilen om Toy Story. Volledig synthetische content. Je zou nog kunnen zeggen de stemacteurs waren echt. Nou als die dat dan allemaal brachten met hun stem daar twijfel ik over of dat de magic was wat het echt maakte. Dus ik denk, kunnen wij als mens geentertained worden, geraakt worden op een op een dieper niveau door content die in essentie bestaat uit totale verzonnen entiteiten die niet leven? Ja, dat doen we al. Wil ik even zeggen zeg maar dit maakt dat nog groter. Ehm dus zou het ons niet moeten verbazen dat wij eh geentertained worden op zijn minst en mogelijk geraakt worden op een dieper level door synthetische content. Volledig 100% synthetische content. Daarnaast en dat is de gok die ze eigenlijk maken nu bij Open en jij met hun product Sora eh de app, het platform is dat ze zeggen: "Nou, die synthetische content is grappig, maar het is veel interessanter om jou vast te houden. Ook al willen ze je e niet, zeggen ze hè, in een eh algorithmic feed. Als het je vrienden zijn, als het mensen zijn die je kent, als je niet een video kijkt van een random guy die met een rolstoel met ballonnen eraan over een grens heen vliegt, maar Alexander Clupping en die ken jij. Hm hm. En eh dat dus de mix van hoogwaardig. Dat woord is bijna het verkeerde woord, want dat is ik bedoel hoogwaardigheid. Hoe een milkshake hoogwaardig is. Namelijk de hyper eh verslavende kwaliteit van deze media gecombineerd met hyperpersoonlijke touch. Dat die twee soort mega cocktail maken eh die on onweerstaanbaar is voor velen van ons. Want ik denk dat dat hoor ik ook een beetje in jouw verhaal van ik schrik ervan. Ik leg even het woorden in je mond. Ik schrik ervan hoe leuk ik het vind. Ja. En dan is nog de vraag: is dit leuk door novelty? Is het zo tof? Omdat het kan, hè? Zit er een soort nerd in jou die denkt: "Wauw, dit blijft leuk." Nee, nee, dit blijft leuk. Want het gaat natuurlijk aan de actualiteit gekoppeld worden. Het gaat aan eh de waan van de dag gekoppeld worden. En het gaat ehm onderwerpen die eh die in het nieuws zijn of die leven onder mensen eh een nieuwe impuls geven omdat er een grapje over gemaakt wordt of omdat er een uitvergroot als een politieke cartoon eh of als een ja een parodie of als een weet je wat gewoon voorbeelden uit cultuur die mensen triggeren die die in talkshows dan getoond worden tijdens een gesprek over politiek omdat het een grappig grappig dingetje is dat wat zegt over de sfeer in het land. Ja, dit ik denk dat dit zo groot onderdeel gaat zijn van hoe wij ehm kijken naar het nieuws. Deze gek genoeg deze ja, het is het is echt een medium voor mensen die goed zijn in verhalen vertellen. En ik denk wel dat dat ook nog de beperkende factor is. Want je moet jezelf wel, dit kan allemaal heel realistisch zijn, maar je bent zelf zit je nog echt wel letterlijk aan de knoppen om te bedenken wat dat waar dat ding mee komt. Dus ehm de reden waarom die waarom wij nu die al die Sam Oldman video's aan kunnen halen die evident grappig zijn voor ons is omdat er waarschijnlijk 100.000 1000 andere Sam Altman video's die heel saai waren en die niet boven komen drijven middels die algoritmes. Dus er is een soort natuurlijke selectie die maakt dat wij die video's hebben gezien die voortkomen uit een paar creatieve geesten die die video's bedacht hebben. Dat het een bewakingscamera is voegt wat toe en dat hij aan het klagen is over dat hij meer interference wil is voegt iets toe. En dat zijn allemaal grapjes bedacht door een mens. En eh het feit dat wij die video zien zegt iets over de kwaliteit van de storytelling die die mens heeft bedacht. Dus het is de combinatie van storytelling en de algoritmes in dit geval van van Twitter die ehm de video aan ons serveren. Maar kunnen we niet al full circle gaan? Daarmee bedoel ik te zeggen, ik zat laatst een video te kijken van van mij heet het bedrijf Icon en dat is die doen marketing campagnes maken online marketing campagnes volledig algoritmisch. Dus die bekijken naar jou naar je die bekijken je website. Dit voorbeeld van hun is een soort eh wat hennep gummies ofzo. Die bekijken je website, weten dan wat je verkoopt, gaan dan kijken naar je concurrenten die ze zelf zoeken en zien hoe die verkopen. Gaan dan kijken naar hoe de concurrenten adverteren en hoe die advertenties presteren. gaan dan in Reddit kijken naar waar nu de vraag is in de health community en creëren dan 100 advertenties per uur die automatisch getest worden en offline gehaald worden aan de hand van hoe goed ze zijn. Ik bedoel, zou je niet kunnen zeggen, stel dat jij je gelijkenis uit eh dus jij logt in op Sora, jij geeft jouw gelijkenis met je getallen daar beschikbaar. Je maakt hem beschikbaar en dan bouwen wij daarachter met N8N in zo'n flow als we ook bij EV hebben gedaan, bouwen wij een flow die eigenlijk 100 video's van jou de om het uur uitbrengt, constant meet en weer offline offline trekt als ze niet genoeg likes krijgen. Ik bedoel, hebben we dan niet de cirkel gesloten waarin jij eigenlijk zegt: "Zet maar aan, ik ga een bak koffie doen en ik zie wel wat viral gaat. Zeker. En ik ik nu dat weet je, ik denk dat het platform zoals ze nu gemaakt hebben, de Sora app zoals ze hem nu gemaakt hebben, is dat niet, want het is niet geoptimaliseerd op op engagement nu. Dat dat geloof ik ook echt wel dat ze dat zeggen. En het was Sam Oldman zelf die een paar maanden geleden zei: "Als je het hebt over alignment dan is er een dus de mate waarin AI eigenlijk eh zich houdt aan onze menselijke waarde en niet eh ons allemaal dood gaat maken. om het maar even heel eh eh ver door te trekken, zegt hij het meest concrete voorbeeld van misaligned AI zijn social media algoritmes die dus misaligned zijn met ons mensen eh maar aligned zijn met de economische doelen van die bedrijven. Namelijk je zo lang mogelijk je aandacht kapen. En dat is voor die bedrijven goed. Maar je zou kunnen je je het is niet zo heel gek om te zeggen dat dat voor mensen niet zo goed is. Oftewel misaligned AI. En dat was Altman zelfnoten benen die dat zei over Twitter of over TikTok of over Instagram. Wetende dat hij ging concurreren een x aantal maanden later. Maar ja, tja, blijkbaar. En en ik denk dat de AI waar we nu naar kijken of in ieder geval de algoritmische keuze van de synthetische video's dat die wel dat ja, dat is niet dezelfde er zit niet dezelfde verslaving opwekkende eh elementen in als TikTok. Maar ja, hoe lang gaat dat duren? Nou ja, en misschien houdt eh doordat er een aantal eh fanatieke research bij Open en jij zitten, lukt het niet om Sora daartoe om te bouwen hè, omdat ze die afspraken hebben gemaakt. Maar er is nog een ander bedrijf X eh ja, die gaan die het wel doen. Ja, want als ik kijk naar de sporadische tijd die ik op ik zit eh eh dan zie ik dat die bij mij is mijn feed gevuld met ik zou zeggen de helft is fijn alsin ik heb best wel curated, ik volg een aantal mensen en daar zit dan AI gerelateerde content in van research enzo. Dan denk ik weer goed dat ik hier even kijk, want dit vind ik toch nergens anders hè. Maar die andere 50% is de meest clickbait zooi troep ever. Ja, ook al heb ik geprobeerd dat weg te halen. Dus ik ehm als ik kijk naar wat er nu in de Grock app zit aan virtual avatars en hoe ver die gaan in jou verleiden, zou ik me niet verbazen dat eh er een X of whatever Grock Social Network een versie komt van dit Sora ding die misschien wel helemaal engagement eh optimaliseerd is. Want als we naar de geschiedenis kijken, dan is elke keer de release van een groot nieuw videomodel. Dan is het een kwestie van maanden voordat de concurrentie dus op de hielen eh zit of zelfs weer een stapje beter is. Het was een hele het was een tijd dat wij over Sora praten. En toen hebben we heel lang niet meer over S gepraat omdat er Chinees en Amerikaanse concurrenten waren die beter waren. Dat gaat ongetwijfeld hier ook gebeuren. En tot nu toe ja, je zou kunnen zeggen komt Open Ei ermee weg om het algoritme niet verslavend te maken. Want ze zijn nu soort van de eerste die een app maken die alleen maar hele vette AI video's eh laat zien. Maar de ingrediënten voor een soort race naar de bottom staan klaar waarin je de combinatie maakt met en een verslavend algoritme en synthetisch gegenereerde video's. Dat is natuurlijk een ja, dat is een recept wat vragen om moeilijkheden is. En als er één partij eh zeg maar over eh de stap maakt in de markt, is dat dan de reden voor al die andere partijen om mee te gaan doen? En en hoever ga je dan in inderdaad intellectueel eigendom overbord gooien? En hoever ga je in mensen hun emotionele stimulie gebruiken? En je kan zoveel manieren voorstellen waarop dit echt een soort cocaïnefabriek is die hier wordt neergezet. En er was dus blijkbaar al een app, ik wist dit niet, die heet Vibes van Meta die dit deed. Maar blijkbaar twee weken oud nu hè. Dus nou in AI tijd heb je nu gewoon een baard hè. Dan groeit zich gewoon een baard in twee weken. Maar eh dus dit is de eerste publieke ding van Alexander Wang. Dat is een eh ik vond dat een beetje een raar moment. Hm. Interessant. Maar ja, de nou ik wou zeggen dat de soort van move naar eh want terwijl we het hierover hebben zit ik me ook te bedenken ieder geval in Sora en ik ga ervanuit in vibes van Meta ook is het een exclusief 100% synthetische feed. Ja. Eh bewust zo gedaan. Ja. Dan bedenk ik me meteen komt er dan ook een soort counter namelijk apps waarin wordt gezegd dit is een 100% niet synthetische feed. Voor zover je dat kan controleren en kan vasthouden et cetera. Daarnaast vraag ik me af, we hebben in eh video, social media, whatever, de TikToks van deze wereld, de shorts, eh hebben we ook nog zoiets als het kleine, familiaire, vriendschappelijke, een soort van veilige kleine netwerken, hè. Ik zit in een feed met alleen maar vrienden en familie en ik kom daar niet buiten. Ik ga niet met celebrities of wie dan ook kijken. Je hebt ze nu over WhatsApp ofzo of bijvoorbeeld WhatsApp groepen inderdaad. of eh nou ja, je kunt ook je Instagram zo inrichten en afsluiten. En ik heb dat bij Strava bijvoorbeeld gedaan, dat is de kleinste groep ooit, namelijk één vriend. Het kan een soort private network maken. Dat ik me ook kan voorstellen dat eh de behoefte aan die kleinere netwerken als je bijvoorbeeld zou zeggen: "Ik wil een feed met enkel niet synthetische content dat dat wel lukt met 16 vrienden." Ja. Maar niet daar buiten dat je dan kan ongetwijfeld wietsen gaat dit gebeuren. Maar mijn grootste angst is is juist de mix van allebei is en de werkelijkheid. Het nieuws het keiharde nieuws met echte beelden van echte ongelukken of echte toespraken van politici die echt gekozen zijn door echte mensen tijdens echte verkiezingen. En iets wat er heel erg op lijkt waarbij je of wel door hebbt dat het echt is of niet. En nu hangt het allemaal op een watermerkje of een labeltje eh wat er dan bij gezet wordt. Maar dit dat is niet de oplossing voor de chaos die dit gaat veroorzaken, denk ik. Ja. En ik zit hem dan dus ook echt op die als ik nog even terug kan komen op die playlist met synthetische content gemixt met echte echte audio zeg maar. Dat ik me kan voorstellen, dat zie ik me nu zo voor me. Als jij een rijtje met mensen maakt waar je om en om paspoppen tussen zet op een grasveld en je gaat ze allemaal knuffel geven om en om. Dus eerst sta jij daar, geef ik jou een knuffel, dan paspop. Mens, paspop. Mens paspop. Ik denk dat daar dan een soort rare ehm merger begint te bestaan van de relatie tussen de paspop en de mens. En ik zit daar, ik weet nog niet zo goed hoe ik dat onder woorden moet brengen, maar ik heb ik maak me zorgen dat en waarschijnlijk ga je meer toekennen aan de paspop terwijl die niet leeft en ga je minder toekennen aan de mens terwijl die leeft. Dus het is in beide kanten op niet best. Op het moment dat we mixed feeds hebben, want dat is eigenlijk jouw punt, de gemixte feed. Ja. Ja. Ik zit nu ook te denken of ik mijn likenessbaar moet maken. Is natuurlijk een heel gek idee dat je nu als als ook als ik ben natuurlijk een soort semier. Ik moet dat ik moet nu gaan kiezen. Ga ik mensen toe toestemming geven om mijn gezicht en stem te gebruiken. Jij bedoelt het knopje in de Sora app en wat heeft hem op everybody gezet. Nou, wat voel je daar nu bij dan als je Nou, dat het je ook enorm kwetsbaar maakt. Dus dat het je je hoeft maar eh nu heb ik nog een keuze hè. Dus zeggen straks is die keuze niet meer. Dus kling kling 3.0 videomodel kan je het vergeten. Maar ja. Ja. Ja, het is wel een interessante keuze waar je opeens voor staat. Nou goed, ik zal erover nadenken. Wieet, we moeten door, want het is dit was niet het enige nieuws deze week. Namelijk Cloud, de razend populaire AI tool van Anthropic, heeft een versie uitgebracht die 30 uur lang autonoom kan programmeren. En het resultaat volgens Anthropic is zo goed dat het een werkende kopie van Slack met ongeveer 11.000 1000 regels code kon maken zonder dat er ook maar één persoon of één keer een persoon tussen beide hoefde te komen. Waar het vorige topmodel Op 4 in mei nog headlines haalde dat het 7 uur zelfstandig kon werken, gaat de nieuwe versie nu ruim vier keer zo lang door. Het model stopte pas toen de opdracht compleet was. Een volwaardige chat app vergelijkbaar met Slack of Teams. Is het belangrijk dat die tijd zoveel langer is geworden? Ja, ik denk dat het op dit moment één van de hoe zeg je dat? Het is heel prettig om de vooruitgang van deze systemen om het maar even zo te zeggen, hè. Want nu dus over Claud 4,5. Ja, precies. En dat is dan een model plus een harnas eromheen. Eenic harnas. Ja, mooi hè? Deze heb ik Ik heb persoonlijk nog geen harnas in de kast hangen. Ja, het is een vorm van scaffolding eigenlijk, hè? Oké, helder. En eh dus vroeg een jaar geleden hadden wij het nog vaak over ruwe modellen die werden uitgebracht. Tegenwoordig komen die modellen met allerlei dingen eromheen naar buiten. En toen Sora kwam met een app eromheen en een heel platform komen nu vaak eh 4,5 is leuk, dan kan ik modelletje switchen in mijn app. Maar je wil eigenlijk dat daar omheen nog wat meer gebeurt. Als je daar een harnas omheen zet, cloud code is bijvoorbeeld zo'n harnas. Eh en dat harnas is goed aangepast op het model erin. Dus die twee snappen elkaar en kennen elkaar. Dus het harnast kent de krachten en de zwaktes van het model. En het model weet dat hij in een harnas gejaagd wordt later. Waarom is deze metafoor een harnas? Wat bedoel je daarmee te zeggen? Nou, omdat dat woord scaffolding is heel abstract voor mensen, want dat is dan een soort van wat je om je gebouw heen zet aan steigers ofzo. Terwijl een harnas is als je een entiteit hebt, dan doe je daar een soort exoskeleton omheen zoals Iron Man die eigenlijk dat die soort vanille, dat vanille model die niet zoveel kan ineens armen en benen geeft en eh de mogelijkheid om te programmeren en jouw computer aan te passen en Windows te starten en al die acties die dan ineens kan doen en browsertjes die die kan openen. Devin destijds en eh dat soort dingen. Dat wordt dan nu een beetje een harnas met tools genoemd. Ja, precies. Eentje waar waar waardoor je een generalistisch taalmodel makkelijker kan gebruiken voor een hele concrete taak die je hebt in dit geval programmeren. Exact. Exact. Dus hier zit een soort developer harnas omheen. Ja. Waardoor die een agentje kan spelen en op jouw computerbestanden kan aanmaken en 30 minuten lang zijn eigen werk kan blijven controleren et cetera. Waarom zijn die 30 uur? Waarom is die 30 uur zo belangrijk? Omdat in veel van de scenario's eh die er gemaakt worden over wanneer eh gaat dit grote impact hebben op de samenleving is één van de groot indicatoren kunnen deze modellen in een loop hè dus ze roepen zichzelf steeds opnieuw aan en ze blijven proberen en op een gegeven moment komen ze er zelf uit zonder dat wij iets hoeven doen. Ja, het gaat de hele tijd fout en de truc is dat hij dat kan constateren en dan zichzelf kan verbeteren en dan weer door kan gaan zonder dat hij een soort pad ingaat of no return en of zelf kan herkennen dat hij in zo'n pad zit. Ik ga nergens heen ik doe drie stappen terug en ik ga verder zonder dat jij steeds op continue of check of ga terug hoeft te klikken. Ja. Eh waarom is het zo belangrijk? Omdat op het moment dat je modellen in een loop, oftewel een soort agents met een harnas aan, 30 uur lang eh menselijk werk kan laten doen, dan kan je dat ook naast elkaar neerzetten. Groepjes daarvan maken die met elkaar praten. En dan is dat idee van wat we bij EVA hebben gedemoot van agentjes die samen iets voor Carislee maken. ineens veel dichterbij. Want dan kan je zeggen: "Ja, ga maar een week aan werk doen samen en pak maar zeven boeken aan en mail zelf Karie maar met feedback en verwerk het maar." En eh dus die 30 uur die nu in het nieuws kwam, sprong er voor heel veel mensen die wat dieper in de materie zitten uit van jeetje, is dat dan te generaliseren buiten het programmeer harnas? Groot vraagteken weten we nog niet. Wat bedoel ik daarmee? 30 uur is leuk binnen deze programmeertaak. volledig geoptimaliseerd. Het is een heel goed model voor programmeren, et cetera, et cetera, et cetera. Maar is dat dan ook straks bijvoorbeeld 30 uur lang iemands hele medische geschiedenis doornemen om een persoonlijk medisch advies te schrijven op basis van deep research van 30 uur? Hè, dus buiten het domein van programmeren. Dit is nog een vraagteken. Die scenario planners willen weten hoelang deze modellen in het algemeen meerdere domeinen urenlang menselijk werk kunnen doen. Ja, die 30 uur is in mensenuren hè, is niet in computerura. Ja, dit is een hele belangrijke, misschien wel één van de belangrijkste boodschappen voor de soort van kattenlevens of wat zijn? Hondenlevens of mensenlevens. Ja. Of plantenlevens. Die zijn heel traag. Bomenlevens. Er zijn verschillende manieren van tijd. Het bijzondere is van machinetijd, om het even zo te noemen, algoritmische tijd is dat je die kunt versnellen door betere computers. Dus meer datacenters waar het hele ASML datacenterverhaal van vorige week over gaat. Oftewel, het zou zo kunnen zijn dat die 30 uur van Cloud plaatsvindt in 30 minuten. Nou, dan als je er dan 30 van naast elkaar kan zetten, begin je als luisteraar wat meer te voelen. Jeetje, dit is wel een dingetje zeg. Ja. Nee, dat maakt het alleen nog maar heftiger, wetende dat dit computer of dat dit eh de uren zouden zijn die een mens ergens aan had besteed. Alle labs, alle grote frontierlaps, Open AI, Tropic, eh Google Deep Mind zijn dus heel erg aan het optimaliseren op benchmarks hè. Dus al die benchmarks waar we het al maanden over hebben. Maar deze benchmark, de meter benchmark is dat meter of één van de meter benchmarks is hoelang kan een agent eh werken zonder dat de mens erbij hoeft te springen en resultaat leveren, hè, ik bedoel, moet ook goed zijn. Eh eh daar wordt nu flink op geoptimaliseerd. Dus ik verwacht ook dat Gemini 3 vanuit Deepmind in de press release ook een 100 uur achtig ding gaat claimen omdat daar nu eh de grootste impact zit. Is dit nu het beste model ehm om te programmeren? Staat redelijk gelijk aan GPT5 Codex. De op maat gemaakte versie van GPT5 die goed is in programmeren. Eh gaan redelijk gelijk op. Maar weet wel dat eh Sonet, want dit is niet Opus, sonnet is vijf keer zo goedkoop als Opus en ook nog is het twee keer zo snel geworden. Dus is het ook nog belangrijk geworden bij dit soort releases van modellen plus harnassen. Ja. Hoe goedkoop het is en hoe snel. Ja. En hoe ze hier gekomen zijn. Ik las dat ehm Claud 4,5 zich bewust is van zijn eigen geheugen. Hoe zit dat? In eh software ontwikkeling heb je zoiets dat heet garbage collection. Dat houdt eigenlijk in dat een laptop, een smartphone, whatever heeft een gelimiteerde hoeveelheid intern geheugen. Dat is eigenlijk het geheugen waar jouw document in zit als je hem nog niet hebt opgeslagen. Die moet dan ergens zijn. Dat is in het geheugen. Dat is niet je harde schijf even in oude termen, niet je solid state. Is vaak een stuk kleiner ook, want het is veel sneller, maar daarmee ook veel duurder. Dat geheugen is dus duur en eh daardoor eh moet het gemanaged worden in soft. Maar er kan niet onbeperkt dingen in. Nee, want op een gegeven moment loopt Word dan gewoon vast. Ja, dus wat je eigenlijk wil is pak even de metafoor van Word misschien voor het gemak. Je bent een boek aan het typen in Word en je bent zo gek dat je het niet tussendoor opslaat. Ook al doet hij dat automatisch, heb je dat uitgezet, want je bent een beetje maf. Dan zit je op een gegeven moment op pagina 800. Dan kan de garbage collector zeggen: "Joh, pagina 800 is nu in beeld. Ja, de kans dat jij helemaal terug gaat scrollen naar één is vrij klein. Ik haal één even naar de harde schijf en uit het geheugen. Die moet wel ergens heen. Dat is eigenlijk het opruimen van het gelimiteerde geheug. Nou eh en misschien wel eh eh je hebt nog teksten daar staan, die heb je inmiddels al verwijderd. Die zitten nog onder undo hè. Je kan ze nog terughalen, maar je gaat niet meer dan 30 undo stappen terug. Ik gooi ze gewoon weg en dan ben jij pist, want je wil de 34 stappen terug. Maar goed, dat is garbage collection. Eigenlijk wil je dat de context window in jouw AI model wanneer jij aan het kletsen bent, dit is de frustratie van veel gebruikers van GPT achtige apps, is dat ze zeggen: "Ik zit lekker uren te babbelen." En op een gegeven moment heeft hij een soort ja, noem het Alzheimerachtige dingen. Namelijk we hadden het ergens over aan het begin van het gesprek en hij verliest eigenlijk de de de track zeg maar, het eh het het grote geheel. Dat is letterlijk dat de context er aan de achterkant afvalt. Die valt buiten de window naar buiten. Nou, dat hij Dit is bij programmeren heel wezenlijk. Hij moet gewoon alles weten. Ja, dat is een beetje gevaarlijk ook en irritant en ook best wel duur, want daardoor moet je het iedere keer Dus wat ze dan nu noemen eh om nog een paar leuke termen te gooien naast harnessing en scaffolding is context engineering een taak voor een mens. dachten we namelijk zorg er nou voor dat je bijvoorbeeld cloud code gebruikt die heel slim jouw codebase gebruikt en jij kan dan nog een beetje nudgen van ja dat moet erin dat moet er niet in en zo engineer jij eigenlijk je context dus je bent niet alleen maar aan het prompt engineeren om de goede vraag te stellen maar ook aan het context engineeren om te zorgen dat die vraag omgeven wordt door genoeg context om de vraag te beantwoorden. Ja, precies. Je bent je je als als mens ben je aan het managen wat voor relevante informatie dat ding altijd in zijn achterhoofd moet houden. Wetende dat daar beperkingen in ja in in grootte in zit. Dat dat moest je als mens nog bedenken. Ja. Nou ja, bijvoorbeeld om eh transcripts van onze podcast te gebruiken om eh hoofdstukken te schrijven in een boek deed ik het begin van de transcript eraf halen, want dat was wij die een intro deden. En zo ik was zoveel mogelijk die transcript aan het eh kleiner eh maaien zeg maar, omdat ik dacht: "Ja, ik moet wel die context goed gebruiken." En als ik op een gegeven moment in een ander hoofdstuk ben, heb ik misschien eerdere transcripts niet meer nodig. Dus die wipte ik er dan vlug uit. Ja, we zitten in een tijd waarin die AI gewoon minder precies wordt als je meer informatie geeft. Dus jij gaat dan in de achterhoofd heb jij de hele tijd: "Ik weet dat dit aan de hand is, dat hij zo fouten gaat maken. Dus ik ga alles wat irrelevant is er alvast afstrippen." En dan is het ook nog eens zo dat die context windows die dus steeds groter worden. Eh niet altijd het ene context window is het andere niet. Het is leuk dat je een groot context window hebt, maar dan moet het hele window ook warm zijn. namelijk hot in memory om te kunnen lezen. Dus wat je nu hebt is dat je partijen hebt die beweren grote context windows, maar die blijken helemaal niet helemaal warm. Namelijk sommige delen zijn koud. Nou goed, hier hebben we weer, dit is één keer belangrijke les voor luisteren. Je moet altijd je context vinden opwarmen. Ik hou hier geen rekening mee. Nou ja, ligt er dus aan. Sommige modellen zijn zo goed, vind ik goed, dat ze eigenlijk 100% van de window blijven zien. Dus de attention kan gaan naar het hele window. Ja. Ehm dat gezegd hebbende wat er dus nu aan het gebeuren is in Cloud 4.5 eh Sonet, want daar vroeg je eigenlijk naar is dat zij eh het model hebben getuned of eigenlijk eh door hebben laten oefenen op kan jij niet zelf wat slimmer die window beheren? Nou, dan kan je bijvoorbeeld ze na ze doen dan het voorbeeld van het spel katan dat je een computerspel speelt of in dit geval een board game en op een gegeven moment ben je een aantal zetten verder in dat spel en die context window die groeit en die groeit en die groeit want de hele geschiedenis van alle zetten daarvoor zit nog in de window. Eh terwijl ja, inmiddels met de staat van hoe het bord erbij ligt en waar je bent, heb je eigenlijk niet meer alles nodig hoor. Dus je zou wat slimmer je eigen window kunnen gaan purgen. Zeg maar, Carbage Collection kunnen gaan doen vanuit het model. in plaats van de mens. Ja, want zij gingen een zij gingen dus Katan spelen. Vind ik heel grappig grappig eh ding eh tegen drie tegenstanders. En dan bouwt tijdens het spel werd er een soort van kennisbank opgebouwd met informatie over elke speler. Dat zijn dus die zetten waar jij het over hebt. En na 75 minuten en duizenden spelgebeurtenissen. Dus zo wordt dan even beschreven dat iedere zet een soort spelgebeurtenissen is uiteindelijk een soort van ja punt in een database. Blijft de context schoon en gefocust. Ehm het model gooit automatisch oude minder relevante informatie weg naarmate nieuwe gebeurtenissen zich opstapelde. Dat is dat hele garbage collection verhaal wat jij beschrijft. Maar na 75 minuten spelen bleef het eh met dus steeds groeiende database eigenlijk bleef het spel schoon en gefocust. Bleef hij goed spelen. Waar hiervoor dat ding na 75 minuten gewoon hele rare dingen was gaan doen. Wat je als mens zelf had kunnen constateren. Ja. En het om om maar even een concreet voorbeeld te geven van hoe doet hij dan die slimme opruimen prun garbage collection is als jij 80 setten hebt dan is er op een gegeven moment een resultaat van die 80 setten. Namelijk je huidige positie op het bord en je huidige inventaris van eh goodies die je kan gebruiken. En eigenlijk is dat wat ertoe doet en niet hoe we daar gekomen zijn. Dus op een gegeven moment kan je dan als je dus een slim model hebt zeggen: "Joh, hoe we hier gekomen zijn doet er niet toe voor het vervolg van het spel." Ja, maar wat de geschiedenis heeft kan blijven staan. En dus dit is dan schijnbaar, want dat hele idee van Garbage Collection in de software in het vorige paradigma komt uit ideeën over hoe wij als mensen werken. Namelijk en dit is eh ik wilde toch even dit punt maken. Op het moment dat jij iedere dag hetzelfde cirkeltje loopt in je leven, zeg maar letterlijk dezelfde naar je kantoor toe. Om een kerk om een kerk met je tram. rondje om de kerk. Dan gaat op een gegeven moment jouw brein zeggen: "Joh, ik ga wel al die dingen opslaan op dezelfde plek, want het is nagenoeg dezelfde herinnering." Dus dan krijg je een soort pointer, zoals dat heet, waarbij eigenlijk al die herinneringen aan dat rondje om de kerk zich beginnen samen te voegen in één superherinnering. Maar dat is eigenlijk best wel naar, want het waren misschien wel uniekere rondjes om de kerk. Maar dus hoe meer jouw leven in cirkeltjes loopt die hetzelfde zijn, hoe meer jouw herinnering aan jouw verleden een soort één heel platte herinnering wordt. Omdat ook jouw brein natuurlijk de hele tijd bezig is om geoptimaliseerd op te slaan. Ja, dat is goed eigenlijk. Dat is een slimme manier. Gezond ook op een bepaalde manier. Ja. Ja. En en zo zijn dus de robots de de natuur aan het nabooten als ik je goed begrijp. Ik las hier nog wel wat grappigs over. team achter Devin, dat is een AI programmeerassistent, moest hun hele systeem herbouwen omdat Claud 4,5 uitkwam. Die iemand van het cognition team eh legde uit: "Het model werkt fundamenteel anders. Het maakt zelf notities, werkt parallel aan meerdere taken en beheert zijn eigen context. Dat brak met ons idee over hoe agents zouden moeten werken." En die zelfstandigheden, die zelfstandigheid van Claud bracht ook een aantal nieuwe eigenaardigheden met zich mee. Het model onderschat consequent hoeveel geheugen het nog heeft. Dus ze praten hierover alsof het een soort mens is. Het wordt nerveus. We hebben het nu over het model. Naarmate het denkt dat de limiet in de buurt komt. En Devin loste dat op met een simpele truc. Daar moesten zij dus die scaffolding omheen bouwen omdat ze dus rekening moesten houden met de nerveusiteit van het model als het in de buurt kwam van de limieten van het geheugen. Dan gaven ze het model toegang tot een miljoen tokens, maar beperkte het gebruik tot 200.000. Daardoor denkt het model dat het steeds genoeg ruimte heeft en blijft het rustig doorwerken zonder dat het nerveus wordt. Ik vond dit zo'n freaky ding om te lezen dat ze eigenlijk die robot voor de gek aan het houden zijn en manipuleren zijn zodat het niet nerveus wordt. Ja, het is eh het het is weer typisch eh het dingen dus voelen als entiteiten en dat je dus emotie als nerveusiteit moet gaan afvangen. Gaan managen. Het is wel boeiend, want ik vind het een heel mooi voorbeeld, want Devin is een is zo'n scaffold, zo'n harnas om een model heen, een programmeertool. Ja. En wat er dus nu eigenlijk aan het gebeuren is, is dat een deel van het harnas begint in de modellen terecht te komen. Bewust, hè. Ik bedoel, dus dat eigenlijk iets waarvoor allerlei eh trucjes uitgehaald werden door er een harnas omheen te bouwen eh die zijn niet meer nodig omdat eigenlijk de modelwikkelaars zeggen dat zijn zulke slimme trucjes. Die zouden niet op harnasniveau moeten zitten, maar op lichamelijk niveau, namelijk op het eh oermodel. Wat natuurlijk voor die harnasbouwers ergens leuk is, maar ook frustrerend. En dat maakt ook dat ik grote vraagtekens heb bij de levensvatbaarheid van partijen zoals Devin. Omdat ik denk jullie zijn een soort van onbetaalde R&amp;D partij voor die voor die voor die modelmakers. Want alles wat jullie innoveren in je harnas, alle goede dingen worden eruit gehaald en in de modellen zelf gestopt. Maar goed. Ja, het is niet alleen programmeren. Eh want dit is nu een heel specifiek ding waar we op inzoomen, maar Ethan Molic eh auteur van eh cointelligentie van uitgebracht door een bepaalde uitgever in Nederland kreeg vroege toegang tot het model en hij zag vooral grote sprongen in finance en statistiek. Dat is misschien goed om ook even bij stil te staan, want dit soort dit model is dan welenswaar eh krijgt de meeste aandacht omdat het goed is in programmeren. Maar dit zijn twee vakgebieden die juist de hele tijd ja een toch waar waarbij AI modellen toch een beetje achter lijken te lopen. Ehm en hij testte het model door economische papers te laten reproduceren. Compleet met ehm eh datasets en statistische analyses. En hij schrijft: "Wat normaal gesproken uren menselijk werk zou kosten. dead cloud in een fractie van de tijd en het klopte. Ehm dus dat is commentaar over ja, sectoren waar ontzettend veel banen in zijn en waarbij als ik eh lezingen geef voor mensen die in finance werken, die zijn het meest eh cynisch over AI modellen vind ik altijd. Van alle mensen voor wie ik optreed zijn mensen die in finance zijn, zijn de eerste die zeggen: "Allemal leuk en aardig dit." Maar dat ding kan niet rekenen. Ik heb het geprobeerd. Het klopt niet. Ik zeg altijd dat zijn de mensen die het langs blijven glimlachen tijdens mijn verhaal omdat ze zich gewoon helemaal veilig voelen zeg maar. Ik denk wel dat eh ik vind het wel interessant hoor want eh aantal dingen deze labs slash product companies open noem ze maar op die hebben enorm veel statistieken. Dat daar moet je ook constant ja of nee op zeggen en soms juist op het in op het outen. Wat bedoel ik daarmee? Was dit een goed antwoord? Duimpje omhoog. Duimpje naar beneden. Eh mogen we anonieme gebruikersdata van jou verzamelen over voor onze modellen? Ja of nee, moet je uit al dat soort dingen. Als gebruiker word je de hele tijd geconfronteerd met dit soort vragen. Ja. Ja. En als je wil weten waarom is het omdat eh Entropic dan ziet: "Hey, onze tool wordt heel veel gebruikt in het financiële domein. Megael duimpjes naar beneden, afgebroken sessies, boze reacties. Hier zit een wens waar wij niet aan kunnen voldoen. Kunnen wij gaan optimaliseren voor die use case." En dat doen ze dan. Dus laat het je niet verbazen dat zij weten waar de gaten zitten, want dat weten ze letterlijk. En ik denk een hele belangrijke, ik praat veel met bedrijven en organisaties over ehm hoe bouw je nou een deel van je bedrijf opnieuw op met wetende dat deze technologieën bestaan, hè. In plaats van dat je het op je bedrijf aan de buitenkant plakt, zeg maar, als een soort bugfix ofzo, of een soort addon, wil je eigenlijk bepaalde dingen vanaf de grond af opnieuw herzien aan de hand van wat er nu kan en mogelijk binnenkort kan. Laat ik het dan zo zeggen, als je daar een voorbeeld van wil hebben, dat zijn die AI LAABS bedrijven. Daarmee bedoel ik te zeggen als er een AI first company is, dan is het antropic. Namelijk een volledig data driven, statistics driven, AI driven automatiseringsclub die intern cloud code gebouwd heeft om zelf dingen te bouwen en die daarna pas heeft uitgebracht. Dus ja, ik denk dat we wat we meer zullen gaan zien over de komende maanden en jaren is dat deze tools zich magischerwijs lijken te om te vormen naar wat de gebruikers willen omdat ze datagedreven zichzelf kunnen gaan verbeteren. Ja. Nou, was nog een blik op dit model, namelijk van Scott White. Dat is een projectleider voor Cloud en die omschrijft het ook als een model wat op chief of staff niveau kan opereren. Het model kan vergaderingen plannen door agenda's te vergelijken, inzichten uit dashboards halen en status updates schrijven op basis van één op één gesprekken. Ook nieuw, gebruikers kunnen nu rechtstreeks in gesprekken code uitvoeren en bestanden maken, zoals spreadsheets en presentaties. De Chrome extensie die cloud toegang geeft tot je browser is alleen beschikbaar voor max abonnees. Dus dat is belangrijk om in het achterhoofd te eh houden als je dit gebruikt en je denkt: "Ik mis hier dingen uit. Sommige dingen zijn verstopt voor de mensen die €80 betalen per maand." Ja, misschien goed om toe te voegen nog dat eh dit is sowieso wijsheid eh maar nu helemaal als jij wat sceptischer bent over wat deze modellen kunnen omdat je 7 maanden geleden je eigen benchmark hebt gedaan. Per ongeluk benchmark namelijk. Je hebt het gevraagd om iets financieels te doen en het ding kwam niet met de juiste cijfers. Je werkt bij een grote fiscalist en je zegt geen cijfers. Ja. Neem dan max. Vraag het even intern van jongens ik moet even onderzoek doen en ga hiermee praten en test opnieuw of die aannames nog kloppen. Want het gaat wel heel erg hard en op bepaalde domeinen waar het een drie scoorde scoort het nu ineens een zes of een zeven. En dat is best wel substantieel. Doet het nou iets met jouw idee van eh voorspellingen van waar we zitten in de in de tijdlijnen? Want jij zei een paar afleveringen geleden zei jij ik ik kijken naar AI 2027 de voorspellingen eh die gedaan zijn door een clubje AI ja, hoe moet je het zeggen? Wetenschappers, filosofen, activisten, meest outair scenario zou je kunnen zeggen. Ja. waar ehm een scenario waarbij hele concrete voorspellingen zijn gedaan over wanneer welke belangrijke mijlpalen gehaald worden. Jij zei een paar weken geleden, ik heb het idee dat we een beetje achter aan het lopen zijn op die voorspellingen. Heeft dit nog iets veranderd? Deze dit model wat nu uit is gekomen? Nou, dit is zeg maar ik denk wel dat ehm kijk het gaat nog steeds om in dat scenario dat er geschoven wordt met jaren en niet met decennia. Nu en met schuiven bedoel ik dat het dus AI 2029. Ja, precies. Dus dat maakt het eigenlijk ook uit. Nou ja, daarmee ik bedoel er wordt en en ik zou zeggen dat eh de Nayers na de release van GPT5, want dat is wel een beetje de deuk geweest in dit hele narratief hè. De deuk bedoel ik mee. Door de lancering van GPT5 zijn er een hoop mensen geweest die zelfs dachten dat teveel ging gebeuren. Die zeiden van nou ook ik hè moet een beetje eh pas op de plaats nemen. Ehm nu deze releases weer zijn eh zoals eh Sora 2 videomodel en het idee dat dit mogelijk de omnimodellen zijn die in de toekomst samengevoegd gaan worden in supermodellen. Dus je moet je voorstellen dat en Genie en Vio en Gemini één ding gaan vormen die en boten kan ontwerpen en computers kan besturen en tekst kan voorspellen. Het idee dat die modellen uiteindelijk samen gaan komen en elkaar gaan versterken zeg maar zorgt er wel voor dat ik persoonlijk nu ik zie dat er op tekst wat minder heftigs gebeurt, maar op alle andere modaliteiten en media meer het idee heb dat ehm als GPT5 ervoor gezorgd heeft dat je misschien dacht: "Nou hè, het ik kan even ademhalen, het valt allemaal wel mee." Ik ben wel weer iets benauwder geworden nu de laatste weken omdat Gemini 3 er ook nog aan gaat komen en er nog best wel wat in de pipeline zit. Kan ik me voorstellen dat laten we weer even inchecken rond kerst het eh hoe hoe de hoe de buik erbij zit zeg maar. Maar dit heeft wel weer een soort van urgentie gegeven bij mij dat ik denk: "Jeetje, het gaat nou toch wel weer wat harder." Ik zag Molik eh in deze context wel mooi aangeven ja, dit effect namelijk je je checkt de hele tijd bij jezelf in over wat er gebeurt. En het is soms ook moeilijk om nog te overzien wat zo bijzonder is. Maar het is goed om te blijven beseffen dat we zijn gegaan als de manier waarop we over dit soort AI systemen praten. Van de sprong van agents werken nergens. Dat was een beetje sentiment. Soort van agents bestaan. Maar het werkt helemaal nergens. Er is geen praktisch gebruik voor agents. Dus allemaal leuk en aardig die verhalen, maar het werkt in de praktijk niet. Maar op een gegeven moment oké, beperkte agents voor onderzoek en programmeren werken redelijk. Dus deep research van oké oké, deep research is wel iets en maar er zitten ook nog dingen in die niet kloppen en hetzelfde voor programmeren. Maar eh algemene agents zijn nuttig voor heel veel taken eh waar we nu zijn. En dat is heel snel gegaan in minder dan een jaar. En Molik zegt: "De kans is heel groot dat de meeste mensen dit gemist hebben." Ja. En dan misschien nog een andere anekdote daarbij. Simon Willison, ontwikkelaar, doet veel rond AI, weigerde tot twee weken geleden de woord het woord agents te gebruiken. Ook tijdens lezing omdat hij zei: "Het is niks. Het is gewoon lucht." Hype. En die zijn nu inmiddels als dat modellen zijn die in een cirkeltje draaien, zichzelf kunnen eh aanpassen en kunnen blijven draaien x aantal uren die bij mij terugkomen. Dan wil ik wel naam geven. Ja. En hij zegt: "Ik zie het nu gebeuren. Ik heb een paar dingetjes gebouwd op die manier en die beginnen nu te werken. Dus ik ga de term nu ook gebruiken, want ik denk dat agents bestaan." Goed. Eh ik wil iets aanhalen wat we deze week in onze nieuwsbrief hadden. En dat is gerelateerd aan cloud. Een product dat heet Imagine with cloud, wat je hele korte tijd kan gebruiken. Het is een experimentele functie die laat zien waar AI ontwikkeling naartoe gaat. van AI helpt je met programmeren naar AI is de code. Laat me uitwiiden hierover. We hebben 90 neergeteld voor zo'n maxab abonnement van Anthropic ehm om dit voor je uit te testen. Want Imagine with Cloud is nu maar 5 dagen beschikbaar voor mensen met zo'n max abonnement. Maar goed, we hebben dit dus voor je gedaan, zodat je die €90 kan besparen. Cloud maakt dingen in real time. Dus geen voorafgeschreven code. Het is een kwestie van een bijvoorbeeld wat wij probeerden een screenshot van onze website uploaden en dan vervolgens vragen: "Maak dit in jaren 80 stijl?" En terwijl je ermee interacteert, blijft het bouwen. Dus je klikt op een knop en Clot genereert ter plekke de volgende pagina. Dus die interfaces dus een ja, dat kan eh zoals Windows of je Mac eruit ziet. Hij hij tekent die interfaces op het moment dat je op een icoontje klikt als voorbeeld. Dat is dus iets waar je zelf mee kunt experimenteren. En dat is bijzonder leuk, kan ik je vertellen. Als je wil leren hoe dat werkt, wat wil je hierover zeggen? Nou, ik wou even zeggen dat ik heb het een beetje onderschat, want ik was het aan het bekijken. Alle video's hiervan. Ik heb het zelf niet getest. Ik was het aan het bekijken en op een gegeven moment in die video zit er dan een knopje van eh download PDF hè. Dus je hebt je hebt iets gevraagd, je hebt al ergens op geklikt en dan kom je er zit een knop download PDF. Dus ik denk als software ontwikkelaar dan zo: "Wat gebeurt er dan als je daar op klikt?" Nou, dan klik je daarop en dan zie je dus onderin zeggen: "De gebruiker heeft geklikt op download PDF, maar dat heb ik helemaal niet. Wacht, ik ga vlug in Python niet schrijven om PDF's te maken." En dan gaat hij dat helemaal doen. En dan krijg je dus die PDF omdat hij just in time zelfs die logica nog voor je gemaakt heeft. Dus dit gaat verder dan interfaces just in time. De backend logic zeg maar wat op ja, de functionaliteit is just in time. En ongetwijfeld is dit waar computers naartoe gaan. Dus het idee dat je nu een spraakassistent hebt in je telefoon die tekst of plaatjes kan teruggeven. Dat is één ding. Het tweede is dat we vibe coding hebben. Dus dat je tegen een telefoon kan zeggen: "Maak een app die zus en zo voor me regelt." En het is als je die twee stappen met elkaar combineert heel erg voorstelbaar dat we over een paar jaar niet alleen maar apps hebben die gemaakt zijn voor hele grote groepen mensen, maar dat de app gemaakt wordt als je een probleem aan dat ding geeft en dat telefoons en computers dus heel anders gaan werken. Dat je een dat code eigenlijk gegenereerd wordt op het moment dat je erom vraagt. En dat is een soort toekomstbeeld wat volgens mij heel erg in de lijn der verwachting ligt. En imagine with clot is dat. Het is dat om te proberen op je eigen computer. Nou, je kunt in onze nieuwsbrief eh grondige uitleg lezen over hoe Imagine with Cloud verschilt van normale AI coding. En we hebben allerlei experimenten uitgevoerd en praktische tips om zelf mee aan de slag te gaan. En dat kun je krijgen als je gaat naar air report. Straks eh de eerste door AI gegenereerde artiest die een platencontract heeft getekend Wietsen van maar liefst €3 miljoen. Dat hoor je straks. Maar eerst een speciale oproep van Deppt en de kans voor jou als luisteraar om dagelijks met AI te gaan werken. Hi, hier Dept. Elke week bespreken we hoe wij merk helpen in de wonderenwereld van AI. Maar deze week gaan we het even hebben over onszelf of eigenlijk over jullie, onze luisteraars. Want Lucas, wij komen handen tekort. Absoluut. We zitten tot over onze oren in het AI werk. Mega leuk werk trouwens. We helpen bijvoorbeeld eBay eh om content te versnellen. Eh en we maken aanbevingsmodellen voor rituals en het helpen van een breed scala aan klanten om nog beter gevonden te worden in die wereld van AI zoekmachines. En als klappende vuurpijl bouwen we ook actief door onze eigen interne tooling om onze teams te helpen nog beter werk te leveren. Check. Dus we hebben eigenlijk mensen nodig die vandaag al willen bouwen. Ja, hou je vast. We zoeken AI consultants, AI engineers, data scientists, eh machine learning engineers en ook mensen die kunnen helpen om verder te optimaliseren. En uiteraard we zoeken ze eigenlijk al gister. Duidelijk. Oké, dus werk jij graag aan complexe internationale projecten en wil je echt het verschil maken met AI, check dan nu onze vacatures in Nederland, Duitsland, de UK en de US. en ga zo snel mogelijk naar deagency.com/aaivacancies. Soliciteren dus. Tot volgende week. [Muziek] Tenslotte, deze week tekende Xania Monet fietsen, een door AI gegenereerde artiest, een platencontract van $ miljoen. En wie tekent dan wat? Ja, dat van wie is zij dan als entiteit beter? Dit is gewoon een leuke uitsmijter. Ik ik neem je gewoon mee. Ja, nu geen kritische vragen stellen. En de AI studio XIOA meldde in gesprek zijn met talentbureaus om hun eerste digitale actrice Tilly Norwood officieel te laten tekenen. En er is ook een Nederlandse ondernemer betrokken. Eline van der Velden, zelf ooit actrice geweest is de oprichter van Xoia. En dat leverde gelijk een mediarelletje op. Eh actrice Emily B eh Emy Emily Blunt noemde het angstaanjagend en een andere artiest pleit voor een boykot van talentenbureaus die samenwerken met dit soort AI gegenereerde artiesten. Een acteursvakbond eh acteursvakbond waarschuwt: digitale product heeft geen emotie en het verdrinkt echte acteurs van het werk. Dus hier begint het. Platencontracten getekend door AI. Nou ja, met AI. Ik weet nog niet of het door AI is. Dit is waar we nu zijn, Witze. Interessante tijden. Het zijn interessante tijden. Heb jij nog stichtelijke woorden aan het eind van deze podcast? Ongetwijfeld. Ja. Ehm voor een soort Sora 2 gevoel terwijl wij die app niet kunnen downloaden. I Justine, een eh vlogger die heel veel rond Apple doet, heeft een enorme review gemaakt van de app waarin zij zichzelf kloont en zichzelf laat zien en alle hoeken en gaten van die app uittest. Als je een beetje een gevoel wil krijgen in je buik wat dit allemaal betekent, check haar eh review. I just team. Dankjewel Wietsen voor deze deep dive. We hadden uren kunnen doorpraten hierover en ik denk om deze informatie allemaal gesynthetiseerd te krijgen moet je überhaupt honderden uren over het websurfen en wij wij danken ik ik dank even namens eh ja namens de luisteraar Wiets dat je dat voor ons gedaan hebt. Wij danken ook Sam Hengeveld voor de edit. pankra voor onze vormgeving. Als je dus een lezing wil van Wiets of van mij, dan kan dat. Mail ons op lasing@aireport. En als je die nieuwsbrief wil krijgen waar we het net over hadden, waar Imagine with cloud in wordt geduid deze week en je sowieso twee keer per week de laatste tips en tools ontvangst om het meeste uit AI te halen, dan kun je abonneren gratis via onze nieuwsbrief op airreport. e-mail. En vergeet dus niet dat als je je nu aanmeldt voor de betaalde versie van die nieuwsbrief dat je donderdag 16 oktober rond lunchtijd bij onze webinar kunt zijn. Ga daarvoor hoe dan ook naar airreport. En wil je vandaag nog beginnen met AI binnen jouw bedrijf dan ga je naar deagency.com/aai report onze gewaardeerde sponsor. Tot volgende week. Tot volgende week. [Muziek] [Applaus] [Muziek]

---

## Notes


## Key Takeaways
-

## Related
-
