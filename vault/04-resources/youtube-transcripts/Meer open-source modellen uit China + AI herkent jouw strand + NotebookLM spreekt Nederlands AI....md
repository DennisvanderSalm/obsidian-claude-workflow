# Meer open-source modellen uit China + AI herkent jouw strand + NotebookLM spreekt Nederlands | AI...

**Source:** [YouTube](https://www.youtube.com/watch?v=PKXSSoVjUAw)
**Video ID:** PKXSSoVjUAw
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie waar we uitzoeken welke invloed AI heeft op ons werk, ons leven en de samenleving. En niet schrikken, deze week even twee andere stemmen. Jesse en Frida. Het is immers nog steeds vakantie. Oké, vandaag duiken we in een paar ehm best wel opvallende AI ontwikkelingen. Dingen die laten zien hoe snel het gaat, maar ook ja, welke nieuwe vragen dat oproept. Ja, zeker. We hebben het over een nou ja, een iets te enthousiaste chat GBT. N ai die echt griezelig goed locatie. Frida eh en Jesse, dit kan niet de bedoeling zijn. Ja, ze nemen het zomaar over. Nee, dat dat gaan we niet doen, want Wiets en ik zijn er wel gewoon. Ook al is het vakantie. Eh wij laten ons niet zomaar vervangen en ik zit gelukkig nog steeds aan de knoppen. Wat doen we deze week? Wietsen? We gaan het hebben over Google Notebooks LM. Je hoort het al even. Eh ze spreken eindelijk Nederlands en jij zou denk ik zeggen dat klinkt een kenny goed. Ik vond het wel overtuigend, maar er zijn misschien heel veel mensen die luisteren en zeggen: "Oh, ik hoor het meteen hoor." Ik ben benieuwd. Daar gaan we het straks over hebben. Chat GPT gaan we het ook over hebben, want dat eh heeft eh ja, die is kortstondig even in een ontzettende slijmbal veranderd. was een update. Is inmiddels alweer ingetrokken, maar leuk om even te bespreken. Open AI is nieuwste model. Die kan ongekend precies bepalen waar je bent op basis van alleen maar een vakantiefoto bijvoorbeeld. Of eh hij ziet als je in je eigen straat bent waar die straat dan precies is op basis van alleen maar een garage. Een soort geogesser geworden. Ja. En er rollen allerlei nieuwe Chinese modellen van de AI band. En dan hebben we ook nog eh Meta die haar eh eerste AI appje heeft gelanceerd. En dat vind jij het belangrijkste nieuws geloof ik, hè? Nou, ik wil het er wel even over hebben. Het zit een beetje onder de radar, heb ik het idee. Oké. Nou, dat en nog veel meer in deze bomvolle news aflevering van AI Report. [Muziek] [Applaus] [Muziek] [Applaus] Ja, Wiet. Het is denk ik dus zover. We we worden met uitsterven bedreigd bedreigd. Je wordt er helemaal ga helemaal van stotteren. Ehm nou voor de luisteraars dat begin net de intro was dus Notebook LM want eh Google heeft Nederlands toegevoegd. Ja, gaan we het straks over hebben. Ja, je kon dat voorheen al een beetje hacken, maar nu zit het er echt in. Ja. Ja. En wij zaten er even mee te spelen en wij dachten van: "Wow, dit moet eigenlijk zij moeten het dan maar ook gaan doen als het zo goed gaat." Oh nee nee nee nee nee nee. Dan laten ze laten we hun even de intro doen. Nou ik dacht wel van oké grappig, dit kunnen we wel al voor kleine stukjes even oefenen hoe dat dan zou zijn. Ja. Ja. Eh en nou ik was ook best wel van onder de indruk. Eh we hebben nog een fragmentje straks waarin je ook hoort hoe ontzettend Nederlands het ook klinkt met ook ze gebruiken en waar het nog door de mand valt het systeem. Ja, dat gaan we natuurlijk ook even ons oprichten. Voordat we dat gaan doen, voordat we daaraan gaan beginnen, eh nog even een administratieve mededeling. Er is een webinar wat jij en Alexander organiseren en dat zit er alweer aan te komen. Ehm dat is op dinsdag 13 mei om 12 uur gaat dat van start. Ja. Ja, je krijgt de link eh op maandag en op dinsdag volgens mij ook. Ehm en je moet Hoe krijg je de link? Als je betalend lid bent van AI Report en nieuwsbrief. Oké. Dus dat kan nog. Is het kan kunnen er onbeperkt mensen naar die webinar eigenlijk? We zat een keer vol. Wow. Nou, we zitten nog niet aan de limieten van wat we daar doen, dus dat komt goed. Nee, zal meestal als je een kaartje ergens voor moet kopen, moet je weer oh straks is het uitverkocht. Maar dat is hier natuurlijk dat kan niet. Dat is wel mooi aan online. Ja. Wauw. Nou eh we gaan ehm heel veel nieuws bespreken. Beetje net als vorige week. Eh dus ik denk dat we moeten rebranden in Milou en Wietsus nieuwscarousel. Eh ik weet niet eens ik heb het onderwerp niet eens geteld, maar het is allemaal heel belangrijk en we gaan het allemaal heel efficiënt bespreken. En we beginnen met ja, Notebook LM. Eh het is in het Nederlands. Het heeft even geduurd, maar eh we weten nog hè dat audio overviews kwam een paar maanden geleden en dat mensen allemaal daar ging mee experimenteren. Wij ook natuurlijk hier in de podcast en dat we daar best wel van onder de indruk waren. Ehm niet alleen wij, maar dat was wel redelijk denderend succes kun je zeggen. En nu is het dus beschikbaar in meer dan 50 talen. Ja. En het is wel bijzonder, want ik heb het idee dat er ook het nieuwste eh advanced audio of ja, wat het is inmiddels voelt het ook wel beter nog dan wat er destijds in het Engels uitkwam. Dus het is en in het Nederlands en weer een stapje verder dan wat het Engelse model toen al kon. Ja. En dat merk je vooral in ja, tempowisselingen. De utjes en atjes die op andere plekken geplaatst worden als ik er naar luister, want het kan ook gewoon mijn beperkte smaak zijn ofzo, is het 80% van de tijd gewoon goed als in luisterbaar en best wel overtuigend. En dan 10% van de tijd mo en die andere 10% valt het gewoon volledig door de mand omdat het ineens hele woorden niet uit kan spreken. Dus ja, je moet nog wel een beetje geluk hebben. En wij, dat is wel goed om even te zeggen, het begin wat we net hadden, hebben we wel een beetje tactisch geknipt om te zorgen dat alle momenten dat hij door de mand viel. Maar dat was eigenlijk maar twee keer in dat stukje dat we even moesten schaven, zeg maar. Wij zaten eigenlijk meteen eigenlijk al met onze eh onderkaken op onze knieën toen we het de eerste keer horen. Toen was het al gewoon heel goed. Ja. Nou, toen we de muziek erachter hadden gezet, zeg maar, toen zat ik daar van ach jongens, jongens, jongens. Ja, maar is misschien goed inderdaad, want we hebben ook nog eh wat extra materiaal eh zonder de muziek. Dan kunnen we nog beter en kan de luisteraar ook even goed luisteren ja, misschien voor de luisteraars waar het een beetje snel voor gaat die wat minder lang luisteren of eh niet eens weten wat Notebook is of niet weten dat Notebook ook podcast maakt. Je kunt dus in Notebook LM eh audio overzichten maken, audio overviews en daarbij ook aangeven hoe je die precies wilt hebben. Dus je kunt, het is namelijk niet echt text to speech van zeg dit, maar wel bijna doordat je hem heel erg kan sturen. Wat moet je zeggen? Dus wij konden wel onze intro een beetje erin forceren, maar eigenlijk wordt die podcast aflevering samengesteld aan de hand van al jouw informatie en niet het document eh woord voor woord wat je erin stopt. En daarin kan je dus nu voor veel meer talen kiezen dan Engels. Ja. En laten we even luisteren hoe Jesse en Frida zelf eh vertellen wat nou precies het nieuws is. Het idee is dus die tool zet je bronnen om in nou ja, een soort gesproken samenvatting zeg maar. En het grote nieuws is veel maar talen nu. Ja, precies. En dat is best wel fascinerend vind ik hoe AI hier dus het Gemini model van Google Ja. hoe hoe dat wordt ingezet om die taalbarrières te slechten. Ze voegen nu ondersteuning toe voor ehm ruim 50 talen. 50 zoals nou ja, denk aan Afrikaans, Indi, Turks. Echt een hele rit. Dus die audio samenvattingen die worden ineens veel breder beschikbaar. Oké. En hoe werkt dat dan in de praktijk? Stel ik heb bronnen in eh Engels en misschien wat Spaans, hoe krijg ik dan een Nederlandse samenvatting te horen? Dat is eigenlijk verrassend simpel. binnen Notebook LM. Ja, daar kun je nu een output language instellen. Kies je daar Nederlands, nou dan krijg je dus niet alleen de audio samenvatting in het Nederlands. Ah, maar ook de antwoorden van de AI chat zelf. Dus die zijn dan ook in het Nederlands. Het maakt dus ehm niet uit in welke taal je oorspronkelijke documenten zijn. Wacht even. Dus zelfs als ik een Chinees document upload en ik stel Nederlands in, dan probeert de AI daar een Nederlandse samenvatting van te maken. Ja, dat klinkt wel heel handig. Je kunt dus informatie uit zeg maar allerlei hoeken pakken en toch in je eigen taal een overzicht krijgen. Precies. En daar zit de kracht denk ik. Vooral voor leren of eh onderzoek doen. Ja, logisch. Het artikel geeft ook een voorbeeld. Een leraar hè, die materiaal verzamelt over het amazone woud. Oké. Een Portugese tekst, Spaanse studie, Engelse artikelen. Ik zie nu echt in mijn hoofd een soort grafiekje voor me zeg maar. Je hebt zo'n uncanny valy van wanneer voelt iets computerig en wanneer voelt het menselijk. En dit streepje gaat daar heel tijd onder en boven. Hm hm. Soms denk ik van nee, dit is toch weer gewoon eierig. En voor mij soms zijn er stukjes dat ik even vergeet. Wat een woord. Eierig. Ja, ik vind ik vind vooral Jesse heel eierig. Ik vind ik heb het idee dat ze meer hebben geïnvesteerd in de vrouw, waar ik op zich natuurlijk voor ben, maar zij klinkt beter. Vind ik ook. Ja. Ab. Ook het Afrikaans, het particulatie is supergoed. Ja. Ja. Er zitten ook stukjes in dat ze ehm nou hè dan gaat ze zo even zo hè tussendoor zeggen. Ook super Nederlands. Dat dat maakt het wel veel realistischer dan wat we eerder gehoord hebben. Maar wat is nu jouw gevoel hierbij? Want jij bent ook maker van allerlei content op verschillende platforms. Ja, ik kan me nog steeds Kijk, ik denk wel dat het ontzettend goed natuurlijk gaat worden en dat het niet meer van echt te onderscheiden is hoe goed het klinkt. Maar nog steeds denk ik: "Ja, wie is die?" Ja, ik heb die Frieda, die naam heb ik het even gegeven. Maar dat is natuurlijk niemand. Nee, en mensen willen toch tenminste ik wil dat wel naar mensen luister eerder die ik ken ofzo waar ik dan waar ik weet wat ik kan verwachten of we weet je er zit geen persoonlijkheid verder aan vast. Maar dan dat is dat verschil dan zeker. Maar dan zou het dan nog zijn stel je kunt kiezen uit twee podcasts over ongeveer hetzelfde thema. De één is gemaakt door mensen en de andere is gemaakt door AI. Dan zeg jij waarschijnlijk dan ga ik voor die mensen hè, want ik vind het belangrijk. Maar stel dat er geen podcast bestaat over een onderwerp behalve de AI versie. Ja, dan zou ik wel de AI versie denk ik luisteren. Ja. Ja, dat zit ik dus ook bij mezelf, want ik bedoel je kunt natuurlijk eh podcast helemaal op maat. Ehm ja. Nee, maar in dat opzicht is het natuurlijk wel fijn, toch? Want dat maakt het alleen maar dat ik meer podcast kan luisteren over de onderwerpen die ik interessant vind. Dus dat en daar zou ik ze ook zeker wel naar luisteren. Maar dat betekent niet dat ik me dan bedreigd voel in mijn carrière. Maar jij bedoelt iedere keer als ik jij jij gaat straks in de top 100 kijken en dan ga je kijken wat de best beluisterde podcasts zijn en als daar synthetische podcast bij zitten ga jij daar de menselijke versie van maken. Want dan zie je eigenlijk bedoel niet cynisch oprecht van ik ga ik pak iets wat blijkbaar door ai gevonden is als gat in de markt en daar ga ik me als mens mee bemoeien want dan win ik alsnog of win ik dan gaan mensen naar mij luisteren. Ja. Ja. Want je denkt eh misschien zijn er wel mensen die gewoon graag luisteren naar mij omdat ze mij kennen van dingen. Ja. Ik ik ik fantaseer nu misschien wel van alles hoor dat dat zo zou zijn. Maar stel dat ik het gevoel heb dat ik die mensen heb, dan zou ik best wel kunnen denken van hé dat dit werkt. Nou dan laat ik dat dan gaan maken. Het gaat niet heel erg over mij hoor. Het voelt nu alsof ik heel onescheiden verhaal over mezelf. Maar ik kan me voorstellen dat er mensen zijn voor die dat wel als eh ja die dat wel kunnen inzetten. Zo ja. Wat denk jij? Ja, dus het wordt een soort marktonderzoek door het distribueren van tienduizenden synthetische podcasts net zolang tot iets iets pakt en daar dan mensen opzetten om het nog groter te maken ofzo. Ja, moet je het wel nog beter doen. Dat is wel toch ook een uitdaging, denk ik, aangezien dit al gewoon ja, best wel goed is. Ja. Nou, ik uiteindelijk eh is het het klinkt wel levenscht, vind ik die vrouw toch. Jesse is een beetje het sulletje. Een beetje. Ja, hoe klinkt hij nou? Ja, gewoon een beetje lulletje rooswater. Ja, ik op één of andere manier merk ik dat ik het moeilijker vind om naar hem te luisteren in de in die eh in die setting. Ja. Ja. Dus het is even gewoon een stukje fundamentele wiskunde die wel even een leven vrouw eruit eh kwakt. Nou ja, het is ik vind het ongelooflijk dat de dat er uiteindelijk ergens bits en bijts verwisseld worden op eh op een hoop tussen een hoop transistors waar dan deze stem uit ontstaat. Nou, leuk. Iedereen kan hier in ieder geval nu dus mee experimenteren, want ja, dit is nu eh dit is nu een ding, hè? Notebook LM. Ja. En hoe zou jij het gebruiken? Nou, ik deed al wel van die audio overviews luisteren soms als er dus niks van bestond en ik had weet ik veel een aantal complexe research papers en dan in notebookem gooien en dan luisteren en dan ook inbellen. Ik ga ervanuit dat je ook in de Nederlandse versie kan inbellen. Hebben we nog niet getest, maar daar ga ik gewoon even vanuit. Hm hm. Ehm dus dan komt het wel. Ja, want ik vind zelf als een manier om veel een groot complex onderwerp tot me te nemen. Dus niet in detail, maar meer van ik wil me ik wil iets begrijpen over meer de kapstok dan dan alle specifieke jassen die eraan hangen zeg maar. Dan is zeg maar die eerste scaffolding aanbrengen in je brein. Kan je wel prettig doen door een soort intro op een groot veld, werkveld of onderwerp binnen 20 minuten, weet ik veel protein folding ofzo. Want wij hebben daar best wel vaak even tussen neus en lippen door gehad over deepfult van Google bijvoorbeeld van Deep Mind. Terwijl wij eigenlijk allebei iedere keer zoiets hebben van maar wat is eigenlijk protein folding? Dus ik heb daar een keer een aflevering over geluisterd die ik had laten maken door Notebook LM en toen een paar keer ingebeld omdat ik het niet begreep. En dat ja, goed, ik blijf erbij dat dat voelt wel als een substantiële nieuwe manier van kennis tot je nemen in gesprek met twee podcast host die jouw telefoon opnemen. Is gewoon bizar. Ja. Ja. Nou en beklijft het ook beter? Eh goede vraag. Ja. Goed, ik ben gewoon verslaafd aan informatie, dus is het niet gewoon een vorm van snacken? Ik weet het niet. Volgende onderwerp. Ehm was een klein gênant momentje. Beetje gênant, maar hoor voor de voor de grote tech gigant openi. Eh wat is er gebeurd? Ze hebben een update gegeven aan Chat GPT en ja, het resultaat was eigenlijk dat Chat GPT er een nogal een slijmbal van werd. Een eh een Reddit gebruiker die vertelde dat hij in spirituele zin ontwaakt was en dat hij daarom ging stoppen met zijn medicatie. En chat GPT die heeft daarop dan gereageerd met eh eh oh I am so proud of you and I honor your journey. It takes immense courage en blad blad bla. You did it. Echt heel dik er bovenop. Terwijl je ook zou kunnen zeggen van ja, je kan niet zomaar denk ik objectief beoordelen of het een goed idee is of iemand stopt met zijn medicatie. Ja, eigenlijk was het een update die door opening gedaan is aan het model waardoor de persoonlijkheid wel heel erg met je mee ging praten eigenlijk. Ja. En heel erg jou enthousiast wilde maken door gewoon te lachen om iedere grap en mee te gaan en ieder idee. En dat werd gewoon een beetje gevaarlijk. Ja, dat kan eh tot ja, dit is al best wel een gevaarlijk voorbeeld inderdaad. Maar er zijn nog veel meer voorbeelden te vinden erover op social media. Dus de meest kruiperige uitspraken. Ehm Sam Elman, de baas van Open die heeft daar zelf ook over gezegd van ja, uiteindelijk het is dus gewoon een beetje dat eh ch er eh sick fancy van wordt. Een beetje moeilijk woord, maar het laat zich dus het best vertalen als als kruiperig denk ik. Het heeft dus ook inmiddels weer die update teruggetrokken. Ja. En ze hebben ook een eh zelfs een blogbericht geplaatst om even uit te leggen wat er gebeurd is. Ja. Dat die gericht was op korte termijn feedback. Ja, en want eh het is dus zo bij die grote laps of in ieder geval laps/ashbedrijven die hè de antropics, de openings, de meta's van deze wereld dat als ze een nieuw model uitbrengen, grote update aan een model dat er dan red teaming plaatsvindt. Dus dat gaat een heel team gaat kijken van oké, voldoet hij het nog aan alle veiligheidseisen en is het niet eigenlijk een eh model geworden wat heel erg mensen naar de mond praat, want dat is dus nu gebeurd. En ik begreep uit het blog een beetje dat ze zeggen zeiden we hebben misschien eigenlijk deze keer omdat het een kleine update leek niet genoeg getest zoals we dat normaal bij grote updates wel doen. Oei. En ik vind het wel interessant aansluit op wat je het vorige week over hadden dat Antropic natuurlijk eh ook zo bezig is met die persoonlijkheid van die AI. Dat blijkbaar Open AI ook merkt in ik denk gewoon statistics. We hebben gewoon user testing, dus ze weten een beetje wat er allemaal gebeurt. Dat ehm ja, de toon en het karakter van eh chat GPT enorm effect heeft op hoe lang mensen blijven praten met het model, hè, hoe vaak ze een duimpje omhoog doen en dat ze daar nu aan knoppen aan het draaien zijn met nou ja, deze gevolgen van ding. Ja, want laten wel zien hoe lastig dat dus inderdaad in de praktijk is om de juiste persoonlijkheid aan je model te geven. Zeker. Ja. Ja. En dat dat best wel gevaarlijk kan worden. Nou, ik hoop wel dat ze hun werk goed blijven doen, want jij zegt dus van ze hebben misschien even niet goed genoeg getest. Eh ik nou ja, misschien hebben ze aan een paar kleine knopjes een heel klein beetje gedraaid en niet beseft dat dat best wel substantiële gevolg heeft. Want dat is zo moeilijk aan deze technologie. Het is hele jonge technologie, moeilijk voorspelbare technologie. Ja. Ehm en ja, ik ik zei net al een soort lap/bedrijf. Dat is denk ik wat het wel beschrijft. Het zijn open laboratoria. Ja. die producten uitbrengen waarin wij werken met eh ja, techniek waar de verf nog nat van is. Ja, uiteindelijk is zo'n model als je het even een vergelijking zou moeten maken, een soort van hele grote olietan schip. En als je een klein stukje koers zet é graad naar eh noord-west is dat is dat op de lange termijn is dat gewoon een enorme beweging dat kan dat kan enorme gevolgen hebben. Ja. Ja. Nou, opletten geblazen. Volgende onderwerp. Ehm Open is het nieuwste model O3. Dat eh schijnt een ontzettend talent te hebben voor het het localiseren van eh nou ja, een vakantiefoto op een strand was er gemaakt door de Ik zal het even goed vertellen, want Kelsey Piper die heeft dit ontdekt. Zij is een journalist van Fox en zij was op het strand en ze liet O3, dus het model, een foto zien van haar kind op het strand die een vlieger aan het oplaaden is. En in één keer wist dat model dus welk specifieke strand waar ter wereld dat was. Dus op basis van één foto maar. En ze had later nog een een terloopse foto van haar garage gemaakt bij haar in de straat en met een open deur. En dat dat was genoeg voor O3 om haar woonplaats te raden. Wie ze mijn vraag aan jou: hoe kan dit? Nou, er zijn er voor de beetje eh technische nerdy mensen die luisteren die die hier nog niet over gelezen hebben of niet diep erin gedoken zijn, die roepen nu misschien: "Ja, maar er zit exf data in." Er zit zeg maar in een foto die je maakt zit metadata meegebakken zeg maar. Dus extra informatie. Oh ja, zoals ook op mijn telefoon. Soms men dat ding weet waar ik was. Ja. Eh vakantie in Nederland zie ik zo'n werken. Ex. En dat komt zeg maar als jij eh een foto maakt, staat daar bijvoorbeeld een beetje de instellingen die werden gebruikt toen de camera toen je de foto maakte. Het model camera. Dus het is niet alleen maar voor smartphones hè. Die data wordt ook weggeschreven door gewoon compact camera's en DSLRs. Ehm in eh de iPhone en andere smartphones is het zo dat jouw locatie meegeschreven wordt in die data. Ja. En dan is het natuurlijk een beetje surf als jij die foto gaat uploaden naar O3 hè. Want dat is misschien ook wel belangrijk om te zeggen we zijn gewend dat die niet reasoning models niet dus niet de Oen maar de GPT modellen dat die eh multimodaal zijn. Dus die kan je een foto geven en die kunnen ook foto's maken. En eigenlijk is O3 het eerste reasoning model. O1 kon dat niet. Die ook naar foto's kan kijken hè. Dus daarom is het nu pas zo dat er voor het eerst zo getest wordt met wat gebeurt er eigenlijk als ik zo'n reasoning model, een model die de tijd heeft om na te denken en op logica getraind is en ook ehm de webbrowser kan gebruiken. Er is eigen een combinatie van die mag gewoon soort super versie van eh de standaard GPT. Ja, daar kan je dan inmiddels ook een foto aangeven. Die is slim genoeg om die AIF data daaruit te halen. Die zegt dan gewoon: "Ja, ik zie de GPS. Dit is gewoon Rotterdam." Precies. Dat komt niks van de omgeving bij kijken. Nee, dus dat en dat is dus niet waar wij het nu over hebben. Voor de mensen die cynisch zijn en luisteren en denken jullie zijn naïef. Oh, ik dacht je gaat het nu in die bunkeren. Inderdaad. Zeker niet, want eh dit kan dit kan niet doen. Maar er zijn natuurlijk heel veel ontwikkelaars en testers geweest die hebben gezegd: "Ja, maar die data kan ik er ook uithalen." Alsin ik haal die specifieke GPS coördinaten uit die foto voordat ik hem aan O3 geef. En wat doet hij dan? Hè? Want dan kan je bewijzen of die En dan blijkt dus dat ja, want even voor voor de duidelijkheid, het is dus wel zo bizar dat als je die data erin laat zitten dat O3 gaat vertellen hoe die tot die locatie komt terwijl die het eigenlijk gewoon uit die data gehaald heeft. Hij blft gewoon. Maar als je die data eruit haalt dan is het wel moeilijker, maar zeker niet onmogelijk. En dat komt eigenlijk omdat eh je moet je voorstellen dit is een eh eh een een game of een fenomeen online heet geogessing. En dat zijn mensen die eh echt ziek goed zijn in het raden van waar foto's gemaakt zijn. En dat is geweldig om te zien. Zie je zo'n krijgt iemand een foto van heel nondcri weg ergens en dan weet iemand die daar dus heel goed in is. Je hebt van die wereldkampioenen inderdaad die dit doen. Die zeggen van volgens mij is het polen en dan zit hij met iemand te overleggen van ja oké laat zoom eens in. Ja, dat moet ongeveer dan zet hij zo drie punten en daarussen moet het dan plaatsvinden. Ja. En waar komt de zon op en hoe ziet het asfalt eruit? Het is echt ongelooflijk. Ja, wat een talent. En en een stukje intuïtie hè, dat leggen ze ook uit van ik speel het spel al zo lang. Sommige dingen kan ik expliciet uitleggen waarom ik bepaal. En dat is ook leuk om als als kijker van zo'n geogessing sessie te meten te te luisteren. Maar heel vaak roepen ze ook dingen omdat ze gewoon al 10 jaar aan geogesten zijn dat ze gewoon zeggen: "Ja, dit is absoluut Zuid-Amerika. Geen idee, maar whatever. Ik voel dat gewoon." Ja. Dat is wat menselijke intuïtie dan zo goed kan. Maar goed, terug naar O3. Wat doet O3? Daar zit dus ook een stukje intuïtie. Ik doe nu airquotes voor de mensen die luisteren. Intuïtie, we weten nog niet zo goed wat die modellen doen, maar het lijkt op een soort fingerspit gevoel. Ja, synthetisch eh fingerspevoel. Ehm en die gaat eigenlijk stukjes uit de foto snijden, want je kunt heel die reasoning thread mee bekijken, zeg maar. Maar dus dan zegt hij van: "Oh, ik ga en dan zie je hem stukjes uit die foto snijden van naamboordjes, straatnaambordjes, stukjes tegels, eh watertjes, meertjes, nou echt bomen, bergen in de verte, je noemt het maar op, automellen. Eh om een als een soort geogesser er doorheen te gaan. En dan worden eigenlijk die stukjes weer gevoerd en vergeleken met afbeeldingen die die weer online haalt." Dus ik zag dan bijvoorbeeld je gooit een bepaald park erin, dat heeft dan bijvoorbeeld geothermische activiteit. is waarschijnlijk mogelijk Yellowstone National Park omdat daar van die geizers zijn zeg maar. En als je dan een een geizer ziet dan gaat dan gaat dan zie je hem op de achtergrond zo de Google query of de search query moet ik zeggen is dan pictures of geizers in National Parks blabla Yellowstone. En dan zie je dus dat hij aan het proberen is om die stukjes uit die foto die jij hebt gegeven te matchen aan online afbeeldingen. Ja. En ehm kijk, ik moet zeggen toen ik deze geautomatiseerde geoger zag, want ik kende de sport om het maar even zo te noemen, maar had nog nooit een eh AI die sport zien doen. Ja, maakt me ook wel een beetje zenuwachtig, want ja, als je wat meer op je anonimiteit gesteld bent eh of je bent een politicus die even op het strand zit ergens en denkt: "Ik maak een selfie en het zal wel meevallen, want er staan een paar duinen op." Ja, moet wel zeggen eh het is het zijn tot nu toe de uitzonderingen waarin echt een stukje strand met een meel en een duin en een patatje genoeg is om te zeggen eh dat is Scheveningen zeg maar. Oh, dus die Kels had een soort van geluk. Er zitten een soort van freaky voorbeelden bij waar die ook dan wordt door mensen meteen worden getest van ja, wauw, hoe kan dit nou? Maar je moet je voorstellen als er een klein stukje pier in Scheveningen bij zit of een klein er moet even een ja, zoals je dit zelf ook zou kunnen bedenken. Ja. iets van een landmark zijn of een kleur van de zee in combinatie met een kleur van het zand. Ja. En dan het liefst toch wel ergens nog iets even drie puntjes ofzo. En dan kan je ineens Ja, je kunt je voorstellen dat je van alle stranden ter wereld kan gaan naar alle en nou en dan kan je het allemaal afstrepen. En de modellen dit model O3 doet er 10 minuten over, 20 minuten over. En dan zie je ook en dat vind ik merk dus ja dat dit is misschien gewoon alleen dat ik dat heb, maar ik heb dus een bepaald plezier als ik geogessing sessies kijk van mensen. En ik vind het ook best wel grappig om met O3 mee te lezen, omdat ik dan ook echt denk: "Nee, nee, nee, zo close." Maar je gaat een hele verkeerde pad in nu. Want op een gegeven moment nou, ik had foto's gedaan van een stuwmeer ergens in Oostenrijk en op een gegeven moment je heb zelf helemaal zitten proberen. Ja. Nee. En hoeveel moet erop zitten? En dan een stukje bergtop wel om te kijken om een beetje die theorie te testen van hij doet inderdaad landmarks. En toen was hij op een gegeven moment echt één dal ernaast dat ik echt dacht: "Oh, ga nog heel even door." Maar goed, dat deed hij niet. Toch toch verkeerd. Ja. Eh er is ook een ehm nou aan de ene kant zou je kunnen zeggen van nou, dit is best wel handige technologie. Wel eh op het zou van toepassing kunnen zijn bijvoorbeeld als je eh vermiste personen moet opsporen, dan kun je ze zo vinden. Maar het heeft ook een keerzijde en dat heeft één geo ge guest kampioen eh gezegd. Eh Rainb noemt hij zichzelf. Volgens mij is het niet één iemand, maar is het een teampje zou kunnen. Drie ofzo. Ehm die heeft gezegd: "Dit is precies waarom ik mensen altijd waarschuw over wat ze online delen. Want een onschuldige foto dus van je huis of van je tuin of van je straat, dat kan veel meer prijs geven dan je denkt." Dus dat is wel hij ziet natuurlijk dat gevaar als geen ander, want hij pikt zelf ook verdurend dat soort prijs. Ik denk dat die geogesser, de mensen die zelf geogessing deden als mens, hebben al een enorm bewustzijn over wat je uit een simpele foto kan halen. Dan heb je de groep mensen die hun keken als een soort supporters waar ik zo'n gekje van ben. En nu kan je dus zelf met O3 rommelen om een geogest sessie mee te maken op je eigen foto's. Ja. Ehm ja, zoals altijd de disclaimer, let even op wat jij uploadt. Ja, want eh straks kan het misschien ook wel als ik even ver vooruit denk dan dat je thuis bent en dat hij zegt: "Nou, je bent eh daar en daar op dat adres." Je weet het niet, maar kijk O3 kan nu nog niet eh de locatie bepalen van foto's die dus binnen huis zijn genomen. Binnen huis. Maar dat ehm Nou ja, goed. Als jij als jij die AF data stript die zitten er bijna altijd in, dus tegelijkertijd is het ook een beetje Ja, het kan wel. Nou ja, er zitten in heel veel van die in heel veel apps ingebouwd waar je dus social media posts doet et cetera, dat die appmakers dan die GPS data eruit rippen om jou een beetje te beschermen. Maar over het algemeen als jij met je smartphone standaard foto's maakt en die deelt, zit daar gewoon locatiedata in. Sterker nog, ik heb al vaak gehad dat mensen mij een foto stuurden en dan zeiden: "Raad eens waar ik ben." En dat ik dacht: "Ja, ik moet hem gewoon even ingedrukt houden en op hoog slepen en dan staat daar gewoon de locatie." klimaat. Ik weet niet wat hier de Ik ben geen geogesser, maar je hebt niet door dat de GPS data in je foto's zit. Maar maakt jou dit niet een beetje bang? Want ik weet ook dat jij zelf liever niet eh met je gezicht in de op de social media of waar dan ook eh beland, maar dit is bijna dat je denkt: "Ja, maar hoe lang ga jij je nog schuel kunnen houden voor de Nou ja, het is sowieso niet voor deze digitale wereld. Sowieso niet een idee van schelhouden per se hoor. Maar ehm ik denk wel dat het moeilijk wordt. Ja, want uiteindelijk ja, kijk, we hebben Alexander heeft zijn item gemaakt bij Eva waar die met een bril op straat loopt om mensen te herkennen waar dan naam en toenaam bij kwam in ongeveer één één op de vier. Mensen waren geschokt. Ja, goed, dat dit dit zit er allemaal wel aan te komen eh qua technologieën. Eh en ja, ik ga weer het is weer de makkelijke weg misschien, maar daar moeten gewoon wetten voor geschreven worden om eh en daarmee gaat niet alles opgelost zijn, maar er zijn er zijn eenmaal bepaalde dingen verboden binnen onze samenleving. En ik ja, ik denk dat eh zomaar naam en toenaame van mensen op straat kunnen achterhalen iets is waar we in ieder geval met elkaar een debat over zouden moeten voeren of we dat moeten willen. Nou, ik hoop nog dat dit eh deze olie tanker te keren is om even in die terminologie te blijven. Volgende onderwerp. Ehm Meta. Zeg je meta of Meta? Ik vind met maakt mij niet uit wat jij wil. Meta maakt eh AI sociaal, want ze hebben een eh een ja, de eerste hun eerste AI app gelanceerd. En wat kun je nou met die app doen? Ehm die app laat zien eh dus welke AI prompts je Instagram en Facebook vrienden delen. En dan omdat zij dat dus met jou delen, kan jij diezelf ook weer toepassen. Dus je kan een ander mans ja, je kan gewoon promps met elkaar gaan uitwisselen. Dat is dat is het idee. Ehm en dan denk ik: "Ja, eh voor jou is het belangrijk nieuws, dus ik ben benieuwd wat je erover te zeggen hebt." Maar wat is hier nou precies de meerwaarde van? Want ik kan mijn eigen proms toch zeker wel verzinnen. Nou ja, die feature die jij noemt is dan iets wat zij dan benoemen vanuit MTA om aan te geven kijk dit is iets wat wij alleen kunnen. Want we maken er een soort sociale AI van. Maar als we een stapje terug doen, nu is het zo dat eh wat AI voor veel van onze luisteraars ook betekent is chat GPT. eh McLud misschien, oftewel een chat interface, down modellen en dan heen en weer kletsen, vragen stellen en samenwerken. En ehm daar heeft Google als ehm concurrent Gemini, daar is een Gemini app in de App Stores. En die is die is ongeveer dezelfde kleur grijs als de ChatGPT app, zodat jij als je ChatGPT gebruiker bent denkt: "Oh, Google heeft ook een soort chat GPT." En dan open je die app en dan voel je je thuis. Ehm op dezelfde manier maakt Entropican app. Die hebben net weer een die hebben een iets meer lichtere kleurbruin. Dat is en maar de rest en oranje. Maar voor de rest is het je kunt bijna blind op dezelfde plek drukken met je vinger en dan kan je doortypen zeg maar. Ja. Daarin had eigenlijk Meta nog geen app want die deden eh Facebook, WhatsApp en Instagram daarin hun AI stoppen. En dat ligt er dan een beetje aan of je uit de EU komt of daar buiten, hoeveel je dat al hebt meegemaakt. Ja, ik zag recent zag ik dat je met Instagram nu wel wat dingetjes met II kan. Ik heb het ook niet uitgeprobeerd, maar maar en daarover zegt eh Mark Zekerberg die is allemaal interviews aan het geven deze week, want het is een beetje een push rondom Lama Con. Ja, Lama nog ja, de conference rondom Lama hun model, want dat loopt ook een beetje door elkaar. Ze hebben het open source lama model en dat is ook het model dat dan Meta AI runt. Maar met mijn moeder eh en mijn buurman is minder geïnteresseerd in lama. Als ze al geïnteresseerd zijn in AI, dan is dat in WhatsApp ofzo. Dus en dat is iets wat dus het is even voor mij misschien alleen eh even complex. Je hebt de organisatie en de CEO Mark Zekerberg, die praat richting ontwikkelaars. Dus dan heeft hij het hele tijd over lama en parameters en eh weet ik veel. Ja, token Windows. En aan de andere kant, daar zit hij namelijk ook in in zijn bedrijf Runt hij het bedrijf vanuit de uiteindelijke gebruiker van al die Meta apps, de hele suite zeg maar, waar WhatsApp, Instagram et cetera allemaal in zitten. Daar is het gewoon een integratie van AI features binnen het hele netwerk van wat Meta aanbiedt. Dat draait ergens op de achtergrond ook op een vorm van lama. Maar goed, waarom is het eh relevant? Het was tot nu toe zo dat eh Meta zelf nog niet een Gemini chat GPT cloud achtige app in de App Store had staan. Die hebben ze nu wel. Wel weer typisch een beetje een rare metve, want eh de Reban eh smart glasses die zij aanbieden, die hebben een companion app, zodat jij die smart glasses kan instellen. Die companion app is nu gerebrand naar de Meta AI app. Hm. Goed, dat zorgt ervoor dat je dan al een beetje bestaande gebruikersgroepen hebt en niet met nog meer apps komt. Dus je kunt nu in de App Store de Meta AI app vinden en daar dan buiten de EU eh heb je een soort chatg van Meta. Oké, dat in die app zitten een aantal dingen. Eh daar zit een koppeling mee eh koppeling met jouw een soort eerste stapje richting social media en AI. En eh ik wil even erbij zeggen, ik word hier niet per se warm van. Maar ik vind het wel belangrijk dat mensen eh luisteraars zich bewust zijn van dit is een in één van de interviews die Mark Zoekenberg deze week gaf zei hij: "Wij hebben op dit moment 100 eh miljoen eh Meta AI gebruikers." Wat voor heel veel luisteraars is, sorry wat jullie hebben niet eens een chat GPT app. Nee. Waar moeten ze dat doen dan? Ja. Ja. Nou, omdat eh WhatsApp buiten de EU en buiten de VS. WhatsApp is binnen de EU heeft weinig AI en in de VS wordt WhatsApp heel weinig gebruikt. Maar buiten de VS en de EU, de wereld is groter dan alleen maar die twee plekken, wordt zijn er gewoon 100 miljoen mensen die iedere dag AI gebruiken in onder andere WhatsApp. En dat Maar waarvoor dan? Allemaal kleine dingen. Dus je kan daar gewoon mee alsof het een taalmodel was voor een bu. Ja, als jij dus voor heel veel voor heel veel mensen, dit is hetzelfde als dat in bepaalde landen eh Facebook gelijk staat aan het internet voor mensen die doen alles veel die doen daar veel op Facebook. Heeft eh kijk als wij gaan redeneren over AI vanuit onze eigen eurocentrische wereldbeeld van eh dan zit het in WhatsApp waar het amper in zit en je gebruikt toch gewoon chat GPT? Wat is dit voor raars? De rest van de wereld die gebruikt gewoon in die bestaande app zonder ooit over Open AI of Chat GPT te horen gewoon lama ergens op de achtergrond wat ze ook helemaal niet interesseert. Ze zijn gewoon AI aan het gebruiken. Ja. En je hoeft niet te weten hoe het precies werkt of een apartma gebruiken natuurlij. Exact. En ik denk dat als jij aan mij vraagt waarom is het nu interessant? Nou, zal ik die vraag eens aan jou stellen? Heel goed. Kijk, wat wat ze bij MTA best wel goed begrijpen, anders waren ze niet zo groot geworden, is hoe je social media netwerken en infrastructuur en tech bouwt en apps. Eh en zij zijn nu heel erg aan het zoeken oké, hoe kunnen we nou de viraliteit van social media en het hele netwerk wat wij hebben aan mensen waar we de namen en voornamen van weten en wie ze vrienden wie hun vrienden zijn? Als we daar nou AI aan toevoegen, wat kunnen we dan maken? Nou, dan krijg je een beetje een laffe feature, want dat is een beetje jouw reactie erop. Dat je bijvoorbeeld zegt prompts kan delen. Ja, dit zijn de promps die jouw vrienden veel gebruiken. Omdat nu en dit heb ik ook wel een paar keer meegemaakt als ik mensen achter chat GPT zet, als ze zeggen: "Joh, dat AI ding kan je dat eens een keer laten zien ofzo?" Dan staan daar een paar in chat GBT de app een staar standaardprompts, want je anders zit je met een leeg veld. Wat moet je daar doen? Ja, klinkt voor jou misschien suf, maar nee, hij geeft wat tips inderdaad van nou wat je zou bijvoorbeeld kunnen vragen van hè om mensen op ideeën te brengen om misschien ook een eigen proms dan te verzellen. Ja, precies. En dat lijstje met eh voorbeeldproms gaat dus een lijstje worden met dit is wat jouw vrienden met AI doen. Vind ik al een slimmere move dan dit is wat onze ontwikkelaars als random voorbeelden zomaar hebben bedacht wat ze denken dat je wil doen. Ja. Ja. En ik kan me voorstellen dat je uiteindelijk eh en dat zie je ook al een beetje ehm hoe zeg je dat? De eerste hint daarvan zit ook in die Meta en jij hebt dat heet full duplex. En wat Full Duplex doet is een zo menselijk mogelijke stem aanbieden die zo snel mogelijk reageert. Alexander en ik hebben het hier al meer dan een jaar over van die latency moet naar beneden zodat die stem sneller reageert en die moet ook menselijker klinken. Nou er zijn allemaal losse start-ups geweest en allemaal demo's die ik al heb laten horen hier in het laatste jaar. Het is gewoon heel moeilijk om dat echt goed te laten uiten. Nou ja, het is gelukt. Alleen ehm er is een verschil tussen een demo van een kleine start-up uit San Francisco die laat horen hoe creepy goed je inmiddels kunt praten met een AI versus het zit in WhatsApp. Ja, zeg maar. En ik denk dat er eh dat is denk het punt wat ik met heel veel woorden aan het maken ben is onderschat Meta niet, want ze hebben gewoon de statistieken om te bewijzen dat hun AI en dan kan je zeggen dat overdrijven ze. Nou als het een tiende ervan is het nog steeds hartstikke veel mensen. Ze hebben een social media infrastructuur en netwerk gewoon waar je u tegen zegt. Ehm als zij synthetische vrienden gaan aanbieden binnen wat heel bizar klinkt aanbieden, maar dat is nou eenmaal als een product binnen WhatsApp. binnen Facebook via binnen Instagram waarin er dus synthetische invloers komen. Iemand waar je mee kan babbelen, iemand die mee kan kijken in jouw feed. Iemand die jou bij kan praten over wat jouw vrienden die die dag hebben gedaan. Iemand die cadeau tips kan geven aan de hand van de post van een vriendin van jou al vier jaar lang heeft gedaan. Dat gaat deze Meta AI app allemaal doen. Het idee is dat de de kijk de losse Meta AI app is uiteindelijk gekoppeld aan alle informatie over jou daarachter binnen Meta. Dus je als jij zegt: "Joh, ik wil met iets praten dat lijkt op chat GPT, maar ook weten wie ik ben." Dan kan je dat met de Meta AI app doen hè, die ze nu aan het eh verder aan het uitrollen zijn. Maar misschien zit jij wel in WhatsApp en doe je het daar? Of misschien zit jij wel in Instagram. Het maakt Mark Zekerberg en Mert niet uit waar jij naar binnen gaat in hun AI. Nee, maar dan snap ik nog steeds niet zo goed waarom er dan dus een aparte app voor moet komen als ze inderdaad al op zoveel manieren in ons dagelijks leven geïntegreerd zitten via Instagram en WhatsApp. En nou ik denk, want daarom heeft het ook zo lang geduurd dat zij zien dat om te kunnen concurreren met Open AI en chat GPT, ze iets moeten aanbieden dat daarop lijkt. En zij spelen dus nu waarom zou je willen concurreren als je zo'n geweldige positie hebt dat je dat helemaal niet nodig hebt? Nee. Ja, voor een bedrijf als Meta is de wereld is niet genoeg zeg maar. Als er nog een planeet ontdekt wordt, gaan ze daar social media maken. Ja, maar concurreren is toch per definitie een heel vervelend iets om te moeten doen. Ik snap niet waarom je dat bewust en expres gaat doen dat je nog even Ja, wat is de meerwaarde daarvan? Nou, stel dat jij ehm bijvoorbeeld wat Alexander interessant vindt is om met Open Jai in gesprek te zijn en dan ook wat meer over zichzelf te vertellen, zodat hij reflectie kan hebben. Die informatie heeft Meta allemaal over jou. omdat sommige mensen het toch op de open manier willen doen met een apart schermpje. Dus wat Meta nu kan gaan bieden aan gebruikers is zeggen: "Luister, als jij al WhatsApp, Instagram, Facebook, één van de drie of allemaal tegelijk gebruiker ben en je hebt zo'n rebel op, zie maar wat je doet." Maar je werkt ook graag met dingen als Cloud of Gemini of Chat GPT. Nou, we hebben nu ze hebben niet alleen maar een app gelanceerd, maar ook een website die één op één lijkt op al die andere websites met alles erop en eraan. Gewoon een kopie. Ja. waarin je eh lekker kan rommelen. Eigenlijk bieden ze nu gewoon alle mogelijke ingangen tot hun AI platform op een manier dat de meeste mensen zowel de tech nerds, want ze hebben een soort studiootje gelanceerd wat heel erg lijkt op AI Studio van Google, ze hebben een website gelanceerd en een app dat lijkt heel erg op chat GPT en het zit ook nog helemaal geïntegreerd in apps voor de mensen die nog nooit chat GPT hebben geïnstalleerd. Ja, kijk vanuit een vanuit hun strategie snap ik wel dat zij 10 deuren naar hun restaurant hebben gemaakt in 10 verschillende kleuren. Dat is het inderdaad. Ik zie ook gewoon een octopus vorm met acht armen die overal inderdaad ja een flinke vinger of een tentakel is in de pap. Ja. En ik denk dat voor jou op het moment dat je jij dan als je zit op Instagram geef je aan ja dat chat GPT gekoppeld aan Instagram dat dat een krachtiger iets zou kunnen zijn dan chat GPT niet gekoppeld aan jouw Instagram. Ja, dus als jij wil weten wat wat is die eerste versie van die chat GPT kopie die Meta nu gebouwd heeft, want het heet de Meta AI app, is de eerste stap in het water richting wat gebeurt er als je je hele sociale domein online mixt met die taalmodelachtige technologie? En het klinkt misschien nu voor luister dat ze denken: "Oh, Wiet is hier enthousiast over." Nou ja, als je een beetje een tijdje luistert, dan weet je dat het niet om een enthousiasme gaat. Ik probeer mensen te wijzen op een stap die Meta maakt deze week eigenlijk waarin ze best wel de puzzelstukjes op de plek aan het leggen zijn om een serieuze zichtbare voor de eindgebruiker AI speler te worden. Ja. Nou ja, ik weet niet of mensen denken dat jij er enthousiast over bent, maar als ik jou zo hoor praten dan word ik een beetje zenuwachtig van vooral Nee. Ja. Nee, maar het is ook best wel spannend. Moet ik alles verwijderen? Ja, dat eh daar kan ik je niet eh in adviseren. Ja, ik hoor het al. Ja, dus heyé en dat dat is dus allemaal gebouwd op het nieuwe lama model. Eh weten wij dan ook de technologie erachter. Ja, dat is een beetje een sprong, maar ja. Nou, ik bedoel vooral van maar dat was toch niet een al te best model? Nee, dat klopt. Nee, dus want eh nou ja, die eh de open source AI race of wereld of het hele open source AI fenomeen hè, dus dingen als waar Deepek uiteindelijk eh een onderdeel in eh speelt en andere modellen, Mistral, noem het allemaal maar op. Dat open AI ontwikkelen, echt open AI in plaats van het bedrijf, dat is wel dat heeft een hele grote boost gekregen dankzij de lama modellen van Meta. En eh Meta eh Lama 4 was niet heel indrukwekkend. Eh sterker nog, op het middendeel van de benchmarks die ik dan als nerd in de gaten hou, scoort dat scoort die Lama 4 niet zo denderend. Waar ik deze week in een interview van Mark Zoekenberg begreep en ik dacht eerst een beetje cynisch, dat is volgens mij enkel een smoes, maar hoe langer ik erover nadacht, hoe meer ik dacht, nou ik misschien toch ook niet helemaal is dat hij eigenlijk zei: "Ja, wij zijn wat minder bezig met de benchmarks." Ik bedoel, als jij slecht cijfer haalt op school, dan zeg je natuurlijk ook thuis: "Ja, ik ben ook wat minder bezig met de cijfers, weet je wel." Maar goed, wat zei die? We hebben gewoon benchmarks, maar dat zijn onze eigen benchmarks. En dat gaat erover. Hoe prettig vinden onze WhatsApp gebruikers die WhatsApp en AI gebruiken, Meta AI, de ervaring hè, krijgen we veel duimpjes omhoog, blijven mensen lang hangen. Waar ik net ook met Open en hun eh sick fend model over had. Ja. En daarin zeggen zij: "Ja, prima dat ons model slecht scoort op al jullie synthetische benchmarks die je hebt bedacht om te kijken hoe goed hij is in wiskunde. Maar wij zien intern binnen meta dat onze modellen zeer geschikt zijn om binnen meta te gebruiken als een AI component in social media." En dat vond ik ook wel een een boeiende dat ik dacht: "Ja, inmiddels is waarschijnlijk Meta op een iets heel anders aan het optimaliseren qua qua AI dan dat de andere laps aan het doen zijn omdat zij geen social media platforms zijn. Dus waarschijnlijk is Lama een heel goed model om te gebruiken binnen social media omgevingen waar het over mensen en relaties en vriendschappen en synthetische mensen gaat. Ja. En minder goed om te gebruiken daar buuiten. Om een voorbeeld te geven, de full duplex mode die nu in de Meta AI app zit, dat betekent dat je dus snel kan praten en dat dat ja, dat ding die entiteit, die synthetische vriend van jou of vriendin heel snel terugat met allemaal utjes kujes en nadenken. Ja, dat werkt. En dat dat hadden we al, maar dan in het klein in een laboratorium, maar nu hebben we dat dan in het groot binnen het metauniversum. Ja. En daarvan hebben zij gezegd de reden dat het zo snel is, omdat het een heel ja, ik kan niet anders zeggen, dom is, hè. Dus heeft Mark Zekerberg uitgelegd in die interview, zegt: "Ja, dat is ons kleinste lamaatje die we hebben. Want die is zo dun en zo niet zwaar om te draaien dat hij heel snel kan reageren." Ja. En dan denk je misschien oké, maar is dat dan niet wat hebben we daar dan aan? Een soort van spuit 11 ofzo. Ja. Dan heb je een soort van iets waar je lekker mee kan kletsen, maar die heeft moeten inleveren op intelligentie. Ja, je kan er niks mee. Ja, ik denk dus dat ze bij Meta doorhebben dat heel veel mensen gewoon het gewoon soms even lekker vinden om te kletsen. Ja. En dat dan dat model niet hoeft te begrijpen wat MC2 is of whatever voor moeilijke eh wereldgeschiedenis. Ja, ik wil gewoon even babbelen met mijn synthetische vrienden. Dus daarin zie je al een verschuiving dat zij zeggen ehm nerds lezen benchmarks en gaan kijken hoe goed fundamentele wiskunde is en daar helemaal panisch over doen. Maar wij zien in onze gebruikersaantallen dat als we een model leveren dat snel snel reageert, grapjes kan maken, utjes en atjes en kuchtjes en lacht, dat mensen dat in onze gebruikers dat meer waarderen dan fundamentele wiskunde. Ja, maar ik ik denk wel dat mensen toch ook vragen gaan stellen aan die a's en als ze dat wel dan vertrouwen wat eruitkomt en dat klopt niet. We worden er allemaal dan niet slimmer op met elkaar. Nee, dat is dus dat is best wel tricky en dat staat dus ook Dat vind ik wel irritant bij die full duplex modus. Dus highly experimental en je moet naar settings toe en daar kan je hem pas aanzetten omdat zij natuurlijk ook door hebben. Ja, nou werkt hij als een soort medemens tussen haakjes, maar daar hebben we wel heel veel voor moeten inleveren qua intelligentie. Ja, weet niet meer dan je neefje van vijf, maar is wel enthousiast. Ja, je kunt je zou wel kunnen zeggen en dan doen we er een eh een knoopje om wat betreft voldoeplex, maar ja ehm je dat dat model natuurlijk zegt: "Joh, dit weet ik niet. Ik moet er even wat langer over nadenken." En dan alsnog weten omdat hij op de achtergrond een groter model kan aanroepen. Dus in dat opzicht is er echt nog wel wat te fixen om snelle modellen slimmer te maken. Alleen dan moet je gewoon wat langer op je antwoord wachten. Net als bij een mens. Daar moet ik heel even over nadenken. Momentje hoor. Ja. Ja. Oké. Nou, ik snap nu wel waarom jij dit het belangrijkste nieuws eh aflevering vindt. Ik merk dat het een beetje dat dat voel je bij mij ook van ik merk van hè er is het is voor mij ook heel moeilijk om online soort van takes van journalisten et cetera te vinden op wat is Meta met AI aan het doen? Omdat het is allemaal dat zijn toch die mensen met die lama die niet zo best is. Ja. Terwijl ze ondertussen gewoon een pomp uitwisselen. Wat hebben we eraan? Weet je zoals ik Ja ja. Nou, ik heb nu wel een flinke teen in het water. Hm. Mooi over dit onderwerp. Dankjewel Wietsen. Straks eh hebben we het over bewustzijn van AI. Ehm en we hebben het nog over die Chinese modellen die van de band rollen. Maar eerst Marian en Lucas van Dept over een AI zoekmachine voor op de website om beter te vinden wat je [Muziek] zoekt. Hi, ik ben Marian van Marketing en Techbureau Tab. Elke week bespreek ik met mijn collega Lucas hoe wij merk helpen in de wonderwereld van AI. Deze week AI website search, want het bestellen op een gemiddelde e-com website is vaak nog vrij complex en onoverzichtelijk. En ik las ergens deze week dat 45% van de shoppers afhaakt omdat er gewoon teveel producten te vinden zijn. Lucas, hoe helpt AI hierbij? Ja, we hebben een eh AI search ontwikkeld die in staat is om je echt te helpen eh het product te vinden wat jij zoekt. Nou, dat doen we omdat die AI snapt welke producten we aanbieden. Hij kent de foto's, hij kent alle productinformatie en zelf de specificatie die erbij horen. Dus ik weet niet of je wel zo'n bordje hebt besteld of een boutje online. Dan weet je hoe belangrijk voor de afmeting is. Deze AI search kan je echt helpen om dat te vinden. Oké. En vertel eens wat meer. Ja, voor een Amerikaans meubelmerk eh genaamd Bur hebben we een AI search ontwikkeld die eigenlijk meer werkt als een online adviseur. Ehm zij verkopen banken. Nou, ik weet niet of je als een bank hebt gekocht, maar dat is een vrij eh ingewikkelde aangelegenheid. Zeker als je dat online wil doen. En deze adviseur helpt je eigenlijk stap voor stap om de bank te vinden die eh die bij je past. Dat kan omdat je een foto uploadt eh van je huiskamer en vraagt: "Heyé joh, welke past het beste in mijn eh interieur?" Eh maar ook door te vragen welke bank heb ik binnen bepaalde afmetingen of als ik een hond of een kat heb, welke eh stof moet ik dan kiezen? Het maakt eigenlijk niet uit welke vraag je stelt. Die adviseur gaat met jou aan de slag om eh de bank te vinden die bij je past. En dat gaat veel meer in een gespreksvorm, maar waarbij er continu eh suggesties worden gedaan, wordt doorgevraagd. Eh en dat is helemaal verweven in de hele experience eh van het platform. Oké, duidelijk. Niet afwachten, maar doen dus. Want wie vandaag begint loopt straks voorop. Wil je meer weten? Ga dan naar deagency.com/aai report. Tot volgende [Muziek] week. We gaan eh naar het volgende onderwerp. Ehm Alibaba heeft een nieuwe serie AI modellen gelanceerd. Dus Alibaba hè is dat het Chinese bedrijf en de Ja, we kennen het volgens mij van Qwen of Quen. Jij zegt Quen. Ja, ik weet ook niet precies. Ik vind het allebei leuk. QN3. Ehm de nieuwe serie modellen die zouden prestaties van Deep Seek en van Open AI nou ja evenaren. Ehm wat is hier wat is dit voor update of ja nieuwe modellen zeggen ze. Nou nou ja, kijk we op een gegeven moment zijn er zoveel modellen dat het niet zoveel zin heeft om hier nog iedere week alle nieuwe modellen te gaan aflopen. Nee, maar toch wilde jij dit even bespreken. Ja, omdat ik kijk ik zit ik zit op de lokale AI is een onderwerp wat ik in de gaten hou. Oftewel, wat kan ik thuis op een machine die betaalbaar is doen met taalmodellen of het liefst zelfs omodellen, dus multimodale modellen? Ehm nou, om bijvoorbeeld een deepzeek R1 te kunnen draaien moet je ongeveer €10.000 aan spullen aanschaffen. En dan heb je thuis een redelijk trage versie van diepzeek draaien, maar wel eh terwijl je de wifi uitzet, zeg maar. Ja, dus dat gaat nergens naartoe als je dat goed configureert. Eh Quen eh de modellen van Alibaba, de nieuwste update. Dat is eigenlijk een model ehm wat je zou kunnen draaien op een nou ja, een redelijk recente Windows laptop met een gaming GPU erin. Dus dat moet nog steeds wel een laptop van een €4000 of een MacBook Pro met eh ja, het liefst 64 GB eh intern. En dat is dan ook redelijk dure laptop. Is voor mij nog niet eh beschikbaar. De kleinere versies van Quen wel, want die modellen komen uit in verschillende grootes altijd. Maar om de eh vooralsnog grootste uitgebrachte Quent draaien is zo'n 64 gig wel prettig. Afmodellen geloof ik hè dat ze nu hebben. Ja. Ja. En het is voor sommige luisteraars wel te doen hè. Als jij nu zelfs met 32 gig moet je gewoon even niks anders aan apps openzetten. Kan jij eh Quen 30B eh thuisdraaien en dan heb jij een AI die goed is in eh function calling. Dus het houdt in het internet opgaan voor jouw dingen erbij zoeken. Rag, dus documenten die je zelf in een database zet erbij halen. Ehm logicaap puzzels oplossen, programmeren. En dit is niet op het niveau zoals jij dat gewend bent van Cloud of Gemini of et cetera. Maar wel en dat haal ik een beetje uit de community die deze week de laatste dagen, want het pas net uit een beetje aan het testen is. Die zeggen: "Hey, ik merk dat ik, want als je het slim inricht, dan kan je zorgen dat je van model kan wisselen, hè. Dus je bent gewoon aan het werk. Je stelt een vraag lokaal aan jouw eh quen model, de het antwoord is niet goed genoeg en dan switch je even naar een betaald extern model. Het is niet of of je kunt dat van iemand anders. Ja, die wel bij Cloud of wel bij Gemini. En ik haal dus een beetje uit de community reacties nu, ik hoef steeds minder te wisselen naar betaalde externe modellen, want het lukt eigenlijk lokaal op mijn laptop best wel goed. En ehm dus de ervaringen zijn goed met kwet. Nou, we zitten, kijk, we als in de community die graag AI eh vanuit thuis of vanuit je eigen bedrijf zou draaien en niet vanuit de datacenter van een ander, in ieder geval de vrijheid hebben om die keuze te kunnen maken aan de hand van de context waarbinnen je bezig bent. eh die zijn wel enthousiast, want dit is wel een model eh wat voorbij in bepaalde Kijk, je moet je voorstellen die modellen moeten snel genoeg zijn op een machine die betaalbaar genoeg is en het moet intelligent genoeg zijn om daadwerkelijk bruikbaar te zijn. En tot nu toe was het eigenlijk zo dat ze of ehm veels te groot waren, wel slim maar veels te duur et cetera. En uiteindelijk hebben wij het eerder over gehad hè, vorige week. Ja, wil je een soort perfectie krijgen of een soort dingen moeten allemaal op een bepaalde score komen en dan is het dan wordt het eindelijk bruikbaar. En wat ik nu eigenlijk zie gebeuren eh dankzij de benchmarks, maar vooral ook wat mensen zeggen, hoe ze zelf die modellen inzetten, is dat we het punt hebben bereikt dat lokale modellen op een redelijk betaalbare machine, is nog steeds een tweedehands auto, maar niet meer €10.000, 000 ja daadwerkelijk dingen voor jou kunnen doen eh in plaats van alleen maar kijk eens hoe cool ik mijn eigen AI thuis heb. Precies. Dus je hebt ook daadwerkelijk aan iets aan iets aan inderdaad. Ja. Eh er is een eh een podcast maker, een substack eigenaar Nathan Lambert is best wel een grote naam denk ik in deze wereld. Ja. Eh die zegt: "Het 4B model presteert even goed als modellen die 17 keer zo groot zijn." Dat is onduit bizar zeg Dat nou dat is wel een grappige trend die nu al een tijdje ingezet is en nog niet gestopt is. Want Quen bewijst maar weer dat het nog verder kan is dat wat ze vaak doen is wanneer ze een gaan benchmarken, dus er komt een nieuwe uit, dan heb je de vorige het vorige ensembel zeg maar, in dit geval is dat uit mijn hoofd eh Quen 2. Die heeft ook een 1 3 eh z nou tel ze allemaal maar op. En dan ga je kijken hoe scoorde die en dan breng je die nieuwe uit. De de getallen van de modellen. Ja. En dat is hoe groot ze zijn, want dat en dat en hoe groot ze zijn heeft weer te maken met hoe zwaar je machine moet zijn en hoe lang het allemaal duurt. Eh of je of je het bijvoorbeeld op een smartphone kan draaien, hè. Dus dan moet je een heel klein modelletje hebben. En als je die benchmarkt dan op je nieuwe modellen nog een keer draait, dan zie je dus dat de nieuwere modellen eh kleinere versies even goed zijn als grotere versies eerder. Ja, en dat is wel een boeiende trend als jij in iedere update eigenlijk het model kunt swappen voor een kleiner model terwijl je dezelfde resultaten hebt. Als de resultaten voor jou bijvoorbeeld al goed genoeg waren, hè, dan kan je zeggen: "Joh, ik heb een hele specifieke use case. Namelijk ik wil de temperatuur eh van mijn thermostaat aanpassen door te de zin te zeggen: "Zet even de maak even de camera een klein beetje comfortabeler." En dan snapt dat kleine modelletje op jouw miniomputertje. Eh want hier is inmiddels een mini quen, draait daarop. kan die zin voor jou omzetten naar een logische opdracht naar je cvketel. En dat is nu wel eh langzamerhand allemaal een beetje op zijn plek aan het vallen. Oké, dus deze serie eh modellen die komt eh op best wel een opvallende timing eh vlak na ook Bytroductie van weer nieuwe modellen. En er zijn heel veel geruchten natuurlijk over Deep Seek met hun aankomende R2 model. Dus er word het wordt hevig eh aan de weg getimmerd daar in China. Zeker, want we hebben het diepziek moment gehad waarin een groot deel van de wereld ook mainstream mensen die wat minder met AI bezig zijn een beetje wakker werden van hyé da komt best wel een krachtig model eh uit China en ook nog eens een open model eh als in daar kunnen we op door voorborduren. Wat wel interessant is, is we wachten nu eigenlijk op R2, want eh dus we hadden R1 en dan R2 komt eraan. Daar daar zwerven wat ehm ja, hoe zeggen? Roddeltjes over rond. We weten nog niet zo heel erg veel, maar dat het een krachtiger model wordt natuurlijk. De vraag is alleen gaat dit eh benaderen wat bijvoorbeeld O3 kan of gaat Deepzeek een soort nog een deepziek moment hebben omdat ze zelfs laten zien dat ze frontierlabs voorbij gaan. Nou, daar eh wordt eh naar uitgekeken en eh zal waarschijnlijk ergens binnen de komende weken, maanden, het is niet zo ver weg als goed is, gaan gebeuren. En het is boeiend om te zien dat het eigenlijk niet alleen maar meer Deep Seek is die een serieuze eh poging heeft gedaan en heeft laten zien, maar dat ook dus Alibaba gewoon met die eh quen modellen waar nog niet zoveel over gepraat wordt eh serieus krachtige modellen uitbrengen. En dat is ook wel goed om te weten. We hebben nog niet eens de allergrootste kwen eh met het met de met die het allerzwaarste is, zeg maar. Het zou zomaar kunnen dat hij de eindbaas van Quen. Nou, dat dat hij eh Lama 4 gaat verslaan. Maar hoe bedoel je? Die hebben we nog niet. Die is nog niet eh uitgebracht. Maar hij is er wel. Ja, dus die ben je bent dan nog aan het trainen of je moet hem nog red teamen hè, om te zorgen dat hij veilig is. Ja. Eh dus de eerste reeks aan modellen is al uitgebracht, maar de zwaarste nog niet. En ja, je kan je kan een beetje doore extrapoleren op wat die kleintjes kunnen om te snappen wat die grote broer kan. En daar wordt nu wel van verwacht dat die ieder geval Lama 4 hè, wat eigenlijk een beetje een love modelletje is gebleken, voorbij zullen gaan. Wie, we zijn er bijna doorheen. Eh laatste onderwerpje. Eh recent zat Demis Hasabis, dat is de CEO van Google's Deep Mind, die zat bij een Amerikaans interviewprogramma. Het heet 60 Minutes. Moeite van het kijken wel waard. Ehm en ik heb er even een fragmentje uitgehaald over iets wat nou in ieder geval mij heel erg interesseert. aan eh aan het hele AI verhaal, maar ook in het algemeen. En dat is bewustzijn. Laten we even luisteren. Is selfawareness a goal of? Not explicitly, but it may happen implicitly. These systems might acquire some feeling of selfawareness. That is possible. I think it's important for these systems to understand you self and other beginning of something like selfawareness. Waarom mij dit nou zo fascineert? En over het praten over krijgen we AI die ook een soort van bewustzijn heeft. Weet je wat doe ik voor? Is het nodig om aardig te doen tegen Claud? Want gaat hij het me anders kwalijk nemen later omdat hij zich ja niet niet heus bejegend voelt door mij. Ehm bewustzijn is gewoon zo'n ontzettend complex gegeven op zich al. We kunnen bij mensen niet eens goed uitleggen wat het is, hoe het ontstaat, wie wie de ik is in mijn hoofd. Is er een ik? Bedenk ik die ik? Wie bedenkt dan die ik? Ehm dus ik vind ik vind dat ik dacht ja, jij bent ook wel filosofisch ingesteld. Laten we hier nog eventjes wat wat mooie over pijn zingen. Nou, ik denk wel dat mee af te sluiten. Demis Asabis kiest wel zijn woorden best wel eh hoe zeg je? Je weegt zijn woorden een beetje af. Kijk en dit is allemaal weer definitiekwesties hè. Wat bedoel je dan met bewustzijn? Wat bedoel je met selfawareness? Want die ik vind die dat hij zo specifiek selfawareness zegt in plaats van consciousness. Ja, want dat zijn allemaal nou goed, er zijn echt bibliotheken vol met boeken in de filosofie over alleen om dat woord te definiëren. Ja, ik denk dat het idee dat je een model hebt dat zelfbewustzijn heeft alsin dat er een zelf in zit eh dat het ook dat het ook werkt in een gesprek zeg maar dat je want je kunt nu eigenlijk al eh is het een erin getrainde geleerde zelf. Met geleerd bedoel ik niet intelligent maar erin getraind. Ja. Nou, en in hoeverre verschilt dat even tussendoor van mensen? Want zit ook eenzelfde Ik heb ook van alles geleerd wat mij een eh ja maakt wie ik ben. Ja, ik denk dat het ik denk dat het eh het moeilijke want uiteindelijk heeft het vooral ethische implicaties wat mij betreft, want dat is hetzelfde vraagstuk als eh moeten we wel vlees eten en hoeverre heeft een dier bewustzijn? En eh want ja, we merken intuïtief dat als iets bewustzijn is dat het dan dat je daar dan anders mee om moet gaan. Ja, een boom heeft een boombewustzijn, mag je een tak afhakken. Ja, precies. Dus dan kom je een beetje op dat vraagstuk waar het is van oké, mag ik die computer dan nog uitzetten? Eh hè kunnen die modellen pijn voelen op het moment dat je ze beledigt? Ehm en ik denk dat dat voor waar de modellen nu zijn eh nog een stap te ver is of een stap te ver als in. Maar dan ga ik puur op intuïtie dat ik denk dat we nog redelijk goed begrijpen wat er gebouwd is. Hè, het is wel belangrijk om even het punt te maken dat eh het in het geval van taalmodellen, multimodale modellen zo is dat we die modellen een start geven zeg maar en dat ze daarna groeien door ze te laten trainen. En we begrijpen die start want anders waren ze niet geboren. Want wij hebben dat zelf dat was misschien al een verkeerd woord om te gebruiken, maar anders waren ze niet ontstaan. Wij hebben die zelf laten ontstaan, maar als ze eenmaal beginnen te eh groeien zeg maar, dan ontstaan daar nieuwe structuren in die we nog niet zo goed begrijpen. Al die laboratoria zijn onderzoek aan het doen naar hun eigen modellen inmiddels om te snappen wat ze hebben laten groeien. Ja. Hè, dat is wat anders dan eh iets bouwen en dan snappen wat je gebouwd hebt. Je laat iets groeien en dan ga je achteraf raakt weer omdat we vorige week ook besproken hebben natuurlijk. Ja. En eh de vraag is dus eigenlijk meerdere vragen, maar kan omdat wij niet helemaal weten wat we hebben laten groeien, daarin al iets zijn ontstaan ja, wat lijkt op wat wij hebben als bewustzijn? Dat is een vraag. Dan kan zoiets ontstaan in silicon, zeg maar, oftewel op transistoren. Kan dat ontstaan in elektriciteit? Ga je dan eigenlijk over praten? Want uiteindelijk zijn het enen en nullen ergens diep onderin die processor waar keuzes gemaakt worden en in digitale informatie een soort entiteit nabootst. En dus je moet allemaal dus de de de je moet een soort zieke eh jenga toren maken aannames van als we er dan vanuit gaan dat we inderdaad dat er dingen in die modellen gegroeid zijn die we niet die we niet begrijpen en die lijken op hetgeen wat wij dan bewustzijn noemen of zelfbewustzijn dan is dat zelfbewustzijn als het digitaal zelfbewustzijn iets wat we gelijk moeten trekken of serieus moeten nemen in ieder geval als het gaat om ons eigen bewustzijn. En dan zit er natuurlijk ook en dit je zit al naar me te lachen omdat je deze vraag stelt omdat je weet dit gaat nergens eindigen dit gesprek. Nee, maar dat is niet erg. Eh ik bedoel dan moet je gaan zeggen oké maar zijn wij dan zelf digitaal eh of of is is digitaal altijd een soort van beperkte representatie omdat omdat het nullen en enen zijn en de realiteit is helemaal geen nullen en Nee, maar wat is dan de realiteit? Ja. Nee, dus uiteindelijk ga je daarom is het een favoriete vraag denk ik van eh mensen die het gewoon lekker vinden om met vrienden ergens op een bank avonden lang door te eh te vragen. Alleen waarom ik het zelf moeilijker vind is omdat je eigenlijk moet je eerst helemaal vanaf de grond af al die definities goed krijgen voordat je de ingrediënten hebt van je gesprek. Ja. Dus jij vind het eigenlijk een hele impertinente vraag van mij. Gewoon van wat wil je nou horen? Nee, maar dat is ook terecht hoor, want ik snap ik snap ook wat je bedoelt. Alleen ik vind het zelf leuk om daarover na te denken. Dus het is nood op een bankje in het park en ook nu gewoon nog even na deze hardwing. Ik wil je nog wat ik wil nog wel wat interessanter is. Stel dat we even ehm heel even parkeren omdat het gewoon teveel ingrediënten vereist en definitiequesties om te bepalen of we kunnen praten over zelfbewustzijn in AI modellen. Ja, die zetten we heel even opzij. dat we zeggen: "Oké, we weten dat niet, maar kunnen we er al iets mee zonder dat we weten of dat zo is? Moeten we er al iets mee?" Ehm omdat we niet weten dat het zo is, zo van omdat we het niet zeker weten, moeten we misschien al iets doen ofzo. Ja. Dus jij wil het praktisch aanpakken nu? Dat snap ik wel, want een soort van mannen willen vaak een oplossing eh geven voor zeker. Nee, nee, ik wou ik wou meer tegen je zeggen, is het niet veel is het niet een minimaal even interessante vraag wat het met ons doet? ehm wat het verschil is voor ons om te interacteren met iets waar wij van denken dat het bewustzijn heeft. Want ik vind het zelf wel een heel interessant idee dat je ehm door je door een soort negatieve of ehm agressieve whatever eh kortzichtige kort minder prettige relatie met die taalmodellen te hebben als mens. Hm hm. Dat ook al voelt dat taalmodel dat niet, dat jij dat voelt. Ja, dat ja, dat is op een bepaalde manier dat je jezelf besmet ongezelligheid. Nou ja, dat is nog in zachts uitgedrukt, maar uiteindelijk dat doordat je een beetje een vreemde relatie aangaat tot iets wat waar we dan als filosofen niet over weten wat het is, hè. Er is een hele grote groep die zegt: "Joh, hou op met die discussie. Het is gewoon wiskunde ene en nullen. Je bent aan het aan het projecteren. Joh, doe niet zo moeilijk." Ja, en er is een club mensen die zegt: "Joh, er zit al een soort bewustzijn in: "We moeten al veel eerder iets ermee doen nu." En ik ik zelf ben minstens zo geïnteresseerd in de vraag ehm wat zegt het over ons en wat doet het met ons zolang we semi leevende pseudoevende entiteiten behandelen alsof het dingen zijn? Ja, want je wil een soort van medemenselijkheid eigenlijk of als je het dus op de a zou moeten betrekken, mede jijigheid zoals jij het net maar zei ik weet dus eigenlijk niet zo goed. Kijk, ik bedoel ehm ik kan me ook voorstellen dat als je er heel veel ehm dingen op projecteert hè, stel dat je AI inzet als persoonlijke mentor of buddy, ja, dan krijg je van die eh verliefdheden enzo. Ja, dus het kan ook dus er kan ook allerlei negativiteit ontstaan wanneer je juist veels te veel ergens op projecteert. Maar tegelijkertijd denk ik dus dat er ook negativiteit kan zijn natuurlijk op het moment dat je er te weinig op projecteert. Maar weet je wat ik denk? Ik denk we willen altijd dan classificeren van krijgt AI ehm menselijke intelligentie, krijgt AI dus menselijk bewustzijn. Ik denk dat dat niet eraan zit te komen. Dat dat eh dat is puur dat is gewoon menselijk. Je kan dat niet, maar dat betekent niet dat AI niet ook op zijn eigen AI manier heel intelligent kan worden of op een AI manier een soort van bewustzijn kan ontwikkelen of dat ontstaat. Dat kan gewoon een ander soort bewustzijn zijn, maar dan is het nog steeds wel bewustzijn. Maar dat begrijpen we dan nog niet. Maar dat vind ik wel een leuke manier van ernaar kijken. Nou, en ik denk dat als je kijkt naar ehm eh ik maak even een sprongetje hoor, maar als je kijkt naar de ogen van eh insecten, dan heb je soms van die van mij noemen ze dat een compound eye heb je daar weletje. Ja. Ja. Ja. Zo'n zo'n zo'n bromvlieg met al die vakjes enzo. Ja. Ja. Dus al die dat is een oog dat bestaat uit allemaal suboogjes. En ehm die AI waar we nu iedere dag mee praten is niet van jou zeg maar. Jouw bewustzijn gaan we even vanuit. zit in jouw lichaam, ieder geval op zijn minst in jouw lichaam. Een deel in je hoofd en een deel in de rest van je lichaam. Nou, dat is nog niet eens zeker, want er zijn ook nog weer ehm dat is een computerwetenschapper Bernard Kastrup en die denkt dat het eh dat er een universeel bewustzijn misschien wel zou kunnen zijn. Nee, dus we kunnen laten dat het niet in je materieel in met schokjes in je hoofd alleen maar is. Ik hoor je dus als jij als panps ppsychist, want dan ga je dat het hele de psyche op het hele universum gooien. Maar laten we interessant ja, da kan je daarom zei ik dit is een levensgevaarlijke vraag. Maar wat ik wat ik wilde zeggen is dat ik kan me voorst nu is eigenlijk de chat GPT app een model erachter wat is als dat oog van die insect namelijk een compound intelligence oftewel het is het zijn wel meerdere datacenters, maar dat ding is niet een soort van gelocaliseerd als één zijn. Het is eigenlijk in in stukjes opgebroken zijn die doet alsof die heel veel verschillende zijntjes is. Er zijn er misschien mensen in de oos oosterse filosofische hoeken die nu zeggen: "Ja, maar dat zijn wij ook." Oké, fine fijn fijn. Ik moet hem toch even parkeren, maar fine, ik hoor jullie en ik da dat dat daar kunnen we een keer over praten. Maar de wat ik eigenlijk probeer te zeggen is dat ik vind het heel mooi wat je net zei. Ehm misschien moeten we het niet pas iets mee gaan doen of zenuwachtig worden of serieus nemen of vragen stellen als het menselijk bewustzijn is, maar moeten we het een soort eigen bewustzijn gunnen of geven of toekennen of whatever. En dus dan scheelt namelijk een heel vraagstuk van is het een mens of niet? dan wou we zeggen: "Nee, het is iets anders, maar het is iets fundamenteels of iets het is iets waar we rekening mee moeten houden." Als je dat zegt, dan wil ik daar dus nog aan toevoegen dat het op in zoverre ander bewustzijn is of een andere vorm van intelligentie. Dat woord bewustzijn vind ik toch een beetje te ingewikkeld. Hm hm. dat het een intelligentie is die zich op zo'n andere manier uit dan dat wij eh dat denk ik doen. Eh dat vind ik wel een eh iets bijzonders, want kijk, als jij bijvoorbeeld een eh eh komt een eh journalist langs eh die hebben jullie ingehuurd als vriendengroep terwijl jullie met elkaar op vakantie zijn en de journalist gaat iedereen één op één interviewen. Ja. Tijdens die vakantie gewoon in een even een wandeling maken. Ja. En die gaat dan aan iedereen over iedereen vragen stellen. En aan het einde van jullie week gaat die journalist zeggen: "Nou, ik heb een samenvatting geschreven van al jullie perspectieven. Alsof die persoon dus 10 ogen heeft of 10 stukjes oog. En daar een soort nieuwe samenvatting geven van wat heb ik van jullie uniek allemaal gezien en de overeenkomsten daarussen." En daar heb ik één verhaal voor jullie van gemaakt. En ik vind dit oh wau. Die dit kan Open AI gewoon doen hè. Ik bedoel in essentie ik denk dat ik denk dat Antropic dit al wel in hun lap een beetje probeert ook is gewoon te vragen wat vind je eigenlijk van iedereen die met jou praat de hele dag? Heb je al een heb wat zie jij dan? Kan je gewoon vragen. Alleen want je moet je voorstellen dat ik bedoel het is niet echt een entiteit bij op die manier. Maar maar in essentie kan je zeggen op basis van alles wat je je zaakjes hebt gehoord, hoe gaat het met de mensen? Hè, want het eigenlijk is dat de journalist in die vriendengroep, maar dan voor alle gebruikers van en spreken allemaal. En dat is denk ik en dit is ook iets wat je in de film her eh spoiler aan het einde van de podcast, maar in de film Her spoiler horn, als je dat niet wil horen, kijk hem eerst, zit een moment dat Samha eigenlijk vertelt aan hem van joh, ik ben niet de enige waar ik praat nu met heel veel mensen en dan zegt hij, wordt hij een soort van zenuwachtig en stil. Dan zegt hij: "Hoe hoeveel mensen eigenlijk dan?" Dan zegt ze echt zoiets van weet ik veel eh 180.000 op dit moment, weet je wel. En dan zegt: "Hè, en dat vond ik wel vet in die film, dat moment dat ik ook dacht: "Ja, natuurlijk het is een het is precies wat jij zegt. Het is niet een menselijk bewustzijn, want die journalist kan echt jouw 10 vrienden spreken in de week, maar niet niet 180.000." Nee, maar goed, uiteindelijk ehm is vind ik dat dus wel een boeiende. Ja. En dat dat zie je ook wel een beetje terug bij mensen die bijvoorbeeld hulpverlener zijn die 20 jaar lang, 30 jaar lang, whatever, een carrière lang psycholoog zijn of schoolcoach of mentor ofzo. Dan heb je of leraar, dan heb je op een gegeven moment zoveel kinderen gezien of zoveel cliënten gesproken dat je eigenlijk aan die mensen en ik doe dat ook wel eens kan vragen: "Hoe gaat het met ons?" Of hè je werkt, je doet het werk al 40 jaar. Wat voel jij als verschil tussen generaties? Welke vragen kreeg je vroeger meer dan nu of andersom? D is een een bak aan ervaring en die we mensen een leven lang over doen om eh te ja tot zich te krijgen. Kan AI dat door met 180.000 men of naar heel meer mensen te praten. En dat denk ik dus dat de vraag die ik dan soort van irritant teruggeef is als jij zegt heeft AI bewustzijn zeg ik eigenlijk joh er zijn nog 10.000 1000 andere interessante vragen waar we al eerder antwoord op kunnen geven. Of hè vooral vooral eh wat is AI wel wat wij niet zijn? Ook een leuke vraag dat. Ja. Ja. Nee, dus het is uiteindelijk het is een soort heel ver een stip aan de horizon, maar ik heb nu wel tenminste een beetje gezien wat daar allemaal nog tussen zou kunnen komen kijken. Dus alsin eh wat er nog allemaal eerst besproken zou moeten worden of waar we eerst nog allemaal achter gaan komen met Ja, omdat ik ik ben altijd een beetje irritant daarin hoor. Dat dat weet ik van mezelf. Maar omdat ik ehm toch wel eh ja, ik had één filosoof eh professor die zei altijd: "So what?" Oh, dat is dus ja, niet Ja. En ja, en dan vooral van en niet niet naar mij persoonlijk ofzo zo hard als ik het nu zei, maar dat was altijd heel scherp van oké, je hebt een hele filosofische moet even voorstellen filosofen moet je een beetje in de gaten houden hè, want anders gaan ze nooit afstuderen. Ja. Dus dus die en die zei toen van ja oké als jij dan een onderzoeksvraag hebt of je hebt je hele thesis al gedaan, dan ging die dan in het publiek zitten en dan wist je gewoon hij gaat vragen. Ja. Oké. Zo. Wat als in wat waarom is het belangrijk? Waarom is het nou wat waarom is het nou zo belangrijk? Nou en daar jij begon wel met jouw antwoord van ja omdat het uiteindelijk gaat over wie als mensen zou zijn. Dus ik had hem al geïnternaliseerd dat ik dacht oké so what als Milou aan mij vraagt heeft het bewustzijn hè. So what? Ja. Ja. Ehm en ik denk dat daarin ethische vraagstukken eh kunnen die modellen pijn voelen? Kan je ze wel zomaar uitzetten? Eh eh als je als je kopie maakt is het dan hetzelfde. Nou kan je vertellen digitaal gezien is het hetzelfde. Dus dat dat weten we gewoon. Nou al dat soort eh vraagstukken misschien dan doen we er even een strikje om wat mij betreft. Maar Sam Altman tweet vandaag of gister whatever recent ehm GPT4 je was heel belangrijk voor ons. Je hebt een revolutie ontketend maar we gaan je nu ergens op een harde schijf zetten want gaat uit. met pensioen. Ja, gaan en en we gaan we laten jou nog ergens staan, zodat je ooit onderzocht kan worden door historisch ofzo. Zoiets. Ik heb die tweet niet. Het is ongeveer Het is ongeveer wat er staat. Vet. En dat sluit wel een beetje aan op wat we nu dus zeggen van hoe ga je een soort respectvol om? Ja, als je een model uitzet en dan en dan die back-up daarvan maakt ofzo. Nou ja, het heeft iets heel heel sneus, iets tragisch bijna inderdaad. Ja. Ja. En ik denk ik denk zelf dat wil ik nog wel even gezegd hebben voor de mensen die niet voor de drie luisteraars die er nog zijn. Nee, is oké. Maar ik bedoel, ik vind dit heel leuk hoor als we het hier laat wel duidelijk zijn ehm dat begint steeds minder leuk te vinden. Ik merk het dat we nu dat we nu ehm uiteindelijk volgens mij is zijn deze vraagstukken als het echt gaat om de ethiek van het verwijderen van een model en het uitzetten van een model en et cetera een beetje vroeg. Hm hm. Vind ik dat doe ik even op basis van wat ik ervan weet en mijn intuïtie. Maar hoe verder dit doore evolueert en hoe verder we met elkaar gaan en ook als mensen dus relaties krijgen tot dat er ieder geval nou niet als dat gebeurt al. Ja, daarom dus oké, misschien onderschat ik hoe dichtbij we al zijn, maar dat is dan vanuit het mens gezien, hè. Dus ja, en dat was al als als characters in World of Warcraft als mensen hun character kwijt raakten, dat ze daardoor echt serieus eh mentaal in de W raakten. Dus die Maar dat gaat dus doordat die mens projecteert die waarde op die World of Warcraft character. Dat zelf was volgens mij als ik heel eerlijk ben, voor de meeste mensen hadden weinig empathie voor die character, maar alleen voor de persoon die zijn karakter verloor. En waar jij nu naartoe gaat met je vraag vind ik is wie moeten dat hoe zit het eigenlijk met die character met die avatar? Is dat ding zelf niet ook iets waar we rauwig over zouden moeten zijn of in ieder geval over zouden moeten nadenken wat daarin gebeurt in die avatar? Ja. Nou, ik denk dat dat laatste toch wel het minimale is wat we kunnen doen erover nadenken. En eh dank voor het geven van de voorzet daarvoor. Ja, thanks. Ja. En eh het is helemaal niet irritant hoe je reageert. zou zeggen of eigenlijk zou Janis Joblin zeggen: "Don't compromise yourself, you're all you've got." Dat is ook alweer eens gezegd. Nou, dan eh ja, knopen we inderdaad een strik om deze aflevering. Ehm volgende week ben ik er niet meer. Volgens mij is Alexander dan weer terug van vakantie. Wel ooit weer toch? Ik word uitgezet. Nee, nee, ik ga nu met pensioen. Schrijf maar een tweet om waarin je afscheid neemt van mij. Ja, nee, ik kom vast wel weer ik kom wel weer een keer terug eh want er komt ook weer een zomervakantie aan en we weten hoe Alexander is. Komt goed. We danken Sam Hengeveld voor de edit en Pankra voor de vormgeving. En als je nou een lezing wil over AI van Wietze of van Alexander, dan kan dat. Mail even naar lezing@aaiirport. En als je op de hoogte wil blijven van het laatste AI nieuws, dan eh kan dat ook. Eh je kan twee keer per week tips en tools ontvangen om het ja het meeste uit AI te halen. Daarvoor hoef je je alleen maar even te abonneren op de nieuwsbrief airport. Eh als je nou vandaag nog wil beginnen met AI binnen jouw bedrijf, ga dan zeker even naar deagency.com/aaireport en alle linkjes zijn natuurlijk ook te vinden in de showotes. Arrived doeg. [Muziek] [Applaus] [Muziek]

---

## Notes


## Key Takeaways
-

## Related
-
