# GPT-5 is hier + Genie 3 laat je dromen besturen + open source zonder drama | AI Report

**Source:** [YouTube](https://www.youtube.com/watch?v=0QHVLPym-mA)
**Video ID:** 0QHVLPym-mA
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie. Zoals beloofd als GPT 5 zou uitkomen tijdens de vakantie gaan wij opnemen. En dat hebben we gedaan. Ik heb Rick Lamers van Grok met een Q in de aflevering. Rick weet ontzettend veel over de ins en outs van taalmodellen, inference, chips, noem het allemaal maar op. Al met al een hele interessante aflevering. We praten over GPT 5, over GPT OSS en we praten over Genie 3 van Deepmind. Eh veel luisterplezier en geniet nog even van jullie vakantie. [Applaus] [Muziek] [Applaus] Hoe zit jij er nu bij na alle vuurwerk van gisteren? Ja, dus ik heb eh gisteren tot in het later uurtjes met GPT5 eh lopen programmeren. Ook omdat één belangrijk onderdeel van de lancering van het model was dat eh ze heel erg benadrukken dat het goed werkt voor programmeren, voor code. En ehm ik vind dit eh ik vind het een leuk dit is een leuke meme. Eh een soort van it's a good model, sir. Dat is wat eh dat dat was volgens mij waar de livestream van Crok 4 mee eindigde. En het is een beetje een meme geworden. Crok 4 is het eh niet model van openh maar van XI van El Musk. En eh dat it's a good model sir. Dat dat thema kwam ook een beetje terug bij eh GPT 5. Ehm en zeker ook online zeg maar. Er zijn een aantal mensen eh er zijn aantal mensen in de community hè. Eh zijn soorten, het is wel grappig, sommige mensen noemen noemen die mensen lm sommel. Zo van eh omdat omdat het zo lastig tegenwoordig is om te kwantificeren. Is een model nou goed? omdat er heel veel wordt gedaan aan zogenaamde benchmark maxing. Dus dan neem je de belangrijkste gestandaardiseerde tests die ze gebruiken om te aan te geven hoe goed een model is. En dan gaan die bedrijven daar natuurlijk allemaal heel erg voor optimaliseren zodat ze daar heel goed op scoren. Maar er zijn gewoon releases geweest in het verleden waarbij eh modellen uitkwamen die heel goed daarop scoorden en dan uiteindelijk in echt gebruik heel erg tegenvielen. En dan had iedereen z van wat is er aan de hand? En uiteindelijk werd gewoon duidelijk dat heel veel van die laps dan heel erg optimaliseren voor die specifieke toetsen. En die toetsen die worden dan eigenlijk slechte toetsen, weet je wel. Eh dus zo'n quote van eh every good matric seases to be a good matric as soon as it's the matric that optimized of zoiets. Ja, zeker ook het verschil natuurlij tussen publieke en private benchmarks omdat die publieke benchmarks die komen als het ware in de trainingszet terecht omdat er z ook nog eens dat het soms per ongeluk gebeurt omdat gewoon die data erin terecht komt en daar wordt wel steeds meer iets tegen gedaan. Maar nou in ieder geval dus die benchmarks die verklaren eh weinig en en daardoor kijken steeds vaker mensen gewoon naar eh mensen die heel actief de het veld volgen en heel veel van die modellen zelf geprobeerd hebben en die ze dan zelf uitproberen op de taken waar zij in geïnteresseerd zijn en iedereen je eigenlijk een soort private benchmarks toch? Ik bedoel airquotes benchmarks, maar soms soms soms hebben mensen ook echt letterlijk eigen benchmarks. Ehm en ehm eh maar het is ook vooral zeg maar gewoon dat mensen even een tijdje het model gebruiken voor hun hoofdtaak. En vaak is dat voor veel mensen is dat programmeren met het model en voor anderen is het zeg maar het model hangen in een applicatie die ze hebben ontwikkeld die draait op AI modellen. En dan wil iedereen weten van eh wat zijn de vibes? Weet je wel? Hoe hoe hoe wat vinden jullie ervan? Dus een aantal van die mensen eh één die mensen zouden kunnen kennen van het internet die heet Swix. Dat is een eh een een soort AI figuur. En dan heb je ook nog Simon Willison, wat ik echt een geweldige vent vind. Met zijn pelikaan. Met zijn pelikaan inderdaad. Zijn ultieme test is voor mensen die het niet weten is hoe goed kan een AI model een pelican op een fiets tekenen? Ja, dan is het wel belangrijk om te zeggen precies met factoren dus. Want op zich zullen mensen luister zeggen hoezo? We hebben toch in middelsbly afbeelding en hele films die uit eh belangrijk detail inderdaad. Dus waarom is dit nog steeds een goede benchmark? Omdat hij dat moet doen blind als het ware in code. In SVG is gewoon een soort HTML. Eh en eh nou die tests die worden dus allemaal gedaan en daar zag ik dus gisteren al dat eh mensen best wel positief waren. Ehm ja, want heel even voor de luisteraars misschien kijk wat ik dus merkte, er was best wel een verschil hè. Dus je had de oké eh best wel een groep mensen die een soort van tegenviel, want er was ons toch artificial general intelligence beloofd en GPT5 zou eh nou ja, buitenaards moeten woelen ofzo. En eh er is een hele groep die zegt: "Nee, het is gewoon zeker de groep trouwens die er al een week mee heeft mogen werken of twee weken hè, want je had een soort van mensen die eh achter eh eh hoe zeg je dat? Eh die moesten even wachten voordat ze erboven mochten praten." Nou embargo. Embargo. Thanks man. eh die achter embargo zaten, waaronder Simon Willison bijvoorbeeld, die volgens mij ook al een tijdje Acess had. En de jongens van Every enzo, die hebben allemaal dropten allemaal rond dezelfde tijd een soort van vibe check van de laatste twee weken GPT 5. Die groep die er al wat langer mee heeft mogen werken voelt voor mij een stuk positiever dan de groep die er pas net mee heeft mogen werken of er eigenlijk nog niet heeft mee mogen werken, maar alleen maar een soort vibe check doen. Zag je dat ook of? Ik denk dat dat ook wel logisch te verklaren valt aan de hand van wat het echt is. Ehm het is namelijk een model dat op de headlines niet heel indrukwekkend overkomt. Dus als je kijkt naar een belangrijke benchmark die relatief moeilijk te gamen is, zeg maar, als je hele hoge scores hierop haalt, dan eh heb je waarschijnlijk ook wel een nuttig model. Daarom wordt is het ook één van de betere benchmarks. Eh want het is heel moeilijk om daar soort van heel goed op scoren en dan in het echt heel nutteloos te zijn. Maar dat is eh een test dat heet de S bench. En dat is een test die test hoe goed kan je een een een ehm een fix implementeren voor een bestaand stuk software. Dus dan heb je een grote bestaande codebase en daar moet er dan iets aan gerepareerd worden en dan moet er getest worden of ook dat ding gefixt is. En dat zijn dan eh dat zijn geloof ik een aantal 1000 problemen, maar ze hebben gereduceerd naar soort schone dataset van 500 van die software engineering tasks. En eh daarop scoorde hij maar dus GPT5 scoort maar 0.5% punt beter dan Cloud Opus 4.1. En Cloud Opus 4, want 4.1 had eh een twpack sneaky gereleased deze week om nog even snel eh zeg maar hun plasje erover te doen van wij zijn er ook en we hebben ook iets iets ietsje beter. Maar Cloud 4 kan groter te maken dat ze in de buurt zitten natuurlijk ook hè toch? Ja. Maar Cloud Opus 4, wat al langer uit was, die scoorde ook rond de 70 72% op die op die benchmark. En Cloud Opus 4.1 scoort volgens mij 74,5% eh 74.4 en dan eh 74.9 voor open dus het is allemaal heel dicht bij elkaar. En dan denkt iedereen van zie je plateau. We zijn we zijn geplate met eh de modellen en het wordt allemaal niet beter. En ik denk dat de belangrijkste of de de de verste manier om te karakteriseren wat deze lancering was, is dat het voor Open AI een soort clean-up act. Ze hadden namelijk een groot probleem. Ze hadden het probleem van een hele verwarrende model picker. Ze hadden zo'n model picker waarbij iedereen op 4 zat omdat je denkt: "Ja, maar er staat ook een driel en dat driemodel moet slechter zijn." Ja, nog los van het feit dat er natuurlijk heel veel eh mensen zijn die eh chat GPT eh niet betalen hè. Dus die zaten sowieso allemaal met 4 te praten. Ik heb tijdens heel veel lezingen die ik geef zeg ik altijd van ja, ik waar ik dagelijks mee werk zijn zo zulke andere modellen als wat veel van jullie dagelijks mee werken. Als het dan handen omhoog doet heb je echt 60% van een groep die op de gratis chatd zit. Ja, daar heb ik verder geen oordeel over. Maar die hebben helemaal niet eens een idee dat er modellen te kiezen zijn. 100%. Dus dus er zijn ook nog mensen die volledig op de gratis tier zitten en die mensen die zagen niet de echte capability in. Dus was er een heel groot deel van mensen die ook het idee van nou dat ding dat is helemaal niet zo slim. Maar ja, dat komat je de domme versie gebruikt. Ehm maar dus Openir had in ieder geval een probleem van geen eenheid in hun eh modellen en een slechte verzameling aan namen sowieso ook. dus hoe ze het überhaupt noemen, zodat het heel verwarrend allemaal is. Het is ook onpraktisch, want hoofd eh hoofdzakelijk hadden ze twee verschillende modellen. Ze hadden een snel normaal model waar ze al eerder mee gekomen waren. Dat is GP340. En dat reageert direct en gebruikt niet veel zoals wat ze noemen test time compute. Dus tijd om na te denken over het geven van het antwoord. Ja, snelle bluf, maar snelle bluf. Hopelijk geenerde bluf. Precies. En aan de andere kant had je eh hun nieuwste model wat dan alleen betaald toegang had 3O. En dat is een reasoning model. Dat daarvoor had je één one als model, maar dat ze allebei dezelfde zijn van die reasoning modellen. En eigenlijk moet je als user telkens kiezen wil ik dat hij gaat nadenken of wil ik een snel antwoord. En dat moest je de hele tijd handmatig doen. Nou, dat was voor iedereen natuurlijk best wel gedoe. Dus veel mensen gebruikten of de hele tijd het dure model wat nadenkt. Maar dan moet je dus altijd wachten, ook als je even een simpele e-mail vraag stelt of wat dan ook. Ehm en er zijn mensen die proberen nooit dat reasoning model, die gebruiken altijd dom model en die die hebben dan een soort onderschatting van wat AI kan en dat moesten ze fixen. En dus deze release was hoofdzakelijk dat ze dat probleem opgelost hebben door één model te maken wat niet eens echt een model is. Het is een systeem en geen model. GBT 5 als model bestaat niet eens. Het is geen één model. Het zijn Ja, dit is misschien even een belangrijk om bij stil te staan hoor Rick, want in essentie ze hadden natuurlijk ook kunnen zeggen we pakken O4 en want ze hadden wel O4 miniseries en ik denk O4 gewoon full intern zeggen we gaan door op die branding hè, dus we stoppen gewoon met die GPT serie qua buitenkant en we gaan voor door op een O4 serie. Ik denk om eerlijk te zijn speculatie dat dit een optie geweest is intern, want die O series qua branding is best wel lekker hè. Dus de modellen van Open AI zijn O1, O3 en dan nu O4. En dan gaan we zo door 567 in de toekomst. Nu pakken ze eigenlijk die oude GPT brand ook omdat natuurlijk GPT5 nog boven de markt hing als het ware. Dus ik snap ook wel dat ze daar iets moesten zeggen. Maar en dan dan eh hou ik weer even mijn mond. In essentie hebben wij zijn we gewend als mensen die hier echt dichtop zitten om om steeds in modellen te praten, hè. Dus dan gaan ook die ja ehm online community meteen weer eh op die modellen zitten en dan al die modellen vergelijken en die weten zelfs wat die modellen ongeveer doen en zijn. terwijl het merendeel van de mainstream GPT of chat gebruikers, zoals mensen om mij heen het veel noemen, die hebben helemaal geen idee van modellen. Die zijn gewoon met AI aan het praten. En ik denk in dat opzicht dat wat GPT5 is inderdaad een soort ja product, een een systeem, een stuk software waar eh die modellen een onderdeel van zijn. Een hele rits van GPT5 modellen. Ja. En wat ze wel zeggen bij het eh bij de lancering van GPT5 is dat het systeem wat ze hebben gebouwd dus nu een expliciet systeem is, maar dat ze dat wel willen terugbrengen naar één model. Maar ze hebben gewoon eigenlijk aangegeven dat ze dat niet hebben kunnen klaarspelen. Dus het was te moeilijk om nu één model te trainen wat eigenlijk de best of both worlds gebruikt eh kan gebruiken van snel reageren als je snel kunt reageren omdat het probleem niet vraagt om heel veel extra denktijd of heel lang nadenken als dat als dat nodig is. En dus wat ze nu gedaan hebben is ze hebben dus een router geïntroduceerd. En een router is eigenlijk niets anders dan iets wat binnenkomt stuurt hij of naar het één of naar het ander. Ja, een soort air traffic controller toch? Die weet welke modellen er beschikbaar zijn en vraag gaat naar het reasoning model O4 in de achtergrond. Misschien hebben ze niet gezegd, maar dat zou zomaar het volledige O model zijn. Dit is gezegd dat op het moment dat je in ieder geval in de free tier eh dat als je wat meer gebruik gaat maken van je free tier dat ze terug kunnen vallen op 4 in de achtergrond. zelfs 4 zeg maar, dus niet eens de reasoning versie is dat er nog een voor hun nog ieder geval die is waarschijnlijk nu lekker goedkoop voor open uit te serveren zelfs een terugval is naar een eerdere GPT serie. Maar goed, nou in ieder geval wat we niet weten is wat er precies met O voor dus niet voor O maar O het reasoning model voor wat de volgende versie zou zijn van O3 of dat GPT5 thinking is genoemd. Dus als je in die model card gaat kijken, dan zegt hij dus we kunnen jouw query uitsplitsen naar een model wat of wel gaat nadenken of niet gaat nadenken. Maar daarna heb je weer een vertakking en dat is als hij gaat nadenken hebben we een groot sterk nadenkmodel en een klein nadenkmodel. En we hebben ook aan de snelle kant een eh groot snel model en een klein snel model. En en dit is allemaal een kostenplaatje. En als je dan als je dan kijkt naar wat is nou dus dus aan de ene kant gebruiksgemak van ik hoef niet meer na te denken dat dat hele sturen naar het juiste model dat doet het systeem voor me nu. Maar wat cruciaal belangrijk is, is dat Open AI heeft dit model geïntroduceerd tegen een extreem aantrekkelijke prijs omdat het competitief is met het beste model van Antropic Cloud Opus. Cloud Opus 4 4.1. Maar het is acht keer zo goedkoop in de output tokens en het is 16 keer zo goedkoop in de input tokens. En dit is misschien sowieso wel een even een interessant onderscheid hoor, want kijk jij en ik als eh ontwikkelaars, meer techneuten die kijken hiernaar. Toen de lancering van GPT5 was gister en ik daarna een model card was zag met allerlei losse modellen dacht ik: "Wacht even, er was ons toch tussen airquotes beloofd dat die air traffic controller, dat die router als het ware in het model meegebakken zou zijn. We zouden een soort supermodel krijgen die zelf dat dan kan beslissen. Uiteindelijk blijkt dat we als ontwikkelaars hè, want wij hebben natuurlijk, kijk, de meeste mensen die hier naar luisteren, die interacteren denk ik vanaf de consumer site. Dus die zijn gewoon eindgebruiker binnen de apps of de website van Open AI waarbij je een modelpicker had als je op het plusplan zat. Maar over het algemeen was dat wat je deed. Terwijl wij op de achtergrond natuurlijk veel meer knoppen hebben om aan te draaien en nu ook best wel weer veel knoppen hebben gekregen. Wat mij dus verbaasde omdat ik dacht ik dacht even dat wij dat niet meer dat ik niet meer hoefde te routen. Want weet jij of wij ook toegang hebben tot die router op ontwikkelings Ja. En hoe heet hij dan als model? GPT5. Nou that's it. En dan gaat hij zelf keuzes maken op het dus. Dus wat eh Open heeft bedacht is dat diezelfde eenvoud van one system eh open je vogeld uit waar het heen moet, dat ook wel waardevol kan zijn voor developers die niet al die verschillende controle willen van ik wil dat hij altijd naar een thinking model gaat. Want ik weet dat de mensen mij alleen maar thinking problemen sturen. Dus als jij ooit een keer naar een niet thinking model stuurt, dan heb je het waarschijnlijk fout. Want ik weet dat ik alleen maar thinking vragen stuur en dus die willen dat risico niet lopen. Dat dat systeem in de weg zit als het ware. Ja. Op het moment dat het straks echt één model is wat ze dus willen, maar wat niet gereleased is met GPT5, dan heb je misschien die controle niet meer. Ehm want dan gaat het echt naar je model. Dus dan moet je maar gewoon hopen dat het model die routing goed doet. Ehm alhoewel je kunt zo'n één model ook vaak wel ehm sturen op een wat striktere manier met system prompts en dergelijke waarbij je dan zegt: "Oké, je moet reasoning gebruiken." En dan zal hij dat ook altijd doen omdat je dan kan overrulen dat hij zijn eh eigen inschatting moet maken. En is dat het hele idee van een van één model iets wat gewoon een soort schoonheid heeft in ons ontwikkelaarshoofd? Of is het daadwerkelijk interessant om dat wel te doen? Het is interessant. En de reden is dat er ehm er sommige sommige problemen zeg maar classificeren of iets wel of niet veel denkracht nodig heeft kan best een subtiel ding zijn. Dus die routinglaag die er nu is, dat is waarschijnlijk een best wel domme routinglaag. En eh dat beter maken, dat hij dat echt holistischer beoordeelt als het ware. Dat vereist waarschijnlijk dat dat gewoon allemaal in één model zit, zodat je dat in zijn geheel kunt trainen. Nu zijn er als het ware losse losse modellen, dus losse neural networks die eigenlijk allemaal hun eigen onafhankelijke weights hebben. En dan kan je hier de weights veranderen en dan gaat de rest van het systeem bijvoorbeeld blijft statisch. En dan moet je weer kijken hoe gaat dit gewijzigde model zich verhouden in het systeem. Dus vooral voor de evolutie van zo'n systeem. Dus als je het beter wil maken ben je echt wackable aan het spelen. Dus dan maar is het nu zo dat eh bijvoorbeeld eh de andere Frontier Labs eh Deepmind Tropic dit al wel doen? Hebben die al die holistische modellen nu of zijn het ook allemaal nog modellen met routers ervoor? Nou goede vraag. Want waar gaat het eigenlijk om? Het gaat er niet eens om dat je meerdere modellen hebt per se. Het gaat erom dat je dynamisch kan bepalen hoang je moet nadenken over een vraag. En wat heeft is thinking budgets. Dus je kunt een eh vraag stellen en je kan zeggen: "Denk er heel lang over na." Dan gaat hij bijvoorbeeld 32.000 tokens gebruiken om na te denken. Of je kan zeggen: "Denk maar maximaal 1000 tokens en dan moet het moet het goed zijn." En ehm dat dynamisch eh dat is nog niet helemaal automatisch dynamisch, maar het heeft wel eh ingebouwd dat het probeert de gedachte af te ronden in 1000 tokens. En dat is wel een interessant verschil, want hij zegt niet van begin maar met denken en naar 1000 tokens stop. Hij zegt denk ongeveer zo lang na en geef dan een antwoord. En wat je dus ehm gaat zien is dat het nog dynamischer wordt. Waarbij het niet eh gespecificeerd wordt hoeveel tijd budget je hebt, maar gewoon echt puur afhankelijk van wat er binnenkomt wordt bepaald hoe langer wordt nagedacht. En dat wordt dat wordt gewoon actief onderzocht door alle labs. Maar er is niemand die dat echt helemaal live heeft. dat hele dynamische reasoning ehm ook in de open weights eh modellen experimenten in kleinere modellen of er zijn misschien wel eh echt niet production skill modellen waar dit idee getest wordt van kunnen we kunnen we modellen laten bepalen hoe lang ze moeten nadenken. Ik kan me herinneren dat ik een aantal papers daarover heb bij voorbij zien komen. Eh maar dat zijn dan vooral experimenten die gebeuren op modellen die echt subscale zijn. Dus eigenlijk bijvoorbeeld een one billion parameter model wat tegenwoordig heel klein is en die dus eigenlijk alleen maar toy problemen kunnen oplossen en dat ze dan voor toy problemen kunnen laten zien ja het model kan bepalen of die moest nadenken of niet. Maar de vraag is natuurlijk altijd generaliseert dat als je naar die grote schaal teruggaat waar deze modellen in opereren zoals een GPT5? En dat is dan even een paar stappen terugnemen hè, want ik begon net een beetje over twee kampen te praten. De het AGI kamp die zegt: "Het valt allemaal tegen. Er is ons eh buitenaardse technologie beloofd." En aan de andere kant mensen die het al hebben mogen testen vaak en een stuk genuanceerder zijn en zeggen van: "Joh, er is hier heel veel tegelijk aan de hand." Één van die punten is dat het een soort refactor is hè binnen openi. Want voor de voor de luisteraars, Chat GPT was een experiment. Het heette namelijk chat with GPT, begreep ik gisteren uit de uit de presentatie. En iets wat ze online gegooid hebben, toen ontplofte dat gewoon helemaal niet normaal. En dan moet je natuurlijk zoals het met software ontwikkeling gaat eigenlijk je fiets repareren terwijl je erop zit. Of in ieder geval je fiets repareren en nieuwe dingen opdoen terwijl die persoon die erop zit moet blijven fietsen. En dan krijg je dus hele rare wildgroei en technical depth, zoals het dan heeten, hè. Een soort ehm absoluut lening die je hebt eh naar je verleden omdat je zoveel eh troep hebt gebouwd en je kon niet door. Ja. En dit is eigenlijk een soort voelt als een soort factor dus hè. Dus GPT5 is een soort schone lei. Het opruimen van eerdere keuzes die zijn gemaakt uit pure eh ja, de on of niet onkunde is het verkeerde woord. Het kon gewoon niet anders, want je wil doorgroeien en je wil ook op nummer één blijven als open en jij. Dus dat ze dit terwijl ze zo hard groeien en zoveel gebruikers hebben in situ doen is best wel bruut. Eh maar eigenlijk los van die van die eh soort consolideren en en opschoonactie is er wel veel meer aan de hand. Eh ik bedoel, ik weet niet of jij hebt gevolgd wat er met de Meeter is gebeurd. De benchmark die kijkt hoelang een model eh zonder ingrijpen eh door kan werken. Dit was één van de eerste waar ik naartoe ging omdat Project 2027, wat hè de luisteraars weten dit nog uit de AGI aflevering, de het scenario eh dat alles eh in 2027 al heel anders zou zijn, want er zit allerlei exponentiële groei in deze modellen en AGI, artificial general intelligence komt veel sneller. Één van de ehm ja eh hoe zeg je dat? benchmarks of eh harde cijfers die in de gaten gehouden wordt in dat scenario van Project 2027 is het idee hoelang kan zo'n agent of in ieder geval een model agentic model eh werken zonder dat wij hoeven ingrijpen en daarin is GPT5 begreep ik best wel gestegen. Ja, ik denk dat dit is een goed bruggetje naar denk ik de tweede andere grote observatie van de lancering. Dus het oké het is een model routed systeem. Eh dat is dat is nieuw. Het lost een aantal technical de problemen overheid. Daar is voor hem belangrijk. Door model routing is het goedkoop. Dat is allemaal eh één deel van de lancering. Ander deel van de lancering is dat het een heel agentic model is. En als je het hebt over wat betekent dat dan? Agentic agents, iedereen heeft het daarover. Maar ik denk dat de meeste mensen die het model agentic noemen die die daarmee bedoelen dat het heel goed is in op een over een langere tijdshorizon. Dus misschien dat de 10, 20, 30, 40 minuten bezig is, dat hij continu een een handeling verricht. En dat is wat je dan in je hargrond een tool call noemt. En dat kan zijn even een stukje extra informatie van de Github eh repository lezen over het project waar het mee bezig is of even iets zoeken in de documentatie op het publieke internet of even een klein stukje code schrijven, uitvoeren, observeren en daar weer op verder iteren. Dat soort handelingen verrichten. En dat dan over een langere tijd horizon. Dat is iets waar dit model extreem goed in is. En dat was in het verleden best goed in GPT40, maar dat was nog niet zo'n reasoning model. En het was veel minder goed in die reasoning modellen O3. En als je eh praktische software aan het schrijven bent, dan gaat het heel erg over dat iteratief ontdekken waar je denkfout zit. Dus als je denkt: "Oh, ik moet de code zo schrijven." dan moet je dat even proberen en dan kan je het runnen en dan kan je observeren en dan kan je weer iets leren. Dus het is die progressieve eh soort van informatievergaring. En dat autonoom doen zonder wat ze noemen in een doom loop te komen waarin je dus vastloopt omdat je de hele tijd dezelfde fouten maakt of je probeert de hele tijd iets op een manier te doen die gewoon fundamenteel niet klopt, maar je blijft toch telkens weer die richting opgaan. Dat eh goed doen. Dat maakt die modellen vooral heel veel meer waardevol omdat je makkelijker kunt delegeren, want ze lopen niet vast. Dus ze kunnen en wat ik wat ik bijvoorbeeld zag in die meter, dat is dus die benchmark om te kijken eh hoe lang houdt zo'n model het vol zonder dat hij of vastt vast komt te zitten of opgeeft zeg maar. Hm hm. Of beide. is dat ik wel interessant vond dat bijvoorbeeld Clad eh eh Ops 4.1 eh doet eigenlijk een plan maken eh nadenken, een zwik aan toolks, achter elkaar, 10 toolkals, dan nog een keer nadenken en dan antwoord geven. Terwijl GPT5 doet eh plan maken, nadenken, toolk, weer nadenken, tool, weer nadenken, op terug, nieuw plan maken, weer nadenken, nieuwe toolk. en kan dus eigenlijk zonder dat in die volgorde te doen echt iteratief stap voor stap zelf ook merken. Want in één van die eh reasoning eh traces stond ook: "Ik zit in een doom loop." Hè, dat is helemaal best wel knap dat je kan herkennen dat je vast, zeg maar. Soort halting problem zeg maar. Ja, het is best wel heel knap dat hij op een gegeven moment zei en daarin zag ik wel dat ik dacht, want ik wilde natuurlijk weten hoe komt het nou dat GPT5 het langer volhoudt. Daarvoor moet je dus dit soort innovaties doen. Ja, en daar is reasoning echt belangrijk voor. Want wat reasoning eh toelaat is een stukje reflectie waarbij het eh kan redeneren over wat er tot nu toe is gebeurd in het proces in zo'n rollout zoals je zou kunnen noemen. En eh echt daar een soort ehm een soort eh streep in het zand zet en zegt of een line in the sand. I don't know. Ehm waarbij je dan eh concludeert: gaan we niet doen, we gaan iets anders doen. En door dat met hele felle woorden te zeggen, en dat is grappig hoe die lm's werken, die moeten dat soort eh stick in the ground zeg maar steak in the ground eh markers achterlaten, zodat dan verder als die doorgaat dat echt in zijn geheugen blijft. Soort van dat ga ik echt niet meer doen, want dat ga ik doen. Ja. En je kunt het ook echt lezen in die reasoning traces dat dus dat soort ja kruimels, markers, whatever achtergelaten worden in zijn eigen contextwind die die zelf natuurlijk aan het bijvullen is om te zorgen van daar moet je gewoon echt niet meer nog een keer over na gaan denken, weet je wel. En dat dat zorgt er dan voor uiteindelijk dat en of dat nou helemaal causaal is of dat dat gewoon een een artifact is van hoe het geïmplementeerd is met hoe die transformer architectuur werkt. Dat dat is lastig te zeggen. Maar het is in ieder geval duidelijk te observeren in die rollouts dat dat gebeurt en dat hij daar ehm continu in staat is om echt wel een exploratie te doen. En daarom is ook eh zo grappig. Er zijn allemaal academische conferenties over machine learning en dan hoor je waar ze het over hebben. En dat is wel een beetje wat in de kraamkamer ook van de Frontierlabs besproken wordt en aandacht voor is. Ehm en één van de belangrijke topics was reinforcement learning exploration. En eh dat gaat over het idee. Reinforcementoning is een techniek die gebruikt wordt om dit soort modellen te bouwen. Maar het exploratieverhaal dat gaat erom van hoe kun je nou zorgen dat als een model autonoom te werk gaat dat het heel efficiënt ehm een soort mogelijke oplossingen gaat verkennen. Dus het moet niet teveel indexen op ik denk dat het zo moet en ik ga dat proberen. Als het niet lukt gooi ik mijn handen omhoog. Het moet eigenlijk heel efficiënt in staat zijn om een soort impliciete eh lijst te creëren van ideeën en die continu te reranken. En dat op het moment dat hij iets gaat proberen dat hij het juiste idee gaat proberen en op het moment dat hij dat daar wat van leert omdat het of niet werkt of half werkt dat hij daar dan weer op basis daarvan de expiration weer weer weer goed afstelt herkalibreert en doorgaat. En dat dat is ja, het is toch wel een beetje eh dat gaat wel neigen naar general intelligence. Ehm en want dat is toch hoe je heel veel problemen als mens ook eh oplost. En dat daar zie je dus hints van. En ik denk dat het feit dat het dus in een één systeem zoic is gemaakt, dat dat merk je vooral als je ermee gaat programmeren. Ehm nou dat vind ik ook wel een boeiende hè, dat zou dan zie je het gewoon heel erg. Ja, want je hebt natuurlijk de benchmarks. Nou goed, die benchmarks halen ze zelf ook tijdens hun presentatie aan. Dus ze gooien een beetje je eigen glaas in, want dan worden die hè en je ze vergeleken alleen met eigen eerdere modellen. Daar worden mensen dan ook een beetje zenuwachtig van. In dat opzicht eh hielp dat zeg maar niet voor het eerste verhaal net na de lancering hè van iedereen ging met de procenten gooien en procentpunten die er tussen de verschillende benchmarks zaten. Terwijl waar ik dan net als jij, ik ga meteen op X en op andere eh platforms zoeken naar al die ontwikkelaars die in hun achterzak een bepaalde ja, noem het eh de facto benchmark hebben zitten. Wat ik bijvoorbeeld heel veel zie is dat de mensen zijn met oude codeas hè, een jaar of zeven of acht oud met daarin een onoplosbaar ding. Het is ze zelf nog nooit gelukt en of ze hebben er geen tijd voor. En die gooien dat ding gewoon iedere keer tegen die modellen aan. Dus ja. En daarin las ik dus heel veel die zeiden: "Finally, het is gewoon gelukt. Ik heb hier iets wat in het verleden al die agents op vastliepen of modellen/agentic models hè. Ook de eh 4.1 vanuit kwam er niet door." En het lukt dan GPT5 door te blijven proberen, te blijven exploreren, eh iedere keer een stap terug te doen en te zeggen: "Oké, ik ben dat pad ingegaan. Ik ga het pad weer uit, want het heeft geen zin. Ik ga toch weer een ander pad in." Dat dat blijven proberen zonder vast te lopen als jij het maar genoeg tijd geeft en er misschien wel vier tegelijk aanzet, hè. Dat is natuurlijk allang een oplossing gebleken, dat hij er nu doorheen bijt. En ik vind dat wel ehm ja, prima dat die benchmarks er zijn. En ik zal die benchmarks ook altijd in de gaten blijven houden, want er zitten natuurlijk ook benchmarks bij die minder makkelijk te gamen zijn, hè. Hè, omdat ze zo breed zijn dat als je die hele benchmark wil kunnen faken, dan ben je gewoon iets wat slim is. Ja, de benchmark verdienen een miljoen dollar met je eigen business. Ik bedoel, als je die kan faken, helemaal prima. Zolang het maar legaal is. Ja, dan kan jij andere dingen ook, weet je wel. Dus dus eh dat dat ja, die die helpen dan. Maar ik het is minimaal zo interessant om te kijken. Ik heb hier gewoon een probleem in de kast liggen en dat trek ik gewoon iedere keer weer uit de kast en dan vraag ik gewoon weer dezelfde vraag. Solve deze bug. En dan zie je dus als je hem tijd geeft en want daar gaat het uiteindelijk wel om hè. Het is natuurlijk heel veel compute wat je geeft eh na trainen en die eh modellen toch erdoorheen weten te bijten. Dat vind ik wel een vette hier. Ja. En het is dus en dat hij dat beter doet, maar ook dat hij eh tegelijkertijd dus veel goedkoper is. Dus dat je ook niet je heel erg druk hoeft te maken. Want met cloud op, ik zweer als je gewoon een kleine codeessie doet, zit je zo in $20 en dan denk je nou ik heb maar ik heb maar een kwartiertje lopen programmeren en nu ben ik al $20. Nou oké, dan moet je wel je uurie verhogen. Dus zeg maar de de kosten zijn ook echt wel belangrijk in dit soort eh scenario's. Ik wil nog een ander ding, belangrijk ding van de release eh highlighten wat misschien een beetje eh ondergesneeuwd kan worden, maar waar waarvan ik denk dat is echt een heel belangrijk resultaat. En dat is eh de lagere hallucination rate. Dus eh het eh hallucinations wordt door niet door iedereen op dezelfde manier gedefinieerd, maar ik eh ik kwam een eh Twitter poll tegen en daar was ik het heel erg mee eens met de definities dat als er feiten verzonnen worden, dus als er gewoon feiten naar voren komen van in deze code en dan geeft hij een naam van een functie die niet bestaat. Dus echt gewoon ja, iets feitelijks verifieerbaars. Gewoon incorrect. Eh ja, het is een eh zeer gevaarlijke bluf die met volledige overtuiging aan jou verteld wordt als feit. Stond er maar bij, ik bluf. Dat zou helpen. Dat precies. En het staat er dan niet bij. En op belangrijke benchmarks zie je dat de hallucination rate ge gedeeld is door vif. Dus hij hij hallucineert significant minder. Dus waren die eerste 5% van de scenario's in een bout benchmark nu nog maar rond de 1% of lager. En het is heel belangrijk, want het gaat gepaard met nog iets. En dat is dat die context window van die model is, hoeveel hoeveel kunnen ze tegelijk in de overweging hebben? Is ook opgehoogd van 200K naar 400K. En wat ze ook nog eens hebben laten zien is dat de stabiliteit van het model, dus dat hij dat die eh waarheidsgetrouw blijft, eh veel beter standhoudt tot aan het hele grenspunt van die 400.000. Ja, want dit is misschien dit is een beetje een eh een punt wat veel vergeten wordt of niet begrepen omdat het ook het is allemaal hartstikke nieuw en vrij complex hè dat er dan wordt gezegd: "Er is een grotere contextwind hè, dus ik zeg altijd je kan er meer boeken in plakken dan dat je gewend was. Je kan meer meesturen met je vraag meer bijlage bijvoegen bij je vraag dan dat je voorheen kon." Maar het is leuk dat jij zoveel ruimte hebt om je bijlage toe te voegen. Maar als die bijlagen daarna amper bekeken worden en eigenlijk niet meegenomen worden in het in de deliberation, dan heb je eigenlijk een soort ja, kartonnen of eh piepschuim context window. Dat is meer een belofte op een specsheet dan een daadwerkelijk werkende context window. Daar heb je natuurlijk training voor hè, dat je zo'n need en een hashack doet. Dus dan stop je eigenlijk een heel klein feitje ergens in die hele grote bijlages en dan vraag je specifiek dat feitje terug. En dan blijkt inderdaad dat veel modellen met grote context windows tussen aanhalingstekens eigenlijk niet de aandacht hebben om dat hele context window daadwerkelijk mee te nemen. En deze heeft het dus eigenlijk wel tot ieder geval 256K begreep ik. 400k. Ja. Oh ja, daar vanaf daar ging die een beetje naar beneden daag. Dus reduceert zeker wel eh voorbij een bepaald punt, maar het blijft echt best wel hoog en er zijn verschillende benchmarks die dat meten. Ik vind trouwens Nederland hck een hele slechte benchmark want dat is gewoon retrieval. Dat is gewoon kan ik een vraag beantwoorden die direct terug te vinden is ergens in deze context. Maar wat veel lastiger is dan dat dat kan je namelijk bereiken met een aantal hele efficiënte architecturen waardoor je tot hele langere context windows kunt voor het retrieval gedeelte. Maar als jij informatie moet combineren die op meerdere plekken staat diep in de contact window. Dus er zijn drie of vier feitjes die gezamenlijk het antwoord kunnen voor 1000 needles in de stack en die moet je met elkaar vergelijken en daar en daar een antwoord op geven. Dat is moeilijk. En en dat is waarom attention ook zo duur is. Waarom die contexten zo moeilijk lang te maken is. Omdat als je alles met alles moet vergelijken, dan heb je een kwadratisch probleem. En dat betekent dat het heel duur is in memory en in compute. Ja, want jouw vraag in heter letterlijk houdt gewoon chips bezet toch die een ander op dat moment niet mag gebruiken. Ja. En hoeveel chips het bezet houdt is afhankelijk van hoe zwaar het is om te berekenen. En dat gaat omhoog, zeer omhoog met de contextwindo. Dus dat we zomaar 400K hebben als contextwind, dat is wel significant. Je springt van hallucineren naar contextwinen. Allebei belangrijk. Maar even terugkomen op het hallucineren, want dit is natuurlijk de grote eh in ieder geval bij de eh hoe zeg je dat? Gemiddelde gebruiker van AI systemen die ik spreek, even zo gezegd is dat hallucineer ding gewoon een beetje onder het volk. De burgers, de burgerij die zeggen van: "Ja, daardoor vertrouw ik gewoon dat hele systeem niet." Terecht, hè. En daarom highlight open in hun lancering ook de use cases legal en healthc. Want op het moment dat jij vragen gaat stellen aan chatt, ze hadden tijdens de demo een patiënt die genezen is, die een hele moeilijke beslissing moest maken in een genezingstraject. En die gebruiken chat GPT om geïnformeerd te zijn. Dus ja, hallucinaties in dat soort situaties zijn desastreus. Dus het was één van de bijna existential problemen voor open air om op te lossen als ze dat niet onder controle krijgen. En daar hebben ze daar hebben ze dus gewoon een hele grote sprong in gemaakt. En wat je ook ziet is dat omdat er heel veel ehm datapnerships gaan, dit is meer chat GPT als gebruiker, eh wordt er heel veel informatie ingetrokken om jouw vraag te beantwoorden. Heel veel super recente actuele informatie, informatie die een paar minuten geleden pas op het internet gepubliceerd is, kunnen ze al integreren in het antwoord. Maar het is dus nu ook heel feitelijk accuraat op al die externe informatie. En dat is toch één van de grote killer use cases van chat GBT is dat het gewoon Google overneemt. En dat is natuurlijk ook de hele lucratieve positie eh die open in eh kan nemen. En is het in dat opzicht niet sowieso hoor, heel even uitzoomen. Maar wat ik ook een beetje voel, ik heb een beetje echo's van ik draai ook alweer een tijdje mee in die hele eh tech wereld releases, keynotes en eh samen chippies eten om 7 uur, want er komt iets vet, weet je wel. Dat was vroeger natuurlijk de Apple keynotes. Dat zijn nu een beetje de open eh presentaties voor mij geworden. Ehm maar toen het was heel erg spec driven toen al hè. Dus in de tijd even echt lang geleden zeg maar dan ging het over oh zoveel herz heeft het scherm of zoveel megapixels heeft een nieuwe iPhone of zoveel gig interne eh zoveel werkgeheugen heeft de iPhone. En dat is dan in het geval van Apple altijd. Te weinig werkgeheugen, te oude camera's, displays die Samsung al 2 jaar heeft als ze niet zelfs door Samsung gemaakt worden. Dus ik heb ik ben altijd heel erg gewend om je hebt de release van nieuwe Apple producten waarin eh ja, de nerd de spec nerds zeg maar waar ik deels ook onderval prima. Eh en ontevreden zijn hè, want het zijn een soort van vorig jaar specs in een model eh apparaat wat nog duurder geworden is, zeg maar. Ahuh. En ik voor mij ik heb een beetje een soort zelfde eh sfeer bij deze open AI eh bij GPT5 dat ik denk het voelt veel meer als een soort eh eindgebruiker consumenten ding hè. Dus dat ze gewoon hebben gevraagd eigenlijk waarschijnlijk in panels en kijk in hun eh user data hoe het gebruikt wordt van oké hè het wordt eh veel gebruikt voor eh medische doeleinden. Het wordt veel gebruikt voor schrijven en het wordt veel gebruikt voor programmeren. Dus die drie gaan we keihard op inzetten. Eh daarnaast zien we dat hallucineren voor mensen een eh probleem is. Gaan we ook op inzetten. Eh prijs is een probleem, want we kunnen niet meer goed concurreren in de markt met de Geminis en de clouds. Oké, gaan we ook aan werken. Eh er is verwarring over modellen, dus mensen willen eigenlijk die modellen niet kiezen. Dat hele reasoning en nonreasoning is te complex. Oké, gaan we ook weg abstraheren. Het voelt voor mij eigenlijk iets heel erg wat gedreven is door hele ja, soort boerenverstand markt inzichten en niet door de model conurs die vragen eh nou ja, je snap je die op zitten van wat kan het model? Ik vind dit dit gewoon dit is de karakterisering van de release, want het laat gewoon zien dat Open echt een productbedrijf is eh in een vrij volwassen fase. En dat is ook wel logisch te rijmen bij het feit dat ze giga groot zijn. En ze hebben volgens mij 700 miljoen actieve gebruikers, wat echt een gigantische grote groep is. En ook in deze release had ze continu over free. Dus de free tier zijn ze de hele tijd aan het uitbreiden. En dat laat ook wel zien dat ze ze gaan gewoon voor de 2 miljard gebruikers, weet je wel, dat ze willen zo snel mogelijk naar dat punt. willen echt die consumermarkt helemaal veroveren. En ik denk dat ze dat met de focus die ze hebben goed doen. Ehm en wat je tegelijk ziet is wat wat de specset nerds als het ware waar ik mezelf ook zeker onderreken eh op hopen is Glimpses of AGI. Full reasoning. Right. En eh ze hebben met zo'n project wat ze laatst gedaan hebben, dat is wel een grappige context, is dat je hebt een een international math olympiad eh de IMO en daar hebben ze aan geparticipeerd na samen met eh Google om te laten zien hoe slim die modellen kunnen zijn in het limiet en dat ze dat soort problemen op kunnen lossen. En er zijn best wel veel mensen ook echt specialisten, wiskundigen en en ook mensen die echt alleen puur op die modellen focussen, machine learning specialist en dergelijke, die vonden dat dat best wel een een sick resultaat was wat ze daar hadden gedaan. Ze hadden namelijk de gold medal gewonnen door vijf van de zes problemen van zo'n nooit gelekte test. Echt een unieke nieuwe test die niemand weet eh hadden ze gegeven aan die modellen hadden ze opgelost. En Open AI heeft daar ook goed gescoord. En ze hebben ook toen gezegd: "Dit komt niet in GPT 5." En het is dus heel duidelijk dat ze een bepaalde capability hebben om bepaalde top tier intelligence te produceren intern en ook zelfs te testen publiek dat ze daar ook open over communiceren dat ze dat behalen. Maar helemaal niet dat niveau per se willen willen deployen. Ja, je kunt het je kunt het ook een beetje vergelijken met ik weet dat is bijvoorbeeld bij Meta eh als ze dan twee keer 16K displays hebben hè. Dus mini OLED 16K displays die laten waarschijnlijk op maat maken ergens in China. Ieder display is een ton per oog. Ja, daar hang je dan een datacentra GPU's achter om eh op 120 fps 21K displays aan te sturen. Die bril die hang je aan een touw aan het plafond, want anders breek je nek. Zo zwaar is die bril. Nou dan nee, maar ik bedoel dat heb je in je lap allemaal staan, hè. Dus je bent een paar miljoen verder al met een set-up. Dat doe je dan bij iemand op. Die laat je rondlopen in VR en die zegt dan: "Wauw, VR is the future." Alleen van dat punt van een goede lab demo hè die je met met miljoenen hebt moeten maken komen naar een consumer product wat je breed uit kan rollen. Daar kan gewoon 8 tot 10 jaar tussen zitten. Maar je kunt dan al wel eh zeggen: "Joh, ik heb het gezien." Hè, dus ik denk ik ik kan me goed voorstellen dat als jij wat wij bijvoorbeeld bij die Math Olympiad nu hebben gezien hè als als buitenstaander, dat je eigenlijk al te zien krijgt joh, als we als we 20 keer zoveel computer zouden hebben eh en eh dat zou betaalbaar zijn hè, want het is nu gewoon niet betaalbaar om zo'n model uit te rollen. Los daarvan kan ik me wel voorstellen even site eh sidene dat Open en jij richting de $2000 eh subscriptions gaat en die ze gewoon aan bedrijven gaan aanbieden. Misschien wel $20.000 Je krijgt denk ik dan een beetje dat Apple Vision Pro verhaal waarbij er dan gewoon geen markt is voor het product omdat het gewoon zo duur is dat er maar een heel select aantal mensen dat nog waard vindt. En dus gaat het heel erg nu om in de markt en bij dit soort releases over hoe ziet de de de aantrekkelijke variant die economisch uit kan op schaal kan deployen. Hoe ziet dat product eruit en wat zijn daar de scores van? En ik denk dat de dus als mensen zeggen: "Oh, die curves zijn flat en de de scores zijn niet beter." Dan is het denk ik veel meer van dit is wat ze op een aantrekkelijk prijspunt kunnen produceren en heel breed uit kunnen rollen. En dit is niet hun maximale wat ze ook maar intern kunnen produceren. Ze hebben misschien waarschijnlijk een set-up die op die benchmark waar ze nu 75% scoren misschien wel 85% scoren. Maar dat gaan ze niet aanbieden als product, want er is gewoon te weinig vraag naar een model wat misschien $10.000 000 per week kost om net even die 10% te krijgen. Dus dan zit je toch in het spel van de mening returns en wat kan je naar de markt brengen. En als we dan even advocaat voor de duivel spelen richting ons eigen argument nu hè, want eh er zullen mensen die luisteren zijn zeggen: "Oké, Wiets en Rick eh GPT5 apologists die zeggen dat er nog een geheime techniek binnen opening beschikbaar is waarbinnen AJI dichterbij is." Eh bijvoorbeeld eh de eh het is het de Arc eh 2 challenge eh hè de de de van ehm Col die eh AGI achtige test doet hè. Arc 1 is dan eh saturated en Arc 2 eh zit op eh ik weet het niet eens uit mijn hoofd niet heel hoog. Ja, voor Grock 4 volgens mij. En dan ook nog de eh de supergrok zeg maar. Ehm en volgens mij scoort GPT5 9 pun zoveel procent daarop hè. Dat is natuurlijk de eerste die ik ook even langs ging in mijn eh onderzoek naar eh benchmars. Ehm zijn er je had het net over een soort tekenen inklings eh van eh potentieel een weg naar AGI hè. Eh bijvoorbeeld dat eh wat ook de jongens van Project 2027 aanhouden, hoe langer zo'n agent eh vol kan houden zonder vast te lopen en zinvolle dingen kan blijven zeggen. Laat dat even duidelijk zijn. Eh ja, dat is voor hun één van de key indicators zeg maar. Wat zijn voor jou nu dan indicators dat je zegt ehm dat eigenlijk valt het wel mee. Het valt op een bepaalde manier ook een beetje tegen. Misschien zijn we toch een beetje aan het afvlakken als we onszelf even uitdagen om die kant te verdedigen. Ja. Eh ik heb het idee dat dat misschien wel minder van open gaat komen dan van andere laps. Dus eh als ik kijk naar Ik heb dus een paar uur bijvoorbeeld geprogrammeerd met GPT5 eh gisteravond en ik kwam er gewoon wel achter dat het bepaalde denkfouten maakt die ik bijvoorbeeld niet terugzieie bij Gemini 2.5 Pro. En ik heb het idee dat doordat ze een soort sweetspot hebben gevonden is het best wel goed, maar ook niet echt heel goed. En ik denk dat er misschien andere partijen zijn die intenser drukken op het bereiken van het allerslimste model. En ik denk dat die Arc AGI is een heel goed voorbeeld waarbij dus Grock 4 eh 16% eh bijna 16% scoort. Ehm wat echt 60% hoger is dan Open Ace. net nieuwe model. En eh die mensen bij de XR organisatie zaten allemaal op Twitter te zeggen van: "Ja, en dat is echt een oud model en we zijn al veel verder dan dat intern." Ja, die waren natuurlijk trots, hè. Ja. Ja, die dachten: "Kijk, wij zijn eh veel beter bezig." Dus ik denk dat ehm tekenen dat er nog slimmere modellen mogelijk zijn, die komen vooral vanuit die signalen dat dat er op dat soort benchmarks nog best wel echt vooruitgang geboekt al wordt. Maar het blijft heel lastig om te zeggen van waar liggen de limieten van deze technologie? Ik denk dat eh benchmark zijn jouw eigen is jouw eigen horizon, jouw eigen scenario's zijn die anders geworden door de release van G. Ik vind het zo grappig dat iedereen is zo van Horizon update, want wat is nu verwachtelijk het limiet van AI? En ik ik denk dat iedereen wel eh een beetje een soort gevoel heeft van de tijdlijn is langer geworden zeg maar. We zijn niet zo super dicht bij echt super intelligence die eh mensen heel snel gaat displacen en echt heel veel heel veel mensen heel snel op zijn leed gaat maken dat er toch eh al als het als we echt zo dichtbij zaten, dan zou een bedrijf als open air gewoon meer releasen dan dit. Dat is toch het overheersende gevoel. Ehm en ik denk dat daar gewoon wel echt een kern van waarheid in zit. Alleen wat ik wat ik tegelijkertijd ook wel eh belangrijk punt vind is dat heel veel van dit soort verbeteringen komen in step changes en we zitten nog steeds in dat paradigm van reasoning zeg maar. We hebben voordat er reasoning modellen waren had je zeg maar een bepaalde plateau van het wordt niet heel veel beter tussen GPT4 en GPT4 en ze probeerde zeg maar ja 4,5 was een beetje een dud natuurlijk kwam uit een eerder paradigma. Precies. Ja. En en toen was met reasoning echt weer een soort nieuwe wind gevonden van hé, we kunnen hier weer echt wel best wel ver mee komen. En ik denk dat eh binnen reasoning is er nog best wel veel mogelijk. Er zit veel rek in reasoning zeg maar wat je ermee kunt. Maar ik denk dat er ehm dat er nog wel stappen gezet kunnen worden die nog weer een boost kunnen geven. En ik denk dat we wel allemaal het gevoel hebben dat zelfs de de beste systemen die we nu hebben met die puur zeg maar reasoning eh scaled up hebben zijn al echt extreem capabel en waardevol waarbij ze heel veel taken echt superhuman doen. Dus er is een benchmark van eh Google Gemini 2.5 vi eh Deep Think Paper eh report. En Deep Think is de variant die zij hebben geproduceerd, die ze ook hebben gebruikt als basis om die IMO 2025 eh wiskundeedstrijd eh te winnen of daar een gold medal in te behalen. En in die paper doen ze een onderzoek naar het reproduceren van machine learning research implementaties. Want zij willen natuurlijk bootstrappen in de zin van we gaan onze modellen gebruiken om ons proces van modellen maken beter te maken. Rond is en dan kan je een soort van koffie gaat drinken. Ja, dan gaat het hard. En dan doe het maar voor mij. En daar zijn twee van de vijf benchmarks die in dat in zo'n zo'n benchmark centraal staan van kun je een machine learning implementatie implementeren. Eh daar verslaan ze een expert mens die 8 uur de tijd krijgt om zijn beste implementatie op te leveren. Die worden verslagen door dat Jaminai 2.5 model. Dus er zijn al voorbeelden waarbij je beter kunt zeggen: "Laat een II model dit deel van de release maar verbeteren." Ja. En ik denk dus dat iedereen wel door heeft van als we daar nu zo tegenaan hikken, dan is er zeg maar één grote unlock nodig en dan is er echt best wel veel aan de hand. Ja, dan krijg je een soort Cambrian explosion achtige sfeer. Namelijk we weten nu hoe het moet, het werkt. En nu kunnen we ook nog eens dat ding gaan gebruiken om dat datacentra te verbeteren, om de interne management van ons bedrijf te verbeteren, om al onze onderzoekers te assisteren en deels te vervangen. En op een gegeven moment gaat het en waar die limieten allemaal liggen enzo, dat is allemaal lastig, want dan dan is het een kwestie van bottleneck. Waar komen de nieuwe bottlenecks vandaan? Daar hebben we het ook al eerder over gehad van de bottlenex het verhaal zeg maar. Maar ik denk wel wat eh positief is voor de sector als je het hebt over AI winters en AI summers waar zeg maar als er een tijdje progressie uitvalt dan zie je vaak een soort kleine consolidatie in de markt en dan blijft alleen het nuttige spul over zeg maar. En wat je wel ziet is dat de omzetten van een chat GPT maar ook de omzetten van een Gemini en de omzetten van een antropic zijn heel gezond. Dus mensen zeggen het over hoge salarissen en grote investeringen in capex en dergelijke voor datacenter buildouts. Maar de omzet die ermee gedraaid wordt is heel serieus. Dus ik denk dat we een lange periode gaan zien waarbij er makkelijk genoeg geld is om in ieder geval de huidige modellen ehm te blijven verkopen. Dus die zijn waardevol. Alle developers die willen op zo'n model hangen. Heel veel professionals hebben dat nodig voor hun eh tekstuele ook een beetje return on investment op dat model hè. Dat heeft je je kan het op de eurocent of dollarcent uitrekenen wat het gekost heeft om dat ding te maken. Dus dat wil je gewoon terug. Absoluut. Dus het is terugverdienen, het is marge produceren en zodat je dan free cash flows hebt om dat onderzoek verder te te zetten. En ik denk dat je wel ziet is dat we wel een punt hebben bereikt waar we comfortabel kunnen stellen de cashflows uit een chatpt business die bijvoorbeeld richting de 10 miljard omzet per jaar gaat. die kunnen comfortabel heel veel nieuw onderzoek betalen. En we zijn niet eens heel efficiënt nu dat onderzoek aan het doen omdat je door de concurrentiestrijd heel dik moet betalen omdat iedereen tegelijk al die resources claimt, de resources van menselijk kapitaal, dus de onderzoekers en iedereen claimt de datacenters tegelijkertijd. Dus we hebben een hele inefficiënte markt. Alles is extreem duur om te kopen en nog kunnen we het bijna financieren vanuit de free cash flow. Dus ik denk dat dat wel voor mij een beetje een teken is van this is all here to stay voor het geval mensen daar nog aan twijfelden. Ja. Ehm en en zo'n zo'n eh release als GPT5 draagt daar heel erg aan bij. Dat is echt zo'n motor die die sector dan echt gewoon heel gezond houdt omdat het gewoon prijseconomisch heel aantrekkelijk is. Ze verdienen waarschijnlijk een goede marge op en het is heel kapabel voor de use cases die mensen veel gebruiken. En daar kan dan weer op voortgebouwd worden. Ja, ik denk ook in dat opzicht, daar hebben we het ook wel vaak over gehad, maar ehm even een een ehm anekdote dat ik ik was op een gegeven moment op router aan het kijken. Zo'n eh tussenrouter waardoor je met allemaal modellen tegelijk kan praten als ontwikkelaars. Prettig. En die hebben gewoon statistics waardoor je gewoon kan zien in een week welke modellen het meest aangeroepen worden. En toen was ik wel even verbaasd dat ik dat dat ik gewoon zag in zo'n soort eh spekkoek eh aan chart van Open Jay is daar maar 5% in ofzo hè. En dan in de categorie programmeren was dit trouwens hè wat zij beschik. Maar dat moet je wel even dat is het ding aan die open data is super nice dat ze dat doen van een open router. Dat is heel waardevol. Maar je moet niet vergeten dat die data super skewed die is heel skewed naar bijna niemand gebruikt op schaal open AI modellen via open router zeg maar. Nee nee precies. Dus ik mijn punt was ook zeker dat is niet de markt hè, want je hebt geen idee wie allemaal eh open direct aanroept op de op de API. Maar eh ik vond er nog wel een signaal in zitten en daarmee bedoel ik niet open en is helemaal niet populair bij programmeurs. Ik denk dat gewoon heel veel ik denk dat cloud code op dit moment in combinatie met eh eh cloud modellen een een een momentje heeft de laatste maanden, laat ik het dan zo zeggen. Maar ik denk dus dat eh dat helemaal niet per se een reden voor alarm hoeft te zijn binnen openi. Eh ik bedoel, het is prettig om geld te verdienen aan ontwikkelaars. By the way, Entropic is rate limits aan het instellen omdat het helemaal niet zo goed lukt om dat maxplan daadwerkelijk eh betaalbaar te houden. Maar goed, ik kan me wat ik eigenlijk wil zeggen is ik kan me goed voorstellen dat je een eh even een fictieve meeting binnen open hebt waar je zegt: "Oké jongens, op router zien we of we zien eigenlijk dat we qua ontwikkelaars eh nog maar 20% van de markt hebben. Eh de conosurs op Twitter zijn allemaal pist onze modellen lame zijn." En dat dan Sam Alman zegt: "Gast, we gaan naar 1 miljard consumers toe." En dit is gewoon de revenue stream die we hebben uit een daadwerkelijk product hebben, hè. Dus je kunt succesvol zijn in een in een in een markt terwijl je misschien minder succesvol lijkt op andere punten. Ik ik wil hier niet mee zeggen: "Alles zit wel goed bij Open. En jij, het is allemaal prima, hè, want ze voelen enorme druk vanuit eh eh Deep Mind op het moment en Antropic en eh Grok." Maar ik ik kan me wel voorstellen dat eh even heel suf voorbeeld hoor, maar ik was laatst in Japan. Ik was ik had even vakantie en ik zat in een guesthous en we zaten met een groep mensen daar te eten en ik hoorde om me heen gewoon heel vaak chat of chat GPT. Dat was even al een ding. Dus ik dacht op een gegeven moment ik ga toch nou even een soort journalistiek doen en gewoon even met wat mensen met wat sakewijn erbij praten. Het bleek gewoon dat nou wat was het van de negen van de 10 mensen in dat guestthus had hun complete reis gepland met chatg. En dan kan je zeggen ja boeien dat was vroeger Google. Maar ik vind dat wel zeg maar een kleine het leeft enorm als product bij de eindeindgebruiker. En ik denk dat het niet zo gek is dat open en jij veel aandacht besteedt aan daar een fenomeen blijven, hè. Absolut. Ja, het is gewoon hun waardevolste markt en waar ze het verst voorlopen. En dat momentum is heel erg lastig in te halen. Dat is ook een eigenschap van consumenten bedrijven is dat als ze eenmaal eh heel veel bekendheid genieten, een momentum hebben, dan is heel moeilijk om daaroverheen te komen. Zelfs met een veel beter product. Ehm en dat is gewoon toch wel wat je ziet is dat mensen stappen niet zomaar over. Consumenten zeker die iets heel nieuws, compleet nieuw paradigma. Het is een soort chatbot en je kan ermee praten. Je kan er foto's naar sturen, weet je wel. Die gaan als iets hebben wat werkt heel helemaal niet snel op zoek naar een alternatief. Ehm maar ik dacht dus ook wel misschien eh hè zie ze een beetje de codingmarkt wel en eh focussen puur meer op chatbt en zie je steeds minder aandacht voor het coding gedeelte. Maar dan zie je toch weer dat die Amerikaanse cultuur misschien eh de kop opzek zegt: "Nee, we willen coding ook winnen. We win it all." En dus ik vond het wel mooi om te zien dat ze toch wel een soort eh ja, echt wel comeback hebben gemaakt in de coding eh wereld. Want ik denk dat eh 80 tot 90% van de developers eigenlijk open AI modellen best wel links liet liggen in de cursor ID's en de cloud code gebruikers omdat je gewoon veel beter Gemini of Cloud kon gebruiken in die eh programmeeromgevingen. En nu eh hebben echt een aantal mensen die echt eh neutraal erin staan gezegd: "Ja, ik ben helemaal om naar GPT5." En inclusief ik zelf heb nu het idee dat dat GPT5 mijn daily driver is en dat ik soms misschien voor super hard reasoning dingetjes nog een keertje even bekijkt wat Open zegt of even kijkt wat ehm ehm Gemini 2.5 zegt. Maar qua usability en kwaliteit zit eh GPT5 echt wel besetpot waardoor ze nu denk ik King of the Hill zijn. En dan zie je ook dat heel veel deelpers gewoon in één keer [&nbsp;__&nbsp;] gewoon hun gebruik overgooien. Heel anders dan in de consumentenbusiness. Want in de consumentenbusiness gaat niet iedereen even chaten wij veel lager bij ontwikkelaars, want die weten wat endpoints zijn en die weet die die zijn natuurlijk veel en er zit er zit curs tussenin hè, want Curser die maakt het een een model dropdown picker. En dat is een echt een belangrijk eh aspect, want ik weet nog dat in het begin dan kon je wel switchen naar Googles modellen in cursen, maar dat werkte voor geen meter omdat ze dat niet testen enzo. En nu zijn ze echt wel gewoon als een soort drie in ieder geval. We integreren minimaal chat GPT of open modellen, Gemini modellen enic modellen op heel hoog kwaliteitniveau. Dat is gewoon de minimum support eh structure. En dan daarna Croc 4 erbij en daarna open source modellen erbij. Ehm en maar die maakt het dat die concurrentiestrijd heel heftig is binnenkort. Ja, Curser creëert zo'n Hunger Games door die dropdown. En als je een als je een analyse zou maken over de markt nu zeg maar voor om het in de geschiedenisboeken te zetten, zou je een boek kunnen maken met die model picker op de voorkant gewoon. Want die model picker dat is gewoon de keiharde nonloyalty van ontwikkelaars om te zeggen: "Oké, ik switch weer over. Ik switch weer over." En dat het ook drop in replacement zijn dankzij het feit dat al die scaffolding die cursor doet op model specifiek ook nog eens helemaal klopt. Het is niet alleen maar een endpoint switch. Ze weten zij zorgen ervoor dat al die prompts en al die dingen hoe je met die met die met die verschillende API's van die providers interacteert dat dat allemaal heel goed werkt. En dat dat is ik denk ik op dit moment is Curser de nummer één concurrentie aanjager op het gebied van coding eh modellen. Ja, omdat het die omdat ze er tussen zitten, wat eigenlijk voor ontwikkelaars prettig is, omdat die druk dan zo op die laps blijft staan om allemaal kwaliteit te leveren. Ja, concurrentie is goed voor de eindgebruiker. Ja. Ja. Ja. Hyé, want we ik ik zat nog te denken, ik wil ehm ik hoor een beetje in het verhaal van oké in het eh soort van eh AGI komt eraan narratief. eh is het niet meteen eh het gaat niet meer gebeuren op de korte termijn, hè. Ik bedoel even die ik ik heb nu een aantal keer Project 2027 genoemd. Eh dat weten de luisteraars die langer luisteren ook. Dat is niet een scenario wat ik 100% onderschrijf en zeg zo gaat het gebeuren. Ik vind het een interessant datapunt en een fenomeen om mee te nemen als je geïnteresseerd bent in dit soort eh gesprekken en dit onderwerp. Eh persoonlijk zit ik op een wat langere tijdslijn, maar niet verder dan 10 jaar. Dat vind ik nog steeds maatschappelijk totaal disruptief. Dus ga kunnen we dan we kunnen met koffie gaan praten over 2 vi of 10 jaar. Maar dat is nog steeds allemaal best wel een ding als ik ja best wel een ding. Dus ik noem het voor mij project 2032 I don't care. Eh iets om in de gaten te houden. Niet volledig weerlegt met GPT5, maar ook niet soort van het had ook zo kunnen zijn dat GPT5 Ik wist het niet. Ik ging gisteravond kijken en ik start echt die livestream en toen dacht ik nou ik ben ik ben heel benieuwd zeg maar. Het wordt of echt een 4.5 achtige DUD. Het valt echt heel erg tegen. Dat is gewoon niet zo. Ikal in mijn ogen subjectief. Rik is het van mij. 5 was echt een mega dut. Echt een mega dut op een hele grote schaal. En GPD5 is dat echt niet. Nee. Dus we zitten op een soort en sterker nog, de grafieken van bijvoorbeeld die meter benchmark lopen nog gelijk. Dat vond ik wel grappig, want die hebben dus een projectie gedaan en daar val dat het een exponent is. Ja, het is Ja, en het is pretty much alsof Open en jij net zo lang is blijven doortrainen tot hij op het lijntje viel en dat het gewoon dat lijntje kon blijven lopen. Dus eh dat dat klopt ook nog eh eh best wel goed. Het is alleen niet eh in mijn ogen ehm wat bijvoorbeeld Genie 3 wel voor mij heeft gedaan. Ik ga toch even eerder over Genie 3 praten dan GPT OSS, omdat ik denk dat we Genie 3 op een aantal manieren hierin kunnen eh vouwen. Toen ik eh kijk toen ik Genie 3 zag eh eh en voor de luisteraar, we zijn al wat meer bekend met ehm nu ben ik even het andere eh hoe heet het andere visuele model van eh world model. Ja. waarin je eh filmpjes maakt. Vio, sorry, ik haal ze zelf. Dus ik wil luisteraars zullen ze misschien ook door elkaar halen, maar Vio is het videogenatiemodel van Google Deep Mind waarin je geen invloed hebt achteraf. Je kan een prompje maken, dan heb je een video en dat was het. De Genie series heb je een keyboard controls alsof je in een computergame bent en kan jij nadat je je prompt hebt ingevoerd het karakter wat dan in beeld komt dat kan een koe zijn, een blaadje en een auto of waar je een boom whatever waar jij controle over wil krijgen, kan jij gaan besturen. Je kunt gaan rondlopen in die wereld. Die Genie serie kenden we al. We kenden hem ook van andere partijen al. Je had meer van die soort active dreaming simulator ofzo. Dit dat soort eh Minecraft in de nieuws ook een keer aangehaald. Dat voelde allemaal redelijk psychidelisch. Alsin je hebt je had echt het idee dat je visueel door een hallucinatie heen liep die ook allerlei artifacts had. Dat had de Genie serie tot en met Genie 3 of tot Genie 3 ook. De Genie 3 series op 27p 30 fps uit mijn hoofd. kan ja vind echt nice. Kan een eh bijzonder consistente eh controleerbare droom voor jou genereren. Niet voor jou als eindgebruiker nu live hè. We kijk bekijken de demo's zoals ze er staan. Maar bij eh Genie 3 en ik heb dat bij Vio ook gehad destijds en nu had ik het bij Genie 3 weer krijg ik een ander gevoel gevoel in mijn buik. Een soort mix van vlinders en angst. Ik kan het niet anders omschrijven als dat. een soort verliefd en het is super spannend wat hier allemaal gebeurt. Ehm hoe had jij dat zeg maar bij Genie 3? Had jij ook zag jij hem al zo aankomen en dat je zoiets van ja had ik al gezien of zag je ook van oké damn dit is wel echt een ding man. Ja, nee ik denk dat ik kan echt al momenten pinpointen wat eh in San Francisco genoemd zou worden feeling the AGI. En ik had eh het moment dat ik Cloud 4 sonnet incursor met een terminal aan de slag zag gaan zeg maar die gewoon even een terminal commandje dit terminal commandje dat en dat dan een heel ding voor mij uitzocht beetje als die meter benchmark van hoel lang die doorgaat. Dat was voor mij echt een feeling die a moment. Ehm en ik had dat bij Genie 3 ook weer ehm nog meer of niet eens nog meer, maar nog een keer nadat ik ook VO3 had gezien. Dus ik had dat ook bij VO3 dat ik denk oké echt toen ik audio en video bij elkaar hoorde en die voorbeelden zag dacht ik oké dit is echt zo'n what the [&nbsp;__&nbsp;] moment echt een zeer ja ik ben toen ook weer even een stukje gaan lopen buiten zeg ik altijd maar ja ik moest echt even touchgrance want echt what the heck dus dat was heel vooral die meta scenario's dat menen zeggen van eh the prompt master is controlling us we will get him dat ja dat ze tegen het glas van de camera gaan slaan om eruit te komen niet beter preci dus dat je denkt van oké Oké. En dat je dit dan met die met die Genie 3 G 3 heb ik nog niet kunnen proberen en ik denk dat het nog meer eh leeft als je het echt uitprobeert. Ja, ik heb wel een aantal handsons kunnen vinden van mensen die al een weekje toegang hadden tot Genie 3 in de persruimte van eh Deepmind/Google. Ehm daar merkte ik juist aan, dat is echt wel grappig, die waren in mijn ogen een beetje overhyped terwijl ik en maar misschien dus niet als in die video's hè, je moet je voorstellen, die hebben een week daarvoren al toegang gehad tot Genie 3 en mogen die game controller, zo'n PlayStation achtige controller beet pakken en er doorheen gaan lopen. En dan en dan gaan ze daarna al meteen takes maken, zeg maar, hot takes van wat ze daar gevoeld hebben. En die staan gewoon in de gang daar buiten die ze echt in de camera te schreeuwen van what the hell, what the hell, what the hell. En ik bedoel, ik denk als je dan een week later een video van hun kijkt, zijn ze al wat rustiger geworden. Maar ik kan ik ik kan me wel voorstellen dat het ehm het is eigenlijk lucid dreaming hè, dus controle krijgen over een droomscenario die consistent blijft. Want dat één van die demo's is minuten lang hè is minuten lang gestoord. Één van die demo's is dat die dat vond ik trouwens nog steeds de meest wouze demo is dat ze blauwe verf op een muur verven. Ik ik dacht gaat hij de blauwe verf doen is die is zo saai. En zo ground zo gestoord zeg maar. Het is ook de perfecte Het is bijna art. Het is zeg maar de combinatie van iets super banaals. Dat is zo'n een muur verven maar dan zo bijzonder technologisch. Dus gewoon dit kon je absoluut niet bouwen gewoon. Nee joh, absoluut niet. Maar dit is denk ik ook het ding hè. Omdat wij, kijk, ik ik weet nog wel eens dat ik dan eh toen ik nog les gaf aan de hogeschool kreeg ik wel eens dingen gedemot door studenten. Die heb je dan dingen uitgelegd en je en dat is binnen een bepaalde scop wat zij dan kunnen, hè. Dus je gaat ervanuit als zij het eind van de week aan mij demonstreren, dan is dat binnen die scop. En dan heel sporadisch zag ik dingen dat ik zei: "Wow, wat heb jij nou gedaan? Dit is niet normaal." weet je wel, wa terwijl ik was op dat moment echt de enige die dat echt op waarde kon schatten omdat ik wist wat die student daarvoor kon. Ik wist welke informatie ik heb gegeven en wat de scope was van de opdracht. En als iemand daar binnen dan voorbij de scope gaat en echt iets heel bruuts doet, kan ik technisch en qua achtergrondinformatie inschatten: "Hier gebeurt iets heel bijzonders." Hè, dat compliment kregen ze dan van mij ook heel vaak van: "Ot je broer laten meehelpen hieraan of jij hebt gewoon net even jezelf voorbij gestreefd." En ik als ik denk dus dat wij als als je wat dieper in deze materie zit en dan die verfdemo krijgt hè, voor de luisteraars iemand heeft een verfroller met blauwe verf dat hij op een verf rolt op een muur rolt dan verder kijkt dan dat hè. Dus die draait eigenlijk de rest van de muur uit beeld. Dus die kijkt naar rechts zeg maar en die kijkt dan terug en ja daar zit nog steeds die verf op die muur. En ik kan me heel goed voorstell erop gesn is. Ja, het druipt nog zeg maar. En ik kan me voorstell ik bedoel en het ziet er trouwens fotorealistisch uit. Dat dat eerste feit is eigenlijk het video feit hè. Dus het generaten van lifelike imaging in videovorm was al gestoord. Dat we daar al aan gewend zijn is al te bizar. En dan heb je daarnaast ook nog eens: "Ja, maar die wereld is er daarna nog. Als je terugkijkt zit die data nog?" En ik en dan kan je als luisteraar denken: "Dan sla je dat toch even ergens op." Nee man, zo makkelijk. Dat kan je niet aan. Nee, dus dus dat is heel bijzonder. En wat ik vooral eh waarom ik zo enthousiast ben over Genie 3, dus sowieso heel knap dat ze dat kunnen simuleren, dat ze dat dat ze dat niveau van fidelity zeg maar voor elkaar hebben gekregen. En eh wat ze ook hebben dus toegevoegd is dat de eh promptable events, dus dat je ook tijdens dat het al bezig is, kan je bijvoorbeeld je loopt bijvoorbeeld door een straat en dan kan je zeggen je loopt bijvoorbeeld naast het water en dan zeg je er komt nu in één keer een jets ski voorbij en dan zie je in één keer zo'n jet ski voorbij komen. Dus dan gebeurt er iets op basis van wat je hebt gezegd. Nou, dat is natuurlijk een soort ultieme game engine achtige omgeving. Dus gewoon een soort Unity engine die mensen waar je zomaal los kunnen gaan op games. En games is leuk. Games is fantastisch. Je kan er heel veel vette dingen mee doen. Maar er is nog iets. Z mij het minst die games. Ja. Nou, ik ben ook niet zo'n gamer. En ehm wat ik vooral heel interessant vind is dat ze kunnen een heel groot eh openstaand probleem oplossen eh in embodied robotics. Dus als je een robot in de echte wereld wil plaatsen, dan is het voor voorheen is het altijd extreem moeilijk geweest om robots betrouwbaar te laten functioneren, omdat het zo godsmoeilijk is om data te verzamelen van die robot in operatie en simulaties. Ja, ik zeg altijd, sorry dat je onderbreekt, maar ik zeg altijd in de fabriek, het is ook nog een gecontroleerd iets. Je weet waar alle kasten staan, waar alle machines staan. Je hebt het full under control, maar dat er die dat er die middag iemand is die die machine komt repareren, zijn zoon bij zich heeft, die daar dan ook rondloopt. En trouwens met een warm kopje koffie wat hij voor zijn vader gehaald heeft, dat zat nou net even niet in de trainingszet. Precies. Precies. Dus dat is een heel groot openstaand probleem. En ik denk dat eh er hebben wel mensen pogingen gedaan om simulaties te bouwen die eh goed zeg maar de essentiële dingen, want het is dan een model van de omgeving, maar heel gesimplificeerd vaak nog. En daar dan proberen ze in een een soort offline training te doen, alsof die 100 of 100 miljoen keer alles kan zien, alle variaties. En dan gaan ze kijken, gaat dat ook echt werken als het in de echte wereld komt? Waar natuurlijk heel veel dingen niet in zitten die in dat model eh zouden moeten zitten. Maar door een soort holistische world eh simulation te maken, zo'n world model wat gewoon de algehele realiteit probeert te modelleren met eh nauwkeurige physic zeg maar, dus hoe verf zich gedraagt, hoe muren zich gedragen als daar een auto tegenaan rijdt, et cetera. Als dat hoog genoeg in resolutie komt, dan kan je die gap tussen wat je kan doen in de echte wereld en wat je kunt doen in simulatie zo klein maken dat je eh robots kunt creëren die heel eh betrouwbaar en autonoom kunnen opereren in de fysieke wereld. En ik denk dat iedereen heeft het gevoel dat de AI wave heel erg gaat over de de white color jobs, de de de desk jobs, de de intellectuele nadenkbaan ofzo en taken. Maar ik denk dat er wel heel duidelijk een push is van dat ook in de fysieke wereld doen. En Tesla claimt natuurlijk ook met Tesla Optimus en dergelijke, maar dit soort doorbraken zijn echt nodig, want je kunt gewoon niet simuleren in de echte wereld op grote schaal. Ehm dat is gewoon dat blijft altijd schaarse data. Ik denk ook het het is ook ik denk voor veel mensen, ik heb dit al een aantal keer eh gezegd, maar ik blijf het even zeggen. Die robotica is niet zozeer een hardware issue. Zeg maar servomotoren combineren tot een soort servo ecosysteem waarin jij bewegingen kunt maken. Ga naar productielijnen van auto's in de jaren '0 en daar komen al armen langs die gewoon een complete auto kunnen lassen, zeg maar. Ik bedoel, daar zat het probleem niet. Het probleem zit hem en zat hem iets minder dus of zit hem iets minder dus nu in een open wereld vol met kansen en dingen die je niet kunt voorspellen en bewegingen en op en ook nog eens eh eh hoe een object reageert. Wat gebeurt er als je iets lichts oppakt? Wat gebeurt er als je iets zachts oppakt? Wat gebeurt er als je iets glads oppakt? Wat gebeurt er als je die dringen na elkaar moet doen en in één doos moet stoppen? In welke volgorde moeten ze er dan in? Noem allemaal maar op. En je merkt dus dat ik vond het wel een leuke eh eh benchmark. Ik maak heel even het sprongetje terug naar GPT5. Één van de privé benchmarks van één van de ontwikkelaars die ik volg is dat hij tegen die metaalmodellen zegt: "Ik ga staan als mens. Ik doe mijn linkerhand achter mijn rechterknie en mijn rechterhand achter mijn linkerknie en nu ga ik lopen. Wat gebeurt er?" En alle modellen inclusief GPT5 zeggen: "Je valt." Terwijl dat is helemaal niet zo. Je gaat gewoon op een ongemakkelijke grappige manier lopen. Maar als jij dit zou maken eh in VO3 of in Genie 3 hè, dus je laat in essentie, ik zeg het even heel eh dom nu hè, want zo gaan die modellen niet werken, maar je laat een tool call doen naar laten we zeggen Genie 3 door een taalmodel, reasoning model, agent model die zegt: "Oké, ik ben even aan het nadenken." Oftewel, ik ben het me aan het inbeelden met GNE3 waarin de prompt is de gebruiker vraagt of ik iemand een hand achter zijn ene knie, hand achter zijn achter andere knie. Dan kijkt hij frame voor frame de beelden die gegenereerd zijn door zijn maatje Genie 3 en dan zegt hij tegen jou: "Dan loop jij wat ongemakkelijk, want dat heb ik net gezien in mijn droomwereld." En als ik ik denk dat als mensen dit gaan dit vind ik wel gaaf hoor, want ik had zelf nog niet eens de link gelegd tussen dat je die modellen naar elkaar toe kon brengen. In mijn hoofd was het nog gecompart gecompartementariseerd. challenge gewoon keihard wel gebied gaat worden. R2 R2 gaat door een ensemble van genie en whatever gebied worden. Nou, dat dit is dus ook een eh ook eh FFI Lee is een eh AI onderzoeker die is echt heel gerenommeerd, want zij heeft Image net afgetrapt. En ImageNet is echt de ontketening geweest van deep learning omdat daar de eerste vision modellen getraind zijn. En dat was een soort wel kritisch moment, want zij had Imagnet als dataset en challenge bedacht waarbij je dat uiteindelijk alleen kon oplossen met deep learning modellen. En er waren toen ook toevallig GPU's. Maar zij zegt dus zij is zeg maar heel of heel ehm legendarisch in in wat zij heeft betekend voor het veld. En zij heeft dus recentelijk geclaimd op podium bij White Combinate is een eh ja, hele aanrader. Die staat gewoon op YouTube. Kan je op YouTube kijken. En eh daar heeft ze dus over physical intelligence of in ieder geval de embodied soort van dimensional spatial intelligence heet het volgens mij. En dat is gewoon iets wat nu heel erg ontbreekt bij die taalmodellen. En inderdaad wat jij zegt als je dus echt gewoon die systemen begint te fuseren. En wat je dus altijd ziet en dat zie je ook bij GPT 5 is dat die systemen die worden eerst aan elkaar geknoopt als een soort roop goldbk machine zeg maar van dan doe je dit en dan ga je naar dat machine. Maar uiteindelijk komt dat natuurlijk wel bij elkaar in een soort unified ding en dan kan het nog verder losgaan. Ehm maar dat wil niet zeggen dat het combineren van een GPT5 met een Genie model dat dat daarop kan opereren en die vis die die al die visuele inputs ook kan eh interpreteren, dat daar wel een soort eh krachtige wisselwerk in kan ontstaan. Dus eh ja, ik denk dat we voorlopig nog wel even druk bezig zijn eh met eh het hele II verhaal. Ja. En ik denk misschien nog wel een een leuk detail is dat als je de interviews kijkt eh die nu allemaal rondom Genie 3 gedaan zijn, hè. Dus eh voor de luisteraars zoek gewoon even Genie 3 launch interviews. Dan gaan ze met de ontwikkelaars die binnen Deep Mind Genie 3 in de Genie serie ontwikkelen, zeg maar interviewen. En wat mij gewoon opviel in ook bij Demis Hasabis trouwens eh eh lead Deep Mind de verbazing over Genie. Zij zitten daar echt in die interviews van yo, we hadden op een gegeven moment door dat je dit kon blijven schalen hè. Dus want Genie zit nog helemaal in de scaling paradigm. Ze hadden gewoon verwacht als we van Genie 2 kunnen we gewoon doorschalen naar Genie 3 zonder al te complexe nieuwe uitvindingen te hoeven doen, hè. We hebben gewoon krachtige grotere datasets meer hardware et cetera nodig. Klassieke schalen zeg maar. En dat zij zeggen dat de real world physics hè fluid dynamics eh eh gravity gewoon alle belangrijke zaken die zo zwaar zijn om te simuleren als je dat expliciet doet hè dat die er nu impliciet in terecht gekomen zijn. En dat is niet perfect hè trouwens. niet 100% nog niet perfect, maar iedere keer weer beter. Gewoon het gooien van een van een stuk piepschuim op een zee waar dan zout in het water zit. En op é of andere manier gebeurt dat en lukt dat omdat die in tijdens het trainen blijkbaar uit al die bestaande beelden een soort intuïtie ontwikkeld wordt voor lack of better term door dat model voor eh natuurkunde. Een veel betere en complexere intuïtie dan in taalmodellen. Want ik bedoel dat heb ik wel vaker gezegd over taalmodellen dat die een soort van belachelijk gemaakt worden als ze bijvoorbeeld niet snappen dat jij gewoon kan lopen met een hand achter je knie. Het feit dat ze iets kunnen zeggen over de situatie als taalmodel is gestoord. Zeg maar, je bent ze helemaal buiten hun kunnen aan het trekken als je over fysiek over fysieke bewegingen gaat praten met iets wat getraind is op Reddit en allerlei andere databronnen zeg maar hè. Dus ja, ik vind dat denk in ensembles van modellen die goed zijn in het ene en goed zijn in het andere en samen een ding vormen. Net als ons brein die verschillende cortexen heeft voor verschillende taken. Helemaal niet zo gek. Nee, en en dat is ik eh dat is mijn pint tweet eh is eh op X eh is if you can compress data well you understand its patterns. En er is een eh één van de weinige talks die Ilia Sutver geeft en dat is één van de co-founders van Openir en is nu met zijn eigen hele geheimzinnige lap SSI eh bezig. En hij geeft dus een talk over ehm over machine learning en hoe hoe werkt dat nou fundamenteel? Hoe leren nou computers van data? En daar zitten heel veel wiskundige principes aan ten grondslag. Maar dat eh dat idee wat Demis Asabes noemt over G genie 3 dat er een soort manifold is dat dat d het het concept dat als je iets eh wil beschrijven, een een fenomeen, dan kun je dat op sommige manieren alleen heel omslachtig doen en op andere manieren kan je dat heel efficiënt doen. Dus zeg maar hoe je iets gaat beschrijven bepaalt een beetje hoeveel hoeveel tekens je nodig hebt. En het idee is dus dat als je in een bijvoorbeeld een C++ code een physics engine gaat bouwen, heb je heel veel code nodig om te beschrijven hoe de hele fysieke werkelijkheid gaat werken. Maar dan is eigenlijk de conclusie dat je het niet moet gaan schrijven in C++ code. Je moet op een andere manier de essentie zeg maar de de essentiële eh informatie eh gaan beschrijven op een manier die veel beter past bij het fenomeen. Dus dat is het idee dat je zeg maar een soort van fit hebt tussen waar je iets mee beschrijft en wat je beschrijft en dat daar hele grote mismatching kan zitten waardoor je heel veel nodig hebt. Bijvoorbeeld het platte gezegde van een foto zegt meer dan 1000 woorden. Ehm het maakt gewoon uit welk medium je kiest als het ware. En ik denk dat wat die modellen laten zien is dat er een manier is om eh om in die modellen dus een efficiënte beschrijving te vinden voor fenomenen. En dat zie je dus terug tussen al die domeinen. Dus aan de ene kant is het tekst, dus dan is het codeccepten en dergelijke. Daar wordt dan uiteindelijk in dat model eh krijg voor elkaar om efficiënt eh redeneren over logic problemen in software. Maar je ziet het dus ook in eh bedrijven zoals Cradle in Nederland, biotech bedrijf met proteïn folding, dat je eh biologische fenomenen, de daar kan ook een soort efficiënte beschrijving gevonden worden in in die in die modellen eh in de gewichten van die modellen. En eh als je dan kijkt naar die video modellen en genie, dan zie je dat in het visuele domein dat daar ook een soort met dus de natuurkundige interacties dat ook efficiënt in die modellen gestopt kan worden. Nou, of het echt efficiënt is, daar kan je natuurlijk nog vragen bij stellen, want het zijn heel veel parameters als het ware. Maar het wordt in ieder geval geleerd van de data. Dus het is misschien niet per se efficiënt in die zin, maar het is wel te leren van de data. Efficiënt genoeg dat het geleerd kan worden van de finite samples die ze laten laten zien. Bijvoorbeeld VO3 is getraind op waarschijnlijk heel YouTube, maar heel YouTube is nog steeds best weinig. Dat is alleen YouTube. Alleen YouTube video's. Dus dus dus dus dit is een zo'n soort van wat kan je leren van data en hoe kan je dat hoe kan je dat extraen? Het dikste zou zijn zeg maar dat schijnt dus weinig limieten te hebben. Ja, ik denk als als je als voorbeeld kijkt naar stel dat je een eh een stuk ambient muziek hebt eh van een minuut hè, dus gewoon een beetje eh Brian Eno achtige vibe music van een minuut. Die sla je dan op in vlak zeg maar. Dus dat is dan lossless. Voor mij is dat ongeveer 10 MB per minuut. Dan zeg je: "Oké, we gaan iets van compressie doen." Pak je MP3, classic MP3 algoritme van lang geleden. Dan kom je op een MB per minuut, hè. Dus 10 keer zo klein. Maar waarschijnlijk in de het is het eh eh beetje die community die van die kleine demo scene code maakt, hè. Die probeert dan in 1KB een eh eh Flappy Bird te bouwen. Die zou waarschijnlijk zeggen: "Het is mij gelukt om ambient music te genereren." Gewoon met waveforms in één regeltje JavaScript van nou ja, weet ik veel hoeveel tekens. En het is natuurlijk en daar komt dan ongeveer dezelfde muziek uit, hè. Dus als je als het jou lukt om het generatieve algoritme achter die data te vinden als het ware. En in dit geval wat een beetje mogelijk aan het gebeuren is met Genie 3 is ook nog eens omdat er zoveel parallellen zijn tussen patronen in het universum. Namelijk eh het lichtspectrum en het geluidsspectrum en al die spectra hebben een soort zelfde fractal achtige patronen erachter zitten. Ik maak hele grote universaliteit van elektromagnetisme et cetera. Is natuurlijk de hoop van de wiskundige dat een soort theory of everything gevonden wordt waardoor je met één regelcode het hele universum kan genereren. Maar goed, maar dit is een beetje waar jij over praat toch hè? Dat je zegt van het is ook een beetje het idee van intelligence is compression, compression is intelligence. Het feit dat jij complexe patronen kan weergeven in steeds minder informatie, dat is eigenlijk een vorm van intelligentie. Dat is wat mensen doen. Ja, het is vooral een signaal denk ik, want het is zeg maar ehm kan je die modellen worden niet groter terwijl ze trainen, hè. Die de modellen die hebben één formaat en die moeten dat formaat blijven. En het idee is dat je kan er heel veel doorheen pompen als Ja. Staat die parameter limiet al vanaf het begin? Ja. Dus ze zijn gewoon één formaat en ze gaan dan gewoon informatie continu krijgen. En het is niet alsof ze opzwellen. Ze blijven exact hetzelfde formaat, maar ze gaan gewoon steeds beter presteren. Dus als je eh een hele grote hoeveelheid data hebt en je kan die eh je voert die er continu doorheen, op een gegeven moment is het idee dat hij alles wat je er doorheen hebt gevoerd, de training data die heeft gezien, dat hij die perfect zou kunnen voorspellen. Dat is wat je hoopt. En in de praktijk, omdat die modellen zo groot worden, je datasets zo groot worden, behaal je niet meer perfecte begrip. En dan zie je dus dat die modellen een soort absorptiimiet hebben. Dus dan je kan er nog meer ingooien, maar ze worden niet beter in dat voorspellen. En eh één van de belangrijkste eh manieren waarop die laps hebben opgeschaald is door steeds beter verschillende data te vinden om er doorheen te voeren. En dan zie je dat dat hij wel weer zeg maar omlaag gaat. Dus de kwaliteit van data die je erin stopt, die bepaalt ook hoe laag die als het ware kan gaan. En ik denk dat dat mechanisme, dus dat fundamenteel leeralgoritme waarbij je aan de hand van data eh die patronen kan eh extraheren, daar gaan we denk ik steeds beter in worden. En terwijl we ook meer data kunnen verzamelen en op betere kwaliteit data kunnen verzamelen. Want als je kijkt naar de de de snelheid waarmee videocent wordt geüpload naar het internet, dat groeit nog steeds allemaal. Dus we onze data exhaust als het ware neemt niet heel erg af omdat we en steeds digitaler leven. Dus we hebben veel steeds meer voetsporen en omdat alle instrumenten om op te nemen die zijn ook steeds hoger in kwaliteit. Elke elke iPhone heeft weer een beter camera. Al die camerabeen hebben veel meer informatie en zo kan een een een G 12 eh kan natuurlijk van de de 900 megapixel videocamera van iPhone kan die op een gegeven moment wel die die echte physical eh dingetjes eh extraen. Dus dus dat is toch een beetje want dan dan ja dan heb je gewoon heel scherp water, weet je wel. En dan heb je gewoon heel scherp water. Heyé, laten we het nog heel even hebben over eh de open source modellen van Open AI. Ehm want één van de dingen die ik ehm tegenkwam is eh GPT eh OS zoals ze heten eh is just 55. En dat ging erover dat je de F modellen van Microsoft hebt en die allemaal opvallen omdat ze getraind zijn op seks synthetische data. Dus enkel op synthetische data. En de de eh de rodel, de rumor, whatever hoe we dit willen noemen, is nu een beetje in de community dat open ervoor gekozen heeft om de open source series van GPT exclusief te trainen op synthetische data om gedoe te voorkomen. Want als je natuurlij zo'n model uitbrengt en met dat model kan je bewijzen in de rechtszaal dat ze rommel hebben gebruikt, dat dat er de dat er de opdracht gegeven is intern, train dat maar allemaal op source. Heel even voor de luisteraar. Mocht je niet hebben meegekregen, Open AI heeft dus nu eh eindelijk open modellen, open weights hè. Dus dat houdt in dat de gewichten te downloaden zijn en te draaien zijn op je eigen machine. Eh de data die erin gegaan is hebben we niet, dus het is niet volledig open source, maar in ieder geval de belofte om modellen uit te brengen zoals we dat gewend zijn van bijvoorbeeld Deep Seek R1 of de Lama series vanuit Meta, is er nu ook een GPT OS serie vanuit Open AI. Hoe kijk jij daarnaar, Rick? Wat wat was je eerste reactie toen die uitkwamen? Valt het tegen of was je niet verbaasd of wat is je take? Ehm kijk, dit is ook een beetje zijn vraag van dus ik denk dat er een kernvan waarheid in zit. Wat wat een beetje de vibes als je het model gebruikt eh wat wat voor gevoel je daarvan kan krijgen is dat het een hele klinische dataset is waar die op getraind is. Dat wil niet zeggen dat de data waarop die getraind is. Ik heb even voor de grap eh net eh de vraag gesteld: "What is React?" Dat is zo'n eh programmeerframework aan GPT OSS eh op Grock gehost natuurlijk eh gevraagd van wat hij dan zegt. En eh daar geeft hij gewoon een super nuttig antwoord, weet je wel. Dus eh de informatie die eh synthetisch geproduceerd is, is nog steeds public web heel groot deel. En het is gewoon vooral heel erg opgeschoond. Dus ik denk dat ze ze hebben lang gedaan over het release van open source model omdat inderdaad een open source model heel veel scrutiny met zich meebrengt. En ik denk dus dat ze de suetpot hebben gevonden van eigenlijk wat wat al eerder zeg maar de wens was van het publiek en de en vaak ook eh overheden met regelgeving van hoe die laps modellen maken. Zodat ze veel gedetailleerder nagaan wat stoppen we nou eigenlijk precies in de pretraining eh dataset en waar waar trainen we daarna nog op verder op door. En ik denk dat je nu het resultaat ziet van een heel eh klinische benadering van het trainen van een model. En dan zie je toch dat dat ja, dat het een beetje het rauwe randje eraf is. En eh dat is ook eh een beetje het stukje creativiteit of een soort verrassingseffect of dat met nieuwe ideeën kan komen. Een beetje die longtail. Dat dat lijkt er een beetje uit de in de vibes. Ja, zijn een beetje saai. Ja. En dat is misschien ook gewoon de het resultaat van als je dus ehm je moet beperken tot een subset van data waar je niet mee in de problemen komt. En dat is eigenlijk al wat er heel lang geroepen wordt is dat als er dan discussie is over het juridische punt van ehm is het fair use voor een model maker, voor een modelbouwer om te trainen op copyrighted content die online staat, maar wel publiek online staat. Dus iedereen kan het gewoon bekijken, maar er heerst wel copyright op. Is het fair use? Is het transformative genoeg? En ik denk dat Open nu heeft gewoon gezegd: "We gaan de veilige kant zitten en dan zie je wat er gebeurt." Dus we weten niet of dat helemaal precies zo waar is, maar ik denk dat van de kern van dat idee dat dat wel eh eh standhoudt dat gezegd hebbende: "Ik heb het model gebruikt voor voor vragen en ehm om om gewoon een gevoel te krijgen bij wat kan het." En op het moment dat je het model combineert met nieuwe data in de context window, dus je gebruikt tooling om allemaal informatie op het internet op te zoeken via search engines en daarna krijg je een antwoord, dan zit die soort van eh dynamische echte unieke nieuwe informatie. Die voel je erzelf in. Dus het model is heel geschikt denk ik voor systemen waarbij je zelfverantwoordelijk bent voor het het invullen van die contextwinder. En dat is belangrijker dan ooit bij dit model. Het kan heel goed met die content die je het geeft interessante dingen doen, maar zal in zijn weight hele vette dingen hebben. Ja, minder. Precies. Precies. Het is een discussie van moet een taalmodel eigenlijk een soort van kennis hebben of kennis over patronen. Oftewel liever wat meer intuïtie over patronen om als kennis geleverd wordt iets juists te kunnen doen met die kennis. dan heel veel achtergrondkennis eh om eh vervolgens een soort eh heel Wikipedia eigenlijk er ook nog in te hebben zitten wat heel inefficiënt is en ook nog eens gedoe kan opleveren. Wikipedia slecht voorbeeld want daar zijn volgens mij minder vragen over maar de hele New York Times in de juiste teken. Dat is de En en je ziet het natuurlijk, de gast die aan of de de de persoon die verantwoordelijk was voor F is naar open gegaan en er zal dus vast een sterke sterke hand van hem in eh hebben gezeten. Dus ik denk dat bedoelde dat trouwens niet per se als een negatieve hè. Ik bedoel je ook zeggen ja die fight modellen waren wel heel negatief ontvangen over het algemeen dus. Ja, klopt. Ja, goed dat er zit ik bedoel het is geen compliment om te zeggen je bent 55 zeg maar. Maar tegelijkertijd als de afspraak is, we laten deze modellen heel goed zijn in eh kunnen werken met eh ja, just in time context, hè. Dus de informatie wordt net op tijd toegevoegd aan de context window. Ehm en eh voor de rest is het gewoon iets wat weinig snapt of we weinig weet maar veel snapt, laat ik het dan zo zeggen. Dat dat misschien best wel een interessante weg is om in te slaan om tot het allerkleinste, meest efficiënte of een heel efficiënt klein model te zijn die niets weet maar heel veel snapt. Ja, want er is wel veel kritiek en het is echt een soort eh paradox of een soort fundamenteel conflict waar mensen nog niet over uit zijn van kun je intelligent zijn in een vacuum zeg maar, kan je alleen maar een soort axioma in je hoofd hebben? De de de is gewoon kan je het kan je kan je intelligentie lostrekken van al die feiten kennis of is heel veel van die feiten kennis ook nodig? En ik denk dat ehm mensen een beetje proeven dat zo'n model wat op de manier getraind is zoals al die andere modellen getraind worden, maar met minder kennis voelt out of the box minder nuttig. En dat is denk ik een redelijk goede conclusie. Maar dit model is ook extreemic in de zin van het kan tool calling doen en nog meer tool calling en nog meer to calling en daar dan chocola van maken. En dus denk ik dat als je het op de juiste manier vasthoudt, if you if you're holding it wrong, it will be bad. If you're holding it right, it could do pretty useful stuff. En dat is een beetje de conclusie, denk ik. Voor voordat we afronden, want we hebben best wel wat gezonden al naar de mensen. Jij zei net even eh trots draait op grok. grok met de Q hè, want dat was nog een ding waar ik me eigenlijk minder waar ik minder bij stil had gestaan is is natuurlijk het feit dat als Open jij die modellen released met een license erbij, Apachi 2 uit mijn hoofd eh waardoor je dit ook gewoon commercieel kunt inzetten dat de partijen zoals Grock, Cerebrus eh nou ja en andere trouwens Bedrock, Amazon, noem ze allemaal maar op. dat die ook allemaal in hun rijtje waar nu Deep Seek, Lama en Quen stond ineens ook GPT OS staat en je want dat is nog het allerbelangrijkst die gestoorde inference speed krijgt met 1000 tokens per seconde. Want ik moet zeggen het eerste wat ik deed was grok in in een IDE koppelen en kijken wat er gebeurt als je entic gaat programmeren als de tokens je gewoon om de oren vliegen. En ik dat vond ik wel even een momentje dat ik dacht: "Ah, snelheid is dus blijkbaar ook nog wel een variable waar eh waar we nog kunnen winnen met elkaar." Ja, en dat is eh waarbij je ziet dat het ecosysteem zich op meerdere assen ontwikkelt. Je hebt eh inference waarbij er partijen zijn die niet zozeer bezig zijn met de modellen en het bedrijf waar ik voor werk rock dat die is daarmee bezig. Maar er zijn heel veel partijen, dus er is heel veel concurrentie om die influence markt goed te bedienen. En als er open source modellen zijn, dan zie je dat ja, dan kan je je helemaal specialiseren op puur het hoe draai je die modellen het beste? En dan kan je dingen doen die open AI gewoon niet voor elkaar krijgt. Zoals wij runnen nu ik dit deze what is React query runt met 1200 tokens per second en GPT OSS haalt voor duidelijkheid 60% op die sweet bench verified. Dat is ja minder dan 75% maar dat is nog steeds prima sparingspartner en prima voor heel veel programmeertaken. Ik bedoel als jij simpele dingen programmeert dan heb je er heel heel veel aan. Dus ja, ik denk dat ehm ik denk dat het voor Open AI een heel interessant ehm strategisch ding is geweest. En het is heel multidimensionaal. Ik denk dat mensen willen liever voor openir werken nu dat ook echt een open model is. Eh er zijn ehm er zijn ook wel zeg maar geopolitieke dingen aan de hand met als China heel erg de overhand krijgt met innovatie doordat zij als enige echt goede dingen opensourcen. Ehm wat doet dat dan met de zwaartekracht van het ecosysteem? Wat zijn soort second order gevolgen van dat soort van zo'n realiteit? En dus ik kan niet precies spreken voor waarom opener dit model geleest heeft, maar ik vind het wel een indrukwekkend model en het is echt nuttig. Het is gewoon het is niet een het is niet een soort fake release. Nee, ik snap hem. Wat een beetje geroepen werd eh net na de release van dit niemand wilde dit, maar ze moesten ofzo. Terwijl daar hebben ze wel veel moeite voor gedaan als het een moedje was. Dat klopt niet helemaal met wat er nu uitgebracht is. En verwacht je dan ook nog een laatste vraag ehm dat hier net als bij de Lama serie en andere modellen een soort van heel ecosysteem gaat ontstaan? Allemaal fine tunes en a bedoel tuurlijk zijn er al allemaal quants gemaakt en dat zie ik al nu gebeuren hè, maar dat dat er echt een soort eh 10% beter presterende versie gemaakt wordt door een groep die open source ontwikkelaars die het model doorpakken. Ja, dat denk ik wel. Ik denk echt dat er op grote schaal, want eh de de soort technologische ecosystemen, de echt de de frameworks voor training en voor reinforcement learning, dat is ook allemaal een stuk volwassener. Eh dus er zijn nu echt gewoon mensen die pluggen gewoon hun bestaande training eh infrastructuur die gewoon konden zeggen: "Ik heb een model en train dat model nu op mijn use case." Veel meer mensen hadden al zo'n harness klaar klaarstaan nu dan ooit tevoren. En die kunnen zo dit open source model pakken en kijken even kijken hoe goed die het op en e doet. En ik denk dat daar ga je wel zien dat mensen door kunnen bouwen op dit soort modellen. Maar nogmaals dan dat vereist als je echt die modellen wil aanpassen voor je use case, dat vereist best wel veel expertise en data en dat is ja, er is wel gewoon een beter model wat je ook kan krijgen. Dus ik denk dat je het het grootste deel van de mensen die kijkt gewoon kan ik met prompting met gewoon mijn vragen op de juiste manier stellen aan het open source model gewoon uit de voeten met dit model voor bepaalde features in mijn software of voor bepaalde codetaken die ik doe die ik gewoon het liefst zo goedkoop mogelijk wil hebben? En er zijn een aantal mensen die gaan kijken naar hoe kan ik dat model nog verder pushen in de capability zeg maar voor een een meer gespecialiseerde use case waar ze unieke data tot hun beschikking hebben om het op te fine tunen op reinforcement tuning ofzo op te doen. Ehm maar dat is voor een selectgroep weg weggelegd denk ik. De meeste mensen kunnen of gewoon out of the box dit gebruiken en het is goed Out of the box en eh of kijken naar nog eh nog betere modellen die dan niet open source zijn. Vet man, dankjewel voor eh alles. Het was een hoop. Eh ik denk als je een grap zou laten tekenen van wat we aangeraakt hebben dat het best wel best wel veel is. Ehm ja, laten we kijken man. Als er als er een Gemini 3 achter bedoel die komt. Ja. Ehm en als het groot is ehm zou ik je graag eh nog eens erbij trekken, man. Z Ja, ik ben heel benieuwd. Ik kijk met eh met heel veel interesse naar alle releases die er dit jaar nog gaan eh plaatsvinden, want het is eh echt fascinerend. Thanks man. Spreek je. Oi hoi. [Muziek] เ

---

## Notes


## Key Takeaways
-

## Related
-
