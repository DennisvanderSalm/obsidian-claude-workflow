# Grok-3 daagt OpenAI uit + NYT omarmt AI + exclusief interview met Rick Lamers (Groq) | AI Report

**Source:** [YouTube](https://www.youtube.com/watch?v=xDCa0xgymMY)
**Video ID:** xDCa0xgymMY
**Tags:** #youtube #transcript #ai-report

---

## Transcript

welkom bij Ai report de Nederlandse podcast over kunstmatige intelligentie waar we uitzoeken welke invloed Ai heeft op ons werk ons leven en de samenleving tegenover mijn Wiets haagen en we gaan het hebben Wietse over eh de New York Times die gaat ondanks hun rechtszaak tegen open Ai zelf Ai tools inzetten op de redactie Toch wel opvallend nieuws gaan we bespreken en natuurlijk het grootste nieuws van deze week eh Rock 3 van elon Musk zijn Ai bedrijf xai dat stormt Nou ja de chatbot lijsten binnen en het het overtreft gpt 4 het overtreft CLA dus dat staat nu op nummer É Dat is toch wel een mooi record wat Musk daar bereikt Maar tegelijkertijd rij natuurlijk ook de vraag kunnen we dat wel los zien van Ja zijn groeiende invloed op de wereld eh met eii maar ook op andere manieren eh dat hoef ik vast allemaal niet helemaal uit te leggen Eh kunnen we dat er wel los van zien en moeten we dan Nou echt erg zorgen over maken eh volgens Wietse wel als ik het zo inschat Hij begint een beetje te lachen Ja eh en Plus die gaat R Lamers van grok met een q interviewen Ja dus dat is die andere grok niet grok met een k maar grok met een q en dat gaat wel weer ook onder andere over grok met een k Yes we dachten we houden het simpel ik ben Mil brand en deze aflevering even terug op het oude nest met de nieuwe naam Ai report veel plezier [Muziek] [Applaus] [Muziek] [Applaus] Piet Alexander die zit weet ik uit betrouwbare bron want ik zag het op zijn Insta in een ramen restaurant op een piste op een Japans toilet met een verwarmde bril eh maar ik zit hier tegenover jou dus eh ja ik weet niet wie er meer geluk heeft maar ik denk dat ik het ben Nou ik vind het vooral leuk dat je er weer zit Ja ik ben ook blij dat ik even even mag invallen het is natuurlijk eh de kindervakantie en Alexander sch schijnt kinderen te hebben dus dan zitten wi hier kinderloos op te nemen Ja ik ga voor een al de kindervakanties blokken dan kan ik hier met jou zijn Ik verheug me erop heel cute dat jij het kindervakanties noemt het is waar ja Dat zijn het ook maar ik ik verat me wel af te vragen eh Welke pieste heeft nou een Japans ramen restaurant Of zit hij in Japan weet jij dat Nee ik heb geen idee Ik ben hem niet aan het beschermen Ik weet echt niet waar die zit nee god wat zit hier onder de radar nou Jullie horen het vast allemaal later nog van hem laten we eh het nieuws gaan bespreken van deze week en ja aangezien ik hier toch slechts op bezoek ben even weer tussendoor voel ik als invaller de vrijheid Wieten om jou te laten openen en jij hebt iets leuks op YouTube gezien Ja ik zag een eh video van eh veritasium zo hebben we het afgesproken toch Ja jij doet nu we zeid gaan we het Amerikaans doen of Nederlands en jij doet nu een soort merch daarvan dat mag van mij ook maar het is veritasium denk ik of veritasium doe die laatste want dan weten mensen meteen moeten schrijven Ja ehm het is een YouTube kanaal dat ik al jaren volg en het voelt een beetje click beaty als in ik heb de video een tijdje overgeslagen in mijn YouTube feed want ik heb ik heb een feed met vooral abonnementen niet ehm adviezen anders wordt ik GK Dus ik krijg alleen maar een lijst met iedereen waarop ik geabonneerd ben en daar is verium er één van en die heeft een video gemaakt eigenlijk waarin die een stukje geschiedenis een soort mini documentaire doet over Ai en dat gaat over die Mind D hasis die nu bij Deep Mind en Google zit en het gaat in zijn voorbeeld eigenlijk over protein folding dus over het kunnen vouwen en voorspellen van de vorm van proteïnen en Eigenlijk vind ik deze video wil ik even tippen aan de luisteraar omdat het is als je even door de click Beus heen kijkt want je je scrollt er zo voorbij heeft hij eigenlijk niet handig gedaan maar als je hem gaat kijken Het is echt een gedegen mini documentaire ehm over eigenlijk de historie en op opkomst van Ai dus eigenlijk Voors spelmachine waar chat gpd een woorden voorspeller is gaat het hier om proteïnen voorspelling Ja we hebben het wel eens over gehad Alva Ja daarom en eigenlijk Alpha fold komt er dus ook in langs maar wat ik heel prettig vind aan de video is één Oké hoe kan dit dan toegepast worden buiten chat gpt achtige toepassingen dat wordt ineens heel helder Het is best wel wholesome want het is om eigenlijk mensen beter te maken Het is om medicijnen te ontwikkelen het is om nieuwe behandelmethodieken te ontwikkelen Ja het is best wel moeilijk om een soort tegen die eh implementatie te zijn en dat is denk ik tussen alle Doom en Gloom die ook langskomt in Ai report wekelijks van wat er allemaal mis kan gaan Ik werd er wel een beetje ik dacht wel aan het einde van die video Ja inderdaad Jeetje wat gaat het allemaal hard want er zit ook allemaal grafiek in van dingen die dus jarenlang niet lukken En dan ineens zo'n zie even een staafdiagram voor je met van 1977 tot en met 2016 waarin eigenlijk geen resultaten geboekt worden en dan ineens zo on dat ineens En is het ineens opgelost zeg maar opgelost als in is er een doorbraak Ja en dat past heel erg bij al die andere groeigrafieken die er nu zijn in die Ai wereld waar wij vooral over taalmateriaal die die echt wel moeilijker als negatief te bestempelen zijn Ja dus als we die taalmakelaar en waarom Deep Mind wat nu onderdeel van Google en de Gemini Models maakt eh echt al een hele tijd mee draait en dat deze technologie gewoon veel breder inzetbaar is dan enkel op eh Sinterklaas gedichtje schrijven copilot of ander soort eh toepassingen maar hierin zie je ook wel dat er zijn eh in deze tijd Mensen maken zich zorgen over van alles waarschijnlijk ook met recht maar ook over de vooruitgang en hebben we dat nou allemaal wel nodig die die technologische ontwikkelingen en Wat was er mis met gewoon zelf een mail schrijven maar uiteindelijk ja de vooruitgang laat zich gelukkig niet stoppen maar je ziet ook op dit soort manieren dat het ook wel echt natuurlijk heel belangrijk is eh want ja we worden hier gewoon We kunnen hier weer langer mee leven kun je je ook weer zorgen over maken uiteindelijk of we de planeet langer moeten bevolken maar dat nieuw Pro je gaat lekker Milou Ik begon zo goed dat ging zo goed Nee ik zat te denken waarom raakt dat videootje nou zo of wat wat wat gebeurt Da nou en dat heeft er dan mee te maken dat die eh dat het beeld wat daarin naar voren komt heel erg gaat over het Het gaat allemaal heel erg hard Het is super breed inzetbaar deze fundamentele technologie en ehm we kunnen hier medicijnen mee maken we kunnen hier mensen mee genezen We kunnen hier meer begrijpen over celbiologie eh proteïnen noem het allemaal maar op dat dat binnen Ja een wereld waarin eni ook op hele spannende manieren ingezet kan worden prettig is om een beetje een soort contragewicht te doen dus het is eigenlijk een ehm mooie toepassing van Ai op dit moment de video heet ook the most useful Thing Ai has everd ga het kijken van veritasium dus op YouTube staat het eh ja het is een lichtpuntje in de in de duistere wereld van Ai Nee hij lijkt soms een beetje duister maar er gebeuren natuurlijk ook goede dingen en het is goed dat daar even aandacht voor is andere toepassing van Ai Eh wie het nu breed in ieder geval gaat toepassen dat is de New York Times zij gaan Ai inzetten eh op de redactie dus een hulpmiddel worden en dat kun je opvallend vinden want nou we weten ook de New York Times is verwikkeld in rechtszaken eh met open Ai over het gebruik van artikelen van de New York Times op hun modell hebben getraind op eh copyrighted text van de New York Times ja maar ondertussen Ja moet de nyt natuurlijk ook mee in de in de vaart der volkeren dus ja ook gebruik gaan maken van Ai of in ieder geval ze zien daar nu opeens wel dan de meerwaarde van dat ze dat wel toch kunnen gebruiken om de redactie te ondersteunen waar moet je dan aan denken wat gaat er veranderen eh de redactie krijgt eigenlijk een heel Arsenaal aan Ai tools tot de beschikking dus denk aan eh het gaat helpen bij het schrijven van pakkende Koppen het gaat helpen met het bedenken van interview vragen volgens mij ook met eh het Research doen Dus je hebt soms wel pagin lang onderzoeken Nou ja ik weet uit eigen ervaring dat notebook LM heel goed kan helpen bij het eh ja het doorploegen van die grote dingen om het beter te begrijpen en de belangrijke details eruit halen of in ieder geval ook de details waar ik naar zoek daar gaat het bij helpen en Ze rollen een eigen Ai tool uit met de naam echo dus ja ze hebben ook nog iets maar is dat een interne tool Ja een eigen Ai tool Ja ja ik ben wel benieuwd want ik zat te denken is het niet gek dat ze aan de ene kant die rechtszaak voeren en aan de andere kant die tools introduceren maar ik denk niet dat het per se een rechtszaak is tegen Ai of tekst voorspellende modellen alsin dat moet weg maar meer Wij moeten gecompenseerd worden voor het feit dat het gebouwd is op ons intellectueel eigendom precies D ander principe en als die deal er helemaal in is dan zien ze op zich geen probleem met het inzetten van die tool Maar hebben ze uiteindelijk een soort Manifesto geschreven dan ofzo of is het nu Helder binnen de organisatie waarvoor je het wel moet gebruiken en waar niet want dat is de belangrijke vraag altijd denk ik ja dat is eh Voor zover het op mij overkomt is dat nu dus Helder gemaakt eh want dat dat nieuwe systeem wat ze zelf hebben ontwikkeld echo dat gaat helpen bij het samenvatten van artikelen en van nieuwsbrieven dat kan journalisten ook weer helpen maar er zijn ook duidelijke grenzen aan wat er ja Waarvoor de Ai gebruikt mag worden dus het mag niet gebruikt worden voor het helemaal schrijven of eh ingrijpend herzien van artikelen en eh ze gaan geen afbeeldingen of video's natuurlijk genereren want dat dat past natuurlijk een eh een journalistieke krant niet en eh ja vertrouwelijke bronnen die mogen ook niet ingevoerd worden in de Ai systemen om natuurlijk ook weer die bronnen te beschermen je weet anders ook maar nooit wat er op straat kan belanden en zit ook een soort belofte die ze dan aan ons doen als lezers kan kan ik ook inzien wat hun Ai belofte is of is dit vooral een interne memo dit is hoe we het gaan gebruiken Nou daar daar moeten we denk ik even eh het oog ophouden want ja ik ben wel nieuwsgierig Ja want uiteindelijk ja je je wil wel dat eh journalisten nog altijd de verantwoordelijkheid dragen voor wat wat er de wereld in wordt geslingerd New York Times zegt ook wel van altijd zal onze journalistiek worden geschreven en geredigeerd door onze experts dus de journalisten zelf die blijven Ook aansprakelijk dat staat in de in de richtlijnen dus eh ja die moet moet ook ja aansprakelijk is niet het goede woord maar die moet wel de de verantwoording af gaan leggen Ja want jij Jij schrijft zelf voor het Financieel Dagblad maar ik ben columnist dus ik Ik schrijf daar Ja journalistiek kun je dat niet echt noemen dat is wel mijn achtergrond Oké maar heb jij daar een soort regels opgelegd gekregen is daar al een echo waar je op Ik zit ben gewoon even nieuwsgierig eh ja nee Nou ik heb er nog niks over gehoord maar ik zit daar dus ook niet elke dag op de redactie dat is anders Natuurlijk werk vanuit huis en ik heb ook geen regels in hoeverre ik wel of niet eh KL mag gebruiken en maar ik kan daar heel transparant over zijn Ik gebruik Cloud eh bijna altijd om gewoon te brainstormen en ook om te kijken als ik iets geschreven heb van Hoe loopt het stel technisch goed is het logisch volgt de ene alinea op de ander en dan geeft hij dan soms tips voor en dan eh dan ja dan feedback en die verwerk ik dan en notebook Alm gebruik je ook ja eh zeker dat doe ik vooral recreatief als ik ga kijken bijvoorbeeld naar Nou laatst was er een een onderzoek Dat was eind oktober toen heb ik ik het gebruikt was een onderzoek althans het A journaal 8 uur journaal de NOS die Opende met een onderzoek jaarlijks overlijden 1300 Nederlanders eerder door koken op gas blijkt uit een groot onderzoek van de Spaanse universiteit nou groot onderzoek stond erbij gelinkt dus toen dacht ik nou laat ik dat eens bekijken want daar kan je dan uiteindelijk echt Kijk het is goed dat ze daar naar linken zodat je inderdaad zelf kan gaan kijken maar als je vervolgens ziet dat onderzoek is 100 pagina's lang Ja wie gaat dat doorwerken en ik vond het tochal een stellige kop gewoon zeggen jaarlijks overlijden 1300 Nederlanders eerder door koken op gas Hoe kun je dat zo direct aan elkaar linken dat lijkt me toch heel veel maar jij denkt dan dus tegenwoordig denk je dan Oké nou gooi ik dat even in nobek Lem Ik ga eens even kijken Ja ga ik even kijken van kun je dit zeggen op basis van eh van wat van dit specifieke artikel want ja zo wordt het wel genoemd dus het kan ook een andere handig toel worden van mensen zelf nee ook niet op gas meer Nee ik heb tegenwoordig El maak je ineens super zorgen Nou ik vind gewoon Ik dacht hy Ik kan dit heel makkelijk checken want het lijkt mij iets waar heel veel dingen meespelen wil je ook weten wat het antwoord was want ik heb hem nog even teruggezocht notebook Lem zegt het is belangrijk om de stelligheid van de uitspraak over 1300 sterfgevallen te nuanceren en de lezer te informeren over de onzekerheden en beperkingen die aan de schatting verbonden zijn en met nog dan een lijstje met de tekortkomingen van het artikel op zich Je kan dan zeggen van Oh wat erg ze hebben het niet helemaal goed gedaan maar dat zie je natuurlijk altijd als er een wetenschappelijk artikel in de populaire media komt dan ja dan pakken ze er een paar zinnen uit die blazen ze op en dan ja want je moet een titel hebben een kop en je kan dan niet zeggen van heel misschien En ondanks de Er zijn wat beperkingen En bla blabla Nuance Nuance dus dat snap ik ook wel weer als journalist Maar tegelijkertijd Nou ja als je dus zelf denkt van Hm dat vind ik wel heel stellig en laat ik zelf eens kijken of dat een beetje strookt met de inhoud van het onderzoek Dan is notebook alleen wel een leuke tip Ja zeker en en nu bij de New York Times gaan ze D dit dus doen Wat vind jij daar dan zelf van als je dat hoort dat je denkt oh ze geven zich over of daar gaat het het is einde van de New York Times Of denk je juist wat goed veel beter onderzoek nu Ik sta er een beetje ambivalent in want het op een bepaalde manier hoort het journalistieke handwerk dat je echt zelf iets helemaal moet uitpluizen en doorgronden dat helpt wel echt bij het beter begrijpen van een eh ja van een hele situatie weet je wel Je kan het is heel makkelijk om ook met zo'n notebook Alem te gaan zitten Cherry pikken van wat hij je er wel uit Ja dan als je daar opdracht geeft aan zo' nobek Alen wat je wil lezen dan dan lees je automatisch dus de andere dingen niet Dus de kans wordt wel groter dat je ook dingen gaat missen misschien ik weet niet Het heeft er zit iets bij van Uiteindelijk moet eh moet het er niet toe Leiden dat we een soort van lui journalisten worden die eh top passend te onpas denken van oh Ai laat ik het wel even doen want ik Ik weet niet zeker of gewoon of of je dan de kwaliteit die je leven als journalist kan waarborgen dat is wel een beetje mijn zorg maar dat is op zich ja Dat ligt misschien wel redelijk voor de hand ook wat denk jij ehm nou ja als geen journalist maar Expert n We zitten in nu in een soort tussenfase en ik weet niet hoe lang die tussenfase gaat duren van ehm als ik dan even het voorbeeld van een zelf riende auto neem dat nu zou je misschien nog zeggen nou niet Misschien nu zeg je nog joh als ik in een zelf riende auto ga zitten vind ik best wel spannend en misschien wil ik wel achter het stuur zitten zelfs zodat ik toch nog kan ingrijpen en in een zelfrijdende auto ga te zonder stuur vind ik al helemaal te spannend hè hm hm Maar er komt een dag Ik weet niet hoe snel dat je zegt ik wil eigenlijk alleen nog maar in een zelfrijdende auto zitten want ik vind het eigenlijk veel veiliger hè want die hebben statistisch veel minder ongelukken en hè die kunnen niet moe worden of een slechte dag hebben en stiekem drinken noem maar op eh dus je hebt de tussenfase van ik vertrouw het minder dan ik vertrouw het ongeveer even veel en dan ik vertrouw het meer Ik denk dat die vertrouw ik meer dan vrij snel volgt op die middelste en dat is dan met listi mogelijk ook dat je denkt ja ik lees liever een platform of uitgave of medium dat Ai augmented is dat hulp krijgt van ei tools want dan gaat die gaat dat onderzoek tenminste diep genoeg of breed genoeg wat één mens of een kleine groep mensen helemaal niet kan dus het is nog een beetje de vraag nu is het misschien een smetje Op het geheel als je aangeeft ik we werken met eii en hou je het een beetje intern in een memot naar het personeel maar misschien wordt het op een gegeven moment wel iets waar je trots op bent hè dat je zegt wij zijn een krant die eh hele geavanceerde EA inzet om te zorgen dat onze journalistieke eh waarheid onze kwaliteit nog hoger is ja dus dat Ja ik moet ik moet denken aan dat eh Little Britain die heeft zo'n Sketch met eh computer says no hm hm Dus straks wordt het Ai Say No of ja dat argument wordt van nou maar het is waar Want Ai heeft het gezegd ja nee dit precies want nou ik merk dat nu merk je nu al wel bij studenten zeker jonge studenten die net beginnen aan een opleiding eh eh dat die dan met voorbeelden komen als het om programmeren gaat maar ook om teksten reflectieverslagen en dan tegen docenten zeggen dit weet ik uit eerste hand van ja eh maar J zegt het hè Hm als in alsof dat een soort gewicht heeft zal Ja goed Ik weet een beetje hoe die systemen werken Dat heeft voor mij niet Pere zoveel gewicht nu maar er komt voor mij ook wel een dag waar ik op ga zeggen ja dat dat heeft gewicht Nu is het nog gevaarlijk nu voelt het nog een beetje als Wikipedia aanhouden als referentie zeg maar Maar ja als het op een gegeven moment wel Deep Research is die dagelijks eh het document update ook hè dus het onderzoek wordt ieder uur geüpdated met de nieuwste bronnen en het nieuwste wetenschappelijk onderzoek ja daar kan volgens mij een menselijke journalist of onderzoeker moeilijk tegenop Ja Ja En in die zin kan het natuurlijk e een een goede aanvulling zijn Ik denk dat we nu nog op tussen punt É en twe zitten van wat jij noemt van de argwaan tussen het kan e verveel tussen het kan meer Ja een terechte argwaan zou ik zeggen want die systemen zijn nog niet zo gaaf Z ook de generationele argwaan verschilt een beetje hè want de Jonge jonge mensen hebben te veel vertrouw vertrouwende wat oudere mensen te weinig maar gemiddeld vinden we allemaal hetzelfde Let op dat scheelt dan weer eh nou het belangrijkste nieuws dan eh van Ja deze week grok 3 van elon Musk eh x dat komt binnen in de hitlijsten van de chat Welke hitlijst eigen de chatbot hitlijsten LM Arena is dat waarschijnlijk wel eh ja ja ja klopt eh chatbot Arena Ja ja ehm Het staat op nummer één want ja de prestaties van het model die zouden he echt indrukwekkend zijn het overtreft Gemini 2 Pro Claw 3.5 sonnet en gpt 40 op eh belangrijke benchmarks dat is op zich best bijzonder voor een bedrijf wat pas 2 jaar oud is en wij hebben het er van tevoren even over gehad eh hoe kunnen we het hier nou op de beste manier over hebben mogen de luisteraars gerust weten want eh ja vooral Jij vindt het een beetje ingewikkeld om het zo hier te doen ja Ik merk dat het soort jolig praten over grok 3 gezien de situatie in de wereld op dit moment waar elon Musk en enorm mijn vinger in de pap heeft eh eh niet kloppen ofzo als we daar overheen springen Ehm ik vind het ook niet kloppen om het dan maar niet over grok 3 te gaan hebben want ELO Musk eh is een onprettig persoon Ik denk dat we het juist over grok 3 moeten hebben gezien de wereldsituatie Wat een aantal dingen die we nu die we nu zien is eh die scaling hypothesis dus het idee dat als je er meer computerkracht tegenaan gooit zonder dat je nieuwe uitvindingen doet fundamenteel theoretisch over hoe jouw taalmodule die scaling hypo hypothesis die houdt tot nu toe als in Er Is geschaald Er is meer computerkracht tegenaan gegooid en dat heeft een model opgeleverd dat iets beter presteert dan de topmodellen Ja dat dat de vraag was ook dat is op op zich ligt al best voor de hand toch Nou ja zou je zeggen maar het kan het kan echt wel zo zijn ehm k al dat soort paradigma's van hoe je eh kunstmatige intelligentie bouwt die liep op een gegeven moment tegen een plafond aan ergens waarin je er wel ehm je hebt het bijvoorbeeld ook in eh in software ontwikkeling Je kunt zeggen Ja een project duurt als ik er één software ontwikkelaar op Zet duurt het 10 maanden duurt het dan één maand als ik er 10 software ontwikkelaars op Zet nou ja intuïtief zou je voel je al Nee sterker nog soms duurt het bij 20 softwareontwikkelaars op dat project duurt het nog langer dan die 10 maanden want ze moeten ook allemaal nog met elkaar overleggen en mailen en ja nou ja hè Dus er komt een stuk overhead bij en op die manier kan je je ook afvragen of steeds meer gpu's tegen dat probleem aangooien hè dus eh schalen op hardware niveau op een gegeven moment is data op dan moet je synthetische data gaan maken op een gegeven moment is energie op nou er zijn allemaal redenen waarom het echt niet zomaar zo is dat die modellen maar door blijven schalen naarmate je ze meer eh rekenkracht geeft eh maar wat nu grok 3 eh ieder geval laat zien is dat de rekker nog niet uit is ik moet ook zeggen toen ik die eh bench Marks aan het bekijken was ze hebben best wel lopen Cherry Pick hoor bij XI want ze hebben wel de benchmarks tussen uitgetrokken waar ze het best waar ze het meest op winnen zeg maar namelijk eh wiskunde als in logica ehm en kijk als jij denkt en er zijn best wel wat mensen die dat denken dat het universum een soort wiskundig iets is hè dus dat het hele universum waar wij in leven een uiting is van fundamentele wiskunde of dat kan je noemen dat we in de Matrix leven of eh dat dat het universum computer is of dan kan je allemaal dingen Alles is een functie Ja alles heeft een is een causaal verband tussen nodes in de in het universum en uiteindelijk zou je in theorie het hele universum na moeten kunnen bouwen in een simulatie Ja als je dat dan gelooft Ja ehm Dan is op zich in de Ai wereld en in je eh taalmodule als het als het onder als de onderste laag Wiskunde is dan moet je gaan trainen op de onderste laag dan volgen de lagen daarboven in die spekkoek Die volgen dan vanzelf ehm nou dat is dat is een flinke aanname want als blijkt dat wiskunde ook maar een laagje op iets anders is dan lukt dat dus niet dan heb je altijd een soort van eh eh ja hoe zeg je dat eh matige representatie maar goed al met al bij X hè Want hun missie is ook Volgens mij eh alle moeilijke vragen van het universum be antwoorden of Zoo hè elon Musk heeft er een handje van om zijn bedrijven eh eh best wel grote missies te geven we gaan spacex we gaan op Mars wonen maar goed maar dit is ook de missie van mensen die sterrenkunde eh studeren of daarop promoveren of weet het is een heel erg intrinsiek menselijke behoefte om de wereld om zich heen echt tot in de diepste zou de missie van de Wetenschap kunnen zijn hè dat je zegt we willen de wereld beter begrijpen waardoor we de wereld beter kunnen vormen waardoor we de waardoor we in de wereld dingen kunnen maken die misschien minder pijn doen voor mensen of mooier zijn en eh noem maar op maar ehm nou de maar is is dat Ehm je uiteindelijk eh vanuit xci nu een model gecreëerd wordt waar zij zeggen wij zijn succesvol met ons model want er komt steeds mooiere snellere wiskunde uit steeds complexere wiskunde want Waar zijn al die eh al die verschillende laboratoria naar op zoek hoe ze hun missie ook eh op papier hebben gezet Wij willen voorbij de mens Wij willen uiteindelijk eh dat er nieuwe eh wiskundige eh eh modellen en eh ja wetenschappelijke eh doorbraken komen we willen dat de Nobel de volgende Nobelprijs en eh enzovoort gewonnen wordt door één van onze modellen en ehm ja dat dat is nu eh lang verhaal kort want ik dwaal weer af wat ik interessant vond nu grok 3 uitkwam Ik ga dan meteen naar die benchmarks toe omdat ik wil kijken nu hebben zij dus een datacenter vol met hardware Die gooien ze er tegenaan wat gebeurt er dan Nou wat blijkt het wordt nog steeds slimmer beter hoe je het wil noemen het scoort beter op benchmarks dat is eigenlijk het enige wat we kunnen zeggen en ehm dat vind ik wel nieuws alsin Oké dat betekent dus dat eh open Ai eh entropic eh Mistral eh Deep Seek die ook allemaal door aan het gaan zijn en met het Doors schalen en met het uitvinden van nieuwe eh trucjes We zijn er We zijn er nog niet En misschien was dat voor luisteraars sowieso van Ja maar dit eii ding ging toch sowieso alleen maar gaver en sneller worden dat dat weten we niet het kan zoma maar dat je toch tegen een plafond aanloopt ergens maar dat plafond lijkt nog niet in zicht zolang we maar meer rekenkracht in zetten Ik snap het enar Wat betekent dit nou praktisch voor mij behalve de geopolitieke praktijk bedoel ik dan gewoon Hoe kan ik gook stel dat ik dat zou doen Ik mag dat mag echt niet ga niks doen maar kan Kunnen mensen het gebruiken Nee in de EU niet eh ik moet zeggen dat op de eh website van grok met een k.com daar staat best wel een Oké berichtje want ik ik had zoiets Oh ja dit gaan ze natuurlijk cynisch framen hè van eh beste inwoner van de EU door jouw bureaucratische bla blabla die alleen maar eh plastic dopjes kan verwijderen van eh colaflesjes dat hadden ze Ik was me niet zou me niet verbaasd hebben als dit er stond fets ze brengen ze niet op ideeën dan Nee er stond eh er staat zoiets van joh We zijn heel erg ons best aan het doen om eh te kunnen eh voldoen aan de voorwaarden wat betreft dataopslag en privacy die voor jullie geldt in de EU toen dacht ik ja D is prima bericht daar ben ik het mee eens dan duurt het maar wat langer maar ehm ja er zijn uiteraard andere manieren hoe je alsnog met dit model kan praten maar de mensen die dat willen die weten dat wel En zo niet ja kijk even naar een VPN of eh die eh Arena waar jij het over had maar zit het ook in op in x ofzo ja het zit uiteindelijk in x als xai zeg maar daarin dan daar zit grok in maar het wordt ook het wordt nu ook een op zichzelf staand iets dus de grok app en de grok site zoals je die kent van chat PT en clad zodat hij mee kan komen in dat rijtje we hebben hem dus ook losgetrokken uit de de XA al zijn de abonnementen wel weer aan elkaar gekoppeld maar goed Ja Ja Ja oké ik vond ehm even heel iets anders maar toch een vraag van mij eh hij geeft altijd zijn auto's dat moet uiteindelijk Z hebben het Mo Model S en model e en Model X dat moet dan seks worden en eh hij geeft altijd best wel gewoon ja die e kon niet door for trouwens dus dat is een drie geweest maar ja ah oh ja precies dat moest andersom Waar slaat grok op eh ja grok is het een soort van fundamenteel begrijpen van iets van I grock It Dus jij zeg maar eh ja ik ik ik op een op een Het is een soort zwaardere manier van zeggen ik begrijp het Oh ja oké oké nou weet ik dat ook weer Ik begrijp het ja jij grok het straks wiet Heb jij een interview met Rick Lamers van een andere grok namelijk grok met een q zij zijn dus niet grok met een k wat grok met een q doet is Ja ze maken Eigenlijk specifieke hardware dus computer chips specifiek voor Ai als ik het goed heb begrepen dus is een soort Nvidia maar dan net even anders Jij gaat hem interviewen Waar ga je het over hebben wiet uiteraard ook over grok met een k eh om het lekker verwarrend te houden maar ook over nog veel meer eh dingen die eh die specifiek Rik weet en ik niet oké dat straks eerst nog even een bericht van onze trotse hoofdsponsor dept en daarvoor hebben wij Marian en Lucas ingeschakeld die even komen vertellen over wat Ai voor nonprofits kan betekenen dus ja Ai voor het goede [Muziek] doel Hi ik ben Marian van marketing en Tech bureau dept elke week praat ik met mijn collega Lucas over hoe wij merk helpen in de wonder wereld van Ai deze week Ai for Good want veel nonprofits hebben beperkte middelen genoeg mogelijkheden voor Ai dus om hun impact te vergroten dat zagen we ook deze week bij de lancering van science wat we samen met Nvidia en American Society for Death Children ontwikkelde Lucas Waarom is het zo'n belangrijk project Ja wereldwijd zijn er meer dan 450 miljoen mensen die doof of slecht horend zijn en voor hun is gebarentaal essentieel om te kunnen communiceren met de wereld om hun heen Helaas heeft niet iedereen toegang tot onderwijs die nodig is om zichzelf de taal eigen te maken Ehm hoe werkt het precies voor een gebruiker heel eenvoudig je gaat naar de website van science start je camera op en kan meteen aan de slag met het model het model doet een gebaar voor en vervolgens Als gebruiker doe je dat na het model laat je dan meteen weten of je het wel of niet goed hebt gedaan Het is een zelflerend model dus het model leert ook weer van iedere interactie die die heeft met een gebruiker wat ook betekent dat als jij een taal al spreekt je ook het model kan trainen die taal te gaan spreken want het is goed om te weten dat gebarentaal niet universeel is er zijn verschillen tussen verschillende markten en culturen het model werkt echt als een leraar dus pas zich aan aan het niveau van de gebruiker dus op die manier leer je samen die taal steeds beter spreken Wow dat is best wel impressive ja ik denk dat we met Ai echt een groot verschil kunnen maken hè veel voorbeelden die we nu zien zijn heel erg marketing of aan de Digital Experience kant maar Science laat zien dat je echt hele grote fundamentele veranderingen kan maken als je Ai goed deet in te zetten oké nou dank Lucas niet afwachten maar doen dus want wie vandaag begint loopt straks voorop ga naar dept .com slai report Als je meer wil weten tot volgende week en dan nog even dit eh op donderdag 13 maart begrijp ik Wietse ga jij en Alexander wat leuks doen Ja tijdens lunchtijd van 12 tot 1 is het eerste webinar van Ai report jullie gaan vragen van luisteraars eh beantwoorden hè begrijp ik ja van leden van de nieuwsbrief die daarvoor voor betalen voor de nieuwsbrief wa belangrijk om te te zeggen en Waar mogen die vragen eigenlijk over gaan eh wat mij betreft alles wat relateert aan deze show en aan de nieuwsbrief zelf van praktisch tot geopolitiek alles Ja ja ja geopolitiek heb ik heb ik eigenlijk de weinig verstand van ik denk dat de de luisteraars en de lezers van de nieuwsbrief redelijk kunnen inschatten waar Alexander en waar ik antwoord op op zouden kunnen geven ja als je ons complexe vrag gaat stellen over eh kernfusie eh of eh eh de situatie van eh China dan Dan hebben wij het waarschijnlijk wel even moeilijk ja ja ik denk dat luisteraars en betalers van de nieuwsbrief wel snappen waar jouw kracht zit en dat zit hem toch ook heel erg in het technische vlak maar ook in het filosofische vind ik toch Er Wiets maar goed in ieder geval kun je al je prangende vragen aan wiet en Alexander stellen over Ai en die kun je van tevoren ook al insturen daarover vind je meer op Airport email SL webinar en begrijp ook al dat er al flink wat vragen zijn in ingestuurd eh ja heb je al een paar gelezen van Go vag zit er leuke vragen bij Oké oké allemaal geopolitiek want ik las iemand is benieuwd naar een serie prompts waarbij de ene prompt de output van een andere Ja daar heb ik het ooit over gehad dus nu willen mensen weten hoe PR oppakt en dat weer beter maakt en hoe dat zelf in elkaar gezet kan worden Ja dus dat is best wel een praktisch vraag en er is ook iemand benieuwd naar hoe Deep Research nou echt in elkaar steekt hoe het te werk gaat in onderzoek Ja handig om te weten Lijkt me wel ja voordat je €200 per maand aan uitgeeft zeker dus het is ook nog goed voor je eigen portemonnee om daar het webinar even even aan te sluiten goed donderdag 13 maart is van 12 tot één dat en veel meer Milou zei het al Ik ben met ri Lamers gaan zitten van grok met een q om met hem te praten over grok met een k en daarnaast over nog 20 andere onderwerpen gerelateerd aan Ai Het is best wel een lang interview geworden Het gaat best wel wat kanten op maar er zit echt heel veel interessants in ehm Ik denk dat je het misschien een beetje heftig vindt soms zet je hem even op pauze en misschien vind je het een beetje lang zet je hem gewoon uit maar al met al een heel interessant gesprek met Rick Lamers van grok Heel veel plezier Rick voordat we beginnen heel even grok 3 eh wat is jouw Take op dit nieuwe model Ja gook 3 is eh de laatste iteratie van xai het is ook Ja zou kunnen zeggen nu wel echt een bonafide Frontier lab is gewoon een een ehm een een serieuze poging om de beste eh eh het beste Ai model te ter wereld te maken Zeg maar zo spreken ze ook die ambitie uit en gok 3 is net uitgekomen Ik heb begrepen dat het eh preiner van het model dat ze gedemonstreerd hebben in hun eh in hun soort van release eh aankondiging dat hij klaar was met trainen op 31 januari dit jaar dus die is echt vers van de pers eh zou je kunnen zeggen en ehm wat ze daarmee laten zien is eigenlijk dat ze eh hetzelfde niveau hebben bereikt als eh de beste modellen van openi eh niet helemaal omdat eh open Ai heeft ehm zeg ik nou net open ai dat is wel ja dus ik dacht e Rik wat ja het Nederlands ik vraag dus eh ze laten daarmee zien dat ze concurrerend zijn met open Ai eh beste modellen die ze publiekelijk eh hebben laten zien dus Open A heeft ook over het o3 eh model dat ze hebben dat Gebruiken ze alleen intern eh voor voor hun benchmarks eh Fun fact o3 wordt blijkbaar gebruikt voor een feature in chat gpt dat heet Deep Research daarmee kan je een eh kan je chat gpt heel lang laten onderzoeken eh voor een bepaalde onderzoeksvragen en die komt dan uiteindelijk terug met een soort geschreven rapport blijkbaar is dat de volledige o3 ehm maar die kun je dus niet direct nog gebruiken en eh Croc 3 is dus een model dat lijkt even goed te zijn als de allerbeste modellen die dus beschikbaar zijn En dan vergelijken ze het bijvoorbeeld met o1 het volledige o1 model van open Ai en met o3 mini eh eh en en dat ja dat is op zich wel interessant omdat het in een hele korte tijd is gedaan en eh kort Dan heb je het dus over iets van anderhalf jaar dat dat team zeg maar echt begonnen is met actief proberen het beste model te bouwen en dan nu bij is met de leider in de Markt open Ai en ehm in zekere zin zijn ze best wel standaard hetzelfde want ze hebben ook gewoon twee versies eigenlijk vier Ze hebben een eh reasoning en een Non reasoning variant en dan een grote en een kleine en het grote reasoning model dat is dus het beste model en het kleine niet reing model is het het slechtste model in termen van kwaliteit van antwoorden op allerlei verschillende benchmarks en ik denk dat vooral die snelheid was een soort van nieuwswaardig mensen wisten niet van gaan ze n het echt voor elkaar krijgen om eh een model zo snel eh af te hebben dat eh repliceert als het ware wat de beste speler in de markt doet En dat hebben ze gedemonstreerd en daar is ook best wel unanieme consensus over dat het is nu gewoon xai en open a zijn gewoon soort van Ad parity zijn gewoon even goed en dat is natuurlijk ook wel interessant gegeven de context want eh elon Musk was betrokken bij openair eerder is uiteindelijk eh weggegaan en openaar is meer separaat gegaan en daar zijn dan ook later rechtszaken eh et cetera over gekomen maar je ziet dus nu dat er dus twee losse bedrijven zijn xai heeft heel veel eh mensen aangenomen is heel erg snel gegroeid heeft allemaal goed research en Ai Talent eh aangetrokken en is dus nu een volwaardige concurrent van open Ai op het gebied van eh ja dit soort taalmodule sloop dan ook open Ja en aan de ene kant zou je kunnen zeggen eh dat is eh indicatief voor dat zij ook eh sneller Eh zullen blijven en dat ze die sloop gaan gebruiken om open Ey te overtreffen en de andere kant is natuurlijk ook wel eh makkelijk om te repliceren wat men al heeft uitgevonden want ze kunnen wel gewoon afkijken eh want ze hebben gerepliceerd ze hebben niet per se heel iets anders gedaan Ze hebben eigenlijk gewoon gekopieerd wat openair al deed en daarvoor hebben we natuurlijk een eigen preininger moeten samenstellen en hebben ze bepaalde training Technieken moeten oplossen Wat Wat interessant was was dat ze het in die eh aankondiging hebben gehad over dat ze eh heel veel moeite hebben gehad om een training Run stabiel te krijgen op de schaal van 100.000 gpu's dus eh ze hadden eerst eh net voor elkaar gekregen om 8.000 gpu's tegelijk te gebruiken voor een training Run en heel veel van de werkzaamheden en vertraging eh om bij te te komen Had te maken met Hoe maak je nou een training Run stabiel en en werkend op 100.000 gpu's eh omdat er als je op zulke grote getallen zit eh krijg je allemaal uitval problemen allemaal hardware defecten die heel zelden voorkomen maar op die schaal wel wel vaak genoeg dat ze lastig worden en dat moesten ze oplossen daar hadden ze het zoveel over vond ik interessant in die in die livestream omdat dat dus blijkbaar echt één van de grootste uitdagingen is en dan zie je dus ook van Wat is nou eigenlijk de de de de de muscel die die organisaties moeten ontwikkelen dat gaat dus niet zozeer zeer om eh de architectuur want weet iedereen dat is Transformer Het gaat ook niet over eh post training Dat is reasoning dan zet je een eh reasoning eh functie op en dan doe je reinforcement Learning eh en en eh het gaat dus eigenlijk meer om Hoe zorg je er eigenlijk voor dat je de de system Engineering van die schaal een datacenter op die schaal die gecol moet worden Ze hadden het over de Energy spikes die ehm eh geproduceerd worden als als een soort concert in één keer al de gpu's tegelijk hard gaan en dan weer niet en dan weer aan hoe vang je die stroomken op in een net ver aangelegd datacenter in een oude fabriek en en dus gaat het eigenlijk veel meer over die die die die die problemen en juist als je dat perspectief benadrukt is het interessant om te de vraag te stellen wat is nou eigenlijk de bottleneck naar eh het kunnen inhalen van Open A Hoe kan bijvoorbeeld xcii beter een modellen nog bouwen dan eh openi en dan denk ik dat je dat je kunt zeggen Nou elon heeft wel trek record als het gaat om dat soort echte soort van Physics problemen eh stroom installatie koel dat mobiliseren als je autofabrieken kan bouwen kan je ook daar Ja als jij een Kiko Factory kan neerzetten op die schaal en snelheid in in China in in Amerika en telijk daar met met zeg maar zeggen van Oh we gaan twee keer zo groot en het dan ook echt doen een jaar later dan zie je dat eh als dat de Skill is die nodig is en belangrijk is voor het opschalen van Ai en nog betere modellen maken dan Ja heb je wel geduchte concurrent te pakken dus eh dat is wel iets waarvan ik denk dat daar zou je op moeten focussen als je wil begrijpen van wie Wie gaat er nou winnen in die race ja En dan we zijn nu heel snel er even ingesprongen ehm ik kondigde het net al aan grok met een q grok met een k Kan je ons nog heel even helpen wat het verschil is tussen die twee ja dus eh die twee namen lijken heel erg op elkaar het het refereert allebei naar het concept van grock in to grock en eh het bedrijf grock met een q Dat is een bedrijf eh waar ik dan voor werk en dat dat maakt eigen processoren om eh Ai modellen te draaien en er is ook grok met een k en dus daar ja daar dat is verwarrend eh Wij hadden de naam eerst eh zij kwamen daarna en ilon eh die eh die die wil zelf eh kiezen hoe die dingen noemt dus eh maar voor de luisteraars Dus ik werk bij grok met een q grock met een q maak processoren grock met een k is een Ai model En zijn jullie dan directe concurrent van Nvidia in een zekere zin Ja en een andere manier niet Nvidia doet veel me dus wij zijn eigenlijk heel specifiek bezig met één eh soort Ai eh workload zoals ze dat noemen in eh computerwereld en dat is inference dus dat is als je een model gaat gebruiken in een praktijk Je bent niet meer het model aan het bouwen Je bent het model niet meer aan het trainen maar je bent het model aan het gebruiken Dat noemen ze dan infant Want dan draaien eh allemaal verschillende verzoekjes van mensen die een een een vraag willen stellen aan een Ai model dat dat doen wij specifiek en en Nvidia doet veel meer los van dat ze in Ai dus zeg maar eh zowel het trainen als het eh inference gedeelte dus het draaien van modellen regelen heeft Nvidia natuurlijk nog een veel bredere markt Dus ze bedienen ook gamers Ze hebben ook andere Edge devices ehm voor embedded Ai voor embedded eh Acceleration dus eh Nvidia doet veel meer maar als je het hebt over Ai dan is Nvidia zeg maar beter in trainen eh dan in inference en wij specialiseren zich ons op inference en dus ehm ja concurreren we op dat gebied wel met Nvidia Ja dus modellen getraind op Nvidia hardware die kunnen ook draaien op hardware van grok klopt want die modellen Als ze eenmaal klaar zijn zijn het eigenlijk niet veel meer dan hele grote rekensommen en die rekensom die wordt uitgedrukt in in operaties dus eh Je pakt een getal Je doet het keer zoveel en je doet er een getal bij en je deelt het door iets dat zijn eigenlijk gewoon allemaal eh rekena appen die je in zijn geheel É groot als één grote rekensom kan zien en ik denk dat het misschien ook voor de luisteraars wel logisch is dat een rekensom als dat een computer probleem is dan zeg maar een rekensom op een computer draaien Dat is niet per se gebonden aan eh specifieke hardware eh elke elke processor kan een rekensom eh uitrekenen Ja in dit geval is het zo dat deze meer parallelle berekeningen die gedaan kunnen worden eigenlijk beter op een gpu een grafische processor kunnen gebeuren zoals Nvidia die maakt voor games maar ook met hun cuda Layer hè dat er Ai applicaties op hun grafische processoren kunnen draaien heeft grok een processor ontwikkeld die heel goed toegespitst zijn op het maken van de berekeningen nodig voor de Transformer achtige modellen zoals een lama bijvoorbeeld van Meta waarmee je tekst kan voorspellen nou je moet hem eigenlijk nog iets breder trekken dus grok eh heeft processoren ontwikkeld niet specifiek voor de Transformer teur als je een beetje het Ai News volgt over chat tpt en wat die modellen waar dat vandaan komen dat dat is allemaal gebaseerd op de Transformer Architecture ehm maar eh grock heeft eh sinds 2016 al eh chips ontwikkeld 2016 even voor de luisteraars dat is ehm het jaar voordat de attention is al you need dus voordat de Transformer paper uitkwam dus op dat moment was er nog geen sprake van een Transformer Die was nog niet uitgevonden eh hadden zij dus al de chip ontworpen en ideeën over hoe je zo'n chip moet ontwerpen en dat gaat dus niet specifiek over die Transformer architectuur maar meer over wat is het karakter van die rekensom als het ware dus wat Wat maakt het nou zo moeilijk of duur om dat uit te rekenen en eh waar eh je in machine Learning in de breedste zin dus eh attention modellen Transformer modellen dat is echt een subset van alle machine Learning modellen die bestaan wat wel een gemene de is over alle machine Learning is dat ze heel erg data heavy zijn dus dat in die berekening heel veel als het ware constanten zitten eh dat daar komt ook dat miljarden parameters verhaal vandaan als je het hebt over grote modellen Wat is dan groot Wat zijn die miljarden parameters dat gaat dus over dat er heel veel data zeg maar die kennis bevat die in dat model is getraind en dat deel maakt dat die berekening op eh in in zijn geheel data Flow heavy is dus er moet heel veel data bewogen worden eh van eh zeg maar de opslagplek harde schijf naar het echt in de chip zelf zetten zodat er een berekening mee gedaan kan worden en dus de chips van grock zijn niet voor Transformers geoptimaliseerd maar voor machine Learning in de brede zin eh waarbij je dus heel veel data eh gebruikt bij de berekening berekening als het ware leunt op op miljarden cijfertjes en die moeten allemaal aanwezig zijn om de berekening te kunnen doen en dat eh specifieke kern eh eigenschap ehm eh maakt dat je zowel veel memory veel geheugen nodig hebt om al die cijfers in op te slaan als je de berekening aan het doen bent eh Maar ook dat parallel iser dus dat is weer eh eh dat zeg je goed Dat is een belangrijk onderdeel want als je al die berekeningen allemaal stap voor stap gaat doen als dat over heel veel datapunten moet dan kan je je voorstellen dat het heel lang duurt maar we willen allemaal snelle Ai modellen en eh de kern is dus dat je eh zowel om moet kunnen gaan met heel veel grote data dus eh grote hoeveelheden data in die berekening en dat je dat allemaal parallel zoveel als kan moet uitvoeren zodat het ook nog een beetje snel gaat kunt je voorstellen als je in je hoofd bedenkt Ik heb 10 miljoen cijfers en ik moet nu eh al die cijfers keer twee doen Nou dat zijn allemaal 10 miljoen verschillende cijfers als ik dat één voor één ga doen dan beginnen we met eerste getal get al derde getal duurt heel lang maar als je zegt nou weet je wat ik kan er 5000 tegelijk dan gaan we gewoon per 5000 5000 Bam klaar 5000 5000 5000 en dat dat parallel isme zeg maar dat zit eh samen met dus die hele hoeveelheid hele grote hoeveelheid data die je in in het geheugen moet laden die twee dingen dat dat is eigenlijk het karakter van machine Learning workload en dan specifiek eh machine Learning eh workloads in de hoek van Deep Learning dus buiten zeg maar als je een beetje z en diagram voor je ziet machine Learning is de grote ronde cirkel daar binnen heb je Deep Learning en dat is eigenlijk altijd zoals ik het beschrijf met dat karakter dat je parallel nodig hebt en grote hoeveelheden data eh transform attention zit hem helemaal ja eh die gaat dus in Deep Learning weer nog een kleiner eilandje bestrijken want er is ook Deep Learning wat weer geen Transformer is en als ik dan zo'n Transformer thuis wil draaien hè dan zeg ik bijvoorbeeld ik ma probeer hem even concreter te maken hè Heb ik een macm mini 16 GB ram zit erin Dat is dan in het geval bij Apple ook nog VI ram hè dus die die grafische processor heeft wat meer toegang nog tot dat ram dus dan heb je die snelheid die je nodig hebt unified memory maar toch als ik dan zo'n Mac minje koop voor €600 dan wil ik daar eigenlijk Deep Seek R1 opdraaien maar dat kan dan niet want ik heb niet genoeg geheugen en dat maar dat hebben jullie dus wel mij grok Wat moet ik me daarbij voorstellen begint bij form Factor dus wat je al zegt de Mac mini die kan je in je hand houden de servers van gr die beslaan hele datacentra dus het begint al met dat we letterlijk gewoon meer fysieke ruimte hebben om al die chips aan elkaar te ketenen en dan samen hebben ze genoeg geheugen om die modellen te draaien dus eh dat is ook gewoon een kwestie van wij hebben gewoon meer ruimte en we schakelen meer van die apparaten aan elkaar om tot het geheugen te komen dat nodig is om die modellen te draaien maar het is dan niet zo als eh want als we nog nog een stapje terug doen Ehm wanneer jij eh thuis eh dit soort modellen zou willen draaien Je gaat wel kaarten kopen bij Nvidia Je hebt een hele diepe portemonnee dan ga je daar of een hele dikke portemonnee eigenlijk diepe zakken dan ga je daar kaarten kopen met zoveel mogelijk geheugen want er moet met heel veel geheugen heel veel data moet er verwerkt worden zeg maar ehm het liefst real time zodat je tenminste antwoorden krijgt die je kan meelezen als een mens hè een aantal tokens per seconde Die passen bij hoe snel een mens kan lezen zodat het een beetje bruikbaar blijft ja eh maar als ik jouw verhaal zo hoor dan is het bij grok zo dat dat geheugen verdeeld is over al die verschillende processoren is dat een heel ander eh een heel ander ecosysteem of lijkt het wel op hoe andere partijen ook eh ja dit soort berekeningen doen in een datac dat opsplitsen dat opknippen van een model eh over verschillende eh chips als het ware die dan op een manier met elkaar eh in verbinding staan Dat gebeurt ook op die kleinste schaal Dus er is bijvoorbeeld een eh project Ik geloof dat dat EXO nog iets EXO laabs of zo heet exs Ja die eh werken ook aan software die het mogelijk maakt om weer meerdere Mac mini's in serie te zetten zodat die eh grotere modellen dan op É Mac mini past kan draaien en eh dat gebeurt dus op die kleinste schaal al van zeg maar Mac mini's thuis hobbyisten die modellen lokaal willen draaien eh tot in de grootste datacenter centers want ook met gpu's eh die modellen passen Ook niet op één gpu dus die moeten ook geschakeld worden aan elkaar en en is dit dan waar ze Ik ga even sprongetje maken hoor eh is dit dan waar ze bij Deep Seek het voor elkaar kregen dat ze Terwijl ze geen interlink hadden tussen die verschillende kaarten van in dit geval Nvidia ze toch interlink mogelijk hebben gemaakt op een andere manier dus dat ze eigenlijk een beetje gehandicapt gemaakt waren tussen al die links tussen al die onderdelen dat gaat over trainen dus waar we het nu over hebben gaat met name over dat stuk inference dus waar Als je model klaar hebt en je wilt het model gebruiken dan ga je model eh inzetten om allemaal queries te beantwoorden eh dus dus dat daar schakel je waar je nog meer afhankelijk bent van schakelen is bij trainen en het verhaal van Deep Seek dat ze slim om de beperkingen van die gelimiteerde chips die eh h8 100 eh die ze wel tot h beschikking hadden hoe ze om die limieten heen hebben gewerkt dat was een verhaal van eh hoe kan je om de de de de verbinding tussen die kaarten de interconnect zoals ze dat noemen Hoe kan je daar eh slimmer en efficiënter mee omgaan Daarvoor heeft die die siek heel slim eh door nog lower level te gaan als het ware een manier gevonden om dat te te verbeteren zodat ze uiteindelijk betere train eh prestaties kregen Ja laten we die inderdaad dan nog even parkeren omdat het dus meer over training gaat dan inference want ik begrijp het jouw verhaal dat grok zich minder richt of helemaal niet richt op trainen Nee helemaal niet Nee klopt Dat is een hele be zijn geen klanten die nu trainen op jullie eh hardware correct correct dat is gewoon eh dat is niet iets fundamenteels aan de aan de de computers want in die zin lijkt trainen en inference wel kaar zit van het zijn allebei zeg maar met Mols en Matrix Multiplication eh maar het is het is wel een ander ehm een andere workload die weer eigenlijk vereist dat je op een andere manier eh die computerarchitectuur maakt en grock heeft gewoon gezegd kijk uiteindelijk zit de grootste markt in het draaien van die modellen want als je eenmaal een extreem goed model hebt eh ook omdat je die modellen dus heel veel actuele en relevante informatie kunt voeden via de context Window in het geval van Transformers kan het zomaar zijn dat we tot een punt komen dat we modellen hebben die gewoon goed genoeg zijn die niet nieuwe kennis nodig hebben maar die gewoon altijd voor jouw vraag gevoed worden met de meest relevante informatie is zit iets waar je denkt dat het naartoe gaat qua qua Dit is een beetje Ik hoor een beetje alsof je dit eigenlijk al gelooft Ja nou ja wat wel leuk was is deze eh in eh Silicon Valley eh zijn er vaak coole meet-ups en hackatons en één daarvan eh is eh die heette voorheen kuda mode en heet nu gpu mode en daar was ik eh als participant ik ging daar een beetje hacken beetje eh ideetjes testen dan lees je een Research paper en dan implementeer je een eh een idee uit zo'n paper dat is een beetje de opzet van dat Event daar waren ook mensen zoals André carpati gewoon aanwezig die liepen daar gewoon rond waren een beetje aan het hacken en aan het presenteren en aan het praten met de rest en ook mensen van bijvoorbeeld die bij Meta werken die Meta heeft dan lama ontwikkeld en eh wie daar ook langskwam was de de godfather van het boek ehm parallel computing Ik moet even de titel opzoeken maar het Het is in ieder geval Het is zeg maar het referentiewerk voor als je kernels wilt programmeren kernels zijn kleine programmaatjes die je schrijft als je een gpu eh wilt programmeren en eh wat hij zei dat was soort van zijn inzicht wat hij wilde delen is dat hij dus denkt dat we veel meer toegaan naar modellen die niet zozeer ook een ook een bibliotheek zijn dus die ook ook al die feitenkennis al die gedetailleerde bijvoorbeeld in die in die laatste modellen er zitten vaak eh dat is heel heel heel raar eigenlijk dan zit er bijvoorbeeld eh de de hash Dus als je een als je een bestandje hebt bijvoorbeeld een pdf bestand en je en je berekent als het ware eh een soort een soort code die samenvat wat in de informatie van die pdf zit dan krijg je een soort onleesbare lange string van letter kan je controleren of je hetzelfde bestand er binnen gehad exact en en heel veel eh eh van dat soort hash strings die gewoon zeg maar eh eigenlijk niet niet direct informatie bevatten maar maar alleen gebruikt kunnen worden om bijvoorbeeld te checken of dingen gelijk zijn zit allemaal in het geheugen van die modellen Dus er zit als het ware heel veel eh Waste in in wat er in die eh modellen zoals een ehm lama 3 eh 3.1 of lama 3.3 70b wat er in die modellen zeg maar in die weight zit en dus het punt wat wat die man maakte op die op dat Event was dus ik denk dat we toegaan naar dat we het voor elkaar krijgen om modellen te trainen die dus niet zo extreem veel informatie eh moeten bevatten maar dat veel meer opvragen als het ware veel meer eh last Ja ik ik ik vergelijk dat zelfs vaak met dat je kan een pianist hebben die allerlei muziekstukken uit zijn of haar hoofd kent en dat dan kan spelen ter plekke zonder bladmuziek of je kunt een pianist hebben die gewoon ontzettend goed die bladmuziek kan lezen hè maar niet niets uit zijn hoofd weet en die geef je dan een stuk van beter Hoven en die gaat hij spelen noem het intuïtie versus feitenkennis En ik verbaas me eigenlijk over hoe want het is ook voor de eindgebruiker nu verwarrend hè Ik praat ik geef veel lezingen Ik praat veel met mensen over taalmodule jij dat het in eerste instantie wel hele grote modellen zijn geworden die toch gewoon complete hashes erin hebben zitten als een soort bij rommel zoals in onze eigen genetische code hè een soort van Garbage die er eigenlijk gewoon uit kan Ja nou kijk het het komt neer op het punt dat we niet weten hoe we eigenlijk een een puurder model moeten maken een model dat als het ware wel al die redeneer eh vaardigheden heeft dus dus bladmuziek kan lezen als het ware om even de de de analogy door te zetten ehm en omdat we dat niet weten zijn we nu aangekomen bij een soort van onze beste poging om om intelligentie eh te creëren eh in een computersysteem kunstmatige intelligentie eh zitten we zeg maar met deze realiteit opgescheept als het ware en waar ik denk dat ze wel naartoe willen is om te kijken hoe kan je daar een soort van En dit is ook weer ook iets wat andere carpati later heeft herhaald ook op Twitter ehm waar die dus zegt van we moeten eigenlijk naar een soort Common Core reasoning model wat zeg maar al die basiskennis heeft ehm en het is is bijna ook een filosofische vraag want kun je kun je eh intelligentie echt loskoppelen van kennis over de wereld en ik denk dus dat e iets wat zegt ik ben heel wijs maar ik weet niks Ja ik ja ik denk dat er allemaal gedachtes al wel over bestaan en die allemaal veel genuanceerder zijn dan ik zou kunnen uitleggen ofzo maar het is ehm het is wel eh interessant Die vraag van kun Hoe hoe ver kun je hem uitkleden als het ware want je zou kunnen zeggen als je helemaal geen kennis hebt van eh zeg maar feitenkennis hebt van geopolitiek eh en niet weet over de historie van hoe landen zeg maar ooit georganiseerd waren en en nu georganiseerd zijn Hoe kan je dan ehm iets zinnigs zeggen als iemand iets vraagt over wat is waarschijnlijk wat er gaat gebeuren met de Oekraïne situatie daar zou je toch ook heel veel feitenkennis bij moeten gebruiken Ja ik heb een goede vriend van mij die zit in het onderwijs die zegt dat tijd eh tegen mij vooral zegt hij van je mist een stukje bilden hè dat is eigenlijk het opbouwen van een soort intellectuele kapstok om dit allemaal aan op te hangen wat dus ook een stuk wereldgeschiedenis is waar liggen de landen hè Ik bedoel ja ik weet wel wat hoor Maar er zitten best wel wat gaten bij mij omdat ik Ik voel me in dat opzicht best wel eh ik heb best wel veel empathie voor eh het dunne taalmateriaal kan opdreunen of eh md5 hashes ja precies en dus jij bent misschien dan een een al The Common Core wat meer en eh reasoning Models jouw woorden ehm maar ik ik ik denk dus dat Ehm kijk de de de Obvious eh oplossing zou dus zijn dat hij dat allemaal dynamisch kan ophalen dus als hij bezig is met nadenken dat hij zegt van Nou ik weet eigenlijk niet hoe dat historisch zit maar ik denk dat het wel relevant is want hij heeft misschien wel het concept van historische context als eh als primitief en en en dan gaat hij dus kijken Nar Nou dan ga ik eerst even heel eh specifiek gewoon de volledige geschiedenis door eh van eh hoe die landen eh en verhoudingen zijn ontwikkeld en dan heeft hij in één keer misschien wel in 90 milliseconden eh een context opgebouwd van eh alle 700 jaar geschiedenis en kennis die gedocumenteerd is daarover en dus ik vind het wel boeiend hoor want het is eigenlijk een onderwijs vraagstuk in een andere verpakking hè want dan het ging bij mij altijd over dat zeid ja waarom zou je Grieks en Latijn leren hè en doodie talen maar die Grieks en Latijn zit onder alle andere talen dus misschien is het wel veel efficiënter om Grieks en Latijn te leren en Duits en Frans te laten liggen Ik Z wat ik bedoel omdat je daarmee een soort van intuïtiever is een veel efficiëntere manier van een mens trainen Ik wil ons niet teveel gelijkstellen aan maar ook Wij worden op een bepaalde manier in onderwijs getraind hè dat je zegt van moeten we niet fundamentele zaken gaan proberen aan te leren en dan die specifieke zaken er vlucht bij zoeken eh Just In Time Ja en dat dat is dat zijn gewoon echt mega grote open vragen ook voor voor alle grote Frontier eh Labs dus al die al die eh bedrijven die zijn natuurlijk een heftige strijd met elkaar omdat het doen van dit soort werk kost heel veel kapitaal je moet al die training infrastructuur aanschaffen Je moet de mensen in dienst hebben er wordt heel erg geconcurreerd om Talent Dus dat drijft ook weer de kosten van talent en er wordt eh daardoor dus heel veel geëxperimenteerd met welke ideeën werken Nou en eh voorheen had je dat heel veel van die mensen dat werk ook deden in de context van academ instellingen en die konden dan ook vrijuit publiceren over wat ze vinden maar er is natuurlijk ook een soort braindrain geweest waarbij al die beste Frontier laabs van open Ey tot entropic tot Deep Mind et cetera dat die allemaal gaan rond snoepen bij al die conferenties die hebben grote grote geschreven NPS en dat een deel van die mensen zegt Hey ik wil wel eh bij een eh bij een lap gaan werken want dat vind ik vet Ik vind het gaaf wat ze aan het doen zijn maar de consequenties dan dat ze niet meer mogen publiceren maar dit is dus actief waar heel veel onderzoek naar wordt gedaan Hoe kunnen we intelligentie het beste modelleren Wanneer krijg je dan de meest kostefficiënte intelligentie dus een klein model zou ook goedkoper kunnen zijn om te draaien dat is goed voor energieverbruik maaral kunnen t ja bijvoorbeeld als iedereen het gewoon allemaal op hun eigen hardware kan draaien eh net zoals dat gamers vo al nog steeds thuis gewoon op een eigen PC hardware gamen in plaats van dat iedereen Cloud gaming gebruikt exal energierekening natuurlijk als Sony zijn en ook misschien dat je Ja de vereisten die je stelt als gamer aan jouw eh hardware qua qua betrouwbaarheid misschien weler anders dan wat je in een datacenter moet garanderen zie je als mensen er een abonnement op hebben dus al die al die eh dingen Ja die die spelen allemaal een rol maar het komt erop neer dat we niet goed begrijpen hoe intelligentie ehm kunnen kunnen emuleren met een computer kunnen kunnen kunnen bouwen met een computer en dat dus al die ideeën geprobeerd worden maar dat er dat er dus op het gebied van als je er weer terug B naar dat computer architectuur hackaton verhaal van wat zij die eh die die die eh die die die eh die heel heel erg ervaren professor die dat boek had geschreven over hoe je dat soort computer architecturen moet programmeren was dat zijn gevoel was dat we nu nog teveel dus alle alle bibliotheek kennis als het ware alle feitenkennis volledig proppen in dat model en dat daardoor eh het draaien van die modellen zo extreem kostbaar is omdat je dus alles in memory moet hebben heel veel loze ruimte gebruikt omdat je misschien voor eh de de miljoen vragen die je daarna beantwoordt heel veel van die kennis helemaal niet aanraakt dit is ook Waar synaptic pruning vandaan toch als één van de onderzoeks dat je zegt ik draai een Benchmark daarna schiet ik erop met een hagelgeweer Dan draai ik hem nog een keer en dan ga ik erachter komen is even heel onger maar deel wordt niet gebruikt voor als je als je het model aan het gebruiken bent en dan kan je zeg maar dat deadweight als het ware eruit halen dus er wordt op heel veel manieren wel gepoogd om dat efficiënter te maken en dat is ook eh eh het het onderzoeksgebied wat eh zou kunnen leiden tot dat we modellen hebben waarbij al die nut eh niet Niet noodzakelijke feitenkennis feitenkennis die als het ware allemaal Just In Time zeg maar opgehaald kan worden eh dat ja hoe hoe je zo'n model bouwt en misschien is dat hè een stukje dat je gaat introspectie gaat doen dus als dat model bezig is dat je kijkt welk deel raakt hij nou eigenlijk effectief aan dat kan je allemaal een soort van met een x-ray erop zetten en dan kan je zien wat er gebeurt Ja zo'n hoedje wat wat je bij mensen op kan zetten met E sensoren zet je dan op je model Ja zet je op een model en dat is natuurlijk bij model stuk makkelijker dan bij mensen ehm omdat het gewoon uiteindelijk rekensommen zijn en dat gewoon delen van eh van die eh Matrix multiplicatie niks bijdragen aan het eindantwoord Leiden die lig er niet op dus dat dat dat speelt allemaal maar dat zijn ook op zich wel relevante thema's weer voor grock eh want die is verantwoordelijk in hun eh bestaansrecht gaat om Wij willen die Ai modellen draaien zo kostenefficiënt mogelijk maar ook met zo goed mogelijke prestaties zodat mensen er vernuftige toepassingen mee kunnen bouwen en als je snelheids budget hebt hè Wij staan bekend omdat we de snelste inference provider zijn eh in de markt en dat je dan extra budget hebt om vette dingen te bouwen omdat je die snelheid krijgt dus dat sneller maken de economische maken dat is eh waar wij heel erg geïnteresseerd in zijn en waar ik dus ook actief eh onderzoek Ja want dat is mij vragen ja eigenlijk precies want is is grok grok kan natuurlijk wachten hè tot er weer efficiëntere modellen komen om die dan op jullie hardware te draaien maar je kan natuurlijk ook onderzoeken en bijdragen aan Dat gebeurt dus ook ja zeker zeker weten dus wij hebben echt hele teams die gewoon bezig gaan zijn met eh bijvoorbeeld het onderwerp quanti Dus als je het even plat slaat eh als je dat nog no nooit hebt gehoord quanti is het idee dat je de precisie van de informatie vermindert dus waar je misschien Normaal kon je 1 2 tot en met 10 uitdrukken zeg je nou Nu mag je alleen maar 1 3 7 en 10 D wordt lagere resolutie JP toch Ja lage resolutie jpeg Dat is een goede vergelijking of of Soms heb je misschien wel eens van die plaatjes gezien die bestaan uit veel minder kleuren dat je gewend bent dat je denkt van nou die kleuren die zijn een soort van platgeslagen op de dichtsbijzijnde kleur maar die lijkt er niet helemaal op en dat dat dat soort onderwerpen ideeën Er wordt actief onderzoek naar gedaan quanti is maar één ding en zo hebben heel veel ideeën waar we aan werken om die modellen efficiënter te draaien en dat zijn dan alleen maar open weights modellen dus modellen die vrijgegeven zijn eh in de markt niet alleen maar dat is wel waar we tot nu toe op gefocust hebben maar we zijn ook bezig met eh bedrijven die zelf een model ontwikkelen dat niet eh om wat voor reden dan ook misschien economisch eh vrij willen geven omdat ze een concurrentievoordeel willen behouden En wij kunnen dan een partner zijn die dan die modellen voor die bedrijven kunnen draaien als ze dus wel die economische en snelheids voordelen willen die we kunnen bieden door onze chips Ja dus niet alle endpoints van van grok zijn publiek Ik bedoel ik Ik kan een account aanmaken bij jullie dan kan ik een API lijkt nog eens op die van open Nei ook dus die plak ik er gewoon in en dan kan ik er mee praten gaat het in één keer 10 keer zo snel maar er zijn Het is niet dat jullie hele infrastructuur alleen maar bezet gehouden wordt door publieke endpoints correct zeker we hebben ook ook gewoon deployments die voor klanten specifiek zijn Ja want de chips worden ook verkocht aan andere datacentra begrijp ik dan of dat niet eh dat was vroeger wel zo dus grock heeft natuurlijk als scale-up en en daarvoor startup wel ook eh een een soort ontdekkings proces van wat gaan we nou doen precies met het business model gaan we de chips direct verkopen of gaan we gaan we meer zelf die chips ontwikkelen en beheren en dan uiteindelijk alleen maar een API eh verkopen zoals eh jij eh die net beschrijft want je kan natuurlijk dan eh open Ai eh inruilen voor het grock endpoint en dan krijg je dus de de modellen van grock die open source zijn maar je hoeft eigenlijk niet veel aan te passen en dat dat die go to market als het ware dus zo verkopen in de markt dat is wel een recente ontwikkeling voor crok dus daarvoor verkochten we meer zoals Nvidia dat deed hardware aan partijen die dan zelf moesten uitvogelen hoee kan ik hier nou efficiënt Ai modellen opdraaien Want nogmaals We waren niet gefocust op Transformers Dat waren ook computer Vision modellen en graft n Networks er waren allemaal andere dingen ehm en eh ja als waar het dan nu zeg maar op neerkomt dat ze h in hun go to market echt gekozen hebben voor wij beheren die eh chips zelf we verkopen niet direct die chips maar wat we wel doen is deployment van chips in datacenters die dan in principe eigendom zijn van een ander maar wij beheren dat nog wel allemaal zodat als onze compiler beter wordt en we modellen beter kunnen draaien dat dat automatisch allemaal overgaat naar die datacentra die dan in de eigendom zijn van andere klanten en en hoeveel procent van van de workload is nu Transformer inference dat dat is natuurlijk het vlammende pan moment geweest voor grock is dat ehm op een gegeven moment zijn die taalmodule model uit eh Meta En ehm toen dat gebeurde was in É keer duidelijk dat er een heel waarde open source Models wat je zou kunnen draaien en toen hebben heeft Kok al heel vroeg was ook voordat ik erbij ben eh gekomen is crok vroeg echt begonnen met eh met met gewoon kijken van Oké hoe kunnen we die dat soort modellen het beste draaien is ook grappig want in de codebase zie je ook zeg maar al die andere modellen die er gedraaid zijn en gecomp zijn voor crok maar dan op een gegeven moment kwam daar in dat lijstje gewoon lama bij en en dat is nu bijna alles the rest is History Ja en en toen eh ja de vragen naar is gewoon enorm want Je kunt er heel veel nuttige dingen mee bouwen zoals heel veel eh mensen die experimenteren met wat je kunt bouwen met dit soort taalmodule eh eh goede modell want hoe jou kijkt nu op op die eh open weights modellen dus modellen die gedraaid mogen worden op andermans infrastructuur zonder dat je licentie kost kost hoeft af te dragen Ja ik vind het persoonlijk geweldig Nee dat begrijp ik maar ik bedoel is het is het zo dat zie jij mijn vraag is denk ik eigenlijk ehm Er is nog een Er is nog een vraagteken Oké je hebt de gesloten modellen hè en de Frontier laps eh als open en jij ehh grok met een k die hun één É en laatste model alleen open sourced Meta die hun Frontier model opor voor z verk weet iedereen heeft daar zijn eigen strategieën in maar eh Denk jij dat het één van de ideeën is die die een beetje rondgaat in de Community is van open source zal uiteindelijk winnen want het is een soort van eh eh dat dat gaat nou eenmaal gebeuren want open source wint altijd ofzo wat op heel veel gebieden trouwens niet gebeurd is dus dat zeg ik altijd al maar het Hoe Hoe zit jij in die in die Wat als jij zou moeten wedden Ik bedoel ik snap dat je bij grok met een q werkt dus dat jij je bepaalde belangen hebt maar nou nogmaals grok eh is ook gewoon beschikbaar voor modellen die niet open source zijn dus het is niet dat grock alleen kan wennen als open source modellen uiteindelijk dominant zijn Ik denk dat heel makkelijk om eh kijk dus sowieso is het antwoord allebei gaan blijven bestaan en net als in de database wereld of als in de operating system wereld Je hebt Linux is heel populair maar je hebt ook Windows heel populair macos en die die twee zijn niet open source eh je hebt ook bij database heb je post crash dat is hele goede database maar je hebt ook Oracle DB Oracle DB is super volwassen wordt er heel veel bedrijven gebruikt en eh zit een heel eh bedrijf achter en en dat is betaald dus ik denk dat als je kijkt naar de geschieden is dan zul je zien dat daar in beide heel erg een grote rol eh spelen Ik denk dat dat ook zo blijft in generatieve Ai ehm wat wel interessant is natuurlijk is om iets te kunnen zeggen of een idee te hebben bij In welke Mate verschillen die dus dus hoeveel verder vooruit gaat die eh die die proprietary eh eh hoek gaat hij gaat hij echt heel veel beter zijn dan open source daar is altijd heel veel discussie over geweest en dan zie je eigenlijk altijd soort bijna maand tot maand een soort van verschuiving van Oké de gap is nu heel groot en de gap is nu heel klein en ehm op om É of andere reden denk ik ook dat eh het probleem heel erg fascineert Je hebt natuurlijk in de markt wordt veel gesproken over ati Artificial general Intelligence en je hebt ook over asi asi Artificial eh superhuman Intelligence en heel veel mensen dus als je kijkt naar Deep Seek bijvoorbeeld dat Chinese bedrijf dat is eh het project van een Fund dat heet highflyer en je kunt je afvragen waarom waarom doen zij dat nou zeg maar waarom investeren in eens want zij zeggen dat ze dat Deep Seek model hebben getraind voor 5,5 miljoen dollar eh equivalente huurkosten van dat soort gpu's om het te trainen maar iedereen weet ook wel en heeft het ook over dat de echte kosten om tot zo'n model te komen vele malen hoger zijn want je moet ook rekenen met alle experimenten die je Mo Ze hebben een soort arbitraire lijn getrokken in dat kostenplaatje heel moooie gal uitkwam wel getal is want het ison het getal eh wat het zeg maar het zijn echt de de Cost of goods zeg maar zeg maar als je een bedrijf bent en je en je produceert 100 fietsen eh dan ga je dan kan je wat zeggen over hoeveel het gekost heeft om die fietsen te produceren en dat is het bedrag om in plaats van 100 zeg maar nog de volgende 100 te produceren dus het is meer de marginale kosten waar ze het over Ja maar niet wat je wat je moest doen om te komen tot het kunnen produceren van die want misschien heb je als bedrijf wel eerst gewoon eh jarenlang miljoenen verlies geleid eh geleiden om omdat eh fiets onwerp eh goed eh ingedaald te krijgen dus zo ook met die Art met die met de modellen eh is natuurlijk bij Deep Seek eh en high flyer ook gaande maar eh dat nog steeds is het interessant om te zien dat de de marginale kosten dus maar eh 5,5 miljoen zijn want wat wat is nou de de situatie en daar waarom is dat bedrag ook wel echt relevant is dat zij hebben wel ook het recept gepubliceerd Ze hebben ook gezegd en dit is hoe we het precies gedaan hebben en wat je niet krijgt van Ze is de pret training data waarop ze trainen dat zijn volgens mij 14 eh biljoen tokens voor tril want het ultieme open source is dat ook nog toch dat is nog het enige stukje dat mis Z discussie over Wanneer is iets open source of open weight eh als je een model krijgt eh dat getraind is dat dat ik vind de beste vergelijking is dat je een een downloadable binary op je computer een Software programma als jij een programmaatje download en je installeert het en je kan het gebruiken dan heb je nog niet de broncode achter dat programma en in in in een zekere zin zijn die open weights modellen steeds zijn zijn meer vergelijkbaar met een binary eh dan met de de broncode ehm dus eh Deep Seek heeft niet die traina gepubliceerd waarschijnlijk ook omdat net als bij alle andere Frontier laabs daar waarschijnlijk allemaal data tussen zit waarvan het Juridisch niet duidelijk is of je er überhaupt op mag trainen onverstandig om laten zien eh waar je dan laat je zien er zitten allemaal boeken in dan heb je alle al die boek boek eh publiceer eh bij aan de deur Dus dat is waarom ze dat niet doen Aan de ene kant aan de andere kant is natuurlijk ook gewoon nog steeds een stukje voordeel wat ze willen behouden want ze ze zijn wel ook in concurrentie en ze willen ook wel graag winnen ehm want ze zijn niet alleen aan het concurreren met het westen ze concurreren ook binnen China met andere Chinese bedrijven zoals met het team van Alibaba of nog andere teams het team van byance et cetera dus eh terug naar dat gat van open source dus hoe groot is dat gat geweest nou Je zag dus dat dat fluctueerde op een gegeven moment lag open source eh echt achter vooral in het begin toen begon het wat dichterbij te komen toen kwam er in één keer weer een Wave nieuwe modellen ook met reasoning modellen toen was het weer echt van wow open source heeft echt geen antwoord hierop D is helemaal geen reasoning model en toen kwam eh diep zek weer en wat je wat je toch terug zet is dat als je ook kijkt naar eh als zo'n diep zek Dus vertelt van hoe ze het gedaan hebben dat de hoeveelheid Innovatie die er gedaan is dus hoe hoe anders is nou eigenlijk dat deeps R1 model ten opzichte van lama 3 wat we al heel lang kennen en weten En dan zie je dat het toch wel Modo aanvoelt als incrementele Innovatie Dus ze hebben kleine tweeky hier tweeky daar trainingsproces net even anders hier net of ander soort data net even een iets ander algoritme maar niet radicaal anders en daardoor zolang dat verschil tussen als het ware de eh de de versie 1 en versie 2 marginaal lijkt incrementeel lijkt dan is het dan is het gat wat dan een open source tussen open source en proprietary bestaat ook niet zo groot Er is ook een hele hypermobiele talentmark in in deze eh markt Dus als je kijkt naar die grote Labs Je hebt xai je hebt entropic je hebt Open A je hebt deep Mind en je hebt nog mestral en nog een paar andere en daar beweegt wel ook veel Talent tussen en je kunt gewoon moeilijk Eh ideeën die opgedaan worden zeg maar echt eh patenteren op een manier dat als een werknemer weggaat en eh bij een ander bedrijf in dienst gaat dat dat die die techniek niet toegepast kan worden wat ook veel van die zijn best wel klein weet je wel is zo van ja kan je nou echt patenteren dat je beter in die volgorde kan kan trainen heen en weer inhuur is is is niet alleen maar om de mensen maar ook wat er in hun hoofden zit Oh absoluut zodat je dus een soort sink een kennissynthese en die had ook voor Meta een heel goed reasoning model kunnen bouwen Maar die is naar open eii gegaan en ik ken hem niet en ik ken zijn beweegredenen niet maar open is Alvast een goed verhaal hebben gehouden tegen hem om te zeggen kom maar bij ons aan reasoning modellen werken en ja dat is wel gewoon hoe die Markt momenteel werkt en die dynamiek die Talent dynamiek die heeft heel veel invloed op het verschil tussen proprietary en open source capaciteit en en kwaliteit ehm en dus is het is kom je echt met een radicale nieuwe verbetering een hele nieuwe architectuur je hebt eh naast de Transformer modellen hebben mensen het veel lang over Mamba dat zijn stage based modellen Dat zijn andere soort modellen dan Transformers Zou die ook goed kunnen draaien op op jullie hardware Ja we hebben ze al draaien op onze hardware maar ze zijn niet populair geworden Ja Nee zoals ik al zei we hebben geoptimaliseerd voor machine Learning breed dataflow workload en niet niet zozeer Transformers ja eh ik ik ben nog even nieuwsgierig hè Want je Ik zat te denken is het dan niet zo want jij gebruikt net het het close source open source eh Oracle versus postgres eh Microsoft Windows kernal versus Linux dat is jouw vergelijking en die Daar kan ik goed in mee Maar in dit geval is is het wel zo dat stel je bent een Frontier lab je nadert Welke definitie dan ook van agi eh en op dat moment zou je bijvoorbeeld jouw modellen kunnen gebruiken om jou modellen nou je modellen gebruiken om je modellen te trainen Dat gebeurt al hè door het creëren van synthetische data en distilling Maar je kunt ook zeggen wij gaan die modellen laten meedenken over hoe je modellen maakt en we gaan die modellen laten mee programmeren aan onze modellen en dan kan je op een gegeven moment een cirkel krijgen een soort takeoff scenario zoals dat dan rondgaat in de Ai Community waarin degene die daar als eerst komt de groep die daar als eerst komt en zijn eigen modellen zijn eigen modellen kan laten verbeteren eigenlijk wegvliegt van de rest als een soort de eerste raket die van de grond komt zeg maar terwijl al die andere raketten nog op de grond staan dat maakt het wel wat mij betreft de eh belangen die er spelen in die open source versus closed source of open source versus proprietary wel groter dan tussen twee operating System kernels of database engines Oké Ja uiteindelijk en D dat vind ik wel een interessante opmerking an zich is dat eh Je kunt je kunt denk ik technologieën een beetje categoriseren of clusteren naar Hoe bounded zijn ze in de zin van eh een heel goed operating systeem Een hele goede auto kan gewoon zeg maar heel nauwkeurig en veilig van a naar b eh maar je kan niet nog sneller en nog sneller want dat is gewoon ongemakkelijk voor die persoon in de auto dus je kan niet op snelheid zit een soort van limiet dus als je gewoon met de nog comfortabele snelheid met extreme Veiligheid en met heel veel precisie van A na B gaat Heb je een soort van de perfecte auto gemaakt die dan ook nog eens nul energie verbruikt of wat dan ook negatief zelfs Whatever maar het is niet je kan niet een auto op een gegeven moment heel veel beter maken en hetzelfde geld denk ik voor operating Systems ehm en database Zoals je zegt maar de categorie eh kunstmatige intelligentie heeft heeft weinig last van dat probleem een een een nog betere nog intelligenter systeem is gewoon weer weer waardevoller en en het is vrij makkelijk om als je dat systeem pakt om te zeggen maar hoe ziet een nog veel slimmer systeem eruit en wat kan dat dan nog weer betekenen waarbij eigenlijk de fantasie en de de ideeën zeg maar Eindeloos zijn weet je als als een systeem Zeg maar eh definitie die over AG agi of agi eh wordt wordt gegeven eh die ik wel grappig vind is eh als het een 100 miljard eh eh dollar in Waarde zou kunnen produceren een soort economische definitie van hoe nuttig of hoe goed is een model ehm en dan eh Kun je makkelijk zeggen van nou oké als als een eh Ai model intelligent genoeg is om dat te bereiken Ja dat vind ik niet indrukwekkend ik wil eigenlijk dat eh alle dominante ziekten die nog eh actief zijn dat die opgelost worden weet je wel Cure cancer c dit enzo en en als een model 100 miljard waardevol eh of 100 miljard waarde kan creëren dat is dat is een soort lagere lat dan Dat weet je wel dus ik denk dat dat moeilijker is meer dan 100 miljard kost en en dus ehm daar daar heb je wel natuurlijk een soort van dat waar stopt dit weet je wel want want je kan altijd nog intelligenter willen bouwen en het is niet duidelijk dat we geen ideeën meer hebben En dan kan je weer naar dat tof verhaal van is er nou sprake of kan het mogelijk een soort takeoff eh zijn dus een soort eh loop die oneindig gaat eh blijven verbeteren Ik denk van niet Ik denk om een vrij simpele reden en dat is dat er gewoon altijd bottlenecks ontstaan die tijd eh nodig hebben om opgelost te worden en heel veel ook bottlenecks die gebaseerd zijn in de natuurkunde of in de in de natuurwetten dus als jij een eh systeem hebt dat heel goed eh zelfstandig onderzoek kan doen Daar heeft eh open het ook over we hebben onderzoekers eh die volledig gebaseerd zijn op ai dat zijn een soort Ai Agents die onderzoekers zijn en dus misschien zouden kunnen bijdragen aan betere ideeën voor betere eh systemen dan eh moet je om bijvoorbeeld stel nou dat hij iets vindt echt iets briljant waardoor het maar een derde van de tijd en energie kost om het nog een nog beter model te trainen dan ze zojuist gedaan hebben dat model kostte wel gewoon drie maanden om te trainen nu heb je een maand nodig dus ook om dat voorstel te testen eh van zo'n eh Ai onderzoeker ook al als het allemaal helemaal klopt en helemaal waterdicht is heb je nog wel weer een maand nood om te wachten en als er dan andere modellen ook getraind worden van andere mensen Ja die nemen dan misschien voorrang omdat die toch Ja menselijke test gaan voor op die die Ai test en en zo denk ik dat er allemaal eh bottlenecks eh zijn dus misschien dat die iets briljant eh heeft bedacht maar dan moet je eerst een nieuwe interconnect eh implementeren heeft hij ook uitgezocht dus al die bottlenecks die gaan uiteindelijk zorgen dat een takeoff niet een soort viral takeoff is die gewoon Nee precies want dat is mij de discussie is de is voor mij hoeveel graden Die lijn is h is dat een rechte lijn omhoog in een soort hele eh Valy achtige ho nee dus jij bent anti hockeystick zeg maar Prima ik volgens mij is dat ook Nou ik bedoel anti zijn veel lijnen die allemaal hockeystick zijn hè Z ver over wat voor stik hebben we het Welk merk maar h niet een soort van ongelimiteerde ongeremde Super li omhoog hè die gaat iedere keer gaan daar eh dempende factoren op duwen hè natuurkunde energie eh bureaucratie hè dus ik ik ik ik kan jou daarin helemaal volgen maar ik denk dat mijn vraag vooral is eh kijk ik zie dan een beetje 10 raketten naast elkaar staan hè vijf close source raketten en vijf of vijf closed weights closed weight raketten en vijf Team open weight eh eh raketten nog even los of het open source is en eh op een gegeven moment begint er één een beetje zo te te hoveren hè zoals je dat van spacex gewend bent nou voor mij zijn ze al een beetje aan het hoveren voor mijn gevoel soms die raketten hè dat je denkt en dan gaan ze weer naar beneden denk je Oeh Dat zag er wel spannend uit en dan gaat iedereen die bij die laps werk vlucht naar buiten rennen en op Twitter roepen jongens Het gaat wel heel hard weet je wel mensen worden ook een beetje zenuwachtig als ze dat zien Ja ja ehm maar op een gegeven moment gaat er natuurlijk één langer Hover Hoger en hoger en hoger en ik denk dat mijn aanname daarin is merk ik nu Nu ik het met jou over heb dat eh de andere teams dan blijkbaar geen kans meer maken ofzo er kan maar één winnaar zijn Ik weet eigenlijk niet zo goed hoe ik dat kan verdedigen maar dat gevoel heb ik dan hè Van Het lijkt wel alsof die degene er dan met de prijs van doorgaat ofzo in een soort Zero game dat denk ik sowieso niet dat het wel zerm is ook omdat die modellen voordat dat model er was die zijn al steeds nuttiger en nuttiger en met capabeler dus als je nu kijkt naar één van de allerbeste modellen die je gewoon kunt krijgen die beschikbaar is op de markt dat is bijvoorbeeld o3 mini ehm o3 mini is al echt insanely Good zeg maar in het schrijven van software dus als jij een programmeur bent eh dan weet ik vrij zeker dat er eh subgebieden zijn waarin o3 mini jou helemaal omver blaast Dus als jij bijvoorbeeld hele goede webdeveloper bent dan gaat dat ding rust en c+ Plus code schrijven waar je waar je met je hoofd niet bij kan als jij eh hele goede c+ plus developer men dan kan dat ding React Component schrijven op manier die jij niet kunt dus de de die dat o3 mini model dat is al extreem goed en we zien dus dat zeg maar o3 mini lijkt weer op R1 Deep Seek en dat is open source die twee zitten nu dus dicht bij elkaar en zelfs als als iemand dus weer echt weer nog een flinke stap maakt Bijvoorbeeld we wachten allemaal op wat entropic gaat doen want die heeft al een tijdje niks uitgebracht ja paar weken nog begrijp ik Ja dus nou dat duurt even en dan komen ze waarschijnlijk weer met iets met iets heel bijzonders en eh op het moment dat dat er is dan gaan er ook wel weer eh wordt er ook weer vol opgedoken van hoe werkt het dan en en en hoe welke vorm verk heeft dus dan wordt er extern geleerd wat er geleerd kan worden Ik bedoel bij een reasoning model weet je wel vrij snel Oh hij neemt heel veel tijd om te Reason h Misschien moet we een beetje in die hoek zoeken Weet je zelfs zonder dat ze iets open sourcen lekt er wel weer informatie naar al die researchers die ook open source werk doen om dat weer te repliceren en te kopiëren en dan ben je weer een soort catch-up eh beweging in eh in in werking aan het zetten dus ik denk dat ehm en en nogmaals Soms zijn die hele goede modellen ook weer duurder om te draaien omdat ze gigantisch groot zijn en dan is weer de vraag van Waar gaan we dit voor inzetten bijvoorbeeld eh o1 Pro mode Dat is een hele dure versie van inference Sam altman heeft publiek gezegd ehm we hebben het prijs op twe prijspunt op $200 gezet maar zelfs dat was niet genoeg om de kosten te dekken van hoe duur het is om dat om dat om die feature te draaien ehm en en dat zegt ook weer dat je moet ook een soort van eh een probleem matchen met de hoeveelheid intelligentie die je er tegenaan gooit en vooral de kunstmatige intelligentie omdat kunstmatige intelligentie is uiteindelijk gewoon stroom ehm en dat moet je wel een beetje matchen want anders ga je eh Te dure eh soort van Ja want ik heb ook begrepen dat GT5 gpt 5 zou een soort router moeten worden toch Hè de de als in wat één van de innovaties van gpt 5 wat ik nu heb begrepen dan is dat hij aan de hand van jouw vraag gaat kijken wat die als een soort mixture of experts maar dan nog breder eh ga ik reasoning doen ga ik af CF meteen reageren zonder reasoning of heb ik dat verkeerd begrepen Nou kijk als je kijkt naar o1 dat is dat model van openair dat eh al dynamisch heid Ik noem het een soort van eh Dynamic Range dus het kan zeg maar heel snel een antwoord geven als ze denkt nou dit is een vrij rechtrecht aan vraag hoe niet echt lang over na te denken Hier is het antwoord How TS die Empire State Building dan moet hij niet een minuut gaan nadenken en dat dat had o1 preview het model voor o1 eh had daar last van dat zeg maar hele simpele vraagen How are you 2 minuten later I'm Great Thanks Ja soort filosoof die denken ook veel te lang na en dan ga je ook kijken k wij kunnen de reasoning traces niet zien van eh openair natuurlijk dat is iets wat zij verbergen om concurrentie redenen maar dan als je dat ziet bij Deep Seek R1 dan zie je als een soort eh hele introverte soort persoon die zenuwachtig ge op die reactie gaat reageren dat is wat je niet wil want dat is niet logisch dat je daar heel veel tijd en en en dus ook eh energie voor gaat gebruiken als het een hele makkelijke vraag is dus o1 is al heel dynamisch in de zin de laatste versie van een een simpele vraag krijg je snel een antwoord kost minder compute en een langer moeilijke vraag die gaat meer tijd kosten en dat is denk ik waar ze op hinten met gpt 4.5 is dat ze het hebben over een systeem dus dat dat heel goed doet dat dynamisch schakelen ehm maar dan noemen ze het meer unified dus met een outer kan je al meer denken aan een systeem dat echt losse systemen zijn waarbij eh iemand gaat beoordelen is de moeilijke vraag is de moeilijke vraag dan gaat hij naar het grote model eh of naar het reasoning model eh met misschien een tijd budget van 9 minuten want ja het is een 9 minuten probleem Eh en dat dat is niet zeg maar wat ze gaan doen waarschijnlijk niet dat discrete soort van echte meerdere verschillende modellen die echt los staan van elkaar ze gaan het wel samen springen in één geheel dan krijg je misschien een nieuw soort architectuur wat wel heel erg lijkt op een TR Transformer want ook bijvoorbeeld Deep Seek R1 is gewoon een Transformer model maar maakt dus gebruik van Die variant dat heet mixture of experts En dat betekent dat het model eigenlijk getraind is als Allemaal losse kleine modellen die wel allemaal geschakeld zijn in één en het model heeft uitgevogeld tijdens het trainen eh voor elke vraag hoe moet ik het verdelen over mijn sub model zeg maar die architectuur is één heel groot deel Maar er zitten allemaal soort discrete blokken in en hij pakt dan de de blokken die relevant zijn voor de vraag en dan heb je alleen 10 nodig maar als ik dan met gpt 5 ga praten dan kan ik dus sporadisch heel snel antwoord krijgen zoals vroeger PR reasoning eh en sporadisch hele lange antwoorden krijgen of trage antwoorden krijgen want er moet eerst nagedacht worden en dat is niet een soort rouje ervoor Maar zit er gewoon in Ja maar het is intuïtief ook natuurlijk hoe je eh nadenkt over de over hoe hoe de mod hoe de hoe de echte wereld of de natuurlijke wereld is misschien een beter woord gestructureerd is dus in computer Science onderzoeken we dat dat heel specifiek dus bijvoorbeeld in Delft daar heb ik gestudeerd eh daar hebben ze het altijd bijvoorbeeld over complexity classes Dus dan kan je zeggen oké dit probleem is eh zo moeilijk en bijvoorbeeld het sorteren van een lijst cijfers is eh makkelijker dan het eh sorteren van een lijst ehm van floating Point cijfers dus niet natuurlijke getallen en daar kan je iets over zeggen analytisch En als jij eh iemand een simpele vraag stelt dan begrijp je dat er minder moeite is dan als je zegt van ik wil 19 winkels in Nederland plaatsen maar ze moeten zo geplaatst worden dat eh eh er minimaal binnen zoveel Dekking van alle grote Burger Kenner eh Ja precies dus als jij een heel moeilijk probleem beschrijft dan is het redelijk om te verwachten dat er meer moeite gedaan moet worden om dat probleem op te lossen of dat nou door mensen of door een computersysteem gedaan wordt en ik denk dat die Ja dat dat dat dynamische is eigenlijk heel gek dat het in het begin niet zo was dus dat elke vraag Nee dat heb ik heel de tijd nu bij dat ding dat ik denk nu ik begint te zien hoe die gaat werken van context moet er eigenlijk niet in zitten maar op tijd toegevoegd worden hij moet eigenlijk nadenken over hoe die nadenkt maar hij moet niet te lang dus waar we mee begonnen was eigenlijk een heel raar ding dat was Zeg maar gewoon eh hij bevatte alle feitenkennis en hij deed over ieder probleem even lang van Hallo doet hij evenveel letterlijk op de op de flop doet hij evenveel berekeningen als dat je zegt van eh ja eh eh maak een vereenvoudigde theorie van eh eh kwantummechanica en eh relativiteit ik ben geen natuurkundige dus I bot is waarschijnlijk maar de e zeg maar dat dat idee dat je daar even veel moeite en tijd aan besteedt dat is natuurlijk niet heel intuïtief en daar proberen probeert men ook nu een beetje in te leunen als als onderzoekswensen dan doen om die eh mismatch op te lossen en krijg je daar dan uiteindelijk eh betere modellen door want Hoe zit jij nu want we hebben het nu best wel casual over eh agi asi eh dat het allemaal beter aan het worden is raketten die opstijgen of niet Maar hoe zit jij er zelf als mens in als je dit allemaal ziet ben je hier hartstikke enthousiast over en vind je het eigenlijk allemaal wel mooi of zijn er ook zorgen over banen en je eigen baan en ben jij straks nog wel nodig zijn dit dingen waar je ook bij stilstaat Ja ik denk ik ik ik denk daar niet extreem veel over na omdat ik daar misschien een redelijk simpele take over heb Is dat ik denk dat met zeg maar dat dat narratief heb waarschijnlijk ook al voorbij gekomen dat met elke technologie zeg maar heb je dat het bepaalde banen automatiseert en dan ook weer nieuwe kansen creëert en die nieuwe kansen de laatste allin podcast ging trouwens eh over dit onderwerp over een soort van de de soort van gaat Ai dingen automatiseren tot het punt dat er heel veel baanverlies is of gaat er allemaal opportunity door ontstaan allemaal nieuwe kansen waar mensen iets mee kunnen ehm en ik ik ik denk dat je ziet het al als je als prog bijvoorbeeld niet bij blijft met wat er kan met de laatste modellen dan word je heel snel buitenspel gezet zeg maar dan ben je economisch echt in één keer stuk minder waardevol stuk minder aantrekkelijk eh om eh in te zetten om het om om software te maken dus een een een programmeur die echt vaardig is met het gebruiken van de laatste modellen van entropic en open Ai voor het ontwikkelen van software die die die die loopt echt rondjes om iemand die dat die dat niet gebruikt niet aanraakt en dat dat effect wordt steeds groter en het kan zelfs zo zijn dat heel veel van de werkzaamheden waar programmeurs hun hun brood mee verdienden Gewoon letterlijk allemaal niet gedaan hoeven te worden dus als je bijvoorbeeld kijkt naar een tech bedrijfsstructuur dan heb je vaak een tech lead daaronder werken mensen dat noemen ze vaak dan ic's individual contributors dat zijn zeg maar heel onderbed gezegd de code monkeys die echt implementeren en bouwen wat er gebouwd moet worden en het lijkt er steeds meer op dat die dat die teag lead positie die bepaalt wat er gebouwd moet worden vaak in samenspraak met nog eener stakeholders daarboven dat die eh steeds belangrijker worden omdat het echt daadwerkelijke bouwen van van de van de functionaliteit Als ze eenmaal een beetje bedacht en geset zijn van het moet dit kunnen doen en het moet on weer zo werken dat dat dus allemaal gedelegeerd kan worden aan Ai systemen en dat is programmeren dus daar zie je al hele grote veranderingen dat als als je niet oppast als programmeur kan je in één keer buiten spel staan waarbij je letterlijk gewoon je baan verliest en niet meer nodig bent als je puur en alleen dat naar de tafel brengt en ik denk dat eh met Ai op het gebied van rende auto's bijvoorbeeld je ziet WMO helemaal doorbreken in San Francisco Nou dan zie je dat als je daar Driver bent dat je echt een probleem hebt dat je echt moet nadenken oké over één tot 2 jaar is waarschijnlijk deze baan helemaal weg gewoon compleet Maar laten we dat laten we dat die mensen Fleet managers noemen hè Dus je zitten één niveau hoger in die stapel die zeggen dan ehm ik ga niet die auto rijden maar ik ga een vloot van auto's beheren net als dat een mens zegt ik ga niet Ik ben geen eh oneerbiedige code Monkey maar ik ben iemand die Spec schrijft en en dan laat ik het implementeren door eh eh code Monkey Agents maar wat als je die sprong niet kan maken ja en daar daar is denk ik eh uiteindelijk heb je een democratie eh hopelijk in de meeste landen en heb je eh een progressief belastingsysteem en heb je vormen van minimum bestaan en Zorg je er in ieder geval voor dat als die technologische ontwikkeling en dit is de Europeanen in mij die zeg maar dit dit dit geloof ik hoor je ehm eh die er dan voor zorgt dat eh als dat taart heel erg gegroeid wordt hè Want het idee is natuurlijk dat prosperity en ubiquity en eh een soort van oneindige creatie van eh diensten en goederen Mogelijk wordt gemaakt door alles automatiseren met computers en robots Dat is een beetje de Silicon Valley Utopia waar ik op zich wel in geloof dat dat tot op zekere hoogte gerealiseerd worden pos groeit exact eh dat je die dan wel moet verdelen op een manier waarbij je niemand echt achterlaat en er wordt vaak dan een discussie gevoerd over eh hoeveel ongelijkheid laat je dan toe en daar zie je dan dat er weer cultureel en en maatschappelijk verschillen bestaan en je ziet gewoon ongelijkheid groot in de VS dan het is in Nederland eh of in andere Europese landen en daar moet een deel van de discussie over gaan maar ik denk niet dat we zeg maar putting The Horse Before The carriage We zijn en nog niet echt ik bedoel het is geweldig wat die Ai systemen kunnen maar we hebben nog niet echt goede robots en we hebben ook nog best wel domme Ai systemen die doing echt nog wel heel erg fout doen maar jij Jij staat in het Jij staat in de modder hè dat bedoel ik dus positief Ik bedoel ik kom nu met mijn helikoptertje van een trapje af ga ik even met jou daar Jij staat eh of ik misschien kan ik het mooier beschrijven jij zit diep in een datacenter complexe dingen te doen klinkt beter dan in de modder Ja je zit er gewoon zit tussen die humm de machines Ja daar Z Daar vind ik jou achter je laptop op de grond die nog even de laatste patches aan het pushen is naar jullie eh compiler top ehm hoe hoe snel gaat gaat dit dan wanneer moet ik dat eh belletje gaan rinkelen ergens dan bij die bepalen hoe het geld verdeeld wordt den Ik denk niet dat het heel snel gaat om he eerlijk te zijn Ik denk dat er gewoon eh heel veel zeg maar het verandert ook voor iedereen tegelijk weet je wel het is soort van als het is niet zo van een deel van de bevolking kan niet meer programmeren zeg maar alle programmeurs worden evenredig beïnvloed door deze systemen en en dat zie je ook met het gaat ook over onderhandeld druk dus zeg maar eh als Nou het heel exclusief alleen maar voor bepaalde programmeurs toegankelijk was en niet voor andere Dan was er echt een soort super unfair shift maar je ziet gewoon dat eh alle programmeurs worden even snel en even veel zeg maar beïnvloed Ik denk dat ik denk dat er allemaal eh redenen zijn waardoor het niet heel snel gaat en ik denk dat we altijd aan de rem kunnen trekken als het wel heel snel gaat zeg maar het is niet zo dat als het heel snel gaat dat dan in één keer er geen democratie meer is of geen mogelijkheid is om wetten te maken maken en ik spreek nu wel zeker buiten mijn domein van expertise ik ben geen eh nee Tuurlijk ik ik kan geen wetten bedenken en ik ben ook niet dus maar mij mij mijn perspectief is meer van Ik denk dat het niet heel snel gaat om dat al soort soort van boot ong wat ik zie is dat er toch nog wel zeg maar telkens weer nieuwe hurdles zijn en dat we telkens wel iets verder komen en dat is echt gaaf wat er allemaal mogelijk is maar dat er ook nog wel weer allemaal beperkingen en limieten zijn waardoor uiteindelijk dingen allemaal niet zo dat de soep niet zo heet gegeten wordt als die opgediend eh wordt en dat dat daardoor er tijd is om te reageren en wat ik wel waar ik me aan irriteer of aan stoor is dat in Europa er heel erg de tendens is om wel op de zaken vooruit te lopen en heel druk en bezig te maken om te discussiëren en te praten over Maar wat nou als er straks een mega grote ongelijkheid ontstaat omdat dan alle kapitaal houders alleen nog maar de voordelen plukken van al deze Innovatie die er is geweest op het gebied van Ai en en dus allemaal slachtoffers er zijn die allemaal door Automatisering een baan kwijt zijn zonder dat er wezenlijk heel veel interesse en poging is om het überhaupt mogelijk te maken want we zijn er gewoon nog lang niet en dat dat vind ik dat dan wel wat is dan lang Nee ik bedoel want in dat opzicht heb je de juiste tegenover je want ik ben ik ben een hele anticiperende jongen Ja we kunnen niet vroeg genoeg beginnen Rik maar ehm en volgens mij isat juist een hele leuke spanning eh tussen ons en tussen mij en wel meer mensen ehm maar want wat is dan lang hebben we Ja ik bedoel ik weet dat dat is soort koffie dik kijken maar ik heb wel het idee dat jij iets meer intuïtie hebt Op dit gebied dan ik dus dat durf ik wel aan je te vragen als ik het dan heb over de mensen die nu vooral op het niveau van Ik schrijf iedere dag regels code en eind van de dag sluit ik mijn teksteditor ga ik naar huis zeg maar hè dus die imp mensen die implementeren van andermans plannen hè Ik bedoel hè zijn hebben die over VI jaar allemaal geen baan meer Ik denk dat die over 2 jaar echt eh al geen werk meer hebben als dat maar dit is toch substantieel gast dit is toch wel een dingetje En daar mag ik nog geen plannen voor maken Zeg jij Ik vind het wel belangrijk Kijk ik zeg niet dat er nu niet over nagedacht moet worden want ik denk dat het best wel eh een urgente kwestie is voor die beroepsgroep bijvoorbeeld hè dus voor voor taxichauffeurs en voor eh zeg maar als je programmeur bent dat dat daar heel veel ehm geautomatiseerd kan gaan worden en ook weer andere beroepsgroepen Customer Support Agents is ook een eh logische soort groep die die heel veel eh beïnvloed wordt door de ontwikkeling in Ai maar doe het gewoon beide dus en heb die discussie en kijk naar wie wordt er straks slachtoffer van Hoe gaan we daarmee om en investeer en en Bouw actief mee aan die Ai technologie om daar te komen want we kunnen wel eens zijn dat denk ik in ieder geval wij maar waarschijnlijk ook wel meer mensen dat het wel netto Als het goed ingezet wordt heel waardevol kan zijn omdat uiteindelijk ook heel veel Mega goede voordelen eruit kunnen komen neem bijvoorbeeld een zelfstandig onderzoeksteam dat eh uitgebreid onderzoek kan doen naar Nice ziektes Dus je hebt zeg maar ziektes die hele kleine groepen van de populatie betreft maar ja daardoor is het moeilijk mogelijk om daar echt eh onderzoeks stappen in te zetten als je de kosten fundamenteel kan verlagen van het doen van eh wetenschappelijk onderzoek en medisch implementatieonderzoek om te kijken van welke medische ehm eh eh Technieken wer zijn effectief Dit is mij voorbeeld van Er komt een hele grote groep mensen naar een datacenter met molotovs want die zijn boos op eii en dan rijdt er iemand achteraan die zegt stop dan zeggen ze Hoezo stop als is genezen als het is genezen hoe dan ja protein folding Deep Deep fold alfold we Did It weet je en dat dat is begrijp Begrijp me niet verkeerd mijn ehm Meta angst zit er meer op dat als je dit eh iets te koud boig doet dat je juist kans hebt dat die versnelling die we willen of in ieder geval laten we zo zeggen het ondersteunen van deze Innovatie dat die tegen gewerkt gaat worden door die bijeffecten hè dus er gaat op een gegeven moment wel iets mis dan worden mensen allemaal panisch en dan mag mag jij in één keer bedoel ik kan hem ook even omdraaien snap je Dus te weinig met risico's bezig zijn is ook Z Welkom op het wereldtoneel dan kunnen we dat in Europa allemaal moorden brand doen maar dan zegt China Nou we gaan toch lekker door en Amerika Nou we gaan toch lekker door dus Ik denk dat ehm dat die realiteit dat eh dat je zeg maar mensen hebt die vragen om ga op de rem en dat dat lukt dat dat weinig kans van slagen heeft mondiaal gezien en dan word je dus slachtoffer dat en dat zie je ook in de wapenwedloop om Ai tussen de grootmachten is dat je dan natuurlijk gewoon dat dat cirkeltje krijgt van oké als wij nu op de rem gaan omdat dat verstandiger is omdat daar onze onze populatie onze maatschappij vraagt daarom dus dan gaan we daar op reageren want is democratie dat je daarmee jezelf buitens spel zet en dat je in É keer onderdanig aan groot mag den wat mij wat mij betreft is het niet eh remmen maar eh de tijd steken in eh anticiperend voorbereiden op en wat jouw eh klacht net was eigenlijk dat je zei ik vind het wel moeilijk dat er nu al zoveel nagedacht wordt over dingen terwijl we nog niet eens die iets hebben gemaakt maar het gaat allemaal over gradaties en verhouding dus ik denk dat ik denk dat er heel veel aandacht en heel veel interesse en heel veel tijd en energie is in Europa rossom Modo in het deel beperken begrijpen voorkomen eh opvangen van de de de mensen die er slachtoffer door zijn en heel weinig echte bijdragen op de schaal die nodig is dus de miljarden kostende datacenters eh de onderzoekers die hieraan willen werken in de gelegenheid stellen om dat te doen Door daar heel actief in te investeren en dat is ook de private sectors dus dus dat betekent ook dat de kapitaal moet gaan naar bedrijven zoals Mistral ehm en en dat is allemaal heel weinig ten opzichte van wat er op de wereld in Ja je zegt eigenlijk als we nou eens de tijd en het geld en de energie die we stoppen in het uitzoeken hoee het ons kan gaan vermoorden op zijn minst ook zouden stoppen in het ontwikkelen ervan hoe ironisch dat ook klinkt want ik bedoel ik niet Dit is gewoon zo dat jij zegt Volgens mij is één van die risico's voor is er in investeren wat er misschien een beetje paradoxaal voelt maar ik begrijp jou wel ook omdat je dan ook een stoel eh hebt eh op het wereldtoneel van de partijen die die technologie beheren Dus we weten niet of de de innovatieve ideeën die uit die laps komen die het niet open sourcen uiteindelijk tot een groot Gat Leiden Maar daar hadden we net een soort speculatieve discussie over van gaat dat heel erg open source veel erg pri worden Dat weten we niet maar als je dus wil garanderen dat je die technologie kunt controleren kunt beheren dan moet je in ieder geval zelf die technologie ook ontwikkelen moet je laboratorium in de buurt zijn ja en en in ieder geval als je kijkt naar chips zeg maar je hebt het dit is natuurlijk eigenlijk een een een een soort tweede golf van de chip revolutie of de chipindustrie Dus je hebt natuurlijk Nederland heeft daar een wezenlijk eh wezenlijke pionnen met ASML die wordt ook gebruikt in die hele geopolitieke discussies over mag ASML wel of niet leveren aan China en ik denk dat dit hetzelfde zeg maar je had het op de telecommunicatie dus 5G G 4G al die mobiele communicatietechnologieën eh chip productietechnologieën van onder andere lithografie machines van ASML en en de stappen die daarna in het proces komen dus chip design als je nu met kunstmatige intelligentie daar dat niet doet actief dan kom je gewoon in een situatie dat je afhankelijk bent net als dat nu die discussie is vind ik een hele goede Bert huber eh die eh die die die zegt dat vaak dat de Nederlandse overheid zichzelf afhankelijk heeft gemaakt van Amerikaanse technologie zoals Office 365 om daardoor je je soevereiniteit eh aantast sdn in Amerika ja bijvoorbeeld en en dat is zeg denk ik als je als je als je belangrijk vindt deze thema's dus het is eigenlijk helemaal niet zo paradoxaal dat als je dus al die al die bezwaren hebt en al die implicaties wil onderzoeken en dan zo zo zo goed mogelijk wil laten landen dat je ook heel agressief erin moet investeren dat voor mij is dat heel logisch om dat te combineren maar ja dat dat ja dat is wel een een een ehm een heftig spel om dat te combineren want het is is heel duur en het is Het vereist heel veel inspanning En je moet je moet dan echt veel risico nemen en dat dat echte extreme lef hebben en risico nemen en kapitaal investeren zonder dat je echt zeker weet of het allemaal gaat lukken dat vinden ze in Europa over gemiddeld genomen toch lastiger dan ja omdat we risico meiden zijn daarin Maar goed tegelijkertijd Deze krijg ik ook heel vaak naar mij toe gegooid hè als ik dan even de embody of Risk of person ben en die probeert dit allemaal in juiste dingen te leiden dat ik dat ze zeggen Ja volgens mij Probeer jij met Jouw voorzichtigheid en onderzoek en Laten we even goed kijken eh wat er allemaal gebeurt en hoe we het kunnen eh kaderen op een manier dat er zo min mogelijk slachtoffers vallen door deze technologie dat er ook mensen zijn die zeggen ja die dat remmende effect daarvan hè Ook al wil ik dus niet op een rem drukken heeft al dat soort van voorzichtig doen een remmende eh remmend effect dat zeggen daardoor worden technologieën die mogelijk leidden kunnen voorkomen ook minder snel uitgevonden dus als jouw doel was om Leiden te voorkomen ben je eigenlijk Leiden aan het creëren doordat je het wil voorkomen dat is natuurlijk een hele ja je moet het holistisch zien en als je dus als als natie of als als als continent eh achter gaat lopen bij andere partijen dat dat heeft natuurlijk een prijskaartje dus als je dan bijvoorbeeld ook een militair achterstand krijgt want deze technologie omdat het zo algemeen is raakt niet alleen maar Transport of taxi's of werkgelegenheid in de zakelijke dienstverlening en de White Color banen zeg maar maar ook Defensie dan heeft dat een prijskaartje Maar ook bijvoorbeeld het niet uitvinden van een veel eh bijvoorbeeld zelfs klimaatverandering Er wordt bijvoorbeeld onderzoek gedaan naar eh soort van Terra terraforming hè dus dat je iets doet om dat klimaatprobleem op te lossen doordat je ingrijpt als het ware op op bijna Ja dus op planeet niveau om te zorgen dat die klimaatverandering eh beperkt wordt of in ieder geval de effecten ervan en eh als de uitvindingen die daarvoor gedaan worden kunnen komen van de wisselwerking tussen briljante geesten en heel capabele Ai systemen dan ben je als het ware door Niet agressief die Ai systemen na te jagen ben je eigenlijk zoals je al zei zelf bij aan het bijdragen aan het leed en de consequenties omdat je niet hard genoeg zoekt naar de oplossing en ik vind rut ge Bregman wel een leuk bruggetje hier eigenlijk zijn boek van morele ambitie heb ik gelezen Ik vind het een goed boek en eh hij zegt dus ook van Ja je kunt dus wel principieel zijn op je strepen staan maar in morele ambitie is het punt eigenlijk dat je zegt je moet ehm ambitieus een eh een probleem wat je aangaat najagen om een oplossing ervoor te vinden want Uiteindelijk moet je niet Denk ik Zegt hij dus parafraseer dan eh je heel erg bekommeren om of jij op individueel niveau ietsje meer of ietsje minder bijdraagt je moet kijken naar de totaalsom van het probleem waar je omgeeft en eh dat probleem oplossen zeg maar op een kwantificeerbaar manier dus bijvoorbeeld dat ziektes geaderd worden of dat je klimaat verandering eh kan kan reduceren Dat is toch uiteindelijk Je doel weet je wel Je wilt toch niet je gelijk halen je wilt zorgen dat de wereld er er er beter uit gaat zien Volgens de morele waarde die je zelf hebt en dan denk ik ga dan a bouwen want dan kan je daar dichterbij komen bij al die bij al die dingen dus meer gelijkheid eh eh veiligere woningen meer woningen meer eh minder klimaatproblematiek zeg maar uiteindelijk en ik bedoel ja nu Nu heb je echt de technocraat de utopist de ik ben wel Believer Ik laat je even lekker praten hoor Ik vind het wel mooi Nee ik bedoel ik wil alleen maar ik ik bedoel de het wat het wat het een Wicked Problem maakt dit hele ding is natuurlijk dat op het moment dat je Ai bouwt dat dan ook de CO2 uitstoot weer omhoog gaat waardoor je eerder nog met je Ai moet komen die het weer gaat oplossen waardoor jeij nog meer Zap je van op een gegeven moment ga je een soort van op zichzelf voedende systemen krijgen ook qua geopolitiek Je noemt het Je noemde het wapenwedloop al hè Ik bedoel als jij zegt ja je buurman bouwt een hogere schutting dan moet jij ook een hogere schutting bouwen op een gegeven moment heb je schuttingen van 80 me hoog in de straat en heb je ergens het ding is wel dat die nucleaire bommen als dat de oorspronkelijke koude koude oorlog wapenwedloop daar was natuurlijk het voordeel van meer bommen hebben niet aanwezig maar het voordeel van meer eh intelligentie en en Systemen die meer kunnen dat dat daar zit niet zo'n beperking op dus ik denk dat die wapenwedloop eh goed is ik denk wel omdat ik dus denk dat de a systemen mee ontwikkeld worden die voor heel veel positieve dingen ingezet kunnen worden net als dat computertechnologie eh delen van de wereld mogelijk maakt ziekenhuizen zonder computers bedenk eens wat voor chaos en inefficiëntie dat z zijn veel minder mensen geholpen elektriciteit dus dus technologie dat dat zeg maar dingen beter maakt is denk ik geen discussiepunt Maar je bent Ik ben het ook wel met je eens met dat een wicker probleem is omdat je wel moet kijken naar de risico's van wat je doet wat ik al zei je moet risico durven nemen Maar er zitten dus ook risico's aan kapitaalvernietiging is ook weer dat je kapitaal allert aan iets anders Dus je neemt dan misschien de kapitaal wat je allert aan Ai van iets anders weg dus je moet wel gewoon bij de les blijven en blijven kijken van is dit nog zinnig is dit nog Logisch is is het zinnig om als we nu een datacenter hebben van eh 100.000 gpu's waar xcr mee begonn en nu heeft opgeschaald naar 200.000 gpu's moeten we dan de stap zetten naar 400.000 gpu's en op deze manier blijven Doors schalen of moeten we even eh een pass te plaats en nadenken van kunnen we de technologie niet anders doen zodat we met deze 200.000 gpu gewoon iets nuttigs kunnen doen in plaats van maar gewoon blijven verdubbelen gast volgens mij zitten we al best wel lang te praten nu en dat is niet erg maar eh we zitten zwaar over de tijd van een gemiddelde aflevering dus ik hoor Alexander een beetje in mijn nek van gast hou het nou even binnen een uur Dat gaat All lang niet meer lukken maar eh 3 uur is ook zo gek ehm ik ja wat wat mij betreft praten we op een ander moment verder hè niet binnen een paar weken maar over een tijdje als je dat leuk vindt eh want er is nog genoeg te bespreken ik ben wel nieuwsgierig van als er mensen zijn die zeggen van Oké dit klonk echt vet Waar kan ik Rick verder volgen Wat kunnen ze dan doen eh ja ik ik ben dus vooral gewoon eh druk aan het werk Ik ben eh niet altijd eh publiekelijk dingen aan het schrijven maar ik heb wel een nieuwsbrief die heet coding with Intelligence punc en eh dat is eh daar schrijf ik gewoon eigenlijk over een beetje op technisch niveau van Wat wordt er allemaal uitgebracht dus papers gup code projecten grote nieuws aankondigingen eh een beetje datet je die die categorie dus als mensen dat boeiend vinden kunnen ze dat checken en ik zit op eh x formally known as Twitter of Twitter hoe mensen het noemen maar daar eh is mijn voor achternaam Rick Lamers met C CK eh dus daar zit ik ook op vet man Dankjewel voor al je tijd en al Ja ik moet het ook nog even processen allemaal ehm ja we we gaan elkaar nog spreken dat dat denk ik wel Le thanks man en dan deze aflevering van eh Ai reporter op Ik ben er bijna een beetje verdrietig van ik sluit hem wel even netjes af natuurlijk nog dank aan Sam hengeveld voor de edit dank aan pankra voor de vormgeving dank aan dept ook voor het mogelijk maken van deze podcast als je vandaag nog wil beginnen met Ai binnen jouw bedrijf ga dan zeker even naar deptagency comomo en als je nou een lezing wil over Ai van wis of Alexander dat kan nog steeds Mail ze op lasing airport en Nou ja nog één ding hè dat hoort er ook nog bij want als je nou op de hoogte wil blijven van het laatste Ai nieuws en twee keer per week tips en tools wil ontvangen of om hoe je het meeste uit Ai kan halen Ja abonneer je dan op de nieuwsbrief via Airport en dan kun je dus ook meedoen aan de webinar de of het webinar Ik zou zeggen het jij weet het niet hè nee ik zie jou schudden De linkjes in ieder geval naar alles wat ik net heb opgenoemd zijn ook te vinden in de show notes jullie komen er wel uit dankt voor het luisteren Do to [Muziek] [Applaus] [Muziek]

---

## Notes


## Key Takeaways
-

## Related
-
