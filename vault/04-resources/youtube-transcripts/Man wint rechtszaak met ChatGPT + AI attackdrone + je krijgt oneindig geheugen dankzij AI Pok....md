# Man wint rechtszaak met ChatGPT + AI attackdrone + je krijgt oneindig geheugen dankzij AI | ✨ Pok...

**Source:** [YouTube](https://www.youtube.com/watch?v=qklxbDDDdBo)
**Video ID:** qklxbDDDdBo
**Tags:** #youtube #transcript #ai-report

---

## Transcript

ben jij van plan om dit jaar te starten met beleggen of ben je er al mee bezig en zoek je een porti inspiratie Wij zijn eh Jasper en Twan twee dood gemon ma compleet verschillende beleggers en iedere donderdag vertellen wij in onze podcast de lange termijn over onze beleggingsrecht staat met een whiskey erbij lekker dus luister eens naar onze podcast de lange termijn Welkom bij poki de Nederlandse podcast over kunstmatige intelligentie waar we uitzoeken welke invloed gaat hebben op ons werk ons leven en de samenleving tegenover mij zit Wiets Hagen Goedemiddag goed middag fietsen in het nieuws in Amerika was er iemand zo slim om zijn huurcontract eens door chpt te halen en wat bleek de huisbaas deed iets wat helemaal niet mocht conclusie de rechter Wees deze persoon $1000 schadevergoeding toe we he we hebben het erover Amazon lanceert het huismerk onder de taalmodule helemaal op de achtergrond en wij analyseren het er is een Europese Ai start-up die bekend heeft gemaakt dat ze Ai Attack drones Ai Attack drones hebben vliegen in Oekraïne en ze maken nu bekend dat andere landen die ook kunnen kopen gezellig Misschien is het voor jou iets en we hebben het de hele tijd over steeds grotere trainingsdata voor taalmodule geheugen voor jezelf maar zelfs ook de mogelijkheid dat je het geheugen van andere mensen kunt gaan raadplegen wat dat betekent doet onze hoofd toolen dat en meer bij poki Veel [Muziek] plezier Ik was vorige week voor een lezing bij eh een grote verzekeraar en die eh vertelde wat ze allemaal met eh met Ai Agents doen Dat vond ik toch vet Ik kom zelfde bedrijven tegen die ik praat veel over Ai maar dat is meestal bedrijven die niet heel veel zelf doen met Ai en dit was een bedrijf die dat duidelijk wel deed en die hadden allemaal Agents die hele delen van dat schadeproces eh met Agents oplossen dus dat dan op een formulier eh een datum gematcht moet worden met de geboortedatum bedrijf bewijs bijvoorbeeld is dan een agent die op de achtergrond draait en zo zijn er tallozen en als al die Agents groen vinkje geven dan zeggen ze de schade kan uitbetaald worden en dat kan dan op termijn zelfs binnen een paar seconden maar dat is dan ook nog een een groepje van Dus er moet een soort consensus zijn tussen die Agents precies Grappig hè Ja ik moet zeggen dat het mij ook wel opvalt dat er best wel wat Ai Squad teams en dat soort eh teams binnen bedrijven zijn het onderwerp wordt wel serieus genomen laat ik het zo zeggen hè Dat is op de ene plek wat meer dan de andere plek Maar er is die urgentie Ik deed mijn lezingen anderhal jaar geleden heel erg over urgentie dat woord kan er eigenlijk een beetje uit inmiddels merk Ja dat is er wel maar die eh dat dat valt me ook op dat het op dat in die kant van het bedrijfsproces is want dit is dan de kern van de verzekeraar is natuurlijk verzekeringen uitbetalen en ehm ik had verwacht dat ze als bedrijven zeggen we doen heel veel met Ai dan heb ik heb ik altijd het idee dat een beetje een soort van Klarna effect namelijk dat marketing en sales eh en klantenservice eh heel heel erg maar grotendeels geautomatiseerd worden maar dat is niet de kern van het bedrijfsproces natuurlijk en dat bij karna ook niet het geval en ik zag ik zag zo'n artikel dat zei als karna nou heel goed zou zijn in Ai toepassen in de kern van hun bedrijf namelijk gewoon eenen lening Boer zijn dan hadden ze dat van de daken geschreeuwd en dat doen ze niet in plaats daarvan hebben ze het alleen maar over marketing dingen marketing assets maken en klantenservice optimaliseren met botjes Ja content genereren Ja dus dat is niet de kern van het bedrijf zeg maar dus maar zou het niet zo kunnen zijn dat ehm iets meer cynisch maar dat wat Agents genoemd wordt eigenlijk algoritmen zijn maar dan met een nieuw jasje Ik bedoel eh ik kan me ook voorstellen dat er werd al grote analyse gedaan op grote datasets op basis van eh verschillende eisen en daar draaide dan een algoritme op Ja dat dat die algoritmes nu gbrand zijn naar Agents Nou het kom dit dit klonk wel serieus ja nee dit was niet dat Nee nee ik ga er niet te veel over zeggen Nee snap ik maar eh eh we gaan naar het nieuws eh ik denk het grootste nieuws eh deze week was eh in de Verenigde Staten waar een huurder een met succes een rechtszaak heeft gewonnen tegen zijn huisbaas met behulp van CH bti als juridisch adviseur hier beginnen we even mee Wiets Dit is een verhuurder die onrechtmatig hoge borg van meer dan €100 had geëist terwijl de maandelijkse huur €100 eh bedroeg wat deze slimme man had gedaan deze huurder is het huurcontract in chpt vraag eh zeg zetten en dan vragen Help mij hierbij dat was best wel brede vraag toen kwam dat ding met een eh artikel uit een lokale wet eh in die buurt eh die in 2019 is gekomen die wet die zat in de trainingsdata die zat in de trainingsdata en daarmee identificeerde die eh ja eh die fout want je mag namelijk maar É één maand huur vragen in die eh in die regio en dat had deze verhuurder dus niet gedaan dus de rechtbank kende uiteindelijk de huurder 80 toe Wieten en daar stond een enorme eh threat over op Reddit en daar gingen mensen zeggen Ja je moet dit kan je doen werkt best wel goed maar je moet niet helemaal vertrouwen op chat ipt Nou oké en wat ze erbij de is wel een handige tips en je moet gewoon naar Advocaten gaan die je per uur betaalt eh en dan doe je gewoon ehm dan Dan vraag je ze van tevoren met expliciet verzoek ik wil één uur van jou kopen en dan ga je gewoon alles wat je met jpt hebt voorbereid ga je dan aan die advocaat vertellen en vertellen wat klopt hier niet ja je komt beslagen ten ij ja je komt echt beslagen te ijs en je zegt gewoon ik ga 1 uur van een advocaat afnemen en toen dacht ik denk ja het is grappig ik ik kan me best voorstellen dat dit ik wi lat ook bezwaar maken tegen iets in mijn buurt en dan dan hoor je hoeveel uur een advocaat denkt nodig te gaan hebben daarvoor dan denk je Ja dag eh dan heb ik dus ook de neiging om dat helemaal voor te bereiden en dan te laten checken door een advocaat Ik denk dat hier een model in zit Ja je hoort eigenlijk Het is een combinatie van een een voorbereiding samen met Ai en dan de opdracht Time boxen ja ja ja je hebt een uur n grappig toch Ja en me dat is het echte nieuws van deze week eh heeft een eigen familie van taalmodule eenvoudig model tot een groot en krachtig model en eh dat gaat dan over tekst en dan zijn er daarnaast ook nog twee media modellen en je de Nova Canvas voor het creëren van afbeeldingen en Nova Real voor het maken van kort video's ehm het indrukwekkendste model van deze allemaal het het krachtigste taalmodule hoeveelheden dat verwerken tot wel 25.000 woorden of 30 minuten video in één keer ja het maffe is Ik had een beetje zitten te zoeken want dit was dan wel best nieuws want het is een grote partij diepe investering Amazon is vaak wel eh goed die hebben genoeg kennis en hardware om iets bruts neer te zetten Ik kreeg een beetje De Eerste reacties op wat dan eh mogelijk zou moeten zijn een soort Amazon Basic idee namelijk dat Amazon vaak doet is de producten die zeer populair zijn Bluetooth speakers noem maar wat daar ga dan ook een Amazon Basics versie van uitbrengen want huismerk spel ja dan snoepen ze van twee walletjes natuurlijk en als iemand statistieken heeft op wat de consument wil is het Amazon zelf dus je gaan gewoon Producten maken die ze zien dat ze groot worden of al groot zijn Het voelde het grapje was een beetje is niet mijn grapje maar dat het een beetje de Amazon Basics van van hetal model zo vet geweest als ze dit gewoon hadden gedaan Amazon Basics Amazon Basic 1 ja ja ja B1 en dan statistieken voor Basic ik zou zou zouden mijn hart gewonnen hebben maar oké is niet gebeurd Nee en wat opviel dat er geen audio is want je zei net in één regel tekst beeld en video maar er is dus geen audio dat is best een dingetje want ja Whisper is één van de beste mooiste toepassingen die open eii ook nog vrijgegeven heeft zelf zelfs Maar goed ik kan me ook wel voorstellen dat de eerste versie hiervan Ik bedoel het feit dat ze de Cirkel rond hebben gekregen dat ze het uitrollen Het is allemaal binnen bedrock beschikbaar hè dus amazon's Azure zeg maar daar kan je straks gewoon zeggen joh eh ik wil niet eh zoveel tokens betalen aan open en jij Doe mij maar die Amazon Basics versie eh voor de helft want dit is een prijsvechter Ja want dit is natuurlijk ding mensen gebruiken AWS om hun eh hun eh software op te hosten en dan is het idee dat je bij AWS heel makkelijk kan zeggen Nou ex als het Dit kost dan doe maar Amazon Basic want nu gebruik je Cloud En is het een dropdown die je verandert en dan heb je K want Amazon heeft geen openi maar die heeft wel een deal met entropic eh en dan zitten in die dropdown straks ook hun eigen taal model dat is gewoon slim voor minder ja ja ja ehm Wat ze ook zeggen is dat ze minder afhankelijk proberen te worden van Nvidia eh eh door eigen chips te maken dat hebben ze ook aangekondigd dat ze eigen chips eh maken en dat onder andere entropic die chips deze specifieke chips Vorige week hadden het al even over ook echt gaat gebruiken ehm en ze zeggen dat Apple heeft eh Apple heeft dus nu die kwam er kwam ook een Dude van Apple van Apple in kwam het podium op tijdens een AWS keynotes Dat is toch altijd opvallend moment mensen van Apple komen niet opdagen op je feestje Hier is een deal gesloten op de achtergrond Nou laat zich natuurlijk raden wat voor deal dat is dat weten we natuurlijk niet Maar ja er zijn allemaal schimmige deeltjes op de achtergrond of schimmig nou ja het zijn allemaal deeltjes op de achtergrond zoals dat Apple tv plus ook in Amazon Prime video is gekomen dus weet je dit soort handj klap zal wel gegaan zijn op achter Misschien krijg ze gewoon korting en het idee is dat ehm Ze denken dat ze 50 kunnen besparen met hun eigen chips en Nvidia zegt de CEO van Amazon zal waarschijnlijk nog lang dominant blijven met 99 van de workload maar hij hoopt dat Amazon trum Train chips een goede niche kunnen veroveren voor specifieke toepassingen de omzet uit Ai diensten groeit volgens AVS met meer dan 100 proc per jaar en de financial Times constateerde dat dit de eh strijd is die Amazon op dit moment aangaat met vooral Microsoft Ja wat ik me dan nog kan voorstellen is dat eigenlijk omdat we het al even over Apple hadden eh wat Apple gedaan heeft met hun eigen chips hè wat een ar chip is met allemaal Apple magie eromheen de m series en de a series in de iPhones is is dat eigenlijk de programmeertaal Swift die ze het liefst hebben dat jij gebruikt als ontwikkelaar dat Swift is ontwikkeld met die chip in gedachten en die chip ontwikkeld is met Swift in gedachte dat ik me ook kan voorstellen dat deze modellen van Amazon ontwikkeld worden met de chip in gedachte en de chips worden gemaakt in eh met het model in gedachte klinkt toch niet zo Basic dan toch niet zo Basic hm Er Is Een Europees Ai bedrijf dat het Helsing Ik weet niet of jij weet wat zij maken Nee ze maken Attack drones gezellig Misschien ken ik ze daarom niet Ja die eh maken onder andere de hx2 eh die wordt al een tijdje ingezet in het geheim in Oekraïne maar ze hebben hem nu onthuld voor het grote publiek Dit is een Ai gestuurde drone en die kan tot 100 km vliegen en doelen identificeren en Volgen Zonder een GPS signaal of een dataverbinding en dat is belangrijk want we weten dat het Russische de Russen eh van die jammers heeft waardoor ze eh storingen veroorzaken waardoor GPS bijvoorbeeld niet werkt waardoor het heel lastig is voor ehm eh voor drones om te vliegen Je moet dus of beeldherkenning doen van wat er op de grond gebeurt bijvoorbeeld of iets anders naar de stellen kijken of naar de sterren kijken om te kijken iets van een patroon ergens ja eh het bedrijf claimt tienduizenden van deze drones per jaar te kunnen produceren dat is belangrijk want je wil ze in swarms laten vliegen tegen lagere kosten dan bestaande systemen onder meer door het gebruik van 3d printing hier nog een optimistische nood bij weets ik blijf even neutraal Oké het is tenslotte Er is een in het nieuws een Research paper uitgekomen die jou op viel Witsen eh met de belofte dat ze eh een taalmodule ja als mijn vriendin luistert als ik op mijn telefoon zit ik Ik speel geen pn packman Ik ben dit artikel aan het lezen deze podcast Ja de wiet Zegt Sorry dat is ja ja ehm wat er gebeurt is eh in de olie ik maak even een sprongetje Heb je zoiets als synaptic pruning nou pruning is eigenlijk bijknippen zoals je een bonz boompje kan bijknippen zie je even iemand staan die met een klein Schaartje dat bonz boompje aan het pren is en synapsen zijn eigenlijk de verbindingen in jouw brein tussen neuronen en synaptic pruning is eigenlijk wat jouw lijf jouw wezen sowieso al doet dingen die niet gebruikt worden op de lange termijn worden weg gepro die knik je gewoon weg jouw brein en eh dat Zorgt er dus ook voor zeker naarmate je ouder wordt dat je wat je niet gebruikt dat verdwijnt en wat je gebruikt dat blijft Oké eh dus dan is het bijvoorbeeld handig om op een weet ik nog wel vroeger gingen mensen op een Nintendo DS heb je een spelletje speciaal voor oudere mensen om hun eh wiskunde op op eh niveau te blauwen Ja dat is heel is de Japanse Ja ja heel cute met Japans Professor Ik weet precies wat je bedoelt Oké en dat is dan een beetje gebaseerd op dat idee van synaptic pruning want wat je niet gebruikt dat verlies je nou dat synaptic pruning kan je ook doen binnen taalmodule zijn geen menselijke breinen Maar er zitten wel heel veel ideeën in die ook een beetje overeen komen met ons brein nou wat kan je dan doen is eigenlijk zo'n model pakken een Benchmark draaien en dan heb je de baseline hè dus dat noemen ze dan een Benchmark van het volledige model pre pre pruning en dan ga je stukjes weghalen en dan ga je iedere keer die Benchmark weer draaien en zolang die Benchmark niet teveel daalt blijf je wegknippen totdat je een groot gat ziet en dan plaats je dat weer terug en als je dan heel veel van die Runs gaat doen dan kan je natuurlijk op een gegeven moment achterkomen wel onderdelen van dat model eigenlijk niet per se nodig zijn om ieder geval op die specifieke Benchmark hè Je moet natuurlijk een Suite aan benchmarks doen Want anders heb je straks een model wat alleen maar goed is in die Benchmark zijn verder niks meer dan maar je moet meerdere benchmarks en dan kan je dus heel veel weghalen Hoeveel kan je dan wegknippen ongeveer de ongeveer de helft hè Dit gaat even voor de voor de kenners onder ons om het Lama 3.1 model van Meta de 8 biljoen versie en dan terugknippen naar de helft en dan scoort hij 1.6 minder op die Benchmark wau Dat is helemaal niet zo spannend Dat is dit is eigenlijk daarom wilde ik hem ook even in pok benoemen een gigantische sprong Ja en ik moet zeggen dat ik zelf eh eh geloof dat eh die taalmoeilijkheden hadden we volgens mij eh chat gpt 2 jaar geleden ze zijn ze waren volgens mij vorige week jarig hebben het niet gevierd cute ja ehm maar goed daarvoor en daarvoor dan gpt 2 en de rest het is allemaal nog hartstikke Jong zelfs in internet tijd ehm dat betekent dat het eigenlijk nog heel veel laaghangend fruit is van hoe je dit kan optimaliseren hè want dan draai het nu op gpu's die eigenlijk bedoeld zijn voor computergames Daar kan je specifieke chips voor maken Ehm je kunt eh kijken naar wat die modellen eigenlijk allemaal in zich hebben wat je nog weg kan knippen Dat zijn ze nu en je bent [&nbsp;__&nbsp;] veel energie in het verbruiken en kan dat efficiënter doen Ik denk dat iedereen wel interesseert dat die bedrijven er minder energie h Dus als jij die modellen kunt halveren in hun grootte Heb je de helft praktisch van de ram vram nodig om die modellen in te laden nou op datacenter schaal is de helft gigantisch daar zouden ze al eh champagne poppen voor 5 PR om eerlijk te zijn dus 50p is gestoord ehm en nu is natuurlijk de vraag eh als het model van Meta en dat is een serieuze partij in dit spel eigenlijk nog modellen aan het uitbrengen is die je voor de helft kan weg prenen en met met schade van 1.6 PR Wat zegt het dan over de andere Frontier Models hè zijn ze in open Ai ook zover is zijn die mini modellen eigenlijk pred Models hè het is een beetje de vraag eh of deze optimalisaties bij een entropic en open eigenlijk al gedaan zijn en Meta heeft het gewoon niet gedaan of is hier met dit onderzoek eigenlijk een enorme stap gemaakt om nog veel meer zaken aan taal modellen te optimaliseren En wat zijn de nadelen van optimaliseren op op een mandje van van benchmarks want ik kan me voorstellen dat in voor gewoon gebruik er dan opeens ehm je je wil het nadeel ervan ondervind dat je gewoon merkt dit ding is echt veel minder goed dan hiervoor kan niet helemaal plaatsen maar ik merk het gewoon Ja wat we nu al wel was hebben hè als er weer een nieuwe Mini of een turbo ofzo uitkomt dat je denkt het is hem niet helemaal meer man precies Ja precies dat ding dat die modellen minder goed worden bij bijvoorbeeld programmeren hoor je dat heel snel als mensen dat vermoeden nou in essentie Ik bedoel ik heb ook al reacties gelezen mensen zeid is dit niet eigenlijk normaal wat Fine Tunen is hè want bij Fine tuning ga je zeggen ik wil dat je op deze taak getuned wordt om specifiek die taak goed te kunnen hè dus wordt heel goed in wiskunde en dat je geen poëzie meer kan schrijven s hè Je hebt nu van die coder modellen Gak wordt je daar ook kleiner van van F Nou dat was het dus tot nu toe niet per se dus dat is het interessante dat ik denk dat als je een Fine tune en een prune doet dat je dan misschien bijvoorbeeld een heel klein programmeermodus prima ehm ik denk dat eh het gevaar is een beetje taalmonument kind op taak B en een baby op taak c waardoor ze vaak ook overschat worden dus de harmonie in eh de kwaliteit van het model was al grappig een grappig ding om te constateren dat je dus heel goed kan zijn in programmeren maar heel slecht kan zijn in sinterklaasgedichten Ja en die disharmonie dat disharmonisch profiel is eigenlijk een term uit de psychologie wat bij mensen kan gebeuren is dat bijvoorbeeld een kind in een klas verbaal heel sterk is maar eigenlijk niet zo goed een een een werkstukje kan maken en dat is voor een docent goed om te weten want anders overschat je die leerling en die leerling komt dan onder stress te staan Ik ben zelf ook redelijk disharmonisch Ik schrijf liever ook niet maar goed die dus ik herken mezelf wel een beetje in die taalen dat ik wel snap hoe het kan zijn om Es mc2 als Alfred dook Quak uit te kunnen leggen Maar tegelijkertijd niet het aantal letters in het woord strawberry te kunnen tellen inmiddels wel maar goed ehm de vraag is inderdaad Wordt dat niet bij dat pruno nou nog veel erger als het straks alleen maar ja dit draait te gek op deze 20 benchmarks maar die lobotomy zeg maar hè Dat verwijderen van stukjes brein heeft er wel voor gezorgd dat eh die sinterklaasgedichten in PR precies maar het is tegelijkertijd ook een hele leuke manier eh ja leuk zolang het niet mensen zijn maar talm modellen waar je stukjes uitknipt eh om erachter te komen waar de magie dan zit hè bij entropic bijvoorbeeld hebben ze een heel mooi blog over geschreven Die proberen erachter te komen waar de sanfrancisco Bridge zit of hoe heet de Golden Gate Bridge daar hebben we het wel eens over gehad een half jaar geleden dat zij gingen zoeken in dat taalmodule dat er allemaal dingen op gingen lichten op plekken die weinig met een brug te maken hadden maar blijkbaar wel met een brug te maken hadden want als ze die uitzetten hè dus een soort van temporary pruning dan kon die ineens veel minder goed vertellen over de over de Golden Gate Bridge dus waar ik naartoe wil is Hoe kan dat dan het woord brug staat er dan niet letterlijk in Nee want die taal modellen zijn in essentie gewichten oftewel getallen eh bij elkaar verzameld in statistiek die die LG er dan op bedoel je Ja maar het kan dus zo zijn omdat het best wel eh net als ons brein een proces is van optimalisatie en compressie dat die Gold Gate Bridge ook deels opgeslagen zit in een eend Ik zeg nu even I heel sus maar je snapt een beetje waar ik naartoe wil dat dat voor dat ding Logisch is maar eh ja voor ons heel moeilijk ja omdat hij eigenlijk een soort metaforen gebruikte hè dus je zou kunnen zeggen net als de appel valt niet ver van de boom lijkt een zoon op zijn vader dat dat taal model denkt oh die twee patronen kan ik prima opslaan als een appel en een boom Ook al gaat het over een jongen en en zijn zoon zijn vader en zijn zoon en dat dat soort metaforische eh manier van nadenken over de realiteit dat dat ook gevangen wordt in die taal modellen omdat het patroon modellen zijn en niet feiten modellen hè Daarom hebben we nu ook dat knopje gekregen dat je een web search kan laten doen voor feiten hè Welk weer is het ehm maar voor patronen is die ontzettend sterk alleen de vraag is dan als jij een Benchmark doet die specifieke dingen aanraakt maar andere dingen niet en dan op basis van die Benchmark alles gaat wegknippen heb je dus kans dat je iets heel moois hebt weggeknipt Omdat je niet begreep omdat je Benchmark dat niet testen waar het voor was nou pok is inmiddels de best beluisterde podcast over Ai van Nederland ondanks dit eh ja hoe moet je dit zeggen Het was wel weer eh ja sorry lekker toegankelijk allemaal Ik neem jullie als luisteraar erg serieus Ja precies en dat eh dat eh vinden jullie duidelijk leuk en dat doet ons heel erg goed dat zoveel geluisterd wordt en dat heeft een grappig bijverschijnsel want dat betekent dat we aanvragen krijgen van adverteerders ehm maar we willen voor volgend jaar iets nieuws proberen en dat is niet heel veel adverteerders langs laten komen maar één partner te kiezen een exclusieve hoofdsponsor van de show en pok dat weten we uit de reacties die mensen ons sturen wordt wordt geluisterd door basen van allerlei bedrijven die verzekeraar bijvoorbeeld waar ik bij sprak ehm die kwam via die luistert de podcast maar allerlei beslissingsmacht laten en dan praten wij verder goed straks gaan wij het hebben over notebook lms product manager Dat klinkt een beetje raar maar die heeft een soort van ode geschreven aan het context Window iets en daar wil ik het graag met je over hebben mijn eerste tip van de week die haalde ik uit eh de Ai report van deze week een stukje over World Labs een bedrijfje dat je in staat stelt om een willekeurige foto te uploaden en er dan Ja het is niet fysiek erin te stappen Maar je kan in de foto komen om er doorheen te wandelen dus het is een model dat gewone foto's omtovert tot 3D werelden waarin je met je toetsenbord kunt of met je muis door je om je heen kijken met toetsenbord bewegen zeg maar zoals in de game doorheen kunt lopen eh en dat werkt gewoon in je browser Je kan ook allerlei camera Trucks toepassen eh waardoor het realistischer lijkt zoals eh scherp de diepte-effect in foto's toevoegen waarbij alleen objecten die op een bepaalde afstand eh in beeld zijn scherp zijn of je kan spelen met verschillende belichtingen special effects allemaal in real time het is allemaal nog niet perfect maar wel eh veel belovend dingetjes werken nog niet zoals je kan niet eindeloos door gegenereerde werelden verdwalen op een gegeven moment loop je tegen onzichtbare muren aan maar dat mag allemaal de pret niet drukken want het is natuurlijk een heel vet idee dat je een foto Nou ja laat het een herinnering zijn die je hebt gehad om daar doorheen te klikken zeg maar nee wat ik ziek vond is die eh schilderij van Van Goch en dat je dan om kan draaien ja dan ga je achter je kijken Dat is heel gek en ik bedoel en wat daar dan achter gebeurt want er zitten een paar mooie Van Goch demo's bij is best wel plausibel dat was niet dat het is geen realiteit maar ik vind het een eh hele knappe Bluf Nou het is grappig Ook omdat die als je als jij aan eh weet ik veel mid Journey zou vragen hier is een plaatje Hoe ziet het aan de achterkant van de camera eruit dan krijg je gewoon een ander plaatje en dan is die magie weg want het zijn twee losse plaatjes die geen maar het feit dat je hem zelf kan besturen en dan die camera om kan draaien dat maakt opeens dat het Magisch voelt Nou dit bedrijf eh heeft grootste plannen ze hebben 230 miljoen aan investeringen opgehaald het bedrijf wordt gewaardeerd op een miljard want zo gaat dat tegenwoordig en ze mikken zich vooral professionele gebruikers van gamemakers tot filmstudio's want nu maken die bedrijven Ja die geven heel veel geld uit aan het ontwikkelen van die virtuele werelden en die ontwikkeld tijd kunnen ze potentieel hiermee besparen dat is idee om erin te investeren en dat gaat met hun technologie hopen zij eh drastisch veranderen Dat is een tip Ja zeker En dan nog los van het feit even voor de fantasie van de luisteraar dat je ook meer informatie gaat geven want nu geef je eigenlijk het beginpunt en hallucineert de rest er maar bij en dan kan je rondlopen dat is al super spectaculair maar wat als je zou weten Waarvan hch die dat schilderij gemaakt heeft in die straat als het een specifieke plek is om vervolgens daar foto's te maken dat eraan te en dan een beetje context mee te geven en te zeggen joh analyse nou isens fantaseer nou eens de boel erbij met een beetje input dat is voor mij betreft een volgende hele gave stap Misschien heb je wel 10 foto's gemaakt zelf op vakantie stitch je even aan elkaar Ja ik ben zo benieuwd hoe dit Hoe vakantiefoto's eruit gaan zien over 2 jaar Maar goed misschien overschat ik dit misschien gaat het toch minder snel dan eerste killer app voor The Vision Pro eindelijk Ja ja nou ja dit was de Ai report van eh van eh afgelopen dinsdag We sturen hem twee keer per week als je dat nou wil krijgen dan kun je gaan naar airport dan krijg je twee keer week dus het nieuws over eh Ai in je mailbox goed het [Muziek] hoofdonderwerp Ik las een fantastisch artikel van Steven Johnson Dat is een auteur van eh eh van boeken en die werkt dus inmiddels bij Google Dat is een vreemde overstap want eh Ja meestal ga je bij Google werken als je weet ik veel programmeur bent of eh sales medewerk om adwords te verkopen stel ik me zo voor maar dit is dus een auteur die eh aan boord gehaald werd omdat hij al heel lang publiceert over twee second Brain achtige toepassingen dus het idee dat je slimmer met je eh geheugen kunt omgaan Als schrijver eh Z de hele tijd bezig om na te denken over wat voor goede tools er zijn om beter te schrijven Dus het is iemand die niet alleen schrijft maar ook heel erg met het proces van schrijven bezig is Ja en dat viel blijkbaar op bij Google die hebben een baan aangeboden en dat is eh de Hij is dus van geestelijk vader van notebook LM geworden en notebook LM hebben we het vaker over gehad een tool waarbij je eh allerlei documenten erin kan gooien zoals pdf's en YouTube video's eh eindeloze tekstbestanden en eigenlijk met een heel groot maximum die heeft een heel groot geheugen wat hij kan raadplegen en eh dan kan hij dingen vinden die hij eh zoekt en dan geeft hij daar de eh voetnoten bij dus het is niet een ding wat heel erg gaat filosoferen en creatief gaat na nadenken en je vraagt dat ding en dan geeft hij daar feitelijk hand Ja het is echt een soort Research Assistant precies en dat is fijn want voor sommige dingen wil je creativiteit hebben en dan kun je clot gebruiken en soms wil je gewoon dat [&nbsp;__&nbsp;] klopt en dan is dus notebook LM fantastisch Ja en het spreekt heel erg tot de verbeelding ehm sinds de de audio overview feature Waarbij die soort van podcast genereert tussen twee Amerikaanse hosts die praten over de artikelen die je hebt aangezet Nou dat allemaal ter context Hij heeft nu een verhaal geschreven ehm over Ik zal het linken in de show notes eh ik Z Raad het zeker aan om het te lezen maar het is niet nodig om eh om om eh om dit stuk te gaan luisteren nu waar ik nu over wil hebben want hij heeft bijna een soort van Ja het is niet een literair stukje maar het is een heel mooi geschreven stuk over Ai Waarbij die metaforen gebruikt die eh die het heel erg tastbaar maken wat op dit moment gebeurt in ontwikkeling van eh Hij vertelt bijvoorbeeld over een jongetje wat in de jaren 0 meen ik van zijn fiets valt en daarmee eh nou ja een zware hersenschudding eh oplevert en die daarna nog wel een lange termijngeheugen heeft maar zijn korte termijngeheugen is weg dus elke keer als hij opnieuw mensen ontmoette en dat is de rest van zijn leven helaas zo gegaan dan was het alsof hij die persoon weer voor het eerst ontmoette als dat een nieuwe persoon was want als hij al in het lange termijn geheugen zat dan herkende die die persoon in ieder geval en wist hij ook van de geschiedenis was een beetje bevroren in tijd zou ik zeggen ja en het was voor wetenschapper voor wetenschappers een heel belangrijk moment Omdat zij daarvoor nog niet constateerde dat er een verschil was tussen korte termijn en lange termijn in de hersenen Dus dit heeft een Hij heeft een hele soort van eh reeks aan onderzoeken in werking gezet over over nou ja dit concept van het brein en deze step Johnson maakt dus de vergelijking van Deze gast en het korte termijn geheugen en het lange termijn geheugen met de manier waarop taalmodule termijn en een lange termijn geheugen het lange termijn geheugen is die enorme set aan trainingsdata waar wij het de hele tijd over hebben en waar we in allerlei wedl openen zijn beland van bedrijven die met elkaar aan het strijden zijn om wie eh heeft het grootste eh set aan trainingsdata en jij bent dan weer aan prenen maar het alsnog het is het lange termijngeheugen Ja waar die eh lokale waar het lokale wetsartikel uit 2019 in zat waar je het net over had die zat erin want 201 2019 is lang geleden precies eh maar je hebt ook het korte termijngeheugen en dat is het context Ja mooi mooi mooi mooi en eh Hij zegt hier is te weinig aandacht voor in de manier waarop wij in de maatschappij in de media maar ook bij technici praten over Ai ontwikkeling want het gaat de hele tijd over grotere modellen maar ondertussen hebben we het niet over het steeds groter wordende context Window en dat is super relevant want hij zegt het succes van chat gpt 2 jaar geleden en wat ik ook al vet vind dat hij het daar überhaupt over mag hebben want is een google medewerker Ik heb nog nooit een Google medewerker het wordt chat BT in de mond horen Nomen ja hij doet daton wat ik aler he cool vind van Google maar Oké chpt succes 2 jaar geleden eh hij zegt is grotendeels te danken aan dat het context Window groter werd want chpt is context Window was vier was 8.000 eh tokens Ja en dat was alweer vier keer groter dan gpt 3 wat we daarvoor nog in de Playground Ja anders past het gesprek niet anders past het gesprek niet en het feit dat het context Window groter werd maakte dus dat dat ding kon doorgaan op het wat je daarvoor had gezegd ehm en dat hij onthield wat je soort van eerder in het gesprek had gezegd waardoor het een gesprek wordt Ja want dat is ook een bepaalde verhaallijn het narratief wordt niet gebroken Dat gebeurt nog wel eens als je eruit loopt dat weten mensen maar aan het begin heb je een redelijk lange verhaallijn maar ik had ik tot dit artikel had ik niet eh had ik niet het besef dat dit zo Ik dacht dat chat PT ehm zo anders voelde omdat het de Interface had van chat dus ik dacht de reden waarom dit is doorgebroken ten opzichte van Wat mensen al eerder op een Playground een soort van zij site van open ai waar je gpt 3 de voorganger van wat we in in chat BT zijn gaan gebruiken ehm waar je al mee kon spelen dat dat zag er qua Interface veel uitdagender uit En ik dacht ze hebben het nu in een chat Interface stop en dat is nu waarom we het met zijn allen gaan gebruiken maar hij maakt een ander belangrijk onderscheid dat is nam dat vergrote context Window waardoor het voelt als een echt gesprek wat wat doorgaat zeg maar nou ja wat daarin wel interessant is als ik mag aanvullen is dat Ja zeker ehm waar ik laatst achter kwam dat wist ik niet is dat eh gpt 3,5 wat ons openbaard werd als eh chat gpt dat het wel degelijk een Fine tune was van gpt 3 om te kunnen chatten dus wat ze hadden gedaan is hem extra punten gegeven voor gesprekken die liepen als een chatgesprek hè dus wat wat je daar voelt is al wel want toen wij ermee spel speelden in Open the Labs heette dat Platform of whatever to kon je text completion doen heel saai en dan plakte hij een alinea erin en dan deden hij er nog een alinea bij en toen zaten wij allebei al wau dit kan echt brute Amazon reviews faken weet je al zo hè Maar dat was niet een chat met een input veldje als een WhatsApp en wat ik nou wat ik jou nu eigenlijk hoor zeggen is ja leuk dat ze dat model geine Tuned hadden op betere gesprekken voeren maar het is het feit dat het een gesprek was en niet een eenmalige interactie hè Ik zeg wat jij zegt wat terug punt maar een eh Train Of thought zeg maar En dat die dat er ruimte is voor die Train Of thought door het vergrote van die context Window is de eigenlijke revolutie van chat gpt Ja precies en en wat wat wat dan al al onze hoofden heeft doen Ehm ja verwonderen over over het wonder van CH PT komt dus mee Hierdoor en dit is onderschat zegt hij En eh die grotere context Windows die Leiden ook tot minder hallucinaties want op het moment dat je het korte termijngeheugen hebt om te raadplegen dan is de dat is dus wat notebook LM de hele tijd doet dat is één grote oefening in eh dingen het context Window intrekken die je zelf hebt toegevoegd als je dat de dingen in je korte termijngeheugen net zoals bij een mens zijn over het algemeen makkelijker te raadplegen en dichter bij de eh ja dichter op wat er gebeurd is en dus ook makkelijker te repliceren dan het lange termijngeheugen die hallucinaties Met andere woorden worden zitten hem in de Lange ter in het lange termijn geheugen van die Ai Ja ja omdat er daar allemaal patronen liggen opgeslagen en geen feiten dus begint ineens over een appel terwijl jij wil praten over een zoon precies en er is op een gegeven moment een soort meme geboren en eh dat werd dat werd heel mooi gevat in een artikel wat op een gegeven moment in New Yorker verscheen van iemand van een van een Staff writ van een New Yorker die eh eigenlijk de Ai van dat moment vergeleek met een soort van blurry JP mooie metafoor dus die die schreef een heel artikel over dat Ai moet je eh je dat je je moet realiseren dat als je met zo'n talmon praat dat het dat je dat je het moet zien als een als een jpeg en een jpeg is een foto met heel veel compressie potentieel en dus dat die fil kleiner wordt gemaakt dan dat hij uit de camera komt en hoe doet hij dat dat is door delen weg te laten door te bedenken wat ziet het menselijk oog niet of valt minder op voor het menselijk oog dan halen we die dingen eruit wordt die FAL kleiner en daar daardoor zie je ook dingen die niet echt zijn in die foto als je heel precies wil zijn Het is niet meer een realistische weergave van de werkelijkheid en hij maakte die metaf met hoe taalmateriaal dit is dit is ingebed inmiddels in de manier waarop wij over misschien op zich niet gek hè Ik bedoel het is een achterhaald verhaal maar ik ik ben het er wel mee eens dat het goed is om in eerste instantie te zeggen ik vertrouw het niet Het zou jammer zijn als je daardoor zegt dan gaan we het ook nooit inzetten om de huisarts te ondersteunen nooit nooit eens lang hè dus daarom wil ik hem even nuanceren Nou en en je kan het preciezer maken door onderscheid te maken tussen die grotere modellen en dat we daar steeds beter in worden en dat dat nog steeds niet ervoor zorgt dat er niet gallucci wordt en de constatering dat bij grotere context Windows het kortere termijngeheugen dat als dat kortere termijngeheugen groter en groter wordt en dat is nu aan de hand eh dat we daarmee ook dichter op de feitelijkheden kunnen blijven zeker Ik denk als ik hem mag aanvullen je zou in essentie hem over drie plekken kunnen praten Ik weet dan niet zo goed Ik denk dat je dan zou hebben het langer termijngeheugen het korte termijngeheugen en de bibliotheek waar die persoon op dat moment zit als we bij een mens houden is hoe die systemen nu werken bijvoorbeeld ook eh notebook LM is er is een taalmodule net als mp3 en jpeg het is niet het originele nummer maar ze bluffen een beetje En jij hebt to niet helemaal door en het is leuk genoeg voor muziek hè Maar het is niet een zipje als je die uitpakt komt hetzelfde boek er weer uit een zipje een zipje is eh niet lossy die is lossless ehm nou dan heb je een lossy eh lange termijn geheugen Met daarbij een eh context Window korte termijn geheugen waar je op dat moment informatie in kan stoppen en daar kan die mee aan de gang maar dat context die context Windows niet Infinite daar past niet de hele bibliotheek in daar passen Ook niet al jouw documenten in die jij in notebook Lem plakt wat Google slim doet hè We hebben het vaak over het grapje Rag Rag ragen Nou als je gaat ragen dan zegt Google wacht even voordat ik jou vraag ga beantwoorden kijk ik even naar jouw bronnenlijst dan maak ik een gok een geïnformeerde gok Welke van jouw bronnen relevant zijn voor jouw vraag dan trek ik hoofdstukken en al niet paragrafen hoofdstukken en al misschien wel het hele boek als het moet context Window in Dan ga ik die vraag beantwoorden en dan krijg jij het antwoord en dat is eigenlijk alsof je bij een professor thuis zit die zegt momentje naar zijn boekenkast loopt alle boek hoofdstukken begint te lezen die relevant zijn voor jouw vraag en dan jou plus zijn hele ervaring eh van alles eh hè dus de lange termijn ervaring training 40 jaar Professor zijn plus alle boeken die hem of haar in de kamer staan dat vlug even lezen Terwijl jij er zit supersnel lezen en dan antwoord geven Juist en dat is veel meer dan een losse jpeg dat is één van de drie in deze trifa Ja ja maar toch als ik jou goed begrijp zeg je dat ding gaat alsnog zelf constateren van alles gelezen te hebben nou hij gaat eigenlijk geïnformeerd proberen te bedenken Welke stukken die heel snel eventjes gaat lezen voordat hij antwoord geeft Op vraag maar hij leest niet alles is wat ik je hoor zeggen Exact Ja en nou dat dat is oké dat is nog zo ja en ik z zijn punt nou en ik zou willen zeggen is misschien al wel een beetje zo want ehm dus ik zal hem Ik probeer hem eh eh houdbaar te maken hoe zeg je dat dat deze metafoor niet een soort driedubbele driedimensionale super metafoor wordt Kijk die die boekenkast met die 10.000 boeken erin die niet in het context Window passen in zijn geheel die zijn wel geïndexeerd dus daar zit een database overheen Daarom duurt het ook even als je die bestanden in notebook Lem zet ik moet zeggen ze doen het supersnel maar daar worden heel snel een soort van compressie jpegs van gemaakt van die boeken in stukjes chunks noemen ze dat en die chunks die stukjes van die boeken die dat zijn eigenlijk wel een soort van eh taalmodule steld aan dat toum model laten we zeggen notebook LM en dan moet ik dus eigenlijk zeggen aan die Ensemble waar een toum model Gemini onderdeel van maakt want we praten niet meer alleen met touw modellen dan gaat hij vragen aan die ja Eigenlijk is dat conceptuele search machine die niet waar je niet alleen maar een woordje aan hoeft te geven maar een concept je aan kan geven die zegt dan Oh ik weet al Welk boek dat is hè Dus er zit een modelletje tussen die eigenlijk zegt ik weet al Welk boek dat is die gaat dan het juiste boek pakken voor Ja en dat als het context Window een beetje groot is nou Gemini heeft gigantische context Windows Gooi dat hele boek maar lekker in die promt Ja maar maar dit is de kern Wiets dat dit aan het gebeuren is klopt want je hebt het nu nog over een soort van slim dingetje wat als een soort verkeerstoren dan gaat kijken welk boek ga ik uit de bak uit de kast pakken maar hij zegt het context Window is nu 1,5 miljoen woorden 1,5 miljoen tokens dus dan dat verwar ik nu even met elkaar maar dat komt ongeveer overheen toch is oké Hoeveel zou je zeggen wat wat het daadwerkelijk aan het woorden is dat het 1,5 miljoen tokens is eh ik heb begrepen tokens is woorden keer 1.5 Ja precies Nou oké ehm op grote getallen hè dus een miljoen is 1,5 miljoen prima Ja maar een miljoen eh of eh maar er zijn eh plannen al aangekondigd voor eh een eh nieuwe versie van Gemini die 7 miljoen Ja voor jouw beeld in de discussies eh de discussies in de eh in het vakgebied eh Ai machine Learning is nu Is this the end of Rag dus is dat heb je het helemaal niet meer nodig dat dat die verkeers Gooi lekker die hele bioscoop erin want Je gooit die hele kast erin bibliotheek bedoel ik Ja Nou en dit is dus aan de hand en hij zegt wat ik nu al kan doen is weet je dit gaat over step Johnson die daadwerkelijk 14 boeken heeft geschreven Hij kan zijn 14 boeken alle artikelen die ooit heeft geschreven alle blogpost die die ooit heeft geschreven alle interviews die ooit heeft gedaan en alle onderzoeksnotitie bijgehouden voor al die media die de output waren kan hij allemaal upload en die kunnen nu al in notebook LM ja ik wil wel de opmerking erbij maken dat ik bedoel de reden dat het context Window zo klein is bij de meeste modellen en zo klein was toen ze begonnen is omdat het niet gratis is om het context Window te vergroten dus je zou je ook nog voor kunnen stellen dat is waar wij al langer op anticiperen en dat het gaat gebeuren is de €500 per maand To taal modellen hè de eh entropic eh Cloud eh Ultimate eh Master die is 500 daar kan eh 100 miljoen tokens in de Tok Window Ik roep maar wat geks maar dat soort getallen gaan in de It vaak van een terabyte ding Dat duur ga dat technis dat het gaat mij gewoon eventjes erom het is mogelijk om je hele Corpus als in je context Window me maar je bedoelt jouw hele levenswerk ja ja en hij maakt dus hij maakt hier een punt van en volgens mij is het heel belangrijk dat hier een punt van gemaakt wordt want hij zegt dus ik heb mag dan wel boeken geschreven maar heel eerlijk gezegd als ik op een boekentour ga dan weet ik heel vaak niet meer wat ik nou precies in mijn onderzoek voorbij heb zien komen en wat nou daadwerkelijk in het boek terecht gekomen want het boek is iets wat nou om het maar bij prune te houden Je begint met heel veel woorden dan wordt het minder dan wordt het een boek Ja en eh als ik op een boek Tour ga dan wil ik soms iets vertellen waarvan ik eigenlijk helemaal niet meer weet of het überhaupt in een boek staat of dat het gewoon in mijn Research voorbij is gekomen Point in case is dat hij dus dit artikel aan het schrijven was constateerde het zou lekker zijn dat ik een metafoor zou hebben tussen korte termijn en lange termijn geheugen in zijn notebook LM ging zoeken en het verhaal van dat jongetje tegen die van zijn wau viel Ja en dan doet het her dus niet toe of dat in een boek heeft gestaan van zichzelf of dat hij dat is tegengekomen als onderdeel van zijn onderzoeksnotitie het voorbij zien komen het is onderdeel geweest van zijn Research Hij heeft daar iets mee gedaan en kan dat vervolgens hergebruiken omdat dat ding kan constateren Dit is relevant wat in jouw geheugen zit en hij zegt dus eigenlijk met ehm met met een groter wordend context vinden zo krijg ik opeens ehm Mijn soort van mijn intellectuele denkwijze zo noemt hij het ehm kan die Ai eigenlijk beter reproduceren dan bijna ikzelf want ik ik was niet bij deze bij dit ding g en ik ben zelf nodig want ik ben tot conclusie gekomen dat het een leuk verhaaltje is over die jongen die die valt en natuurlijk mist die Ai de soort persoonlijke geschiedenis emotionele geschiedenis maar het is ook weer niet ondenkbaar dat je dagboek eh gaat toevoegen hieraan of dat je Ja uiteindelijk k ik ik denk natuurlijk wat wordt het moment dat je daadwerkelijk je gezichtsveld de hele tijd gaat opnemen en dat toe gaan voegen als context dat daadwerkelijk alle gesprekken die je voert kan toevoegen als aan context dat dat je echt je hele leven in het context Window past maar zelfs als we daar niet naartoe gaan dan nog kun je zeggen Oké alles wat ik doe voor werk of eh alles wat ik lees in leven Laat dan soort van daartoe is als nog enorme bron aan informatie stel je kan dat allemaal in een context Window krijgen Wat kun je dan doen en eh hij zegt eigenlijk Dit is een soort van nieuwe vorm van mens machin samenwerking waar we nog maar beginnen te begrijpen wat voor effecten dat potentieel kan hebben Ja want als ik jou nu eigenlijk zo hoor want ik begin nu een beetje door te krijgen waarom jij dit zo gaaf vindt Ja Nee ik voel hem Ik voel hem is dat laten we zeggen jouw Digital twin of jouw Digital Ghost hè Dus alles wat van jou in woord bestaat digitaal gedigitaliseerd of niet kan later ook nog dat is een aantal tokens gemiddeld hè en voor een mens die ontzettend veel leest en ontzettend veel kletst zijn dat meer tokens dan voor een gemiddeld mens maar mijn vraag is namelijk tot nu toe altijd geweest Wanneer past er een boek in de context Window toen was het Hoeveel boeken pasten er in de content Window en jij zegt nu er loopt nu een grafiekje ergens die zegt Average de token The amount of tokens of an Average researcher Ja en Wanneer past die eigenlijk in een token Window en nog even los van Ik denk namelijk dat die discussie is het een puur token Window Of is het eigenlijk ook Rag Whatever weet je als het voelt dat jij een Needle in de heag want die is wel belangrijk hè dat je een dat je een specifiek voorbeeld van een jongetje en een mooie metafoor die je ooit hebt gehoord op of zelf hebt verteld wat je niet meer weet kunt vinden hè dus niet een blurry jpeg maar feiten en misschien zelfs een quote uit een eil van jou van 17 jaar geleden dus dat is een vrij scherpe jpeg is een zipje dat je die dat jij erin past als mens met al jouw artifact en al jouw eh digitale ehm identiteit dat is wel een groot ding maar hij zeg jij jij zegt nu zoek de Needle in de htag en dat is de soort van eh de test die onderzoekers nu al heel lang gebruiken om te kijken of dat ding daadwerkelijk goed kan vinden wat jij zoekt wat verstopt is in hele grote hoeveelheden in informatie Dit is een soort test voor Ai modellen Ja maar hij zegt ik wil dat dat ding de hele [&nbsp;__&nbsp;] hashtag eh kan vinden waarmee hij bedoelt hij had een eh een boek geschreven over een ehm nou doet er verder niet toe maar hij had een soort van eh stukje geschreven eh zoals een auteur dat doet in een in een spannend boek waarbij een stukje geschreven waar die cruciale eh kennis eh onthoudt aan de lezer om het spannend te maken dus hij beschrijft een hele kleurrijke scène met iets wat je tegenkomt Wat Wat eh wat de protagonist in het verhaal tegenkomt als je een bepaalde ruimte binnenloopt en vertelt dan Heel kleurrijk over wat hij ziet en ook wat hij hoort en dan vraagt hij aan die eh aan notebook LM eh wat komt hij tegen Wat Wat is wat is de betekenis hiervan en dan eh begrijpt dat ding dus dat later in het boek wordt dan onthuld dat er een bommelding eh in het pand was en dat het geluid wat hij hoorde de tikkende klok het geluid van de bom was dat komt later wordt dat eh duidelijk en hij zegt dus dit is niet de Needle in the hashtag Dit is hij begrijpt hij begrijpt gewoon als een mens wat ik verderop heb bedoeld met deze soort van Ja het is niet een metafoor Het is een hele beeldende beschrijving van iets maar hij begrijpt het concept van dat dat later een bommelding is hij hij probeert te zeggen Dit is niet meer zoeken naar de naald Het is je je We moeten het gaan beschouwen als de hele htag en dat kunnen we gaan accepteren ne denk ik denk dat nu nu ehm hoe zeg je dat Wringen we die eh naald een beetje uit maar het idee van die idee van de Needle in htag is om te testen of de hele haack erin zit hè dus wat je doet een paar needles zoeken en dan zodat je zeker weet dat het ding Ja blauwe m&amp;ms Ja want vroeger was het zo met wat mensen zeiden moet je voorstellen als je een taalmakelaar alles in zit preci nou exact dit en hij zegt dus dit is iets wat gaat gebeuren want hij zegt dus we kunnen ons niet voorstellen waar Zeg maar hoe gaat dit als dit kan dit grote context Window en Da kan alles in zitten wat voor jou relevant is op dat moment dan kun je dus gaan nadenken over nieuwe toepassingen voor ei en hij zegt dus bijvoorbeeld als jij het hebt over die Zip of die Zip die die losl metafoor als je de hele Als jij alles kan als jij mijn notebook LM kan gebruiken waarin mijn notebook LM alle teksten staat die ik ooit niet alleen geschreven heb maar ook gelezen heb en jij kan daar toegang toe krijgen tot alles wat ik besloten heb ooit te lezen dan is dat potentieel wat waard en hij zegt dit zou best als een soort nieuwe inkomstenstroom gezien kunnen worden dat niet als vervanging van expertise maar eigenlijk de de de weg er naartoe te te kopen je je koopt Het is als de Matrix Weet je wel dat je zo kong fu kan inpluggen het is dat Z samy the Tank program Ja maar ik denk dat als ik Ik heb een leuke anekdote die komt ook bij Google vandaan zij hebben YouTube Dat is één van hun eh dingen en eh ik had een video gezien vorige week van een YouTube creator en die was heel erg boos dat vind ik altijd interessant niet omdat ik Rage Bait aan het klikken ben maar dit was gewoon iemand die boos was maar op Ai dus ik dacht nou daar moet ik even naar kijken als mensen boos aan het worden zijn op Ai dan gaat wie wel opletten nou wat heb je hebt een YouTube Creators dashboard Dus als jij YouTuber bent en je bent groot dan heb je een Creators dashboard waarop jij alle comments kunt zien eh en dat is een soort inbox voor jouw eigen YouTube kanaal anders moet je onder je eigen video's gaan scrollen op zoek naar reacties niet handig dus je hebt een unified inbox voor al jouw video tegelijk en daar komen alle reacties op binnen daar is al controverse op geweest omdat daar een influencer filter op zit Zodat je alleen de reacties krijgt van mensen met meer dan 10.000 volgers Zodat je alleen reageert op jouw mede Homies die ook cool zijn op YouTube Maar goed die feature is ook wel weer logisch want je wil niet een reactie missen van iemand met 20 miljoen volgers en die een soort van negeren Ja maar er zit een nieuwe feature in als jij in de Beta Creators program van YouTube zit dan staan er al reacties klaar de reacties staan al klaar Je hoeft alleen maar ja ja en hij is heel erg geschrokken deze jongen want dit is een jongen die maakt video's over Dungeons and Dragons die doet best wel diepe analyses van goede Dungeon and Dragons games spelen Nou dat is hele eigen eh wereld een hele subcultuur eh en die mensen daar zijn streng want Danes and Dragons is een serieus spel dat is geen grapje Ja ik meen het Ik ben ook een beetje boos Nee Ho ik heb het één keer gespeeld die ziet een reactie klaar staan die klikt erop die ziet een reactie klaar staan verrassing van hemzelf wat natuurlijk een hele vreemde ervaring is en het is een reactie waar die het mee eens is een hele goede inhoudelijke reactie waar die van dacht eigenlijk kan ik nu gewoon drukken op post maar even voor de helderheid Dat is een reactie vanuit zijn account op iemand anders video nee of een comment dus iemand Ah het is onder zijn eigen video's commenten mensen en dan de reacties op die comment die staan klaar oké gotje en die vond hij goed Ai generated draft comments een experimental feature in de YouTube Creators omgeving ja ja ja en hij zei Dit is echt een hele goede reactie en waarom was hij boos Nou omdat hij zei wa Waarom is deze reactie zo goed waar komt dit vandaan Dit is niet getraind op enkel alle reacties die ik tot nu toe heb gegeven prind op mij dit is getraind op een transcript van alles wat ik ooit heb gezegd in YouTube video's Jullie zijn een Digital twin Ja jullie hebben al een Digital twin van mij gemaakt ja ze Legt nog wel voor dat is nog wel vriendelijk dus hij mocht hem nog hij is geframed als draft dan kan je hem zelf een beetje aanvullen en hij zeg echt zo waarschijnlijk Ze hebben een Digital twin van hem gemaakt ja en hij het is een jongen die verder niet zoveel verstand Hee heeft van Ai dus die zei ja er is een model gefinetuned op mij nou ja jij en ik daar gaat deze discussie vandaag ook over weten Nee jongen jouw transcript zit in de context Window en hij zoekt de juiste video's erbij en dan pakt hij de wat we net hebben gezegd en ja eigenlijk nog best simpel ja en de makers van notebook Alm Google hebben in hun YouTube Platform ook Google een feature gemaakt die eigenlijk reacties aan het bluffen is maar aan het bluffen is op basis van een kopie van jou Ja en eh zijn discussie in die video is ook dat hij zei Wat is een goede reactie doet het er nu eigenlijk toe waarop ik eh begon na te denken Toen ik die video had gezien ik krijg best wel veel Mail jij ook allemaal lieve mensen die eh opmerkingen hebben of soms ook vragen over Ai en eh wat we in pok hebben besproken Ik vind dat best wel overweldigend soms eh dit is niet per se om mensen te ontmoedigen maar weet wel het kan even duren waarop een vriend van mij zei ha dan moet jij dan toch Ai voor inzetten Want daar heb jij het toch altijd over en toen zei ik nou dat voelt niet prettig want dan ga ik Ai antwoorden geven hm hm en toen zei hij Hoezo dat voelt niet prettig kan je dat ding niet trainen op al jouw eerdere podcast afleveringen kan je dat ding niet jouw mail een beetje laten doornemen dan een draft neerzetten voor jou en ik bedoel nu geef je eigenlijk of laat of geen antwoord en dan zou jij met je Digital twin een antwoord geven met wis approved Ja Straks wordt een daad van agressie als je die comment niet plaatst want Hoo communiceer je niet met je achterban en hij is Wiets approved hè als ik heb die draft gezien Ik vond hem Oké en ik heb hem gestuurd Nou ja en ik ik ik merkte bij mezelf ook dat ik dacht Oké dit voelt als een beetje een rare tussentijd waarin nu iedereen een beetje stigma heeft rondom Ai reactie sturen Maar ja als als die Dungeons and Dragons Go Hij zei negen van de 10 van de drafts die klaar staan is troep maar deze gaf mij de shippers Ja dit is grappig want dit is eigenlijk dit is weer een ander hoofdstuk wat je opentrekt want dit is een soort van eh Digital Twins en ehm dat is iets wat op YouTube natuurlijk dit dit voorbeeld gaat dan over dat is dan het equivalent van de YouTube to B enner maar maar je zou ook kunnen zeggen Dit geldt eigenlijk Dit geldt voor iedereen want waarschijnlijk gaat er op je werk gaat er ook een Digital twin van jou komen over een tijdje als de als Als de cultuur dit allemaal toelaat noem noem het jou copilot Ja precies Ja Nou en in dit stuk zegt hij dan dus ook die die bedrijfsbeslissingen die of hij zegt het Het gaat over een tijdje bizar zijn om niet bedrijfsbeslissingen langs soort van een reeks van Digital Twins te trekken Ja hoe jij de aflevering begon hè met de Agents bij die verzekeringsmaatschappij die consensus vinden over een bepaald onderwerp Ja ik snap je en hij zegt dus dit wordt gewoon een plek aan tafel bij bedrijven eh dat als je belangrijke beslissingen gaat nemen dat je dan eigenlijk Je hebt heel erg je best gedaan om de belangrijkste documenten van je bedrijf te cureren en die in die context Window te zetten ehm en dat kan dus heel groot zijn kan alsnog heel veel zijn maar waarvan je zegt dit is hier dit deze dit It needs to pass this test en eh dat hij zegt dus succesvolle organisaties zullen ehm niet diegene zijn met de krachtigste modellen maar met de best samengestelde context want die krachtige modellen dat is eh soort commodity maar die context die eh eh verzameld als bedrijf dat is waar de dat is waar de waarde zit nou of de dit nou Waar is of niet Het is een verschuiving van het van de aandacht en ik denk dat die eh dat die heel eh eh terecht is en en en ook echt noop tot nadenken want dit Dit zou dus kunnen betekenen dat je als bedrijf bijna een soort van eh ja professionele archivarissen moet hebben ofzo die je kennisbank helpen beter geschikt te maken voor dit soort toe voor dit soort toepassingen Het is de big data belofte van jaren geleden waargemaakt en dan Ik denk dat hè want of ik vind het eigenlijk in dat opzicht wel interessant dat we hadden het vorige week over die model eh context protocol daar zit het woord context ook in In Context Window zit dat ook Ik denk dat onze discussie ons verhaal hier vooral gaat over je hebt een blurry jpeg van het internet of van de wereld namelijk het foundational basismodel hè gpt 4o clot Noem ze allemaal maar op maar dan ga jij terwijl je die vraag stelt korte termijn meegeven maar die korte termijn dat wordt kort klinkt klein maar dat is niet zo dat kan steeds groter en hè mijn Nuance daarbij is dat ik zeg je kunt zelfs een systeempje maken een eh die die vluchten boeken erbij vindt die nodig zijn zolang niet alle boeken erin passen hè dus ik denk eigenlijk dat we met wat slimme trucs er al zijn hè Dus dit is niet eens meer een toekomstverhaal alleen eh dan is de vraag vooral eh Wat stop je in die context Window want je zou je zou kunnen zeggen ik heb hier veel discussies over met eh programmeurs dan zeg ik ja dan eh kan jullie hele code beest erin dan zeggen ze moet je niet doen man Hoezo niet daar zijn we niet per se trots op hè vriend dat is een codebase van 18 jaar oud wij willen helemaal niet dat dat ding dat gaat nadoen eh jij kan ook zeggen ik ben een schrijver Ik gooi Mijn eerste boek erin wat bedoel je het ding niet nadoen want dan gaat hij in zoal de slechte elementen ook blijven Zolang jij dat niet hebt gelabeld Je kan het labelen op datum en zeggen eh Only use code examples from recent Times hè Dan heb je al iets op Lost Maar als jij een schrijver bent ga je je middelbare school tesis erbij plakken Ik zou zeggen bijna van niet eh Of je moet uitleggen joh eh ik heb je hebt een soort recency bias maar eh ik wil alleen maar zeg dan wat hij bedoelt met dat labelen dat is dat is die kennisbank optimaliseren Ja die moet wel eh het taal op waarde geschat worden ja misschien zeg je zelfs joh er zitten hier wat eh eh data in die mag je wel gebruiken maar alleen maar eh als een historisch iets en niet gaan proberen dat na te doen maar zoals wij de laatste drie briefs geschreven hebben voor een bedrijf dat mag jij zeker nadoen hè dus ik daarin is vol mij is nu de vraag een beetje aan het worden hoe augmenter we die basismodellen die generic Models met een context Hè hoe we dat technisch ook doen doet er even niet toe een context die ervoor zorgt dat we die stap gaan maken de belofte van Ai namelijk eh dit ding is slim Nou het is zo slim als de context die jij kan meegeven ik zit ook te denken wat het betekent voor uitgevers want het we we we zeg maar we hebben kleine eh we we hebben paar keer wel gehad over dat er van die juridische start-ups zijn waarbij dan de het het het werk in een advocatenkantoor bijvoorbeeld gevat wordt in een [Muziek] taalmodule zet dat dat onderdeel is van eh ja dat dat ding daarvan leert en daar en dan dat kan repliceren bij nieuwe documenten om maar een voorbeeld te noemen ja of eh we weten van eh dat maar ik heb op een gegeven moment zo'n demonstratie gezien van Microsoft die dan zegt je kan nu hier Lexus Nexus bij aanzetten dus dat je dat dat ding opeens toegang krijgt tot echt als de Matrix toegang krijgt tot een data proprietary database die niet in de standaard lang dan En voor de luisteraars beeld wat daar op de achtergrond gebeurt want dat weet ik best wel goed Hij zoekt gewoon in die database en die record voegt hij toe aan de context Window en dan geeft hij pas antwoord ja precies ja maar dat is prima je hoeft Niet die hele database ineens in die context die gooi je erbij word niet nodig en dat laatste trucje net als die model context protocol wat we vorige week zeiden dat lijntje naar buiten naar al die databases toe Dat is nu wat ervoor gaat zorgen dat het echt interessant gaat worden ja maar ik denk dan dus ook want ik ehm voor eh ik had ik had één Ik heb dat Never split the difference dat onderhandelings Boo toegevoegd om te om te onderhandelen over iets en dan gaat hij dus keurig die principes proberen toe te passen ehm maar uiteindelijk wat ik hem zie doen is toch een soort van extractie uit Hij hij maakt een soort extractie van het boek Hij hij gaat dan zeggen Nou als je onderhandelt dan doe je dit en dit en dit en dit ehm en dan doet hij misschien één voorbeeld erbij ofzo maar het blijft best wel een beperkt prompt dus ik dacht al Ja jezus als ik dit ding n moet gaan zitten optimaliseren voor onderhandelen er zijn zeg maar als ik het gewoon se vraag onderhandel me dan is het gewoon echt bager wat er je uitkomt als ik een boek toevoeg dan maakt hij eigenlijk een veel te simpele samenvatting van dat boek waardoor nog steeds die onderhandeling echt niet zo heel veel beter gaat maar Hierdoor word ik wel aan het denken gezet dat ik dacht Ja dit is soort van alleen al dit gewoon door de lens van onderhandelen kijken en dan waarschijnlijk binnen onderhandelen zijn er weer best 1000 subcategorieën onderhandelen over keukens onderhandelen over auto's onderhandelen over bedrijven verkopen Dat er de soort van de de context Window die je erin hebt dat dat gaat bepalen hoe eh hoe goed dat ding gaat zijn dat we zoveel toepassingen nog gaan krijgen Ja ik moet zeggen dat ik ook want alles is nu nog toch een beetje cowboy wat we aan het doen zijn hè met je moet een goede prompt hebben als je slechte prompt hebt komt de crap uit hetzelfde model met een betere prompt komt er iets fantastisch uit is de grote leerl voor de meeste mensen die nu een cursus prompt engineer volgen ehm ik vraag tegenwoordig ik Vroeg laatst Hoe kan ik op een eh prettige manier eh nou Ik moest een of andere boodschap overbrengen naar iemand maar ik vond het best wel spannend en toen begon zo'n laf gemiddeld antwoord zelfs uit clat de nieuwste clad dat ik dacht oh ja zo was het voelt een beetje chat gpt van 2 jaar geleden Ik denk wat doe ik nou dus ik zei oké Je mag best wel bouwen op bestaande ideeën over hoe je communiceert met mensen Geef mij nou eens de boeken die ik aan jou toe moet voegen Ja kreeg ik een hele lijst dus ik zoek die boek op hè netjes ePub je opengebroken gekocht en opengebroken eh erin gegooid en toen zei ik nou Hier is het boek gaan we verder praten maar als je dat dus kan automatiseren hè in die modellen hè want precies wat jij zegt als als je misschien krijg je wel eh waarschijnlijk Hoe open hij een stukje van zijn geld gaat verdienen Ik wil graag het boek toevoegen ja here to instant order Ja precies €8 dan mag hij erbij precies Ik pak die aup wel ja maar voor uitgevers ook hè Wat Wat eh wat wat kranten kunnen gaan verdienen aan eh en en ook boekenuitgevers het feit dat je gewoon boeken erbij kan klikken in je kennis het wordt gewoon echt als de Matrix maar eigenlijk is het misschien als we hem aansluiten op vorige week die model control protocol model context protocol stel dat dat protokoll je dat bruggetje wordt toegevoegd en dat er ook een payment feature in dat protocol geschreven wordt geen proble me ja die dan zegt M pay Ja en dan zegt hij eh al Blend Sorry man eh gaat zegt hij joh volgens mij wil jij een boek over nonviolent Communication erbij ja ik kan die wel een uur Koch huren Ja ja dan mag die een uurtje erbij in de context Window en hebben zij een uitgev dealtje en dan kan je hem huren voor 10 cent God krijgen we toch weer contact of krijgen we toch weer micr payments mijn leven zal rond zijn Ik hoop het zal rond zijn jongen ik eh Dank u voor het luisteren mijn eh hoofd is weer eh verrijkt wio ik dank jou voor je mooie eh inbreng want dit is een interessant artikel Ik ga hem ook nog eens lezen Ja doe dat zeker Het is de moeite waard Wij danken Sam hengeveld voor de edit als je een lezing wil over van Wiets Of van mij dan kan dat mail naar lezing pooks Vergeet je niet te abonneren op de nieuwsbrief daarvoor ga je naar [Muziek] Hey hallo man man man hier met iets leuks de komende vrijdagen hoor je namelijk niet onze podcast zoals je die gewend bent maar je hoort iets nieuws man man man de warme winterweken vanuit ons eigen café achter de Koekkoek in Utrecht bespreken we het afgelopen jaar met bijzondere gasten als Sofie Milzink en Stijn van Vliet Ja en heb je nou geen podium maar wil je dit wel luisteren Dat snap ik ga dan nu snel naar podium.nl manmanman en claim jou 60 dagen gratis luisteren dan hoor je ons vanaf 6 december met de warme winterweken [Applaus] [Muziek]

---

## Notes


## Key Takeaways
-

## Related
-
