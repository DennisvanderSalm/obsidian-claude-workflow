# Anthropic scheurt ruggen van duizenden boeken af + AI-chatbots infiltreren WhatsApp + robotica dr...

**Source:** [YouTube](https://www.youtube.com/watch?v=GOLYoJllq_s)
**Video ID:** GOLYoJllq_s
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie, waar we uitzoeken welke invloed AI heeft op ons werk, ons leven en de samenleving. Anthropic, het AI bedrijf, scheurde letterlijk de ruggen van duizenden boeken, scende ze in, stopte ze in hun AI modellen en Amerikaanse rechter zegt: "Dat is prima, ga je gang." Deze week vonden er twee baanbrekende uitspraken plaats die bepalen hoe AI mag leren van menselijke kennis. En terwijl de rechtsspraak worstelt met deze nieuwe realiteit, infiltreren AI chatbots ondertussen stilletjes WhatsApp met hun 3 miljard potentiële gebruikers. En in de recruiting wereld voeren AI sollicitanten en AI recruitters een absurde wapenwedloop waarbij AI kandidaten screent. Terwijl sollicitanten AI gebruiken om die testen te verslaan. Misschien zegt dit allemaal wel iets over deze tijd. Machines leren van machines en de regels worden geschreven terwijl het spel al begonnen is. We gaan je bijpraten. Welkom bij AI Report. [Muziek] Beetje over tw weken is alweer de laatste webinar voor de zomervakantie. donderdag 10 juli als mensen daarbij willen zijn op ons vaste lunchmoment tussen 12 en 1. Eh Wiets en ik zitten klaar met bammetjes en om jullie vragen te beantwoorden. Eh als je daarbij wil zijn dan ga je naar airport. Wees daarbij. Dat is heel erg leuk eigenlijk elke keer. Ik ben elke keer tot nu toe is het erg gezellig. Ja. En verbaasd over de leuke vragen die mensen stellen. Dan kunnen ze up voten. Dus de community bepaalt welke vragen wij beantwoorden en eh dat is gewoon heel erg leuk. Wil je erbij zijn, ga dan naar AI report. En neem een abonnement. Goed Wits, we duiken het nieuws in, want er is heel veel gebeurd deze week. Ehm laten we beginnen bij alle copyright rechtszaken die nu gevoerd worden. Want er zijn drie rechtspraak eh rechtszaken deze week. Althans twee uitspraken en één nieuwe rechtszaak. Microsoft wordt aangeklaagd door een aantal schrijvers. Eh Anthopic is eh en eh en Meta zijn voor het hekje gesleept. En daar heeft de rechter daadwerkelijk een uitspraak gedaan. En dat zijn als ik het goed begrijp vrij positieve uitspraken voor die AI bedrijven. Dit gaat allemaal om het trainen van AI modellen op boeken. Dat is een groot eh ding die AI bedrijven gebruiken allemaal. boeken om hun modellen te trainen. En de vraag is een beetje hoe legaal dat is. Eh dat is ook niet helemaal helemaal helder nog of dat nou allemaal mag. Wat Anthropic dus deed ook om die juridische ja vaagheid te ja om om te om om te gebruiken wat ze waarvan de waarvan de rechtspraak nog niet helemaal duidelijk is. Hebben zij dus fysieke boeken gekocht in Tropic. Daar hebben ze de ruggen vanafgescheurd. pagina's losgesneden en vervolgens alles gescand om een digitale bibliotheek te maken voor AI training. En dat doet zo'n bedrijf natuurlijk niet als denken dat dat niet zou moeten, want het is natuurlijk veel makkelijker om gewoon epubs epups te kopen op Amazon. Maar het feit dat ze daar door al deze eh moeilijkheden zijn gegaan ehm ja eh onderstreep dat ze daar dus dachten dat ze daar juridisch mee weg zouden kunnen komen. En het nieuws is dus dat ook daadwerkelijk lukt. Eh dat de rechter de rechter in de zaak tegen Antropic heeft geoordeeld dat het inderdaad oké is om boeken te kopen eh en dan vervolgens daarmee modellen te trainen. De rechter vergleek de klacht van een aantal auteurs van boeken met eh klagen dat het leren schrijven aan schoolkinderen zou leiden tot een explosie van concurrerende werken. Ehm en eh die rechter zei het auteursrecht, zo stelt hij, is bedoeld om originele werken te stimuleren, niet om auteurs tegen concurrentie te beschermen. Ehm tegelijkertijd vind vond rechter ook dat het eh massaal downloaden van illegale boeken uit illegale bronnen zoals Lipgen is zo'n database met allemaal eh ja een soort nepster voor boeken. Dat vond Rechter in de zaak van Antropic niet oké. Maar nu is er ook een uitspraak geweest en hou ik op hoor ook een uitspraak geweest over meta en daarbij heeft de rechter gezegd dat dat wel oké is. Eh maar dat kwam dan voornamelijk omdat de schrijvers zo'n slechte rechtszaak gevoerd hebben. En wat de rechter in die zaak ook deed was eigenlijk zeggen: "Jongens, dit was eh dit het is niet dat Meta nu eh eindeloos illegale boeken mag gebruiken voor het trainen van haar airmodellen." Eh maar eh de tegenpartij maakte zulke slechte argumenten of de klagende partij maakt zulke slechte eh zulke slechte argumentatie. De volgende keer en hij gaf toen je gratis juridisch advies. De volgende keer kun je beter zorgen dat je gaat pleiten voor het concept van market dus. Het argument dat AI de markt overspoelt met eindeloze hoeveelheden content. En dat dus eigenlijk schrijvers in een slechtere economische positie terechtkomen als de markt helemaal overspoeld wordt door allerlei AI slop. En dan hebben ze wel een punt. Lang verhaal kort. AI bedrijven mogen eh trainen op content als die content op een juiste manier verkregen is. Dus dat is wel interessant. Dat betekent dus dat eh het makkelijker is geworden om eh een content te acquireren door het gewoon te kopen, maar dat het niet zo simpel is als illegale boeken databases downloaden. Drie rechtzaken in één week wietsen. Het laatste wordt hier niet over gezegd. Nou, ik ben heel benieuwd, want het heeft natuurlijk grote gevolgen eh voor alle toekomstige debatten rondom copyright, ieder geval in de US. Ik was wel ik had wel begrepen dat het digitaal maken van die fysieke boeken en daar een database van maken dat dat dan weer niet mocht wat heeft gedaan. Dus het was ook nog een beetje ja en z ik bedoel dus het feit dat je die boeken koopt prima. Dat je dan die boeken gebruikt om op te trainen, oké. Maar dat je dan in de tussentijd even een digitale database moet maken. Die database aanleggen was dan weer wel een probleem. Maar to goed. Dit laat volgens mij ook vooral zien dat er gewoon ehm ja, hoe zeg ik dat netjes? Het klopt volgens mij nog niet helemaal hierover nagedacht wordt. Want zeg maar als jij en ik naar de bibliotheek gaan, daar 20 jaar lang boeken gaan lezen en vervolgens zelf boeken gaan schrijven helemaal geïnspireerd op al die boeken. Daar is niet iemand op tegen. Dan ben je gewoon geïnspireerd. Maar als je een algoritme dat supersnel allemaal laat lezen en dan API keys gaat verkopen om dat algoritme in te zetten, dan zit daar toch volgens mij iets in dat je ergens waarde onttrekt. en vervolgens die waarde ontsluit en daar dan een een dollarbedrag aan hangt. Dat echt hem even zo plat sla, dan zou je zeggen daar is meer voor te zeggen dan het is hetzelfde als iemand die allemaal boeken leest en allemaal geïnspireerd raakt. Maar goed, ik ben geen jurist. Het voelt intuïtief gewoon niet helemaal kloppend nog. Nee, maar ja, en ik denk ook dat die grote tech de manier waarop die grote techbedrijven in de wedstrijd zitten is dit is een transformele technologie. Wat zitten we nou te neuzelen over copyright? Trans transformele technologie is blijkbaar ook in het Amerikaanse auteursrecht een ding waardoor er allerlei bescherming van auteursrecht opeens niet meer geldt. Want de blijkbaar is in de wet iets ingebouwd dat als de impact op de maatschappij zo groot is, dan kom je dus eigenlijk weg met ehm ja, wat wij auteursrechterenschending zouden noemen. En dat is dus iets wat eh ja, wat wat waar die bedrijven eh voor staan. Eh en ik geloof ook dat ze dat echt geloven. Kun je van alles tegenoverzetten. Dat snap ik ook wel. Maar nou ja. Nou ja, misschien zou ik zou voor mij kijk op het moment dat je bijvoorbeeld Lipjam pakt zoals Meta gedaan heeft hè, dus die grote boeken database nepser voor boeken die eh pak jij daar train jij een heel groot sterk model op en dat model geef je daarna weer weg hè. Dus je je haalt je je haalt het uit de commment zeg maar uit het park en dan doe je het in een machine en dan aan de andere kant wat er weer uitkomt zet je weer terug in het park voor iedereen om te gebruiken. Heb ik al persoonlijk een ander gevoel bij dan dat wat je hebt gepakt achter een API met een key zetten waar mensen voor moeten betalen. Daar zit voor mij volgens mij de meeste kan redelijk mee in jouw verhaal van is het niet zo'n ik bedoel wat is het doel van kennisoverdracht? Wat is het doel van van fictie? Hè, is dat doel niet ook bereikt met zulke supermooie boeken waar je tegen kan praten in essentie wat taalmodellen zijn, hè? Is dat niet Moet je dat nou een soort van irritant gaan tegenhouden door je jaren 70 of whatever wanneer dit allemaal geboren is? Copyright argument. Dus ik voel die ergens ook wel, maar het schuurt bij mij vooral het de commercialisering van andermans eh eh inhoud. Ja, geef het dan ook weer weg als je vond dat je het gratis mocht pakken. Ja. Nee, en het idee is natuurlijk dat er een incentive blijft voor makers om dingen te maken. En zonder dat eh gaat er ook echt iets kapot eh als we alleen nog maar gaan vertrouwen op die eibedrijven. En wat voor wat voor eh teksten zij gaan genereren, mocht toch niet hopen dat we naar een wereld toe gaan waar dat de enige plekken zijn waar nog informatie gegenereerd wordt. Dus nou ja, er is heel wat eh beschermen, maar het is helemaal niet zo simpel. Oké, we gaan door. Eh jij zette iets in het draaiboek iets over dat chatbots van concurrerende bedrijven van Meta nu WhatsApp Business gebruiken om toegang te krijgen tot met gebruikers. Hoe zit dat? Nou, ik ik had hier twee weken geleden een beetje overheen gelezen ergens in een Reddit thread van iemand die zei: "Mijn moeder praat alleen maar met chat GPT via WhatsApp." En ik dacht: "Oh, grappig, hoe dan?" En dan nou ja, er is ooit een WhatsApp telefoonnummer opgezet. Daar hebben wij het wel eens over gehad. Dan kan je ook naar bellen. Dat is echt zo'n plus é chat GPT, weet je wel? Dan moet je die getalletjes met je T9 knopjes op je oude toetsenbord gaan omzetten. Whatever. Er was al bellen met chat GPT. Maar als je precies datzelfde nummer toevoegt aan WhatsApp, dan komt daar gewoon een WhatsApp vriend met het logo van Open AI. Dat is allemaal opgezet door Open AI zelf. En dan kan je WhatsApp gebruiken of chat GPT gebruiken via WhatsApp. Dan denk je: "Oké, grappig, leuk bruggetje, eh boeien." Maar je kunt ook audio messages sturen, voice messages waar die gewoon op reageert. Je kunt ook foto's maken van je omgeving waar die gewoon op reageren. En ik besefte me toen eigenlijk een beetje laat dat voor Kijk ik ben als ik aan het reizen ben zie ik heel vaak dat WhatsApp op telefoons op staat. Beetje ligt er een beetje aan welk land je bent maar WhatsApp is gewoon gigantisch. Daarom heeft Meta ze ook een tijd geleden gekocht. Daar wordt veel gecommuniceerd met voice messages onderling omdat die culturen niet opgegroeid zijn in die textuele Nokia cultuur waar wij in met elkaar bezitten smsen. Die komen meteen daar in die rijke voic modus terecht. Ehm waardoor dus WhatsApp één van de meest gebruikte apps op een telefoon is. Dus in WhatsApp zijn hè als bedrijf hè dat is een beetje het argument wat je natuurlijk met die everything apps in China hebt waar alle alles in één app zit. Meta zou ook het heel gaaf vinden als wij met z'n allen de hele dag alleen maar in WhatsApp zitten, hè. Want dan zitten we in de metaverse eh punintended. Hier is het zo dat op het moment dat je, want ik heb het getest, chat GPT dus toevoegt in WhatsApp, dan gebeurt er iets met hoe je chatg beleefd. Dat merkte ik ook gewoon meteen dat ik denk: "Ah, grappig, ik vind dit eigenlijk wel chill." Ik vind namelijk de chat GPT interface wel chill. Ik hoef heel vaak helemaal niet al die dingen eromheen met welk model of WhatsApp interface vind je wel chill, bedoel je? Ja, omdat ik en ik denk dat de ehm ja, de cognitive load zeg maar, dus hoeveel energie het je kost mentaal om software te gebruiken, die is voor jou en mij kunnen we echt wel wat hebben. Wij zitten in we zitten nu in Riverside, er zitten een hoop knopjes op dit moment in beeld en ik kan het hebben terwijl ik een verhaal probeer te vertellen. Maar voor een groot deel van de planet en de mensen daarop die vinden WhatsApp al een heel heel ding zeg maar. Dat is best wel al voor hun om een smartphone te gebruiken is dat ze daar op WhatsApp kunnen gebruiken met het fontje lekker groot. Zoals mijn moeder altijd doet. Het ziet er altijd heel groot uit. Een soort kindertelefoon. Het het is dus een soort hijack dat die bedrijven Perplexity eh want die doen dat ook. Eh ja, iedereen begint nu mee te doen ook, want die die hebben natuurlijk door van daar is een soort ding te battelen. Ik wil het niet te groot maken, maar als jij eh toch even hoe hoe kan dit nou een battle zijn waar als Meta Meta Meta heeft haar eigen AI die ze best wel hard aan het pushen zijn ook in WhatsApp weet je. Ze hebben aangekondigd dat ze in Amerika eh binnenkort gaan ze ook samenvattingen doen van WhatsApp gesprekken. Dus als je in een WhatsAppgoep zit en al jouw vrienden hebben in de nacht drukke discussie gehad en jij was daar niet bij. Je wordt 's ochtends wakker en dan moet je eindeloos gaan scrollen door de duizenden notificaties, dan kan je in de Amerikaanse WhatsApp dus binnenkort eh de samenvatting krijgen. Oftewel Meta AI krijgt een steeds prominentere rol in eh in WhatsApp. En eh die dan dat is toch geen daar kun je toch niet mee concurreren als open of Perplexity zijnde. Nou, ik denk dat je eh niet moet onderschatten dat ik bedoel dat is hetzelfde als met replica en eh die andere soort partijen die een soort virtuele vrienden aanbieden. Kijk, tuurlijk zal Meta al deze diensten stuk voor stuk namaken en gaan aanbieden direct in WhatsApp op een manier waarop die diensten erzelf nooit diep in kunnen. Maar de vraag is of dat dan ook nog het enige wordt dat mensen gaan gebruiken. Doel, we leven in een wereld vol software waarin eh verschillende partijen hun diensten aanbieden. En ik ze staan 1-0 achter al die andere partijen als het om WS op WhatsApp gaat, want Meta kan ieder knopje toevoegen wat ze willen. Dat ben ik met je eens. Maar ja, laat hun maar dezelfde soort het is het Giebli afbeeldingen waar heel veel mensen zo enthousiast over werden in Jack genereren. En ik denk dat waarom ik in eerste instantie overgeslagen had en nu toch wilde benoemen omdat ik het een interessante dynamiek vind dat ik me goed kan voorstellen en ik ben benieuwd of open en jij deze cijfers of Perplexity ook gaat publiceren. Hoeveel procent van de gebruikers WhatsApp of instant messaging apps gaan gebruiken als de ingang tot AI diensten? Omdat die losse AI app zou ook een soort van fluk of history kunnen blijken achteraf, hè. Misschien is wel de hele de Meta er best wel goed voor staat, denk ik. Misschien is wel hè de social media direct messaging app omgeving, de ultieme omgeving om AI te integreren. Zeker naarmate het steeds meer een soort mens wordt. Ja, open AI is natuurlijk in heel veel rechtszaken worden zij aangesproken en dat betekent ook dat er vaak interne documentatie naar buiten komt wat altijd interessant inzicht geeft in hun interne denken wat vaak heel anders is dan hoe ze extern communiceren via woordvoerders. En ik kan me herinneren dat er een document naar buiten kwam waarin Open AI zei dat zij meta zien als hun grootste concurrent. Wat ik wat ik toen ik dat voor het eerst las dacht dat ik dat het een beetje opvallend was. Want ik zou eerder denken aan Google of zelfs aan Anthropic. Eh maar dat Open AI juist Meta als een grote concurrent ziet heeft hier waarschijnlijk iets mee te makelijk. Namelijk hun enorme distributiemacht. het feit dat zij ook een chat interface maken genaamd WhatsApp of Facebook Messenger. Het zijn geen kleine apps. En dat eigenlijk Open AI ja heeft dat een beetje nagedaan. Die user user interface eh weet je de de chat vorm is de manier waarop de chat GPT app werkt. En eh dat is een nieuwe app die mensen moesten installeren wat ze in grote getalen hebben gedaan. Maar er is toch voor de meeste mensen denk ik meer reden op een dag om WhatsApp vaker te openen dan chatpt te openen. En dus die distributiemacht die WhatsApp heeft omdat ze nouaal een app zijn die mensen 2000 keer per dag openen eh is aanzienlijk. En ehm en en dus misschien is inderdaad wel de messaging app zoals met zoveel dingen is gebeurd een eh een goede concurrent voor de standalone app. Aan de andere kant wieten, weet je, dit roepen we ook al 100 jaar over het bestellen van een Uber. Daarvan zeiden mensen ook: "Ja, die Uber app gaat verdwijnen. Want we krijgen alleen maar super app zoals in Azië, waarin één app je zowel je je je gasrekening kan betalen als je taxi kan bestellen, als je met je vrienden kan appen. It didn't happen. Het gebeur het is gewoon niet gebeurd in het Westen. Ehm dus nee, wij hebben enorme behoefte aan context en dat we daar tussen kunnen switchen en dat we weten dat daar de AI dingen gebeuren en daar de WhatsApp dingen gebeuren en daar de Uber dingen gebeuren. Daar ben ik met je eens. Daarom is het hele idee van de Super App hier nooit geland. Maar ja, laten we gewoon kijken. Ik had hem een beetje ook een soort brushed away van nou ja, dit die 3% mensen die ooit GPT gaan gebruiken via WhatsApp, het zal wel, maar ik kan me ook voorstellen dat wij over een jaar met elkaar praten en dat daar veel meer aan de hand is inmiddels in messenging apps. Ja, omdat ik nou dat is dat is vooral heeft dat het natuurlijk mee te maken in hoeverre die eh AI bedrijven als eh Open AI en Tropic ervoor gaan kiezen om en het nou ja, bij Open AI hebben we het antwoord al om AI aan te bieden als een soort synthetisch mens. Want dat wij gaan daar een soort van jij en ik gaan daar in onze gesprekken al een beetje vanuit de hele tijd. Terwijl dat is gewoon een keuze. Je kunt je AI ook op de achtergrond laten meedoen of eh alleen maar mailtjes naar iemand laten sturen in de vorm van een butler. Er zijn zoveel manieren om AI te laten uiten. Ja. om daar echt een een eh vriend of vriendin van te maken. Als je dat eenmaal doet, dan z kan ik me voorstellen dat die vriend of vriendin tussen alle andere vrienden en vriendinnen staan in messaging apps. Nou, het is ook een vraagstuk hè, want kijk als je als je het al beperkt tot eh dat dat chat interfaces de manier zijn waarop we met AI ehm interacteren, wat precies een beperkte blik is van hoe dit waarschijnlijk in de toekomst zal gaan, maar het is wel heel erg aan de hand op dit moment. gewoon vrijwel alle dingen die je doet met AI of nou plaatje genereren is of eh advies ergens over krijgen gaat in een chat interface en iedereen bouwt nu zijn eigen chat interface en ik moet bijvoorbeeld denken zelfs Albert Heijn of Cool Blue zijn bedrijven die nu in hun eigen apps chat interfaces bouwen en er gebeurt dat is natuurlijk wel grappig want zij gebruiken dezelfde API als wat je waarschijnlijk ChatBT zelf gebruikt in haar eigen app en het vraagstuk waar wil de consument zijn als ze advies willen krijgen over wat ze 's avonds willen koken of wat voor wat voor MacBook ze moeten kopen. Weet je, die bedrijven gaan ervanuit dat je dus naar coolblue.nl gaat en dan naar de weet ik veel navigeert naar één of ander poppetje in een blauwe polo en dat je daarop klikt en dat je dan een chat interface op je scherm krijgt. Ja, wat is logischer dat je dat doet op de site van Koblue of in de app van Koblue of in WhatsApp of in de app van Open AI in de chatti app. Ehm ik geloof er eerlijk gezegd wel in dat ehm dat mensen gaan praten met verschillende chatbots voor verschillende redenen. Dus dat die hele metafoor eigenlijk van eh ja, ik wil vrienden geen metafoor noemen, maar hoe WhatsApp nu werkt, namelijk dat je jouw vrienden die je kent onder elkaar staan. Het idee dat daar een Coolblue adviseur tussen staat die eens in de zoveel tijd raadpleegt als je advies nodig hebt over wat voor tv je moet kopen of elektronica of wat dan ook. Dat is niet iemand met wie je iedere week praat, maar die waarvan het best wel chill is dat hij je kan helpen en dat je weet dat hij in je WhatsApp staat. Dat lijkt mij eigenlijk logischer dan dat je een Coolblue app opent wat in feite een webwinkel app eh is die je voor dat gebruik. Ik denk dat mensen eerder naar WhatsApp zullen gaan. Dus dat de combinatie van synthetische figuren om mee te chatten en echte vrienden in je Messenger app helemaal geen gek idee is. En dat dat dus best wel ehm ja, ik als ik zou moeten gokken wat mensen chill zouden vinden, zou ik denken dat dat je dus dat je niet in de Albert Heijn app gaat vragen: "Wat moet ik vanavond koken, maar dat je dat in WhatsApp vraagt." Ik vind dat helemaal niet zo'n raar idee. Ik denk dat de vraag is natuurlijk sowieso hè wat nog een soort van onze oude manieren van doen zijn en de oude metaforen waarin we leven. Dus hè dat we dingen nou eenmaal zo gaan doen omdat we het niet anders meer kunnen ofzo. Ik bedoel zegt nooit nooit maar we zitten nou vast in Want wat jij nu over Cool Blue vind ik wel een mooi voorbeeld. Ik was laatst op zoek naar een eh beeldscherm en dan wilde ik heel graag 4K 120 Hz. Want dan heb ik een Ja zo en ik dus ik kijk zo iedere paar maanden zijn ze er al? Zijn ze er al? Nou, ze bleken er al langer te zijn dan ik. Ik was nou omdat de Daar ben ik nog niet, maar de eh veel van de smartphones, de Android gebruikers gaan nu echt lachen. Die luisteren, denken van: "Ah, zitten jullie nog op 60 fps of 60 Hz op jullie iPhones? Cute." Maar goed, heel veel smartphones zitten al lang op veel hogere verversnelheden van je scherm, waardoor het hele scherm veel Nou, ik heb dan een probleem, want als ik eenmaal één scherm in mijn leven naar dit hogere ververs Maar wat is het? Wat gebeurt er dan? Nou, normaal als jij eh bijvoorbeeld je Chrome window op je MacBook versleept, zeg maar, dan wordt er iedere 30 seconden in het opg van een MacBook 60 iedere 60 keer per seconde wordt dat beeld vervst, zeg maar. Dit is bijvoorbeeld voor computer games veel belangrijker, want als jij gaat gamen, dan vind je het prettig dat het een beetje vloeiend loopt, hè. Als het als er 10 hog refresh is vloeiender, minder schokkerig. En als jij eenmaal één één device hebt die een hele hoge refresh rate heeft in jouw leven, dan is dat een nieuwe standaard. Dan ga je erger in alle andere schermen. You got it. Oh. Oké, dus je moet Ja, dit is dit is echt niet eens een first world problem. Dit is niet eens een problem. Maar goed, ik hou dus een beetje in de gaten wanneer kan ik een soort van trifecta die hele set-up in één keer upgraden dat alles in mijn leven figuren. Maar goed. Ja. Oké. Dus dus ik zat eh op mijn een soort hele klassieke manier heel cute met meerdere tabs open op tweakers en in vergelijk websites en dingen. Had ik dat hele onderzoekje te doen. Ze had ik op een gegeven moment had ik dat gedaan. had ik het scherm gevonden wat ik wilde na 20 minuten. Ik moet eerlijk zeggen die zoektocht is bijna leuker dan het scherm hè. Dat is prima. Dus ik had dat het is heel meditatief voor jou. Ik ik begrijp het. Ja. Dus ik had dat gedaan en daarna dacht ik ben ik nou zo soort legacy bezig? Ik had natuurlijk gewoon deep research moeten doen laten doen. Da had ik namelijk andere dingen kunnen doen in de tussentijd. Nou dus ik die research alsnog aangezet en nou die kwam dus met het exact hetzelfde scherm als ik had gevonden na 10 YouTube reviews kijken noem het allemaal op. Want het moet ook werken op een Mac enzo, hè. Er zit best wel wat eisen aan dat scherm. Het moet allemaal wel kloppen. Moet opladen. Moet ook een MacBook Pro kunnen opladen. Bla bla bla bla bla bla. Je kent dit soort research wel toch? Nou, dat had hij helemaal zelfde scherm. En toen dacht ik: "Ja, nou wil ik hem dan ook wel ergens gaan bestellen." Toen ging ik weer al mijn tabjes openen om in alle verschillende webshops alles te vergelijken. Dat had ik dus weer gedaan en gevonden. Toen weer duude deep research. Ging ik weer terug. Toen vroeg ik aan Deep Research: "Kan je dat onderzoek doen?" Dat zei hij. Toen ging ik dat doen. Alleen maar drie Amerikaanse webshops met twee verkeerde schermen, zeg maar. Toen dacht ik weer oké jammer. Maar ik merkte wel ga ik nou met de Coolblue bot praten of met een bot die heet je slimme neefje of whatever die namelijk ook K Blue als bron heeft of is het gewoon ik vertrouw de algemene chat GPT dat hij ieder moment kan transformeren naar de ultieme eh zoek een scherm voor Wiets pot en bestel hem ook meteen. Ja, ik snap deze gedachte. Namelijk gaan wij een soort van overkoepelende winkelbots krijgen die je helpen. Al de consumentenbond of wirecutter of gaan we individuele winkels krijgen waar we advies vragen? En ik denk dat beide bestaan in de echte wereld. Ehm en er is nog steeds een reden om Coolblue Bots te willen raadplegen denk ik. Omdat Coolblue informatie heeft over bijvoorbeeld hoeveel artikelen er worden teruggestuurd. Dus als mensen eh een bepaald gedrag vertonen tijdens een tijdens een verkoopgesprek met zo'n bot. Ehm dit is natuurlijk in het zeg maar zonder bots ook al aan de hand, want mensen kopen op de Cool Blue site een MacBook. Nadat ze getwijfeld hebben welke maat eh beeldscherm ze moeten nemen. Dan zijn ze teleurgesteld omdat hij te groot of te klein is en niet in de tas past of weet ik veel het scherm te klein is en dan sturen ze hem terug. En Coolblue weet dat. Zij weten dat een gebruiker eerst heeft getwijfeld en toen een laptop heeft gekocht en hem toen teruggestuurd heeft en een ander eh schermgroot heeft gekurd. De optelsom van die informatie, en dit gaat niet alleen over schermgroot, maar dit gaat over alle elementen, ehm is natuurlijk heel waardevol en kan je gebruiken voor een goed voor een goede eh keuzebot, weet je. Die die informatie kan terugvloeien naar die chatbot en kan dus zeggen: "Ja, jij denkt wel dat je deze maat wil." Maar denk nog even over na, want eh andere mensen die dit eh deze eerdere antwoorden hebben gegeven dat je toch gaat nudgen naar het juiste antwoord. Want het is in beider belang. Het is ook een cool blues belang dat die laptop niet wordt teruggestuurd. Maar is het dan niet logischer om wel die eh Want deze dingen sluiten elkaar trouwens allemaal niet uit hè. De Gol Blue Bot versus de consumentenbond bot. Ik vind dat wel een mooie gaat zeker weten. Ehm het is natuurlijk niet gek dat die consumentenbond bot dan praat met de Klue bot. Dus eh snap je, sterker nog, ik kan een mooi bruggetje maken, want ja, maar dat gaat K Blue Bot denk ik niet willen. Als daar als daar verkoop uitkomt. Stom als ze zich niet in het netwerk voegen, toch? Zou ik? Ja, maar dit wordt dus de hele dit dit wordt dus het de de vraag. Waar ga je als je als webwinkelier en dit is een metafoor voor ieder ondernemer denk ik, waar ga je je autonomie eisen? Dit is dus dezelfde vraag als ga jij als Koblue je bot in WhatsApp zetten? Ja of nee. Dus ergens ook je autonomie weggeven aan meta, maar wel het gebruik maken van de distributiekracht. En dit is een keuze waar heel veel media bedrijven ook voor staan. Soort van doen we het op onze eigen site alleen maar of verspreiden we het ook via YouTube. Eh dat is een dat is dat is een duivelsdilemma, want eigenlijk wil je dat die mensen op je eigen website blijven. En met die met die dat je deze hele verandering naar praten met bedrijven ervuit gaan dat normaal gaat worden. En ik ik denk eerlijk gezegd dat dat weet je als je nu als je nu een nieuwe nieuwe zorgverzekering wil weet je aan het eind van dit jaar zullen mensen nog wel naar independer gaan, maar gaan ze dat volgend jaar ook nog steeds doen? Nou, de nu nog mooier voorbeeld van je, want in in dat opzicht dan ik denk dat het goed is in ieder geval voor de organisaties die nu op independers staan om zich af te vragen of het niet verstandig is om hun bot die ze al hebben en uiteindelijk alleen maar hè die dat worden bots die van nou ja aa whatever eh een aabot die veel meer informatie heeft dan de standaard algemene bots hè dat is jouw punt ook met de cool blue bot want er zit allemaal grounding en context achter die alleen maar binnen die organisatie aanwezig zijn waardoor dat advies gewoon veel beter kan zijn dan zo'n vanille advies dat je krijgt van een algemeen ding. Maar dan zou ik me nog steeds ik zou niet zomaar nee zeggen als independer zegt: "Oké, ORA, jullie hebben zo'n toffe helemaal gefinet Superbot gebouwd. Daar gaan wij wel mee praten op de achtergrond, zodat we uiteindelijk de consument kunnen aanspreken via independer die op de achtergrond al die verschillende botjes eh in daarmee in conclaaf gaat." En dat is dat is een bruggetje wat ik even ongeforceerd wil maken. Dat wisten we niet toen we het hierover gingen hebben. Maar er is een protocol. Weeten jullie nog dat wij het ooit over MC MCP hebben gehad? Eh en dat het inmiddels nou ja, voor heel veel luisteraars die wat technischer zijn een heel logisch verhaal is geworden. MCP's zijn een soort van ontploft. En inmiddels kan je in Antropic in de Entropic site zoals wij dat ooit hadden gehoopt integrations doen en allemaal logootjes aanklikken van andere partijen waardoor je kan praten met je documenten en je kan praten met jou. zijn een soort plugins, een soort apps binnen je AI app waardoor je in bijvoorbeeld eh chat GPT met je eh Gmail box gaat kunnen praten en eh met je agenda en dan kan vragen aan aan Gmail heb ik nog nieuwe e-mails. En dan gaat hij dat beantwoorden keurig in chat GPT. Dat zijn MCP's. Ja. En die Inmiddels hebben we een nieuw protocol daarnaast waar ik eerst van dacht: "Oké, is dit nodig? Eh kan dit niet gewoon MCP zijn?" Maar inmiddels heb ik het protocol doorgelezen en denk ik: "Nee, ik snap hem wel." Het protocol heet AA, agent to agent. Het is opgezet door Amazon, Google. Hele lijst met allemaal partijen die hier aan meewerken. Wa Microsoft, waarom is het belangrijk dat A2A bestaat? namelijk een protocol hoe agents met elkaar kunnen praten. Dus precies waar we het net over hebben. Hoe zorg je ervoor dat als jij als bedrijf een agent aanbiedt waar je misschien van verwacht dat hij alleen met mensen praat, met consumenten of klanten, dat daar ineens met jouw agent gesproken gaat worden door een andere agent, namelijk de independer agent om meten maar die metaforen even uit te breiden. Nou, wat zit er dan bijvoorbeeld in het protocol is dat de independer agent kan vragen aan de agent van ORA: "Hoi, wat kan jij allemaal? Hoe wil je dat ik jou aanspreek? Wat is de data die jij meer hebt dan ik? Hoe kan ik daar gebruik van maken? Et cetera, et cetera. Waardoor ze dus met elkaar afspraken hebben over hoe je die afspraak of hoe je elkaars eh mogelijkheden met elkaar deelt. En het is want als we dit niet doen, we als in de techneuten, dan krijgen we natuurlijk dat die agents met elkaar gaan praten en op de meest rare manieren gaan proberen uit te vinden wat ze kunnen et cetera. Nou, laten we nou gewoon ervanuit gaan dat jouw agent ook aangesproken wordt door een andere agent. Hm hm. En hier, het is wel tof, want als je dus die A2A dat kan je dan natuurlijk aangeven hè, dat jouw agent A2A support heeft en dan kan je weer in een hele lijst komen van A2A ecosystem waardoor je uiteindelijk ja, een wereld gaat krijgen waarin agents aan agents verbonden zijn en dan op een laatste punt van het hele grafiekje pas bij een mens komen. En wat kunnen we hiermee? Nou, als ontwikkelaar als je luistert je inlezen, want dit is er dit is mogelijk weer zo'n protocol waar we dan later van gaan zeggen: "Oh ja, eh logisch natuurlijk." Ik denk ehm en ik denk dat de niet ontwikkelaars eh dus product owners eh mensen die nadenken over communicatie binnen organisaties even mocht je dat nog niet gedaan hebben moeten gaan nadenken oh natuurlijk alles wat wij bouwen is natuurlijk niet alleen maar meer voor mensen. Die AI's die agent die gaan ook onze software en onze agents gebruiken. En ik dit ik leg dit vaak ook uit aan bedrijven hè dat je niet alleen maar user experience hebt maar ook experience. Namelijk als een agent op jouw website komt, kunnen ze dan kan die agent dan jouw website goed gebruiken? Geef je die agents dan een soort nou niet een backdoor, dat lijkt me een onverstandige term, maar een soort zijspoor. Klinkt beter van joh, jij moet helemaal niet rond gaan klikken op die site, joh. Kom maar hier. Jij bent van het level dat we gewoon één op één met elkaar via A2A eh kunnen praten. Dus dit is ook dat A2A is in essentie ook een manier om te stoppen met computer use en dat rare tussenstap van agency rondklikken op jouw website. Ja, dus eigenlijk wat je zegt is het is er is nu al een belang voor eh bijvoorbeeld de nou ja, wat is nou een goed voorbeeld? Nou, sowieso de de Gemini bijvoorbeeld is misschien een aardig voorbeeld. Dus je je je zoekt iets met Gemini, dan is het nu nog zo dat Google websites gaat bekijken en die eigenlijk scrap eh om antwoord te kunnen geven op je vraag. En straks gaat het zo zijn dat als Gemini dan daadwerkelijk naar een website gaat voor jou, dat ze dan niet de websites lezen zoals een mens, maar eigenlijk veel gestructureerdere informatie krijgen en ook meer kunnen opvragen dan met het blote oog zichtbaar is. En dat gaat het mogelijk maken dat je met dat je als consument met eh bots gaat praten die weer andere bots kunnen raadplegen waardoor ja, de de ervaring beter gaat worden. Precies. En het zit en voor de mensen die nu luisteren denken: "Huh, maar dat nou is het toch gewoon weer MCP? MCP is vanuit een AI praten met data op een gestructureerde manier. Aa is vanuit AI praten met een andere AI. En dan dan heb je toch wel een ander soort interactie. Namelijk ook een dynamiek van heen en weer praten, et cetera. Ja. Oké. Mijn hoofd ontploft hier een beetje van. Ik zat iets grappigs te lezen op de New York eh New York Times website. Namelijk een verhaal van een HR consulent in Utah. Eh die eh die plaatste een vaature online voor een eh remote eh baan bij een techbedrijf met maar 3 jaar ervaring vereist. Oftewel een baan waar een hoop mensen op kunnen solliciteren. Maar toch verrast de de soort van eh aanmeldingen voor die vacaturen verraste deze HRP persoon. Want binnen 24 uur waren er 600 sollicitaties binnen en uiteindelijk meer dan 1200 eh in een week. En LinkedIn ziet, zo schrijft in New York Times, het aantal sollicitaties met 45% stijgen naar gemiddeld 11.000 per minuut. En dat komt omdat mensen chatgebruiken om te solliciteren. Dus wat ze doen is ze voeren alle zoekwoorden uit eh vaatureksten ehm in hun CV eh waardoor het allemaal relevanter lijkt, je eigen ervaring. En sommigen betalen zelfs voor specifieke AI agents die zelfstandig banen zoeken en te solliciteren. Dus dat is weer de volgende stap. Dat niet is dat jij zelf naar een website gaat om daar te solliciteren, maar dat jij een agent gebruikt die voor jou relevante banen uitzoekt en dan automatisch solliciteert. Daar zijn dus al tooljes voor. Nou, dat is natuurlijk vervelend voor bedrijven, want die krijgen dan 1200 sollicitaties binnen en daar moet je dan wat mee. En op dat is op een gegeven moment ook niet meer met de hand te doen. Dus wat doen die bedrijven? die doen geautomatiseerde video interviews en sollicitaties packken met AI chatbots. En dit is dus ook al in de praktijk gebracht. Chipotle is een Amerikaans restaurant keten. Die hebben een AI chatbot die heet Ava Cado. Leuketsen. En die ja die screent kandidaten, plant gesprekken eh automatisch. Ehm en die eh heeft de verwerkingstijd met 75% teruggebracht. En wat je hier natuurlijk ziet is een soort van kat- en muisspel tussen mensen die solliciteren aan de ene kant en dan steeds uitgebreidere tooling daarvoor gebruiken en dan aan de andere kant worden die bedrijven gedwongen om ook weer hun eigen tooling te gebruiken. Ehm er zijn zelfs allerlei systemen die nu op getuigd worden waarbij eh je via als je zo'n ehm als je solliciteert bij een bedrijf dat je ehm patroonherkenning werk je je eigen geheugen eh testen, soort van tryouts eh voor emotionele intelligentie dat dat ook allemaal heel vroeg in het proces wordt gedaan. Iets wat normaal gesproken pas werd gedaan als weet je je bij de laatste drie kandidaten hoorde en dan werden ook nog even wat zware testen gedaan. Maar dat schuiven ze nu allemaal naar voren om de last bij de gebruiker te leggen, de de sollicitant te leggen. Want ja, het maakt toch niet uit. Eh het is niet dat het bedrijf meer geld eh meer tijd kost en je krijgt een ehm een betere selectie. Dus het is eh ja, een soort kat en muisspel waarbij ook nog eens kandidaten worden ja geïncentivized om vals te spelen. Want hoe meer met kattenmuis bedoel jij als j een hele zwaar als ik als mens een hele zware emotionele test krijg aan het begin door een AI afgenomen, ga ik daar natuurlijk weer tools op inzetten om die toets te halen. Juist. Ja, want dan ga je dus een een emotionele intelligentiie test krijgen waarbij hij een AI gaat gebruiken om die test te door ja te doorlopen. Want er is gewoon een gewenst eindresultaat en die AI kan dat natuurlijk nadoen. Dus het is een AI tegen AI strijd. Ehm nou, in hoeverre dit in Europa allemaal mag, eh in Europa zijn we hier vrij streng in. De AI act in Nederland classif of in Europa classificeert ehm dit soort eh dingen die gaan over werk en solliciteren als een hoog risicocategorie. En daar zijn de strengste restricties. Want wij hebben in Europa allerlei zorgen over eh discriminatie en eh dat er ehm als er geautomatiseerd geautomatiseerde processen zijn bij dit soort sollicitatieprocedures, dan zijn ze daar over het algemeen veel strenger in dan in Amerika. Maar ja, in Amerika is dat eh is dat gewoon niet zo. En ehm eh dit artikel concludeert met dit is een soort van wapenwedloop waar heel veel tijd en geld aan verspeeld gaat worden aan beide kanten. Aan de kant van de sollicitant en aan de kant van de werkgever. En uiteindelijk is de conclusie eh van het eind van de rits heel simpel. Namelijk iedereen gaat toch weer terug naar eh een mens die z die zelf moet solliciteren en een mens die zelf die zelf moet kijken of iemand geschikt is. Ja of nee. Eh dat is uiteindelijk waar het op uit gaat draaien. Maar het gaat nog even duren voordat we hierchter gaan komen. Is de conc van het Newstuck. Ik ben benieuwd of jij het daarmee eens bent. Nou, het is natuurlijk de vraag of het een remote only job is. Kijk, als jij door een AI systeem helemaal bent ondervraagd en aan de andere kant een systeem hebt neergezet dat al die vragen perfect heeft beantwoord en op maandag kom je op je werk. En je kan dat allemaal helemaal niet zeg maar dat ja, je bent helemaal niet zo sociaal als dat jouw bot was of jouw avatar, whatever. Dan heb je natuurlijk een groter probleem dan als het een remote only job is waar jij gewoon zegt: "Nou, dat ding wat ik al die tests heb laten doen gaat ook mijn werk doen." Hè, dus dat de de eh hoe digitaler en hoe abstracter jouw werk is, hè, hoe meer het gemedieerd is door informatie, hoe meer je er nog mee weg kan komen na je sollicitatie zelfs om datzelfde systeem te blijven inzetten. Maar als jij Ja. Ja, als dat echt zou is het dan bestaat die baan binnenkort niet meer. Nee, maar d dat dat is natuurlijk hetzelfde als mensen uit het onderwijs die mij vaak een soort grappuntend aanspreken van inmiddels maken de studenten alles met jpt en wij kijken het na met chpt. Zullen we die twee dingen gewoon aan elkaar koppelen en dan en dan dus gewoon uitzetten? Want dit is een soort van hè dat dat zijn grapjes. Maar dat is wel ja maar het maar weer met de hand gaan doen. Ja, precies. Z zet nou zullen we dat dat systeem daarnaast gewoon uitzetten, want het zijn inmiddels twee AI's die tegen elkaar praten. Het kost alleen maar energie. is echt zonde. We testen niks meer, hè. En dan daarna gaan we weer eh terug naar testen. Ik moet zeggen, er is best wel wat beweging wereldwijd hoor in onderwijs om naar oude toetsmethodieken te gaan of klassieke misschien moet ik ze zo noemen. Want de oude wat de toets instrumenten toetsingsinstrumenten zouden moeten doen, doen ze niet meer. En dan moet je ze dus afschaffen, want ze meten niet meer, hè. Maar goed, dat is een andere dat is weer een hele aflevering onderwijs. Straks gaan we het hebben over Google die een belangrijke aankondiging deed over hoe AI in robots kunnen gaan werken. Maar eerst een oproep van Dept aan jou als je het leuk vindt om bij ze te komen werken en van AI je dagelijkse baan wilt maken. Hi, hier Dept. Elke week bespreken we hoe wij merk helpen in de wonderenwereld van AI. Maar deze week gaan we het even hebben over onszelf of eigenlijk over jullie, onze luisteraars. Want Lucas, wij komen handen tekort. Absoluut. We zitten tot over onze oren in het AI werk. Mega leuk werk trouwens. We helpen bijvoorbeeld eBay eh om content te versnellen. Eh en we maken aanbevingsmodellen voor rituals en het helpen van een breed scala aan klanten om nog beter gevonden te worden in die wereld van AI zoekmachines. En als klap de vuurpijl bouwen we ook actief door onze eigen interne tooling om onze teams te helpen nog beter werk te leveren. Check. Dus we hebben eigenlijk mensen nodig die vandaag al willen bouwen. Ja, hou je vast. We zoeken AI consultants, AI engineers, data scientist, eh machine learning engineers en ook mensen die kunnen helpen om verder te optimaliseren. En uiteraard zoeken ze ze eigenlijk al gister. Duidelijk. Oké, dus werk jij graag aan complexe internationale projecten en wil je echt het verschil maken met AI, check dan nu onze vacatures in Nederland, Duitsland, de UK en de US. En ga zo snel mogelijk naar deagency.com/aaivacencies. Solliciter dus. Tot volgende week. [Muziek] Dan Google Deepmind kondigde deze week op X aan dat hun nieuwe Gemini robotics on device model, best een goede naam wieet zit, beschrijvend, ik ben niet van ze gewend, eh maar een belangrijke maalpaal heeft bereikt. namelijk eh best wel krachtige AI die volledig lokaal op robots draait zonder internetverbinding. Wat is de Waarom is dit relevant, Wietsen? Nou, eerste stap is om kort even uit te leggen wat een VLA is. Een vision language action model. Vision language action model. Ja, want dit dit ding, dit model dat Google heeft aangekondigd, een versie van Gemini, die kan draaien lokaal. En dat lokale betekent dan een machine die bij een computer of bij een robot kan staan of in een robot kan zitten. Ja. En wat bedoel je kan ook zeggen: "Het is lokaal, maar zo groot als een klaslokaal." Ja. Oké. Dit is ook nog compact hè, omdat het model is niet zo zwaar. Dus het kan draaien op hardware die aan een accu kan hangen en zelfs mee kan met de robot. Dat is gewoon wat een lokaal betekent in de robotica. Een vision language action model is een model specifiek gemaakt eigenlijk om beeld te kunnen binnenkrijgen, hè. Hè, want zo'n robot heeft vaak ogen. Noem ze sensoren, noem ze ogen. Die moet taal kunnen begrijpen, want iemand geeft opdrachten aan die robot wat die moet doen. En die moet acties kunnen doen, want uiteindelijk wil je ook dat er beweging gaat komen. Dus zo wil ik een robot die mijn vaatwasser inruimt. Dus die ziet mijn vaat, die hoort vision. Ja, die hoort mijn eh mijn opdracht, namelijk ra language. En die pakt die vaatwasser in. Action. Juist. Vi alle. Oké, dit is eh dit is letterlijk jouw voorbeeld is het meest gebruikte voorbeeld. Heel goed. Eh en dat zie je ook in zeg maar de paper. Dit is zo'n lekkere ja, hoe noem je dat? Vroeg werden veel eh wetenschappelijke artikelen vaak als eh klas PDF's aan ons getoond in een heel Roman fondje zeg maar, waardoor het er ook allemaal heel chiic uitzag. Altijd tegenwoordig worden veel research papers gewoon websites, want er zitten heel veel animaties in en video's en dat zijn rijkere. Dus dit is zo'n lekkere webper paper die ze hebben uitgebracht. En daar zitten dus ook allerlei voorbeeldvideotjes in van zo'n klassieke tweearmige robot 3D geprint die allemaal opdrachten gaat doen aan de hand van opdrachten die mensen geven in speech, zeg maar, in tekst. Ja, wat zie je dan? En nou bijvoorbeeld eh dit is dus dit zijn dus beetje suffen voorbeelden altijd hoor, maar blokjes op elkaar zetten, een t-shirt vouwen. Dat t-shirt vouwen is trouwens wel echt eh ja, dat is niet suf, dat vind ik zeer relevant. Dat is ook best wel moeilijk zeg maar. Ja, maar uiteindelijk komt het erop neer dat je eh die VLA modellen omdat ze dus best wel multimodaal zijn hè, ze kunnen veel dingen tegelijk begrijpen tussen airquotes zijn het hele zware grote modellen. Dus het zijn een cloud modellen dat moet hè die robot is eigenlijk een thin client. die heeft een dikke verbinding naar het datacenter. En op het moment dat er geen internet is in de fabriek of bij jou thuis, dan staat die robot dan een beetje te wachten tot er weer internet is. Dus wat je uiteindelijk wilt is ieder geval een deel van de robot lokaal hebben, hè. Dat kan je doen om privacy redenen, maar ook om eh veiligheidsredenen, hè. Het is toch lekker dat een robot niet thuis je hele huis kapot gaat schoppen omdat hij geen internet heeft, hè. Je wil een soort basic VL hebben dat hij zegt: "Oké, ik heb een VLA in de cloud, maar op het moment dat ik die cloudverbinding niet heb, val ik terug op mijn local VL en kan ik tenminste zelf naar mijn oplaadplek lopen of op de bank gaan zitten wachten tot jij thuis bent." Maar is het niet ook gewoon veel sneller? Ja, dus zeker er zijn heel veel taken waar je veel sneller moet reageren. Dus dan wil je sowieso een VL hebben die lokaal is, hè. Dus het is een latency vraagstuk, privacy vraagstuk, duurzaamheidsvraagstuk, redonantievraagstuk waarom je lokaal zou willen gaan. En he even want het is normaal gesproken is zo in de clouds in de grote modellen en wat je dan lokaal kan draaien is minder goed. En ik kan me voorstellen dat voor een robot waarbij er fijne motoriek vereist is, precieze weet je, als jij een t-shirt wil vouwen, dat is geen dat zijn geen grove bewegingen. Eh is het hun gelukt om het van een cloudmodel naar een lokaal model te krijgen met met gelijkwaardige prestaties? Is dat wat hier gebeurd is? Wat is dan het nieuws? Nou, het ja, goed. Gelijkwaardig dan heb ik in mijn hoofd meteen zitten het is hetzelfde, maar meer in de buurt, meer dan genoeg om lokaal van alles te doen. Bijvoorbeeld een tas te openen en de rits ervan open te maken, binnenin die tas te kijken, dan die rits echt wel die fijne motorieken in plaats van alleen maar blokjes stapelen waar eh waar je gewoon niet zoveel aan hebt, zeg maar. Dus eh als ik zo de grafieken een beetje doorneem zeg maar versus Gemini on Device en Gemini robotics eh op sommige punten zelfs beter tijdelijk denk ik dan Gemini robotics is wat in de cloud zit. Ja juist. Ja. En ik en ik denk waarom ehm ik dit zo'n belangrijk onderwerp vind is sowieso omdat eh ik merk dit ook vaak tijdens lezingen hè. Ik zet dan eerst even neer waar hebben we het eigenlijk vandaag over? Wat is AI? Hè, jullie hebben het waarschijnlijk over chat GPT, dus over grote taalmodellen. Maar die taalmodellen zijn inmiddels alweer multimodale modellen. Want kijk maar boven in je app, daar staat 4 van Omni. En dit doe ik even zo, dat hele intro ding. En die VL's die ik nu even hier drop, zeg maar, Vision language action models, dat is weer in die wereld van modellen een andere flavor zeg maar eh die ook kan luisteren, maar ook kan bewegen, et cetera. En dat die nu ook al lokaal gaan eh is best wel prettig, want de taalmodellen kregen we als eerst alleen in de cloud. En en nu hebben we tot de dag van vandaag een soort, nou ja, we hebben het al veel over gediscussieerd, matige lokale modellen terwijl we hier nu met een met de volgende generatie AI modellen direct ook lokaal gaan en ze zijn niet matig, ze komen in de buurt. Ja, ik las ook dat ze heel snel nieuwe vaardigheden kunnen leren die robots nadat mensen het hebben voorgedaan. Ja. Ja, dus dat is ook het gave. Je je zou kunnen zeggen de enige input die modellen hebben ehm of de sterkste input is tekst zou je kunnen zeggen, want jij geeft steeds opdrachten en dan doen ze die. Maar uiteindelijk wil je natuurlijk dat die modellen kunnen kijken naar beeld waarin iets voorgedaan wordt door een mens en dat hij daarna dat ook kan na x aantal voorbeelden. Hè, dus die eh vision language action models zijn niet statisch, die zijn niet in het steen gegrift. die zijn vloeibaar en kunnen nog doorleren. En dan kan je je voorstellen dat we niet eh bijvoorbeeld nou, laten we even zeggen in een fabriek waar je ook nog eens met allemaal chemicaliën werkt. Dus er zullen veel luisteraars zijn die zullen zeggen: "Nou, dan snap ik eigenlijk wel dat we daar helemaal geen mensen meer willen." Hè, dus dat helpt even dat ethische argument eventjes opzij te zetten. Een heel spannende plek waar je geen mensen wilt hebben, maar nu wel mensen zijn. Die zijn dopjes aan het dichtdraaien, aan knopjes aan het doen met met allemaal hele fijne motoriek. Je je zou dan kunnen zeggen die hele fabriek heeft Gemini in de cloud en dat is één Gemini model en die kan alles. Of je zegt: "Nee, alle onderdelen in die lijn hebben eigen modellen hè. Dus een vision language action model voor een specifiek deel van de productielijn waar met eh vloeibare eh onderdelen gewerkt wordt. Dat ding is supergoed als het gaat om liquids hè. Die kan heel goed voorspellen waar dat allemaal terecht komt. Maar als je die kan je niet zomaar oppakken en in een ander deel van de fabriek zetten. Een soort expert modellen zeg maar. En waar nu een beetje de als je dan leest in de in de research papers et cetera naartoe bewogen wordt, is het idee van expert VLA models die lokaal samenwerken met andere VLA models die in de robot zijn en precies zoals jij zegt daardoor ook heel snel kunnen reageren en niet allemaal met één meesterbrein praten boven in de fabriek of boven in het datacenter. Oké. Maar mij overvalt wel een beetje het gevoel van het zal wel. Oké. Het zijn dus losse losse modelletjes in plaats van één groot omnimodel. Who cares? Nou, ik denk dat ehm je kunt je voorstellen dat die w ik heb ooit wel eens eh vind ik hele prettige metafoor gelezen over vroeger werden motoren gezien als iets heel unieks. Eh zeg maar het feit dat je een motor hebt. En als toen kwam de elektromotor en toen werd al snel door een aantal futuristen geroepen: "Wacht maar, straks zit in je auto 30 motoren." En dan zei iedereen: "Doe doe normaal, want een motor is iets heel bijzonders." Dat is heel raar dat nou nu is het inmiddels al lang zo, want je raam, je achter achterklep, man, dan zitten je je aircosysteem zijn allemaal kleine elektromotoren. En ik kan me dus voorstellen dat een AI systeem, laten we zeggen zo'n VLA, dat er uiteindelijk wel 100 VLA's kunnen zijn op een plek of 200 of misschien wel meerdere VL's die met elkaar samenwerken in één robot. Ik noem maar iets geks. En ik denk ehm voor veel van de luisteraars dat AI aangesproken wordt en wordt gezien als een soort van dat is een ding out there, net als de cloud. Hm hm. Terwijl wat waar het nu in de praktijk naartoe bewogen wordt is een ensemble hè een ehm een groep vogels zeg maar die met elkaar samenwerkt. allemaal kleine lokale intelligentie die zwermen gaat vormen. En ik vind dat eh een interessante beweging om nu te zien in robotics. Ja. En je ziet dit eigenlijk ook door heel breed door AI ehm gebeuren. Want ik zag bijvoorbeeld een nieuwsbericht over dat Windows 11 eh in de in het settingspaneel om maar even aan te geven hoe specifiek AI kan worden. Dus de instellingenscherm dat er nu een AI agent door Microsoft is gemaakt met een eigen AI model om natuurlijke commando's eh bijvoorbeeld eh ik kan eh de lettertypes op mijn scherm niet lezen. Het is allemaal klein. Maak het groter. die zeg maar Rotterdamse eh taal kun je nu invoer kun je dat nu invullen in de zoekbalk en dan snapt dat ding wat je bedoelt en eh verandert het dan ook in één keer. En dat is een volledig lokaal eh model dat draait op de eh op de specifieke hardware voor dit soort AI gebaseerd op FA het het de de eigen Microsoft modellen, de kleine modellen, maar dan nog veel kleiner een tiende van de grote van de normale fine modellen met vergelijkbare prestaties. En dat is nodig omdat ze in een settingscherm waarin je een opdracht geeft als in de letters zijn klein maken het groter wil je niet ook maar een half seconde wachten. Want je bent voor dat soort eh ja instellingen op je computer gewend dat het direct werkt. En daarom hebben ze dus nu een specifiek model op die alleen maar op dit settingscherm en alleen maar op die latency, dus de snelheid waarmee die aanpassing gedaan wordt getraind, zodat die gebruiker krijgt wat ze eh verwacht. En ik dacht eigenlijk hier zie je dus in de praktijk gebeuren wat jij nu over heel heel groot met robot zegt zie je dus ook het heel erg klein gebeuren. Alle samenwerken mo Ja. En dan is het ook nog eens zo dat ik heb wel eens een onderzoeker die bij Microsoft aan F werkt horen zeggen: "Alle andere foundational labs werken omhoog hè. Dus de modellen moeten groter en sterker en wij werken naar beneden. Kleiner en specifieker. Is ook slim want bovenin daar gebeurt al genoeg. Het is duur, laten ze het maar met elkaar uitvechten. Wij gaan de andere kant opwerken, zeg maar. En ehm ik vond ook wel, want ik wat jij net zei over dat control panel, ik was het aan het lezen en wat ik wel grappig vond, als je nu naar een winkel gaat, whatever, Mediaamark, Cool, Blue, noem ze maar op, en je zegt: "Mag ik een laptop met AI zeg maar en ik zou in die winkel zijn hè, zeg maar Wiets Hagen, dan zou ik even die persoon aantikken, want zo ben ik dan zeg ik: "Joh, heb je het nou over dat knopje op je toetsenbord?" En jij en jij is niet op een laptop, weet je wel. Want ik bedoel je als erge of chrome op zit kan jij naar chatg.com. Maar dan zou nu die persoon als het een veel beter ingelichte persoon is dan ik kunnen zeggen: "Nee, dude, ik wil een laptop met een Qualcom processor waar een TPU in zit waar het mini model op kon draaien. Speciaal getuned voor die mini TPU van Qualcom, zodat ik mijn settingspanel kan aanspreken, vriend." En dan zou die gelijk hebben. En want ze hebben dus die FA ook nog eens doorgetraind op ik bedoel je krijgt nu allemaal producten. AMD heeft de AMD Ryzen 5 AI hè. Qualcom maakt de Qualcom Snapdragon AI hè. waar wij als techneuten dan van zeggen: "Jammer dat het allemaal zo gei branded wordt. Wat een onzin." Maar eigenlijk is dit rare control panel voorbeeld van Microsoft een voorbeeld waar dus daadwerkelijk de hardware die alleen in die chip van Qualcom zit een model opgetraind is wat precies heel goed kan draaien, zodat je inderdaad een zin kan zeggen ops Rotterdams en die settings panel gewoon aangepast wordt zonder cloud op een stukje hardware wat alleen in jouw laptop zit. Is wel gaaf. Ik vind het wel mooi dat we dit eh gesprek begonnen met eh kunnen al die AI bedrijven het allemaal wel maken? Die miljoenen boeken jatten en dat het dan gaat over robotica wanneer eindelijk je t-shirts gevouwen worden door een robot en je vaatwasser ingepakt worden door robot. Dat we eindigen met het settingspaneel van Windows. Ik weet niet, het heeft poëzie zich. Ja, mooi hè? Ja. En ik denk dus dat wou ik nog zeggen eh Apple heeft vier maanden geleden of zoiets een vi uitgebracht voor het erkennen wat er in beeld gebeurt, zeg maar. Dus eh ja, en dan ook daarna acties kunnen doen. En die is dus ook helemaal getuned op de Apple hardware vanaf de iPhone 15. Je kan gewoon zoeken op Apple of VLA. En dan zie je ook meer van ah grappig. Dus het wordt echt op maat on device heel krachtig omdat er ook krachtig hard in zit. Nou, wat je nu eh bijvoorbeeld eigenlijk niet wilt in mijn ogen is dat jouw hele fotolibrary door een cloud heen moet om daar dan te zien wat er op jouw foto's gebeurt. Dat is nou echt een taak om lokaal te doen. Maar ehm even van een plaatje naar tekst gaan is niet zo makkelijk zeg maar. Dus je wilt uiteindelijk eh opdrachten kunnen geven bijvoorbeeld eh verwijder deze persoon uit deze afbeelding of ehm weet je, je wil acties ondernemen aan de hand van inhoud van beelden en jouw tekst eroverheen. Dus Apple is al ook al langer via lees aan het maken vision. Want action gaat niet alleen maar over fysieke actie van servomotoren in robots. Dat kan ook gaan over het klikken op knoppen, hè. Dus action. Dus dat is nog wat breder. Of actie nemen in het settingspanel van Windows. Hm hm. Dus die VL's die gaan we nu nog even complexer maken. Moet je niet helemaal koppelen aan robotics. Moet je koppelen aan eh beeld iets doen. Ja, precies. Beeld erin en opdracht erin. Of opdracht erin en beeld erin. Dat die volgorde doet er niet toe. En daar moet dan uiteindelijk een actie uitkomen. Namelijk de vaatwasser inruimen of de brightness slider in de controlpanel naar 80% sliden. Want mijn scherm is te vel gast. Ik zit hier te verbranden. Ja. En het is wel als je daarin geïnteresseerd bent heel want ik wil die vier lees gewoon even droppen bij de luisteraars. Want dit is best wel een groot nieuw groen veld zoals ze dat zeggen op zijn Engels. Een green field van AI toepassingen die echt eh best wel stoom aan het krijgen is. Stoom aan het komen is. We blijven het voor u volgen lief luisteraar in deze podcast eh AI Report. bedanken Sam Hengeveld voor de edit, Pankra voor de wormgeving. Als je een lezing wil van Wiet Hagen, dan kan dat van mij. Zijn er is er nog plek voor lezingen voor jou? Bij mij zit het allemaal vol. Nog een beetje na de zomer. Ja, oké. Heel klein beetje. Dan kun je dus mailen naar eh lasing@ireport. En als je op de hoogte wil blijven van het laatste AI nieuws en twee keer per week tips en tools wil krijgen om het meeste uit AI te halen en dus bij onze webinar eh wilt zijn, wanneer is die ook weer iets? Heb je goed opgelet? Nee, volgende week laatst voor de zomer. J donderdag 10 juli wietsen. Neem je bentox mee. Ga daarvoor naar airport. En dan kun je wietsen alles vragen wat je wil over AI. En wil je vandaag nog beginnen met AI binnen jouw bedrijf, ga dan naar deagency.com/aai report. Ze zoeken goede mensen. Dank voor het luisteren. Dag. Doeg. [Muziek]

---

## Notes


## Key Takeaways
-

## Related
-
