# Google overweldigt met nieuwe AI + wanneer werkt er een robot bij jou thuis? | AI Report

**Source:** [YouTube](https://www.youtube.com/watch?v=UWjdPXxCbLU)
**Video ID:** UWjdPXxCbLU
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie, waar we uitzoeken welke invloed AI heeft op ons werk, ons leven en de samenleving. Vandaag duiken we in een fenomeen dat science fiction wel echt realiteit lijkt te gaan maken. Namelijk humanoid robots. Dat zijn robots die eruitzien als mensen. Niet alleen kunnen ze denken, maar dus ook veel dingen voor ons doen. Ze worden nu getest om uiteindelijk te gaan werken in fabrieken en magazijnen. Misschien ook zelfs wel in je eigen huis. En het grappige is dat je vroege versies van deze humanoids gewoon al in een webwinkel kunt bestellen. Dan komt er een kris en dan kun je zo'n ruot in je keuken neerzetten. Met andere woorden, de technologie die we kennen van ChatGBT krijgt nu armen en benen. Dat verandert een hoop. Want wat gebeurt er als diezelfde AI die nu kantoorwerk overneemt ook fysieke arbeid kan verrichten? En hoe verandert onze maatschappij als robot niet alleen maar ons denkwerk, maar ook ons handwerk overnemen. Dit is AI Report. [Muziek] [Applaus] [Muziek] [Applaus] Oh mijn god Wiets, wat was het weer een week. Ja, ik heb een eh samenvattertje laten schrijven door Gemini. Door Gemini, dat is mooi, want Google heeft onwaarschijnlijk grote aankondigingen gedaan. Daar moeten we het over hebben. We moeten het overhe codex hebben. Hun nieuwe programmeer Ja. hulp. Eh en we moeten het hebben over de samenwerking tussen Johnny Ive en Sam Oldman die samen gaan werken, de voormalige hoofddesigner bij Apple. Ik vind allemaal vrij intens. Ja, het is veel. Dus ja, ik weet niet eh waar je wil beginnen. Ja, ik denk toch wel bij Google Google e is dat het belangrijkste. Om het even verwarrend te maken, dat ding van Johnny Ive en eh Sam Altman en ook dat heet ook IO. Maar we hebben het nu even over Google IO. Ja. Nou, oké, laten we beginnen bij Google. Maar al die al die andere twee die krijg je dan zooteen van ons. We beginnen bij Google, want waar Google al nou ja, een tijdje eh hele interessante dingen doet om maar een understatement te maken, lijken ze elke keer niet de cultuur mee te hebben. Het is Open AI waar alle aandacht naartoe gaat. Zelfs Apple waar veel aandacht naartoe gaat over AI. In Google lijkt elke keert onderspit te del in hoe erover gesproken wordt. En nu leek er toch even een soort van glow-up moment te zijn. Consolidatie van jaren aan werk waarbij het nu lijkt alsof ze toch wel nou ja, ze lieten een hoop spierkracht zien. Laten we het helemaal uitpakken wat ze eh gelanceerd hebben, want het is een hoop. Allereerst het ding wat voor mij het meest tot de verbeeldings sprakietsen was hun nieuwste videomodel VO3. Ja, wat niet alleen eh ja, hele goede beeldkwaliteit video eh genereert. Echt eh nou ja eh next level 4K 60 fps. Ongelooflijk realistisch beeld, maar en dat verraste mij, ik zag dit echt niet aankomen, daarbij ook audio genereert. Dus niet alleen genereert dit dit model eh video, maar ook de bijpassende audio. En dat betekent dus geluidseffecten, omgevingsgeluid, zelfs dialogen, zelfs musicals waarbij die audio dus native meegegenereerd wordt met het beeld. Zeg er eens iets nuttigs over. Nou ja, kijk, ik ben er weer eh een beetje van van slag eh merk ik. Ik zeg het een soort van chill, maar ik bedoel ergens ja, het lag allemaal in de lijn van verwachting. Het zal allemaal wel, maar het is toch een beetje moeilijk inschatten van is dan het zorgen dat die Kijk dat ze audio konden maken los van beeld. Dat wisten we hè, want dat doen ze al heel knap in notebook en daar zit dan advanced voice mode achter. Ja. En we kennen het van Judio, van Suno, video audio generatie tools. Wist ja, we wisten eigenlijk al dat dat medium als het ware het geluidsmedium, het audio medium ook al eh eh ja, dat daar heel veel geavanceerde AI bestaat. Maar voeg voeg dat maar even samen en dat die mond goed beweegt enzo. En dan ik zat gisteren bijvoorbeeld even gewoon voor mijn gevoel. Dit raad ik echt wel mensen aan die nu luisteren. We zijn best wel jad aan het raken. Ik gebruik even dat Engelse woord maar een soort van gewend aan het raken. We zijn een beetje gewend en verwend. Nou ja, ik zit ik zit de reacties eronder te luisteren te kijken en het ging bijvoorbeeld over één van de VO3 video's. Een soort video ergens op een autobeurst die nooit gebeurt is. Maar ja, heb ik gezien. Het zijn een soort voxbopjes die alsof ze op de Amerikaanse tv zijn uitgezonden waarbij mensen ja geïnterviewd worden op een autobeurs. Inderdaad. En het bizarre is dat je ziet aan die mensen, je lijkt te zien aan deze AI gegenereerde mensen dat ze ter plekke aan het bedenken zijn wat ze gaan zeggen. Er zit een soort twij menselijke twijfel in die het zo echt maakt. Ja. En ik denk dat, kijk, voor mij de dan lees ik lees ik de reacties, dat gaat een beetje van oké, wauw, ik wist niet dat het al zo ver was tot eh oh inderdaad veel leuker met audio, wel een leuke dimensie, maar ook best wel een flinke groep. Ja, op de achtergrond staan auto's die niet echt bestaan. En ik zag ergens in de verte iemand achter iemand verdwijnen dat ik denk van really? Maar goed, wat ik mijn tip is eigenlijk om even te kijken naar de video's van Synthesia. Dat was een beetje de dienst Synthesia, hè. kan je een eh soort virtuele avatar maken in videoforaat die een verhaaltje vertelt. Als je die nu kijkt en daarna kijk je in een VO3 video, dat is gewoon echt dag en nacht. Ja, je bedoelt dat is een jaar of 2e jaar geleden en dan dit nu. Ja, zeker. En ik ik dat dat is gewoon echt een enorme sprong. En voor mij eigenlijk het me een heel suf voorbeeldje. Want nu vliegen dan je hebt allemaal vi voorbeelden van Google zelf hè, Cherry Pick, maar prima. Als ze dit eruit weten te krijgen, ook al zijn ze gekozen vind ik het nog steeds knap zeg maar. Als één op de 100 zo goed is, ben ik nog steeds impressed. Eh maar er vliegt ook het een en ander rond op op x wat van andere mensen dat zelf hebben gemaakt. En ik kwam er één tegen en dat was een video dat je iemand eigenlijk iets ziet uitleggen volgens mij ergens in eh voor een eh ehm hoe noem je zo'n dingen? Piramide ergens in de tijd van de farao's die daar met een soort van nou ja, kleedje om eh bij een steen een verhaal staat uit te leggen als een docent. staat ookon een grafiek die scherp is met termen en toen dacht dit is gewoon een een e-learning een e-learning in ook nog een soort leek als of een soort of slecht een slecht toneelstuk hè met een soort slechte props. Maar ja, dat goed in mijn hoofd en volgens mij werkt dat bij jou precies zo. Ik pauzeer dat dan echt en denk ja, maar dit kan dus helemaal dit maar dan onderwijs. Ja. En dan alle kanten op en dan inderdaad cursussen gaan maken et cetera. Ik bedoel en ik we we z we zagen hem al. De meeste mensen die die ons al een tijdje luisteren zagen hem al. Maar wat hier nu gebeurt zeg maar, dat heeft ook een beetje te maken met dat idee dat dat je lang consistent kan zijn, hè. Dus heel vaak liepen die video's zonder audio toen nog aan de eerste paar seconden ging het wel lekker, maar daarna raakte die een beetje in de draad kwijt. Dat is met Sora ook echt zo. Dat is dat is totaal random wat er de hele tijd gebeurt. Ja. Hele beetje wouze dromerige psychidelische sfeer zeg maar. En ook hier zie ik daar nog inklings van. Ja, maar de tijd dat het eh model zeg maar dat VO3 het volhoudt om iets consistents te presenteren en waarbij ja, dit is misschien al een beetje over eh of niet hoeft bijna niet meer gezegd te worden, maar de prompts zijn vaak ook AI generated prompts over scripts. scripts die AI generated zijn met audio. Het is zeg maar, ik moet nog een beetje bijkomen van het hele idee dat eigenlijk de hele set-up hè, dus niet alleen maar de beelden van de cursus cursus, de slides die getoond worden in die ear-learning, maar het hele script van de e-learning zelf ook allemaal AI generated is, zeg maar. Het is in de breedste zin. Ehm en wat er nu en dat dat vond ik nog het laatste eh duid in het zakje die Google deed dat ik echt dacht maar wacht even is Flow. Dat is hun tool waarbij ze eigenlijk zeggen: "Maar wil je niet een productie maken? Wil je niet een een feature length filmen maken?" En wat Flow eigenlijk doet is een soort de Adobe Première zijn van generative video en zeggen: "Leuk dat jij van die broll hebt hè eh eh clips, maar volgens mij wil jij gewoon een cursus video maken van 15 minuten en dan heb je eigenlijk een systeem nodig dat al die clips in een soort geheel tot een tot een geheel doet en dat is eigenlijk wat flow kan." Ja. Dus je hebt je dit is een soort videobewerkingsprogramma voor eh AI gegenereerd beeld, maar je kunt dan je kunt achter elkaar zetten en ja, maar ook soort van vertellen hoe ze eh tot elkaar verhouden die die clipjes waardoor het één lang geheel wordt en je kan de camera manipuleren en Ja. Ja, want dat is ook nog even een ding hè, dus dat je wat hiervoor was het wel een beetje een soort van je trok aan een hendel en dan hopen dat er iets tofs uitkwam en nu kan je echt zeggen van nou het is wel tof, maar ik heb eigenlijk liever dat je even zoomt. Zoom even op dat in. Ja. Ja. Als een regisseur. Ja. Ja. We zouden alleen al bij VO3 anderhalf uur kunnen stilstaan denk om te bedenken wat betekent dit voor film, voor acteurs? We ze introduceerden hun eigen keynote met een met gegenereerde introductie video van een soort Pixarachtige figuurtjes die in een soort van cowboy eh western film lopen. Ja, dat was extreem goed. Dat was leuk om naar te kijken. Nou, ik moet zeggen, ik vind het leuk dat je dit aanhaalt, want ik sowieso schrok ik een beetje eh de Verge doet altijd van die supercuts en die supercutten altijd naar 10 minuten. En deze was supercut 32 minuten. Dus da ik weet niet wel alle afdelingen hebben laten zien wat ze hebben zitten kopen zeg maar al die tijd. Dus dat is eh was echt bij Apple event kun je tegenwoordig makkelijk terugknippen naar een minuut of zes. En dat kan niet bij Google. Het lukte niet meer. Het is echt rogbrood zeg maar. Zit een hoop in. Dus dus die eh maar die wat ik interessant vond is even een beetje de misschien jij hebt het nu over die best wel leuke Pixar intro en als het werkt ook. Het is entertaining. Het is het is best wel goed misschien ofzo hè in kwalitatief goed. Wat mij opviel die hele presentatie van ik heb uiteindelijk heb ik die 32 minuten gekeken en daarna nog wat stukjes ingezoomd voor mezelf die ik belangrijk vond. Ik heb niet het hele ding gekeken, maar alles was geanimeerd. Alles was kapot geanimeerd zeg maar. Dit waren niet meer bullet point slides, zeg maar. Het kwam invliegen. Er waren allemaal visualisaties. Het was Ik was jaloers laat ik zo zeggen. Ik heb vaak ook wel een visie over hoe een goede dek moet zijn. Ja. Toen herinnerde ik mij dat er een eh dat heet material UI, dat is eigenlijk waarop alle Android dingen gebaseerd is, die hebben een nieuwe dat heet material UI 3. En daarin zit het hele idee van Expression van mij. Nu je hebt het nu over de vormgeving van Android. Ja. En en eigenlijk het hele de Google wereld, de Google beeldtaal. En toen dacht ik, ik denk dat dit een generative deck is. Ja, ik heb het idee dat die kwaliteit van die hele eh eh presentatie van Google, want die tot 32 minuten teruggeknipt is, is zo hoog omdat zij nu Generative AI aan het gebruiken zijn om ze hebben een geheime versie van Google Sheets. Ik weet niet wat ze draaien. Oké, we moeten door. We moeten door, want er zijn niet alleen VO3 is gelanceerd, ook Gemini Live. Dat is nu iets wat op Android telefoons gewoon eh werkt. Volgens mij trouwens op iOS ook wel in de Gemini app. Dat is dus dat je niet alleen die voice mode aan kan zetten en dat er dus een stem aan het praten is, maar dat je dus video kan laten zien aan het eh model live en dat je dus met dat ding kan praten terwijl je dingen aan dat ding kan laten zien. En Google. Ja, dit haakt haakt heel erg in op ons op onze Wables aflevering. Want het idee is dan natuurlijk dat dat cameraatje in jou zon ber bril zit. Nu is het allemaal nog een beetje ongemakkelijk. de de demo die ze gaven was iemand die zijn fiets aan het fixen was en die had dan een pixel telefoon lag dan een beetje op een soort van eh ja verhoginkje waardoor dat ding kon meekijken naar dit is een eh dit is een schroefje. En dan vraagt hij: "Hyé hoe hoe wat voor schroefje moet ik eigenlijk hebben?" Deze schroefjes heb ik. Liet aan de muur had hangen en vervolgens begeleid die stem je ja door het fixen van een fiets. Ja. Is misschien wel goed om een klein beetje de verwachtingen te managen. Er is Gemini live die nu kan meekijken. Bizar uitgerold. Gister kan je gebruiken op iOS en Android. die die jongen met die fiets dat is Project Astra. En Project Astra is deels research, deels wat we kunnen. Want dat stukje in die video wat jij nu beschrijft dat hij een dat hij ook nog het bakje aanwijst waar dat waar dat schroefje zit zeg maar. Nee, maar ik wou zeggen en want die kan ook namelijk browsen op YouTube rondklikken en je hele telefoon bestuuren zeg. Preci dat ja oké die demo gaan ze nog verder want dan zegt inderdaad eh zoek even de handleiding op van deze fiets en dat doet hij dan op de achter. Ja. Nee, zeker. Dus je ziet inderdaad dat ding scrollen. Ja, dat is inderdaad weer maar alleen al het feit dat je iets aan een AI kan laten zien waarbij dat ding live eh meekijkt. In de demo eh vond ik ook heel grappig, liepen ze op straat en wezen ze naar een eh een vuilniswagen en zeiden ze: "Dat is een leuke convertible." En dan gaat dat ding je corrigeren door te zeggen: "Dit is een vuilniswagen." Of je ziet een schaduw en je zegt: "Wacht, iemand volgt mij." En dat ding dan zegt: "Dat is je schaduw." Ja, dit was een dik naar open AI omdat die natuurlijk hun model hebben teruggetrokken laatst omdat die alles met je eens was een sick zeg maar. En deze AI zat je eigenlijk alleen maar terecht te wijken. Ja. Ja, mooi. Mooi. Eh dus dat is live en dat is daadwerkelijk iets wat je kan proberen. Dat is VO3 waar we het net over hadden is voor Amerikanen live. Eh maar niet voor Nederlanders natuurlijk. Eh in Europa krijgen we dat niet. Oké, laten we doorgaan, want er is nog veel meer. De er zit nu een er zitten allerlei agents heeft Google nu gelanceerd op verschillende niveaus. Één daarvan is de agent mode in de Gemini app. Dat wordt een systeem waardoor je eh kan dat ding kan dan voor jou het internet opgaan en dan op de achtergrond brows een beetje vergelijkbaar met manus als ik het goed begrijp. Ja hoor. Ja. Ja. Zij noemen het dat is hun project mariner en eigenlijk al die soort van research projecten krijgen nu een plekje in delen of in zijn geheel in de daadwerkelijke consumer facing apps. Ja, maar het is allemaal onbegrijpelijk, want dit is Gem in de Gemini app. Absoluut onbegrijpelijk. Ja, die kan dus in de cloud heeft een of andere computer die die dan zelf kan bedienen en dan krijg jij zeg maar het eindresultaat van zijn zoektocht als ik het goed begrijp. Ja. Let me browse the web for you. Let me browse the web for you. Maar ook dingen doen. Dus niet dus hij gebruikt het web. Niet alleen maar om informatie op te zoeken, maar ook door te zeggen: "Nou, hij doet dingen daar. Ik ga naar Funda. Ik pas de filters aan naar eh weet ik veel huizen onder de bla en dan krijg je alleen maar wat mensen dachten dat Siri was 5 jaar geleden. Nu kan het." Ja. Nou ja, nu kan het. Dat is de belofte. Ja, goed dat je dit Ja. Ja. Nee, want ik ik moet zeggen, er wordt nu natuurlijk terwijl wij praten van alles getest hè, mensen krijgen beta toegang et cetera, heeft heel grof gezegd, ik denk dat 50% van wat we hebben gezien thuis hun verhaal is legitiem bruikbaar en de andere 50% zijn de beste demo's die ze konden maken. Absoluut. Ja. Nou, dit zit dus in de Gemini app. Ze ze hebben dus ook een agent functionaliteit in Chrome gebakken waar je een zijbalk hebt gekregen in Chrome waardoor je kan dingen kan vragen over de webpagina en ook over alle andere tabs die open staan. Voor wie komt dat na beschikbaar? Geen idee. Eerlijk. Dit is maar dit wordt wel problematisch dat de hosts van de AI podcast niet weten wat nou echt een nep is. Nou ja, nee, ik bedoel ik dacht jij bedoel region regionaal, maar ehm kijk uiteindelijk misschien ook wel even een goede met remark om nog te maken op dit hele ding. Dit zijn allemaal verschillende teams binnen Google. Ja, nee, dat is duidelijk. Die als opdracht hebben gekregen: "Doe iets met Gemini, hè. Wij gaan nu AI uitrollen to the Max en daardoor krijg je dus ook dat er drie soortgelijke producten tegelijk gelanceerd worden door drie teams. En het Chrome team echt dat doen we binnen Chrome die soort van hetzelfde doen en een andere naam hebben en waarschijnlijk over een half jaar weer een andere naam hebben gekregen. Want ook dat is gebeurd. Gemini Advance heet voor een Gemini Pro wietsen. En Gemini Pro is weer aangevuld met Gemini Ultra. Dat wordt de $250 per maand versie. Dit is wat al die bedrijven nu aan het doen zijn. Het is niet alleen een bedrag eh niet alleen een abonnement van $20, maar ook een abonnement van $250 per maand. Dus je kan wachten dat er nog een nul achter komt over een jaar. Eh daarin komen nu alle grote nieuwe dingen zoals die agent mode in de Gemini app. Als ik het goed begrijp zit dat alleen maar in de eh dure versie. Alle coole dingen worden het eerst uitgerold in het in de duurste tiers. Maar eh pak pimer er niet op vast, want het is allemaal onbegrijpelijk. Dat is wel weer ehm dat is wel weer een beetje jammer. Het zou wel lekker zijn om een soort website te hebben waar je gewoon een hele grote tabel hebt met de features binnen verschillende AI applicaties en dan per regio en is het een paper launch hè, een verhaal of is het daadwerkelijk beschikbaar? Want het is toch verschrikkelijk iets wat een tijd. Ja, het is gewoon veel. Maar ik moet wel zeggen bijvoorbeeld ehm een notebook LM is even een die is eigenlijk al voor IO aangekondigd, maar die is nu ook visueel geworden. Dus je kunt decks maken en dan praten de twee podcast host mee terwijl ze doorklikken op een PowerPoint presentatie. Ja, eigenlijk is het in plaats van een podcast genereren kan hij een TED Talk voor je genereren. Ja. En dat is dus het maffis. Dus ik was daar best wel nog steeds hoor van onder de indruk en toen kwam VO3 en toen dacht ik oh maar nu kan er dus ook een persoon die twee mensen uit die die gaan er dan naast staan in een soort keynoteachtige set-up. Nou ja goed eh I digress. Maar maar nu nu ben je dus aan het doen wat wat is in Nederland beschikbaar onder welke naam? Wat is in Amerika beschikbaar onder welke naam? Wat is toekomstig in Amerika beschikbaar? Ja. En wat is daarna eh nou ja, goed. Eh daarnaast introduceerden ze personal context. Eigenlijk wat voor inbt alleen maar beperkt kan zijn tot het geheugen wat dat ding opbouwt doordat je met dat ding communiceert. Dus bijvoorbeeld als jij een keer tegen ChatBT hebt verteld dat je een piano hebt, dan kan je in latere gesprekken daarnaar eh verwijzen. Dat is iets wat eh ja beperkt is tot tussen alle tot alle interactie die je met chatg hebt gehad. Het geheugen rijdt natuurlijk niet verder dan wat je dat ding expliciet verteld hebt. Google heeft weet meer van jou, want ze hebben waarschijnlijk ook eh bestanden van jou in Google Drive en je gebruikt Gmail en misschien gebruik je wel eh nou je hebt talloze to sorry talloze tools die je gebruikt om informatie van jezelf achter te laten. En ze hebben nu aangekondigd dat ze al die informatie gaan eh bundelen in iets wat ze noemen personal context. Dat wordt een knopje wat je aan of uit kan zetten waarbij Gemini toegang krijgt tot al die persoonlijke informatie. Dus als een vriendje vraagt naar die roadtrip die je vorig jaar maakte, dan duikt Gemini in je Gmail en in je Drive om een antwoord te formuleren. Dat klinkt alsof jij het zelf schreef. Dat is een ding. Dit is best wel een groot ding. En het is ook wel interessant dat eh Apple hier een eigen antwoord op heeft waar we nog niet bij kunnen, maar die dat heeft ook iets dat heeft een naam met context. Doe het even niet toe. Het was onduidelijk voor mij. Ik kon er ook niet goed achterkomen Apple heeft aangegeven en daarom duurde het ook allemaal zo lang dat ze zeiden als jij die personal context of hoever zij het noemen aanzetten en waardoor eh Apple Intelligence eh weet wie jouw moeder is eh weet waar je bent op dat moment en weet waar je naartoe gaat vliegen morgen. Want daar komt het eigenlijk op neer, want al die apps en al die mails en al die wallets zijn allemaal ineens zichtbaar voor dat model. Dan doen ze dat lokaal. En ik kreeg niet helemaal uit eh Google's verhaal goed als ik die personal context aanzet, wat gebeurt daar dan op dat moment mee? Dat daar heb je keuzes in te kan je keuzes in maken technisch. Het is wel een ehm als ik het goed begreep op opt in toggel. Dus jij gaat naar een ding toen je zegt: "Ik wil dat jij meer over mij weet." Ja. Ja, het is nu nog de optin. Ik kan wachten dat dat op een gegeven moment automatisch gaat, maar dit is waarschijnlijk in de ja toch de het vertrouwen wat wij als burgers hebben op te brengen ten opzichte van het dit soort enorme AI bedrijven eh is dit natuurlijk een gevoelig dingetje. Dus waarschijnlijk maken ze daarom op de in. Ja. Eh dan introduceert Google AI mode in search. Oftewel we hebben het nu over google.com. Misschien eh iets wat je herkent uit je jeugd. Eh de nieuwe versie van Search is eh R1 waarbij je ja het soort wordort een soort mix tussen eh Google zoals we dat kennen van zoektermen invoeren en resultaten krijgen met daarboven een samenvattingskaartje. Kun je nu veel langere complexere zoekopdrachten geven die uit meer perplexity. Het is soort van deep research for the masses. Ik moet zeggen de eerdere AI mode of whatever die ze hadden gelanceerd waar al die grapjes uitkwamen van benzine op je pizza gooien zeg maar. Ben op je pizza. Ja, dat was echt een hack als in een goed dat was iets met een pizzarestaurant of recept. Daar zat benzine in om hem lekker spicy te maken. Dat was toen het een beetje het media rondom die AI was. in Google ben je van gewend dat er feiten uitkomen en dat ding kwam regelmatig met dingen die niet klopt. En wat er nu eigenlijk gebeurt en dat daar hebben wij het ook vaak over gehad is is ten dele een kwestie van model swapping. Dus het houdt in je hebt een hele applicatie gebouwd waar een taalmodel onderdeel van is. En zonder verder die applicatie al te veel aan te passen switch je naar een nieuwe model waardoor die hele applicatie beter wordt. Hè, dus wat Google nu zei in de presentatie, ik zeg expres zei, is we hebben de nieuwere Gemini eronder gezet, want er zat nog een hele oude Gemini onder. Het zijn vaak die flash modellen van hun. Dus die snelle, kleine, goedkopere modellen die ze achter Google Search zetten, want er zijn heel veel Google searches per seconde, per nanosecondde niet normaal. Ja, dus er zat een oude Gemini achter die ook nog eens eh labomized was, zeg maar, dus een heel dun dingetje. Daar zit nu de nieuwste flash. is nog steeds klein, maar super slimmer dan de vorige. Dat heeft heel erg geholpen. En al die eh eh dingen die ze geleerd hebben rondom hoe werkt in het heet bij hun deep search eh wat open jij deep research noemt eh en notebookm en al dat soort hoe breng je nou context eromheen om hem een beetje te gronden in de realiteit waardoor hopelijk die hallucinaties afnemen en eh praten met Google. Want dat dit is eigenlijk de unified search interface dat ze zeggen we willen even vanuit heel eh commercieel marketing perspectief dat waar jij nu nog naar chat GPT gaat om een typische chatgellen dat jij je psychologie weer omgooit en zegt die kan ik ook prima intypen in het zoekveld van Google en Google bepaalt wel of dat een soort zoekopdracht wordt of een soort perplexity-achtige research vraag. Ja. Nou ja, in de meeste gevallen gaat er natuurlijk op neerkomen dat Google gewoon het antwoord op de vraag gaat geven in plaats van jou gaat linken naar een website. En daarmee is ook wel een beetje die ja, dit is toch wel een beetje de nagel aan de doodkist van bedrijven die afhankelijk zijn van Google Traffic. Die zijn maken zich natuurlijk al een tijdje zorgen. Als je bijvoorbeeld de Volkskrant bent, dan krijg je nu een groot deel van je verkeer via Google. Of als jij cool blue bent, krijg je een groot deel van je verkeer via eh Google eh ads of of eh soort van organische zoekresultaten. Dit is gewoon eh Google zegt dat nu dus ook zelf voor het eerst. Soorts van dat is inmiddels legacy. Dat dat gaat gewoon weg. Ja. Het is alsof je bij de bibliotheek komt en die persoon daar achter de baliie jou of meteen het antwoord geeft of begint iets uit te printen wat ze zelf hebben geschreven wat het antwoord geeft. Maar er gaat geen boek meer die bibliotheek uit. En dat is een groot ding eh voor eh bedrijven en mensen die afhankelijk zijn van ehm ja, mensen toegang hebben via Google, traffic krijgen via Google. Oké, we moeten doorwietsen. Eh tenslotte eh Gemini heeft ook weer zelf een update gekregen. Eh 2,5 Pro heeft een nieuwe versie gekregen, wat ook weer onmogelijk is om te begrijpen waarom een versienummer met een nieuwe nummer. Maar mag lang hij mag langer nadenken. Deep Think ofzo heet het volgens mij. En dat goed dat doet dan van alles in de benchmarks. Ehm lang verhaal kort daar op dit moment terwijl wij praten weet ik er zou ook iets vanuit open en jij moeten komen vandaag. Ik weet dat niet zeker. Maar dat zag ik maar we ik het was er nog niet voordat we gingen opnemen. Dat is leven. Dus als het er straks wel is joje. Op dit moment eh at the time of recording is Gemini 2.5 Pro Deep Think het allersterkste supermodel ter wereld nu. Ja, maar waarschijnlijk als je het luister al weer achterhaald. Nou ja, dat is onze podcast. [Muziek] Dan open jij eens codex. Vertel over deze. Ik ik zag een heel grappig momentje over de Dit is dus een nieuwe programmeerhulp van Open AI. Ik zag een heel grappig fragmentje waarin een mevrouw van Open AI met haar collega's op een bank zit. En dan is er dus een moment waarop zij zegt dat zij al een tijdje codex gebruikt. Deze nieuwe tool waar jij zo over gaat vertellen. En dan is er een ongemakkelijk moment waarop zij zegt eh ik eh praat eigenlijk liever met eh Codex dan met mijn collega's. Nou dan heb je de Crè de La Crè van de programmeurs van de wereld en die werken bij dat bedrijf onder andere. En die zitten dan dus zij zegt dan letterlijk: "Ik praat liever met die AI dan met jullie." En dat levert heel ongemakkelijk gelach op en daarna gaan ze gewoon weer door. En toen dacht ik, dit is een metafoor voor wat er aan de hand is. Vertel over codex fietsen. Nou, het is eh codex bestaat al een tijd, grotendeels intern binnen open AI, want deze open AI of deze AI laps hebben ook hun eigen AI tooling en die dok voeden dat natuurlijk voordat dat naar de eindgebruiker gaat, hè. Dus je blijft iets wonderlijks, maar ze gebruiken hun eigen AI om hun eigen AI beter te maken. Ja. En dat en hun eigen processen en hun eigen slacks. Eh er zitten waarschijnlijk allemaal botjes overal. Bedoel, het zijn mensen die echt eh diep in een in de AI eh rabbit hall zitten. Dus die zien waarschijnlijk alles als een potentieel agent vraagstuk of zo gaat dat een eigen laboratorium. Ja. En ehm nou tot nu toe hebben we al ik bedoel jij noemde net even manus eh ik roep het ik roep vaak edder. eh koopid heeft tegenwoordig een agent mode. Allemaal manieren om te programmeren met AI als buddy die jou tips geeft, maar ook als iets waar jij je het soms aan eventjes aan overgeeft en dan gaat zitten wachten terwijl jouw copiloot eh agent aan de gang gaat. Maar er is een grote visie die zat eh vooral in Google in Github Workspaces bijvoorbeeld. Namelijk software, grote software projecten, serieuze software projecten hebben versiebeheer. En versiebeheer houdt in dat mensen met elkaar gaan samenwerken aan een groot stuk code. En dan wil je niet dat je elkaar spullen kapot maakt. Dus je wil engien wie wat gedaan heeft. Dingen kunnen terugrollen in de tijd. Maar dat soort versiebeheer omgevingen eh waaronder bijvoorbeeld GitHub, daar zit veel meer omheen dan enkel dat versiebeheer. Namelijk ook een soort projectmanagement van een software product. Iemand heeft bijvoorbeeld een beuk. Nou, dan maak je een issue aan en dan zeg je: "Dit is de issue." Je kunt ook een issue aanmaken voor een feature die je wil of beide. Dus maar net hoe jij met elkaar het daar allemaal ideeën over hoe je dat met elkaar moet doen. Dan mogen mensen lekker zelf uitzoeken. Maar er zit wel een soort basis in dat je een issue aanmaakt. Dan fixt iemand die issue. Die maakt dan een eh eigenlijk de vraag: "Mag mijn fix de codebase in?" Nou, in een goed professioneel bedrijf kijken dan even wat mensen naar een soort peer review zoals dat gaat in de academische wereld enzovoorts. Die processen lenen zich natuurlijk enorm om ook helemaal identified te worden, hè. Eh eh dus dan heb je bijvoorbeeld iemand die zegt eh ik ben tester van deze software. Ik programmeer zelf niet, maar ik heb eigenlijk een request gehad vanuit de serviced desk binnen onze organisatie dat er iets fout gaat in één van onze applicaties. Ik heb dat kunnen reproduceren. Het lukt mij nu ook. Nou, dan ben je altijd blij, want dan heb je het te pakken. Ik omschrijf die hele issue en dan zeg ik eigenlijk wat ik had verwacht dat daar gebeurde, hè. Dus wat gebeurt er? Wat had ik verwacht? Nou, dan kan eh Codex die issue lezen, hè, en zeggen: "Nou, ik wil wel een poging doen als agent zijnde om jouw probleem op te lossen." Ja. En dan eh kan eh maakt hij een eh eh pool request aan. Oftewel, dit moet naar binnen getrokken worden in de code. Hij schrijft code en dan doet hij dus dan stelt hij eigenlijk voor: "Dit is wat ik heb gemaakt. Wil je dat ik dit doe?" Ja. Dus en de code en de omschrijving wat wat die gedaan heeft, zodat mensen het weer kunnen lezen. Want we willen humans in the loop op dat moment. Ja. En een programmeur krijgt letterlijk dan te zien: "Dit is wat ik heb veranderd en dit is een een vinkje of een kruisje." Ja. Wil jij dit eh gaan we dit doen of niet? Zeg maar of wil je dat ik nog even wat andere dingen doe? wil je ook wat aan je kan in gesprek gaan dan natuurlijk, want deze processen waren dus al heel erg geformaliseerd en eh gebaseerd op informatie en die lenen zich dus enorm als het al zo procesmatig is om ze door een coding agent te laten doen. Nou, dan kan je zeggen die coding coding agent draait bijvoorbeeld op de laptop van de developer of op de computer ergens binnen de binnen de team hè. Maar Codex is ook nog eens een cloudbased code assistant. Wat kan je dan dus uiteindelijk doen? zeggen: "Ik heb een repository." Hè, een code bij Github staan bijvoorbeeld. We hebben al wat issues open staan, misschien al een paar maanden, want niemand had zin om ze op te pakken of ze hebben weinig prioriteit. Hey Codex, ga jij eens even er doorheen en doe maar even wat pogingen. Wij gaan er wel naar kijken. En dat wil je dan dus laten gebeuren in de cloud. Want dan hè dat dat wil je niet per se om andere redenen. Maar dat is wel prettig dat jouw assistant niet een lokale assistent is in dit geval, maar echt een collega die meedraait vanuit eh de cloud. Voor IP van je code enzo moet je hier allemaal supergoed over nadenken. Maar het is een product. Maar maar dus dat ding, als ik het dus goed begrijp, je hebt je je hebt een software eh product als bedrijf. Ja, dan eh staat die code van die software staat al in de cloud. Dat is al jaren zo. Maar wat nu nieuw is dat wat normaal gesproken die hele was en dingen waar je maar niet aan toe komt, want dat is natuurlijk in ieder bedrijf aan de hand. Iedereen heeft wensen. Die wasst die moet normaal gesproken opgepakt worden door programmeurs die zijn beperkt in hun tijd. En nu kan er dus een cloud tool van Sam Altman dit op de achtergrond doen. Ja. En dan krijg jij gewoon voorstellen van dat ding van dit zijn suggesties. Wil je dat ik dit allemaal doe voor jou? En ik ben dan uiteraard gedoken in Want er was een opmerking in de eh presentatie van Microsoft vorige week waar een soort gelijkproduct is aangekondigd. De banden zijn eh erg nauw. eh waarin ehm eh werd gesuggereerd: "Joh, wij hebben zelf we gebruiken dit al binnen Microsoft ook en ook in een aantal van onze open source producten. Dus allemaal ontwikkelaars gingen vorige week: "Oh, nou dan gaan we eens even meekijken, want dat dat zijn repositories die kan je meelezen." Als en je kan die code zien die die geschreven heeft Ja. en hoe die het heeft aangeboden et cetera. Nou goed, daar komt dan nu uit in eh in het copilot geval wat ongeveer dezelfde modellen zijn. Ja. Mah. Oké. Maar ik bedoel goed, ik had het net al over model swapping. Ik wil niet iedere keer het gevaar is dat wij heel de tijd de AI belofte naar de toekomst gaan verschuiven. Wacht maar, wacht maar. Ja, hoe dit integreert nu is gewoon best wel knap. hoe de hele context begrepen wordt, hoe de interface werkt, namelijk human language, taal, hoe wij kunnen gewoon meelezen. Ja, kijk, zelfs een zelfs een eh dit gaat natuurlijk naar het punt toe dat zelfs simpele zielen zoals ik begrijpen wat daar nou ja, jij kunt meelezen, testen, misschien kijken misschien, weet je, waarschijnlijk voegt hij op een gegeven moment een videootje toe. Kijk, dit is hoe mijn oplossing eruit ziet, hè. Ja, dat kan een ziel als ik ook. En dan kan je je voorstellen dat deze processen hè, dit gaat dus nu bijvoorbeeld, laten we zeggen typisch op het niveau kleine issue eh zou een junior developer kunnen oppakken, heeft geen prioriteit, doet nu een eh het is een Gemini of een GPT41, pakt dat op, schrijft een issuapportje en het is redelijk oké. Hm hm. En als we er dan even vanuit gaan aanname dat die modellen krachtiger zullen worden en het proces ligt er al, dan kan je en die modellen multimodaal zijn, dan kan je je voorstellen dat je uiteindelijk een pool request krijgt met een video erbij vanuit gemaakt door VO3 met een collega van je die daarop een slide uitlegt in een pakje uit de tijd van de Romeinen eh dat hij een aanpassing heeft gemaakt met een video erbij in de Chrome browser die die zelf heeft bestuurd waarin die laat zien hoe de aanpassing eruit ziet. En dan ga jij dat goedkeuren. En ik denk dat die eh stappen die gemaakt gaan worden de komende tijd van een eh ja collega, een nieuwe collega in jouw ontwikkelteam die in dit geval draait vanuit Codex eh open en jij iets is wat de luisteraar die in dit werkveld werkzaam is serieus moet nemen. Er wordt alle kanten het eh het collega in Pak de Romeinen. Dat is denk ik belangrijk. Ehm hoe eh hoe big deal is dit nou? Want dit klinkt een beetje alsof ze een alsof ze een nieuwe user interface hebben bedacht. Ik vind eh het het ik bedoel Codex is eh denk ik belangrijk als nieuwsitem om goed te begrijpen waar we eigenlijk over praten als er wordt gezegd EA je nieuwe collega of whatever van hoe uitziet dat dan dit is hoe voor programmeurs is dit nu de uitingsvorm en dit geldt straks ook voor de marketing en de HR afdeling want daar gaat het op dezelfde manier zo gaat het op dezelfde manier gaan wij met die AI collega af werken. Ja, je kunt je voorstellen als jij veel meer in het visuele zit, hè, dus je zit in Figma of iets waar je ook eh reacties kan plaatsen, versies kan beheren, et cetera, want dat is heel erg geïnspireerd op elkaar. Dat je daar op een gegeven moment in diezelfde systemen suggesties gaat krijgen van ik zou het zo aanpakken, et cetera. En dat ik ik dus ja, ik denk dat de hoofdboodschap van ons de laatste maanden al is dat wat wij zien in de in de krochten van de software ontwikkeling, wat allemaal in de mijnen voelt voor heel veel mensen, gaat ook naar grafisch designers toe komen. Ja, ik begrijp het. Oké, tenslotte van het nieuws dan, want daarna begint deze podcast pas. Luisteraar eh Open AI eh wil graag IO overnemen. Dat is een start-up die vorig jaar door Johnny Ive, sir Johnny Ive moet ik zeggen, is opgericht. Eh Johnny Ive is voornamelijk bekend als de designer van de MacBook Pro eh of de MacBook mag ik zeggen. Eh en eh de iPhone. Toch geen twee kleine voetnoten in de geschiedenis. En dat is een eh overname waar miljarden mee gemoeid zijn en waarbij dus de twee grootheden op dit moment in de tijd gaan samenvatten. Zij het is eigenlijk een aankondiging van een aankondiging, want ze ze kondigden dus aan dat ze een eigen hardware tak gaan maken voor het produceren van hardware AI producten voor Open AI. Dat is een gerucht dat al langer gaat en wat ze nu dus officieeler aankondigen. Ik wil je even een kort moment laten horen van deze twee heren in een geweldige uit een geweldige video. Je hebt hem gezien toch? Zeker. Ja, we hebben het hier nog niet over gehad, maar ik smulde van deze video van 10 minuten. Een kort eh moment waarbij de twee heren aan een bar zitten en elkaar vertellen over wat die wat die hardware moet gaan doen. Beetje vaag, maar je krijgt toch een idee. I thinkolestie of technology that ever seen. unable techy decades old and common sense to thinky products we have like magic intelligence in the cloud if ied to ask something right now about we talked about earlier think about what would happen i would like reach la webser enter dit is op zoveel manieren interessant vind ik wat hier gebeurt. En ik ken jou ook als groot Apple fan. Het voelt als een terugblik in de tijd van toen Apple nog echt een vet bedrijf was. eh de tijd van Steve Jobs en dat Johnny Ive eh de de de septer zwaaide. En wat wat hier gebeurt is een hoop é ze kondiga aan. Dus dat er een een of andere AI tool of hardware komt waarmee ze eigenlijk zeggen: "We gaan de hele computer opnieuw uitvinden." Ze zeggen eigenlijk zijn laptops en eh iPhones, MacBooks en iPhones, bijna letterlijk. Wordt door de uitvinder van deze producten legacy producten genoemd. Het is een onwaarschijnlijke dik naar Apple dit überhaupt. Dat ja, eigenlijk de ziel van Apple eh die nog leeft, de levende ziel van Apple zit in Johnny Ive. Meer dan in Tim Koek of in in andere mensen zou je kunnen zeggen. En die gaat nu met Sam Altman, de grote vijand ervandoor. Dus het in de in de Hollywood versie van Openij dit een belangrijk moment zou ik zeggen. Wie? Hoe heb je dit eh hoe consumeer je dit? Ik zat eh aantal weken geleden was een interview met eh Johnny Ive. Ik weet even niet waar, maar die kan je wel vinden. Dankjewel. Kijk, het is lekker hè. Ehm en die heb ik helemaal gekeken om toen merkte ik wau, wat zit hij ineens af te geven op zijn eigen legacy hè. Van ja, we zijn de verkeerde kant op gegaan. Ja. Maar ook echt wel van ik ben niet blij met wat de technologie is, wat het effect is van de technologie waar ik zelf aan meegewerkt heb. Ja. En dus ik had na bij de video dacht ik: "Oh, wat interessant." Een soort in mijn persoonlijke mening een soort voice of reason van van een soort gezondheid van jeetje, al die mensen op die telefoons hè. Nou, de hele ook een vibeshift hoor over voornamelijk het bedrijf Apple, want dat is dat ja, ik vind het ik moet zeggen is het nodig weet ik niet zo goed, want ehm ik ben het wel eens met Pete Sampris. Laat je tennisrecord praten. Wauw, een sportmetoor. Ik dat dat in deze podcast nog zou gebeuren. Dat praat met je tennisrecord als in slag gewoon mooie ballen. Dus Jonny, laat maar zien dan zou ik zelf zeggen. Tot nu toe maakt hij wel jassen, heb ik het begrepen. Ik snap ook wel dat je een soort verhaal wil maken eh en dat interview daar blijkt dus achteraf natuurlijk een beetje gepland in het hele narratief van nou ja, whatever. Goed, ik had na het interview zoiets van ik ben nu geïntrigeerd, want wat ga jij dan doen? Nou, als je dan eh met Sam Altum gaat samenwerken binnen Open heb ik mijn vraagtekens bij dat ik denk: "Ja, volgens mij kijk je naar alle andere initiatieven die de man Altman maakt, is hij niet zo heel erg bezig met het per se bewaken van onze privacy of het Hè, dus ik begon toen te twijfelen wat bedoelde Johnny dan bij de soort van negatieve bijeffecten van de technologie die hij heeft ontwikkeld?" Ik denk dat hij het vooral heeft over waar die eh interfaces zich bevinden, hoe je interacteert met dat hoor je ook in dit barg gesprek zeg maar van eh dat je die telefoon uit je zak moet halen. Dat die telefoon tussen jou en je mede eh eh de mensen om je heen inzit, hè. Dus dan kom je een beetje op ons variable verhaal. Oftewel het moet zowieso een variable zijn. Ja, een brosch. Dus het wordt echt een dingetje. Ehm en ik denk dat waar de humaane eh toch even de humain pin er nog even bij te pakken zeg maar. De dat was een brosch een high brosch die veret is gegaan na een jaar. Precies. Wat daar soort van geprobeerd werd zit meer in de lijn met wat hè soort pendant achtig dingetje waar je dan Star Trek communicator mee gaat praten. Dit is allemaal de lame versie die Wi kan bedenken. Ik ga er dan vanuit dat Johnny Ive met iets voorspelt een brosch. Nou ja, iets wat wat ook fashionable is waarschijnlijk enzo. Dus dat moet heb ik helemaal geen verstand van. Neem van mij aan. Ehm ik vind het een interessante samenwerking. Het voelt ook als je een wat cynischer bekijkt als een beetje een desperate move vanuit Open en die nu sinds gisteren helemaal door Google weggeblazen is. Absoluut. Hè, ik weet niet wat er wat er gebeurt de komende week, maar ik eh eh goed, ik praat praat in ieder geval op de als programmeur alleen nog maar met Gemini. Dus er is gewoon heel veel gebeurd ineens, zeg maar. En ehm dat maakt niet ineens open en jij van de één op de andere dag niks meer. Er kan nog van alles gebeuren, maar ze gaan naar product toe. Er moet hardware gemaakt worden, hè. De het hele besturingssysteem moet vervangen worden. De hele paradigma van hoe wij met eh intelligentie buiten ons praten, want daar komt het eigenlijk op neer, moet op de schop, hè. Dus en op zich als je dan je eh je gok neemt, zeg maar, ja, als je Johnny Ive kan strikken, ik snap het wel, zeg maar, hè. 6,5 miljard, maar dan heb je ook wat. Precies. En ehm maar ja eh er is er is wel vaker een eh hele goede voetballer bij een ander team toegevoegd. Dat dat was daar komen heel veel publiek op af. Maar ik moet weer een sportmetafoor moet je even ophouden. Ik moet ja ik laat ik het zo zeggen. Ik moet het nog maar zien. Ik ben benieuwd. Voor de luisteraar. Keyword die je in je tool naar keuze kan gooien is eh Ubiquitous Computing. Namelijk eh UBCOM eigenlijk uit de jaren 80 uit mijn hoofd. Dat gaat over een visie uit de laps destijds waarin ze zeiden: "Het hele feit dat jij bewust aan het interacteren bent via verschillende interfaces, muizen, toetsenborden, touchscreens eh et cetera, is een heel wordt een heel kleine bli. Want uiteindelijk wil je een computing environment waarbij jij een woning binnengaat, er is geen thermostaat, er is niet eens een voice assistant. Ja, ison de temperatuur die klopt. Ik denk een beet technologie die opgaat in de ruimte in plaats van via dit soort krakkenmikkige glazen interfaces. Dus ja, niet eens meer eh het het moet op jou reageren zoals een eh bloem opaat als de zon komt. Nou, weet, ik kan jou één ding vertellen. Dat gaat de firma Google niet uitvinden en dan verwacht ik toch iets meer van de heer Sir Johnny Ive. Ik denk als het gaat om mensen en ook wat mensen bereid zijn te dragen, ja, dat je aan Johnny Ive een goede hebt. Want hij heeft tot nu toe wel bewezen dat het hem lukt. Dat het niet alleen maar een technologie is waar mensen over het algemeen eh de waarde van inzien, maar ook nog eens bereid zijn om dat op zich te dragen. Dat is denk ik de hele pitch van zijn persoon. Ja. Dus we gaan het zien. Ik ben heel benieuwd wat daar zes maanden ofzo volgend jaar beloven ze. Ja. Oké. Ben benieuwd. Dus waarschijnlijk nog een jaar vermoed ik dan. Een brosch. Goed, straks gaan we naar het hoofdonderwerp, namelijk eh humanoid robots en het effect daarvan op de arbeidsmarkt. Maar eerst vertellen Marian en Lucas van Deptje hoe je AI kan gebruiken op conversie op e-commerce websites te verhogen. Hi, hier marketing en techbureau Dept. Elke week bespreken wij hoe wij merk helpen in de wonderen wereld van AI. En wist je dat je met AI de prestaties van je e-commerce website flink kunt verbeteren? Wij helpen even onze klanten om zowel de user experience als de conversie te optimaliseren. Yes. Door een AI continu te laten meekijken met de analytics data en daarmee eigenlijk het gedrag wat gebruikt op het platform laten zien en daarnaast hem ook eh het design in de content te laten scannen, zijn we in staat om eh probleemgebieden of gebieden voor optimalisatie te identificeren. Omdat we de AI daarnaast ook getraind hebben op best practices rondom optimalisaties is hij in staat om dataonderbouwde eh verbetersgesties voor te stellen. Oké. En wat kunnen merken daar dan mee? Ja, nu eigenlijk al best wel veel en straks denk ik nog veel meer. Dus op dit moment helpt het team om sneller problemen te identificeren en aan de slag te gaan met voorgestelde oplossingen. Op dit moment zijn we de AI aan het uitbreiden waardoor die ook in staat is om zelf de test te ontwikkelen en op termijn misschien zelfs de implementatie daarvan ook te doen. Op die manier is de AI in staat om op een schaal te testen die voor veel merken op dit moment simpelweg eh onhaalbaar is. Duidelijk. Oké, niet afwachten, maar doen dus, want wie vandaag begint loopt straks voorop. Wil je meer weten? Ga dan naar deagency.com/aai report en tot volgende week. [Muziek] Een jaar 25 geleden maakte de wereld kennis met de Asimo robot van Honda. Journaals openden ermee. Het zag eruit als een soort astronaut met een rugzak en hij kon trappen oplopen, zelfs een beetje voetballen. En mensen waren nogmaals 25 jaar geleden, volledig weggeblazen. Maar wat weinig toen doorhden was dat die robot aan een kabel hing, amper 10 minuten batterij had en volledig voorgeprogrammeerd was. oftewel hij reageerde helemaal niet op zijn omgeving. Het was een soort science fiction poppentheater en niet meer. Maar nu wie door testhallen loopt in China kan zomaar een slungelig figuur van metaal en kunststof tegenkomen die dozen aan het stapelen is. Zonder kabel, zonder operator die dat ding bestuurt met een afstandbediening. Gewoon aan het werk. We praten in deze podcast veel over hoe AI kenniswerk overneemt van schrijvers, programmeurs en grafische ontwerpers die allemaal terecht bezorgd zijn. Maar dat gesprek gaat over bits, over pixels en teksten op een scherm. Vandaag gaan we het hebben over atomen, over een machine die niet alleen je tekst kan schrijven, maar ook in de toekomst misschien wel je huis kan schoonmaken of je oma uit bed kan tellen of zelfs oorlog kan voeren fysiek aan het front. Het was een grappige vondst anderhalf jaar geleden. Een Amerikaans bouwbedrijf had een billboard opgehangen op een bouwplaats in de trand van onder indruk van AI: "Je ziet chatipt niet zo snel een gebouw bouwen." Maar bij deze technische revolutie zouden niet alleen kantoorklerken aan de beurt kunnen zijn. Want ondertussen wanen praktisch opgeleiden zich onterecht veilig voor de gevolgen van AI. We staan op een kantelpunt en er is geen handleiding. AI blijft niet langer opgesloten in een scherm. Het zal je gaan aankijken, bewegen door je keuken, door je woonkamer, door je slaapkamer. Het tilt nu al dozen, maar over een tijdje misschien ook je kinderen. En dit is waar we het vandaag over gaan hebben. Over hoe AI uit onze schermen kruipt en een lichaam krijgt. Over de beloftes, de angsten en wat dit betekent voor ons allemaal. The robots are coming, zeiden ze altijd in Hollywood. Maar dat klopt niet. Ze zijn er al. Oké, Wiet. Over 10 jaar werken de meeste mensen nog maar twee dagen per week. Robots en AI doen de rest. Was getekend Bill Gates in maart van dit jaar. Wat denk je als je dat hoort? Ehm dat loopt wel los, maar er is wel iets aan de hand. Ja, je gelooft het niet? 10 jaar hè. Ehm nou ja, goed. Er gaat er gaat een hoop gebeuren in die 10 jaar. Absoluut. Ja, het is wel een beetje mijn tijdslijn ook waar ik vaak op zit. Verder kijk ik ook niet meer, dus dat is het. Maar je zegt dus eigenlijk dat je het met Bill Gates eens eens bent. Ik heb denk dat we deze tijd dat we dit even moeten gaan gebruiken om dat te nuanceren, denk ik. Waar wel, waar niet, zeg maar. Oké. Nou, we gaan het vandaag eh in detail hebben over het fysieke aspect van de AI revolutie. Want tot nu toe hebben we het heel veel gehad over eh dingen die via een scherm of via audio tot je komen, maar in ieder geval alles wat door een internetkabel kan. En we gaan het vandaag hebben over de vertaling naar ja, een lichaam eh met servo's, sensoren en batterijen waardoor zo'n systeem niet alleen maar kan denken, kan uitvoeren, maar ook dingen in de echte wereld kan doen. Wat wat zit er als eerste in jouw hoofd als ik vraag jou te laten voorstellen ehm als AI op een punt is dat het niet alleen maar denkt, maar ook dingen doet in de fysieke wereld. Waar denk je dan als eerste aan? Nou, stapsgewijs zijn het een soort van losse ledemmaten. Eh dit is het wel daadwerkelijk al zo in de fabrieken, hè. Dus je zou kunnen zeggen dat de oude auto-industrie productiestraten met die grote robotarmen eh die kunnen lassen en kunnen eh schroeven et cetera. Dat is natuurlijk al heel lang zo. Een soort, maar dat zijn in essentie hele grote armen hè. Dus dan heb je al een ledenmaat. Alleen die werden en worden vaak aangestuurd in een ander paradigma. namelijk die hebben een hele route geleerd en eigenlijk geprogrammeerd. Dat is dat is de ja, dat is wat Google Translate was tegenover wat chatGPT nu doet, hè. Dus het voelde al een beetje intelligent en cool dat het kan vertalen, maar de technologie achter Google Translate was niet wat nu chatt is. Hm hm. En eigenlijk die grote robotarmen, daar zat niet een al te snugger brein achter. Maar die armen zelf die konden al wel eh op heel fijn detail eh lassen. Die hadden servomotoren die eigenlijk de punt van die robot naar een naar een dartboard konden sturen en precies de roos konden raken. Dat hadden we al zelfs eh opereren met het Absoluut. Ja. Eh en zelfs opereren op afstand door een arts die dan een die dan teleoperated. Dit dit hebben we eigenlijk al. Ja. Dus je bedoelt de mechaniek van de daadwerkelijke ja de arm of wat dan ook de ledemaat is met een beetje fantasie. Dat is er allemaal al. Ja. Ja. En eigenlijk wil je, want je hebt natuurlijk nodig ehm ja om eigenlijk de eh ja het finger speed gevoel van de mens. Dat hebben die Duitsers mooier gezegd dan wij ooit. Ehm omdat er zijn heel veel plekken waar voorheen mensen werkzaam waren. Eh waar we inmiddels al robotica hebben, want de automatisering is al gebeurd, hè. Die krijgt het namelijk heel vaak terug vanuit publieken waar ik voor sta als ik praat over robots dat er dan altijd iemand zegt: "Ja, jongen, zit je niet op te letten. Dat is er toch al." En dan probeer ik uit te leggen dat er nog een best wel een substantieel deel is. Bijvoorbeeld de raamrubbers bij auto's over het algemeen worden nog door mensen gedaan. Want dat is nou net eventjes een exponentieel moeilijker ding dan een deur lassen. Ja. Dus als ik je goed begrijp is de kritiek die mensen dan op jou geven als jij zegt robots gaan de wereld overnemen is dat ze zeggen: "Ja, maar er zijn Nee, nee, wacht even. Er is iets aan de hand van robot heel plat." Ja. Oké. Maar robots, er gaan er gaan meer robots praktisch werk doen. Eh dan zeggen mensen dat gebeurt al en dan zeggen ja, maar nog niet alles. Ja, dus het is eigenlijk het hele Kijk, als er een bepaalde taak eh te vervangen is door een robot die die kan herhalen, dan is het best wel eh waard om zo'n hele complexe taak, een hele specifieke robot voor te ontwikkelen. En dan hè en dan ga je dat is ook wel eens wat wordt gezegd in in productie. Sommige bedrijven daarbij is eigenlijk het eindproduct bijna niet meer hun product, maar de productielijn het product als je begrijpt wat ik bedoel. Hè, dus de grootste innovatie is hoe ze hun product bouwen. Nou, dat heeft ermee te maken dat je dan dus zegt: "Nou, het is ons eindelijk gelukt hoor. Raamrubbers, we hebben de raamrubber robot gemaakt ofzo, maar dan heb je iets heel specifieks. Dat kan je niet op andere plekken inzetten, et cetera." Dus als je door zo'n fabriek loopt, ik loop er alleen maar virtueel doorheen op YouTube, waar nu auto's gemaakt worden, zie je megael robotica zeg maar. En ook eh megatronics, echt gigantische eh platen worden daar geslagen, et cetera. Alleen daar zie je ook nog een hoop mensen rondlopen. Hm hm. En dat is niet per se omdat de eigenaar van die fabriek zegt: "Ik heb er graag een paar mensen bij." Nee, vind ik gezellig. Ja, dat is leuk. Is gewoon fijner. Ja, hè, want het is vaak ook gevaarlijk, hè. Er lopen allemaal gele lijnen over de grond, want je mag daar niet bij overal spatchermen, zodat er geen vonken in je gezicht komen. Het is best wel een serieuze fabriek bij. Fabrieken worden ook is zijn op hoog tempo de afgelopen decennia verplaatst vanuit Nederland omdat er elders goedkoper arbeidskrachten video's over vinden. Dat zijn ook niet echt per se prettige plekken over het algemeen. En ehm daar is het nu zo dat eigenlijk eh ja de de ambitie eh al langer is geweest bij een substantiële groep industrialisten om ook die rol daar van die laatste mensen eh soms eh eh dat dat die geautomatiseerd kan worden. En daar heb je dus veel meer voor nodig dan een paar armen. Ja. En wat is dan wat is dan de Want je zegt eigenlijk heel veel van die armen zijn er al en misschien ook wel benen of misschien wel of een soort van eh ogen en oren. Maar wat is dan nu de wat is dan nu daadwerkelijk anders door de komst van AI? Nou, dat je eigenlijk als we als we onder AI beschouwen de multimodale omnimodellen zoals een O4, Gemini en Cloud dat die modellen omdat die eigenlijk een soort menselijk brein simuleren eh nadoen, hè, laten we het daar even bij houden, kunnen die ook beeld pakken, daar objecten uitdedcteren, eh plannen interpreteren, eh daar weer nieuwe plannen voor schrijven en ook als ze weten wat een servo motor is de juiste commando sturen naar een motor waardoor je dus eigenlijk een soort van eh spin in het web krijgt die eh heel veel verschillende vormen eh modaliteiten van informatie tot zich kan nemen om daar vervolgens weer acties uit te uitvoeren. Hè, dat is een soort van meest platgeslagen robotische versie van de mens, hè. Dat kun Wat kan er dan meer dan wat er nu kan in een autofabriek? Ehm nou, wat er in essentie eh kan is dat je ten eerste een eh robotisch platform hebt. Dus dat is iets wat kan bewegen door de fabriek. Hè, dus de Boston Dynamics die we kennen van Spot. Dat is dat gele hondje die al jarenlang eh YouTube rondgaat, zeg maar. Ja, dat zijn die enge YouTube video's van die robot honden die ze onzelf tijd een trap in hun buik geven en dan blijven staan. Nou, Bosson Dynamics was daar destijds altijd ja, een beetje die had de gaaste video's om het even helemaal plat te staan. Maar wat je ook bij hun ziet en dat zie je nu ook op hun product page is dat humanoids, daar gaan we het straks verder over hebben, die die staan op hun research tab, hè. Dat staat bij research bij hun. Want daarvoor staat een hele productlijn met allerlei platforms. Namelijk een soort rijdende eh grasmaaier met een arm op zijn rug of eh een grote grote rumba met een hele grote arm op zijn rug die bijvoorbeeld dozen uit vrachtwagens kan pakken om die dozen vervolgens met zuignappen uit die ding te trekken en dan op een lopende band te zetten. Allemaal plekken waar mensen stonden. En dan kan je zeggen: "Is dat nou een humanoid?" Eh nee, maar het is ook niet meer die arm eh die op een vaste plek Ja. Oké. Dus je bedoelt dit is dan een dit is dan een soort van robotstofzuiger met een arm die een pakket van A naar B kan brengen. En daarvoor moet moet dat ding kunnen begrijpen hoe de hoe de omgeving eruit ziet. Ja. Het moment dat die arm gaat rijden, om het even heel eh concreet te maken voor de verandering, hè. Die die arm gaat door die fabriek heen rijden. Dan moet je ineens mensen ontwijken, want die lopen daar nog steeds. Weten wat de fabriek is, waar je in de fabriek bent, wat je wel en niet mag aanraken, hè. Of je de juiste doos te pakken hebt, of je die doos wel kan dragen. Nou, enzovoort enzovoort. Want eigenlijk eh pak je een hele gecontroleerde arm die de hele dag hetzelfde deed. Die geef je een stuk vrijheid en daar komt een hoop intelligentie bij kijken. Ja, er is dus echt wat aan de hand op dit gebied, want al die losse elementen van robotica, daar is daar zijn de afgelopen decennia heel veel eh sinds sinds die die Honda Asimel robot is er een hoop gebeurd. Al die al die elementen, die losse elementen zijn beter geworden. En die hersenen bestonden, als ik het goed begrijp, uit een soort van losse ja, alsof als alsof het losse elementen waren die niet samen een brein vormden. Dus ze praten niet in realtime met elkaar. Eh en daarnaast waren er ook allerlei beperkingen zoals dat ze dat de batterijduur bijvoorbeeld kort was, waardoor ze maar een paar minuten konden opereren in plaats van uren. Nou, daar heb je natuurlijk geen reet aan in een in een in een daadwerkelijke fabriek. dat ze sterk leunde op teleoperaties. Zoals dat met zoals ze dat met soort van operaties dat een arts aan het eh of een chirurg bezig is met een robot het heel normaal vinden dat dat via teleoperatie gaat. oftewel, er zit een mens de dingen uit te voeren. Ehm de optelsom van al deze dingen maakt dat ongeveer 9 jaar geleden nog niet een miljoen dollar geïnvesteerd werd in start-ups die alleen maar gefocust waren op humanoids. Oftewel eh de robots waarbij dit allemaal bij elkaar gebracht wordt, namelijk mensachtige robots met AI in hun hoofd, was 10 jaar geleden eigenlijk gewoon een nietbestaande sector. Maar vandaag ehm is het bij de start-ups beland in plaats van bij de grote laps en maakt de CEO van Nvidia de dikke claim. Humanoid robotics is likely to be the next million multitrillion dollar industry. The multitrillion dollar industry. En ook Sam Oldtman van Open AI is dit soort sentimenten aan het echou op dit moment dat hij zegt: "We hebben het nu over AI en over wat dat gaat betekenen voor ehm voor kenniswerk." Maar begin met nadenken over wat eh wereldmodellen waar we het dadelijk over gaan hebben en humanoids gaan betekenen voor de mensen. Waarom is de huidige belofte van humanoids, want laten we daarover gaan hebben, nou echt zo anders dan die vorige eh ja, robotbeloftes, zoals we die al 25 jaar nu zien? Nou, ik denk dat ehm ik ben op zoek naar een metafoor. Ik ga mijn best doen. Ik ga ik ga het anders doen. Als je nu Ik heb Asimo gezien in Japan, want dat wilde ik. Ik weet niet. Heb je Asimo gezien toevallig? Video zoiets. Oh nou, ik ben er geweest. Eh want die wordt die ik weet niet of dat nu nog zo is, maar een aantal jaar geleden kon je naar een soort van plek toe en dan kwam Asimo oplopen op het podium en wij allemaal klappen. Maar dan sta je dan zit je dus te klappen voor een Efteling attractie. Foody scripted. Dat ding. Wat bedoel je met fooly scripted? Nou, die robot heeft een pad wat hij bewandelt. Die gaat op een gegeven moment staan zwaaien. Maar die ziet ons niet. Nee, die is niet met ons bezig. Die is helemaal nergens mee bezig. Alleen maar 3 me naar voren, arm omhoog, zwaaien, draaien, teruglopen. En trouwens hij zei: zoals een kind Lego kan programmeren. Gewoon drie stappen vooruit en dan zwaaien. En dan draaide die een MP3 af. Hello, I am as M. Dat was niet eens text to speech. Nee, het was gewoon een MP3. Oké. Ja. W. Nou ja, een waf. Absolut een waf. Dus dat dat was dat. Maar zou je precies die asimo pakken? Ja. En dan zeg je eh wat normaal het script is wat hij afloopt gaan we door chat piti laten schrijven. Jaè. Ineens gaat hij dan al exact dezelfde robot het podium zelf overkunnen. Nou het cameraatje sluit je aan op eh Gemini Live. Ja. Dan zegt hij: "Ja, ik zie publiek zitten." Je geeft hem eh het is het eh advanced voice mode via een API. Je geeft hem eigenlijk gewoon wifi. Hm hm. zelfde robot, dan kan je eigenlijk daar ineens soort van telle operated by AI om het lekker complex te maken. Als je maar een bruin brein buiten zichzelf geeft, hoeven die robot verder niet aan te passen. Dan gaan we hem live aansturen vanuit iets slimmers. En dan zou je daar met exact dezelfde robot ineens een veel interessantere presentatie kunnen hebben. Hij komt oplopen en hij zegt: "Zo druk met een kinderklas hier vandaag. Ik zie jullie zitten." Hij wijait er naartoe, zwaait en zeker jij daar vooraan. Haha, leuke rode shirt heb je. Rood shirt heb je aan. Lekker weer hè jongens buiten. Hij doet even een tool call naar de weather API. Ik bedoel ineens kan dat allemaal. En dit is ook mijn eh één van mijn nou ja eh frustraties. Het is op dit moment eh best wel ingewikkeld en dat gaan we proberen uit te leggen in deze aflevering eh met moeite nog goed te begrijpen voor mensen van huh, waarom zijn dingen dan nu ineens anders of beter en waarom kunnen dan nu ineens dingen? Omdat de software en het brein en de intelligentie versus de hardware, namelijk die servomotoren, dat hij kan lopen, dat hij niet omvalt, et cetera, die uit dat hij kan voelen, voelen, dat hij goed kan zien. Dus al die al die menselijke percepties voor taal, beeld en geluid en voelen dat dat allemaal ja, op é of andere manier samenwerkt. Ja. En dat daar dus ook zeer zeker wel om het nog lekker in nog complexer te maken natuurlijk wel ontwikkelingen zijn geweest sinds Asimo hè. Sinds ik bedoel de de humanoids eh die je rond ziet rennen letterlijk van Unitree hè, die gewoon een grasveld, een heuvel overrennen, omdraaien, taekwando doen en dan weer terugrollen en dan zwaaien naar je. Dat is wel even wat anders dan Asimo. Maar dat mag ook wel met de tijd die er tussen die twee robots zit. Je bedoelt al die losse elementen in de hardware zijn ook anzig verbeterd afgelopen 25 jaar? Tuurlijk wel. Want en waar gaat het het meeste om uiteindelijk? Eh eh vaak is dus die eh bewegingsvrijheid en de handen namelijk de mogelijkheid om heel veel verschillende objecten op te kunnen pakken zonder ze kapot te maken en weer neer te zetten zonder ze kapot te maken. Bijvoorbeeld daarvan. Nee, stel de meest dun geblazen theepot of een ei. Ja. of een ei. Dat moet dan vervoerd worden. Dat moet op herkend worden, opgepakt worden, vastgeknepen worden en ergens neergezet. Dat is allemaal echt wel beter geworden. Dat komt eigenlijk er nog bovenop. Dus we hebben een soort upgrade van het brein, hè, van het bewustzijn tussen aanhalingstekens van de robot zelf. Plus ook nog eens een prettige doorontwikkeling van alle onderdelen, alle ledaten van die robot. En die twee samen komen nu samen, hè. Dus we hebben eigenlijk Asimo 2 qua hardware plus Asimo 100 qua brein, want het was een soort rulebased scripted toneelstukje naar iets wat doet alsof het een soort wezentje is. En als je die dan in één vat giet samen, dan krijg je een soort nieuwe elixer. En dat is eigenlijk waarom humanoids nu ineens een eh aflevering waard zijn op zijn minst. Want omdat eh ik het idee heb dat door die eh trage vooruitgang op het gebied van robotica, door al die eerdere science fiction films en beloftes, daar weer net als bij de zelfrijnde auto, veel overlap tussen dit onderwerp en de zelfrijde auto, terecht heel veel cynisme is wat ik eh eh zo van ze beloven het al 100 jaar, dus ja, ze lopen wel los hè. Oh, komen ze weer hoor een robot in mijn huis. Ja, precies. En ehm tot het en dan tot het moment dat ik filmpjes laat zien aan jou Alexander Clupping die tegen mij zegt: "WiSt, check even of het niet een render is." Hè, want ik sta er Jij laat dan beelden zien van een robot die op een bepaalde manier beweegt en dat ik dan denk dit is CGI. Dit is niet echt. Ja. En dat jouw intuïtie, want ik heb daarna over nagedacht, dat zei jij een aantal weken geleden tegen mij van wat gebeurde daar op dat moment? dat ik zit veels te diep erin waardoor ik dat filmpje die was wel echt Maar eigenlijk jouw CJI intuïtie klopt want die beweging die daar gemaakt wordt zeg maar net als dat we nu van die balletjes op mensen plakken en dan eh laten we ze een rondje rennen of dansen en dan daarna gaat een CGI in Star Wars ofzo gaat een vervangend 3D object in die film dat nadoen die eigenlijk aangestuurd wordt door een mens erachter. Ja, hij doet de mens na. De werkzaakte beweging van een mens doet hij na. Ja. waardoor eigenlijk zo'n Ork ofzo in Lord of the Rings een heel organisch menselijke beweging maakt. Dat is logisch, want die is opgenomen van de 3D informatie van een daadwerkelijk mens. Juist. Die robots die jij ziet bewegen in die video's, die doen bewegingen na. in dit geval niet meer opgenomen, maar die doen bewegingen op basis van een bewegingsmodel getraind op mensen en intuïtief bij jou en bij velen, want ik laat die kungfu eh eh schoppende unitary robot vaak aan mensen zien van word even wakker, we zijn Asimo wel even voorbij. Dat die bijna altijd zeggen: "Dit is CGI." En dat ik dan zeg: "Ja, maar niet op de manier dat jij denkt. Het is een fysieke robot in de fysieke ruimte die jou een schop zou kunnen geven als je ernaast zou staan als hij niet oplet. Die bewegingen doet die eigenlijk niet van de robot zijn, maar die zijn geïnspireerd op heel veel beelden van eh Aziatische vechtkunst. En daarom triggeren wij erop omdat we denken: "Ja, nee, maar dat ding is aan het faken en dat nou het is ook omdat de bewegingen inderdaad zo snel gaan, want wij zijn gewoon gewend dat robot en dat is ook gewoon de cultuur waar we waar we in leven, de cultuurproducten die we consumeren. Er zijn robots toch nog steeds." Ja, kijk, als je aan gemiddeld mensen op straat vraagt: "Wat is een robot?" Dan krijg je zeg maar: "Er zijn nog acht wachtenden voor u." een beetje zeker. En een en een en een het idee het het idee dat een robot dat je dat hij gewoon normaal kan lopen zoals een mens kan lopen. Dat voelt nog heel ver weg. Tegelijkertijd kwamen er allerlei video's, vooral uit China waarbij robots dus een soort van ja eh hoe moet je dat nou zeggen? een soort van snelheid van bewegingen en nuance van bewegingen hebben die dus fake voelen. En jij zegt: "Het is fake in de zin van dat dat ding niet zelf heeft bedacht hoe die moet bewegen zoals dat voor ons heel onderbewust gaat. Maar het is ook geen computer gegenereerd beeld. Het is wel een robot die echt in de echte wereld leeft. Het is een computer gegenereerde beweging." Ja. En het is dus ook niet eh dat zoals je die die eh Asimo nog zei: "Ga 3 me lopen en ga daarna zwaaien." Nee, het is hij heeft als het ware geïnterpreteerd wat alle menselijke bewegingen zijn door naar video te kijken en dan maakt hij zelf daar een soort mix van. H het is alsof alsof hij het leert en dan het opnieuw doet zonder het exact na te doen. Begrijp ik dat goed? Ja, zeker. En ik denk als je daar meer gevoel voor wil krijgen, er zijn heel veel eh video's te vinden van eh digital twins, oftewel robots in een droomwereld die door Nvidia eh eh unit met een dromwereld. Dus zie je meer een computergame voor je. Het ziet er ook zo uit, een soort van een beetje lege 3D wereld hè. Als alsof iemand die eh een architect in het computerprogramma zit. grijze achtergrond, witte lijnen op de grond, een overduidelijke computer gegenereerde wereld met daarin een hele ruwe versie van een robot die lijkt op zo'n Unitree robot, maar het is het is het is nep en dat niemand probeert ook jou te overtuigen dat die video echt is. Het is namelijk gewoon een render. Wat gebeurt daar? Daar staat een zo ehm compleet mogelijke twin, e een tweeling in een digitale wereld, digital twin, van die Unity robot met zwaartekracht erin en servomotoren, allemaal nep. Allemaal in een simulatie die dan eh met 10.000 broertjes van hem, vaak staan er nog 10.000 andere robots omheen. Een soort leger staan ze naast elkaar. Ja, ziet er best wel indrukwekkend uit. Maar goed, het is ook het is een game hè, dus valt allemaal wel mee dan nog. en die dan eigenlijk opdrachten krijgen van eh joh, hier heb je een eh hier heb je heel veel eh beweging. Krijg je ze eerst te zien als het ware die gaan niet met elkaar in de bioscoop zitten voor de luisteraars, maar stel je even voor. En dan wordt er gezegd: "Ga van A naar B. Er zit een soort berglandschapje tussen. Succes. Zie maar hoe je er komt." En jij hebt zoveel mensen zien struggelen op stenen. Doe ze maar na. Leer maar. Hè, dus en als één van die robots dan met twee benen niet zonder op de grond te vallen een paar stappen verder komt, gaat de rest slapen. Echt zo die dan wordt die ene die het meeste succes heeft behaald om één steentje omhoog te lopen gekopieerd en laten ze gewoon evolutionair keer voor keer honderdizenden keren desnoods die robot struggelen over die rotsen heen in een virtuele wereld tot die aan de andere kant van die doos of aan de andere kant van die bergrotsen op twee benen staat zonder te vallen. En hoe brengen ze dan die virtuele wereld zeg maar hoe brengen ze dan die rots dat rotlandschap in die virtuele wereld? Dat was gewoon een verzonnen landschap hè. Dus oké. Dus als het goed begrijp heb je dus een soort game weergave van zich 1000 robots die een soort van formatie bij elkaar staan. De iedere robot heeft zijn eigen rot belevingswereld zou je kunnen zeggen. Ja. En dan is er dus een computergenereerde omgeving met allerlei obstakels, rots of wat dan ook. En dan zeggen ze dus tegen die 1000 robots tegelijkertijd: "Navigeer daaroverheen." Dan mogen ze allemaal individueel bedenken op basis van wat ze allemaal geleerd hebben over de wereld. Ja. Hoe ze eroverheen zouden komen. En de mensen en de robot mensen de robots die dat lukt, die mogen blijven doorgaan en de rest moet gaan slapen. Ja. En dan komen er ja, ik zeg ook even slapen voor het gemak. Eh ja, die zijn af. Ja, dit is die kan je dan hè, dus zie dit is eigenlijk eh ja, een soort eh reinforcement learnings. Je bent je bent ze ook een je geeft ze ook als het ware een prijs hè van ja, zo jij bent het vers gekomen en hey het is een soort Hunger Games, de rest doei. Ja, het zijn audities. Ja. En dan iedere keer start het opnieuw maar met de slimste van de vorige groep hè. En dan als je dan blijft gaan op een gegeven moment, want waarom eh doen ze dit in die laboratoria? Ehm digital twinning doe je zodat die dure robots die jij hebt staan niet constant tegen de muur aan rennen en je nieuwe moet bouwen. Gewoon duur en echt zonde. Je ziet je hebt best wel wat filmpjes online dat die robots op hol slaan. Nou gelukkig gingen ze aan kabels is niet best. Best wel stevige robot ook hè. Dus daar wil je niet eh klap van krijgen. Is niet best. Dus dat doe je liever in een soort veilige eh wereld. En dat kan dus blijkbaar je kan ze laten oefenen in die veilige weten. Absolut. Dit werkt dit is al lang eh feit zeg maar. Ja. Eh sterker nog, oké, stap voor stap. Je doet je doet daar dat trainen, dus je traint in een soort droomwereld, noem het, simulacrum van de daadwerkelijke wereld. Maar daar is wel zwaartekracht en die robot moet goed genoeg kloppen, anders heb je niks aan die training, hè. Ja, hij begrijpt die die gamewereld begrijpt heel goed wat die fysieke robot die datzelfde bedrijf heeft gemaakt kan allemaal. Hoe snel zijn vingers kunnen bewegen en et cetera. Ja. En in plaats van dat je dan dus een parcours gaat uittekenen over die rotsen als mens gaat proberen te begrijpen wat lopen eigenlijk is om vervolgens stap voor stap dit gebeurt all lang niet meer hoor maar even voor de andere kant van het spectrum van heel vroeger asimotijd ga je gewoon zeggen luister een baby ga je ook niet een boek geven als die die leert kruipen zeg maar is daar zit een soort aanleg in plus eh oefening dan laat je die robots eh oefenen. Het voordeel van die digital twinning is dus punt één, scheelt een hoop hardware en gevaar eigenlijk. Eh punt twee, waarom zou je die oefening daar in die in die eh droomwereld op menselijk tempo doen? Ja, precies. Het gaat natuurlijk veel sneller en voel de tijd gewoon vooruit. Dus 1000 tegelijk, 1000 keer zo snel voor het gemak. Oké. En hoe want er is dus een er is wel iets wat die robots in die game van de echte wereld begrijpen, maar wat hebben ze dan precies meegekregen waardoor zij überhaupt begrijpen wat lopen is? Nou, dat begrijpen ze eigenlijk niet. Dus je ziet eh als je die video's ziet, ik vind het altijd een soort ongemakkelijk om naar te kijken, want in eerste instantie liggen ze op de grond te rollen, echt te rollen. En hun en hun eigen enige opdracht is dan: "Wie kan zijn hoofd het langst hoog houden?" En dan gaan ze gewoon hoger dan vanaf de grond zeg maar. Dus het is een grond die kan opstaan. Ja. En lang en dan en dan dus op een gegeven moment liggen ze daar een beetje op de grond te rollen als een soort wormpjes. Heel weird. En op een gegeven moment is er één die heel eventjes omhoog komt en dan gaat de rest weer slapen en dan mag die door en dan op een gegeven moment staat hij en dan is gooien er een bal tegenaan. Dit zie je dus vaak ook in de fysieke films met zo'n hockeystick komen die cllo's er dan omheen om dat ding te slaan. Maar goed, blijf staan. Ja, dus op een gegeven moment is het eh ga staan, blijf staan, blijf staan met dingen die tegen je aankomen. Wind gesimuleerd, ballen, stokken, noem maar op. Maar dit is echt een spel uit koortsdomen. Gewoon als ik 1000 robots zie liggen die als wormen aan het eh soort van bewegen zijn totdat ze kunnen opstaan. Ja, dit is gewoon echt. Ja, maar dan dus echt ja, het is niet echt, maar we begrijpen elkaar toch? Ja, het is een echte droom. Ja. Nou, en dan op een gegeven moment heb je die eh kijk eh op een gegeven moment zit daar dan eh zo'n neuraal net is dan getraind eigenlijk, hè. Want daarom daarom is die stap tussen Gemini en een robot niet zo gek. Want deze principes worden ook toegepast om VO3 te maken. Even voor de luisteraars zeg maar. Die videomodellen zijn ook getraind en geoefend en hebben prijzen gekregen op prijzen en rewards op betere beelden enzo. Dus dit een soort van evolutionair leren enzo. Dat dat is in de breedte toepasbaar. Maar laten we even bij de robot blijven, anders worden er mensen die vallen van hun fiets. Eh net als de robot. Je moet je even voorstellen hoe die robots op een gegeven moment eh stabiel kunnen functioneren binnen een droom waarbij de zwaartekracht genoeg overeenkomt met die van ons en ook de gewichten van hun onderdelen als robot kloppen en hoever ze kunnen bewegen met hun servomotoren. Al die variabelen moeten kloppen. Anders ben je heel veel tijd aan het kwijt om robotstraat te lopen in een droom. Het idee is en dat lukt dus ook om uiteindelijk een bergstenen random in de echte wereld neer te gooien dan je die robot uit de kast te pakken en te zeggen heel even wachten hoor maat kabel in zijn nek update van zijn droomwereld en dan zeggen loop er eens overheen en dan loopt hij dus over die bergstenen heen. Ja, dat is En dit is zo'n Ja, je hoort het aan mijn aan mijn eh stem. Eh ja, dit is zo groot. Ja, het is echt trainen. Maar is het dan is het dan trainen zoals een mens dat doet? Namelijk een mens heeft hoeft ook niet per se eerst eh een wandelroute gedaan te hebben om die te kunnen doen, maar heeft gewoon eerder in haar leven wandelroutes gedaan waardoor ze die ene wandeling door de Pirineeën ook kan doen. Is het een beetje dat? Ja, het generaliseert dat is natuurlijk ook de hoop, want anders moet je alles gaan oefenen en dit gaat eigenlijk Kijk, wij kijken maar goed, dat is de vergelijking met die auto eh die autorobots is dus niet gegenaliseerd, want die voeren de hele tijd hetzelfde dingetje uit en reageren op voorgeprogrammeerde events. En dit is daar dit is iets totaal. Breekt daar helemaal uit. Ja. En ik denk dat ehm eh ik had net ik had het over Peete Zampers en tennis. Wij als mens trainen ook hè. Je bent als kind ga je naar de tennisvereniging en dan balletje hoog houden, balletje stuiteren, balletje slaan, nog een keer slaan en dan maar oefenen, oefenen, oefenen. Nou, daar ben je dan niet met 10.000 kinderen van jezelf tegelijk. Het moet allemaal in jou gebeuren en dat duurt allemaal best wel lang, maar je bent aan het trainen en je wordt daar beter in. En als je dan op een gegeven moment een eitje gaat bakken met een pan, kan ik je garanderen dat jij die pan met die pannenkoek of dat eitje ook beter vast kan houden, omdat je dat record beter kan vasthouden, hè. Dus dat generaliseert het vasthouden van een object in je hand. Ja. En dat je leert om hem bij de hendel vast te pakken in plaats van bij de zijkant. Want die die robots die dat doen mogen gaan slap mogen gaan slapen. Ja, die ging slapen. Of of of En dit gebeurt dus ook wel eens. Dit gebeurt dus ook wel eens even als eh grappige sidetrack dat ze dus terugkomen om te kijken in de droom en dat er dus een robot soort van op één enkel aan het rondspringen is. Want dat is best wel dat werkt, weet je wel. Die komt heel hoog door op een hele maffe beweging te maken, zeg maar. Maar dan moet je en als je dat dus hebt dat hij dus gaat optimaliseren richting een plek waar je denkt: "Oké, dit zou in de fysieke wereld een soort hele rare kangero zijn die je nu bent geworden." Dan heb je dus niet goed. Dan moet je dus zeggen: "Wacht even, het moet wel op twee benen, hè. We hadden hadden blijkbaar jou nog even één extra regel moeten geven wat je nu Want Ja." Ja, want als als die robot zelf echt dingen mag bedenken, dan gaat hij ook dingen doen die mensen eigenlijk helemaal niet logisch vinden, maar waarmee die wel zijn doel alsnog zou kunnen bereiken. Ja. En dit gebeurt dus ook heel vaak in andere domeinen van schaken of het spel go dat daar de meest wouze moves worden uitgevonden. Daar waar wij eerst om lachen en daarna denken: "Dit dit dit is eigenlijk best slim bedacht door die robot. Ze pakken gewoon een eh een buitendeur zeg maar." Maar dit is wel een interessant punt, want die die robot die humanoids, daar zit niet voor niks het woord human in. Er is dus een deze robots anders dan robots zoals we die gewend zijn uit fabrieken waarbij eigenlijk één deel is genomen. Een arm of eh ja, vingers of of wat dan ook de menselijke metafoor is, is een humanid probeert echt een soort van menselijk lijf na te doen. Waarom hebben die Chinese bedrijven die nu vooroplopen met deze ja, deze robotvolutie, waarom passen die dan de menselijke vorm toe? Want je zou ook kunnen zeggen dat beperkt juist in een wereld waarin als die robots aan het dromen zijn eh de meest gekke trucs kunnen uithalen die eigenlijk veel ja beter zijn dan hoe wij gemaakt hebben. Ik denk dat ik denk dat ehm is die gewoon marketing ook absoluut want het doet iets anders met ons. Dus je hebt jouw soort van eh argwaan bij humanids is terecht. Want het het investeringsgeld gaat gewoon eerder stromen op het moment dat jij iets een conf laten doen ergens. Want op één of andere manieren is het dan dit zal dit is waardevol of dit is krachtig ofzo. Dat dat weten we dat dat weet dat wordt niet eens meer bevraagd. Kijk, een mensachtige. Kijk. Ehm maar Boston Dynamics bijvoorbeeld heeft dus ook humanoids, maar echt een beetje gek gezegd als een bijzaak op hun website van hey wij doen dit ook hoor, maar tegelijkertijd zijn we ook gewoon een bedrijf die al daadwerkelijk robots verkoopt. Namelijk armen op stofzuigers. En dat die zijn namelijk heel handig. Ja. Als je in een magazijn eh werk moet doen. Ja. Ja. Ja, daar kunnen we al genoeg waarde mee toevoegen. En eh maar goed, we doen ook wel mee met humanoids. Wat is dan de plek van de humanoid in de wereld? Zou je kunnen zeggen, we leven in een menselijk materiële cultuur. Oftewel deuren hebben een bepaalde grootte, handendels hebben een bepaalde verwachtende hand. Eh er zijn allerlei technologieën, technologische objecten in de wereld van eh fysieke gebouwen tot en met heggenscharen. Ja. die allemaal aangepast zijn op en gevormd naar de mens. Dus je wil eigenlijk iets bouwen op zijn minst één van de robotvormen, want het is gewoon één van de robotvormen. Auto's zijn robots hè, stofzuigers zijn robots. Eh allemaal prima. Één van de robotvormen is de humanoid vorm. En de humanoid vorm is het meest compatible met het bestaande technologisch materiële cultuur van de mens. Wauw. Jij kijkt eigenlijk nu naar de wereld als in wauw. Hier staan allemaal objecten in deze wereld die zijn aangepast voor menselijke vingers en zijn aangepast voor armen. En gaat er niet vanuit dat je kan reiken naar een supermarktplank die hoger is dan de gemiddelde mens. Oftewel onze hele wereld is aangepast aan mensen. Ja. En dat betekent dus dat als je daarmee wil interfacen, want dat is het de wereld zoals hij nu is, is een auto met een stuur dat gemaakt is voor mensen of een lift met knopjes die gemaakt is voor mensen. Daar als je wil dat robots daarin kunnen helpen, moet je die robots dus ook zo maken. Dat is dat is logisch om ze menselijke handen en voeten te geven. Ja. op dezelfde manier als dat agents niet een menselijke avatar zouden hoeven hebben of Engels zouden hoeven spreken. We zijn daar ook dat aan het doen, want we willen interfacen met de menselijke wereld, hè. Dus we doen het in het digitale doen we het nu al in ieder geval dat ja, ze zouden ook bliep bliep bloep bloep op de achtergrond kunnen doen, maar dat dat werkt niet, want wij willen ermee kunnen praten. Ja. Of zich uiten als dier, weet ik veel. Ja, en ik bedoel en die parkeer ik nog even voor een verdere aflevering bij deze beloofd. Het zwaatjes gepland. De vraag is sowieso moet AI zich eigenlijk wel uiten als een agent of een humanoid? Daarmee bedoel ik niet ethisch ofzo, maar ehm we zouden er ook voor kunnen kiezen dat we zeggen wij doen die mensen dingen fysiek, want daar is de wereld is fysiek met hendels en deuren enzo. Laat ons dat maar doen en laat AI maar gewoon hele goede eh verkeersborden aansturen en eh tuinen onderhouden met kleine eh roembaar robotjes. Alles behalve de menselijke vorm. Maar goed, eh wij gaan er nu vanuit dat logisch is. En als je dan eenmaal eh dus je je er zijn dus robots die zich dan stel dit wordt allemaal eh die servo's, die motoren, die die die de tactielen van die huid waardoor die heel precies kan bewegen, dat wordt allemaal zo goed of is in sommige gevallen al zo goed dat je het combineert met de grote taalmodellen zoals die nu zijn of de omnimodellen moet ik eigenlijk zeggen die ook beeld kunnen herkennen waardoor de ogen van die robot ook daadwerkelijk door die AI begrepen kunnen worden en dat hij daarop kan reageren. Ehm dan heb je dus mensachtigen die kunnen kijken en horen als een mens, ook kunnen voelen als mens en kunnen meedoen in onze voor mensen geoptimaliseerde fysieke wereld. Is dan eh die vorm van ehm van eh van humanoids? Is dat niet ook gewoon een nadeel omdat ze weet je alle nadelen van mensen krijgen ze er ook bij? Dus we zijn mensen zijn instabieler dan een eh iets op vier wielen. Eh wij wij zijn wij zijn sneller om te duwen dan een eh maar je ziet je ziet dus ook bij Unitree dat één van hun form factors is dus het hondje wat spot is bij Bossen Dynamics en bij hun heeft hij een of andere codenaam en daar hebben ze dan ook nog eens wielen onder gezet nu want er zijn geen dieren met wielen in ieder geval bedankt. Ik hoor het. Ik hoor Er zijn geen dieren met wielen mensen. Ja, er zijn wel dieren met tandwielen erin trouwens. Zoek dit op. [&nbsp;__&nbsp;] bizar. Van bot gemaakt. No joke. Maar goed, even dat gezegd hebben. Een soort kaaktandwiel is dat volgens mij. Whatever. Geen dieren met wielen. Ehm maar de het wiel wat wij hebben uitgevonden, hè, hebben wij gedaan. Apap met kleren aan eh is best wel bizar als je dat combineert. Dus dan krijg je eigenlijk een eh een robot met vier poten die dus stuk stabieler is dan die bipedles die wij zijn zeg maar op twee poten. Ja. Die ook nog eens snelheid kan maken, maar ook nog eens die wielen als een soort voetjes kan inzetten. Want als je die wielen stopzet dan worden het ineens gewoon rubber voeten, hè. Dus dit zie je ook ontstaan nu bij Unitree waardoor je een soort hybrids krijgt tussen precies mens en dier. Ja. wat het wat de wat de wat de evolutie heeft uitgevonden en wat wij hebben uitgevonden in een soort nieuwe hybride vorm. En ik moet zeggen dat is ook de video's van Unitree van dat ding zeg maar die vier potige rijdende superc. Ja, wat beschrijft dat eens? Wat is nu de soort cutting edge aan Chinese robot technologie filmpjes die jij hebt bekeken? Ja. En ik denk dus dat ehm voor wat ik kan vinden is, want Unitree ik zeg ik Unitree meteen eh dat is een Chinees robot bedrijf. Ja. En die beetje de DJI van robot zeg ik altijd als je DJI kent van de drones en eh de gimbals et cetera. Als ze zijn ze zijn goed met hun spulletjes. Ja, het is best wel knap wat er allemaal gemaakt wordt. Voelt heel erg als wat Bossen Dynamics voelde. Eh maar goed, in de robotvormen die Unitary heeft zijn spot zal het dus met de vier wielen eh zoals hij bij Bossonnemics heet en eh vier poten met vier wielen die ook trouwens op twee benen kan staan. Ja, hè. Als een soort je je hebt wel eens honden gaan ook wel eens op twee benen staan en katten ook. Nou, dat kan deze ook. Ja, die kan als een soortway. Hij kan ook een soort van tolletjes doen als een soort van acrobaat. Het is bizar. Daar ben ik van onder de indruk ehm en dan wil ik altijd bij zeggen: "Daarmee is niet meteen het oordeel gemaakt. Dit moeten we willen." Maar ik ben absoluut onder de indruk van wat ik daar zie. Onwaarschijnlijk knap. Ja. En eh dat doet mij gewoon nadenken van jeetje wat waarom nu ineens zo snel? En ze hebben hun eh humanoid vorm. Een heel klein eh robotje in verhouding zeg maar. En betaalbaar hè, want in het intro had jij het over je kunt het bestellen en dat dat kan ook. Weet dan wel dat je een robot thuis gestuurd krijgt die in potentie iets kan. Die kan heel vrij bewegen, die kan komen. Die kan ja, de hardware is heel goed. Maar ja, de de software is allemaal nog heel erg in beta en ook heel erg niet in de robot op dit moment. Het brein zit er zit een thing client in om even terug te pakken op vorige week. Het zijn hele dunne breintjes die nu in die robot zitten, niet de dikke breinen. Ja, het is eigenlijk als je nu zo'n Unitree robot bestelt en dat kan gewoon je kan gewoon een Unitary googlen en dan kijken welke types ze hebben. Dan kun je zo'n hond of zo'n mensachtig ding gewoon kopen. Ja. Ja, we hebben ze in de studio gehad bij Eva samen en daar stonden ze een soort van ongemakkelijk als objecten of fans. Ja, maar er staat ook een meneer achter de schermen en die heeft een joystick in zijn. Ja, het is gewoon zoals je een radiografisch bestuurbaar dingetje van de Intertoys bestuurt. Asimo vibes hè, als in scripted. Ja. En ehm alleen laat ik is dat teleoperated? Is dat een gaat dat nog lang een eh een deel hiervan zijn? Want kijk die asimor kijk als je nu een ik probeer me dan voor te stellen. Nu heb ik eh stel je voor die Asimo of sorry die ehm die eh Unitree Robot. Ik koop er eentje. Dat wat kost zo'n ding? 10.000 15.000 voor invoer. Ja, voor invoerrecht. $18.000. Oké. Nou, zeg zeg €20.000 hè is er één voor jou. Ja. Ehm duurt speelgoed, maar heb je Ja, maar ja hè. En dan vervolgens heb je eh heb jij besloten: "Nou, ik wil dat dat ding in mijn huis gaat helpen bij Wat zou nou iets zijn waarbij die qua hardware nu zou kunnen helpen?" Nu, vandaag, nu? Ja. Nou ja, om eerlijk te zijn, ik eh wat jij dan nodig hebt is een of ander ziek Unitary Control Center die een world model heeft. Nee, maar dat bedoel ik niet. Ik bedoel, want daar komen we uit. Maar ik bedoel, wat kan het nu qua hardware? Als je zo'n robot koopt voor €20.000 en je zet dat ding in jouw keuken? Niks. Maar als je met de joystick als je met dan ga je dan ga je een hoop ga je een hoop eh kopjes op de grond gooien. Oké. Ja, dit dit is goed dat we dit bespreken, want dat is dus nu het hele punt. Hij kan lopen en hij kan met zijn armen bewegen. En als we naar YouTube video's kijken kan hij ook weet je dansen en kungfu. Ja, maar dat is dus als jij zegt kan niet als hij als in dat kan niet. Maar technisch zou het kunnen. Maar nou ik denk dat dat het dat het belangrijk is dat je ehm omdat het omdat er ehm als we zeggen kan I dan hebben we het waarschijnlijk over de robot. Alleen omdat die robot komt die komt zonder brein. Ja. Oké. Oké, maar laat ik het dan anders vragen. Stel je geeft dat ding een bezem in zijn handen. Kan hij dat? Kan hij een bezem vasthouden? Ehm ik denk dat hij een bezem kan grijpen als hij een lokaal grijp dingetje aan heeft staan. Waar ik aan moet denken namelijk is de bijvoorbeeld de wat jij eerder zei over hoe Pixar films gemaakt wordt. Namelijk dat er een een vrouw in een studio met een bolletjespak staat. Dat er allemaal microfoon of allemaal camera's omheen hangen die die bolletjes ziet. En dat die animatie die computer vervolgens maakt de perfecte kopie is van wat er in het echte leven is gedaan. Ja. Gaan wij een tijd krijgen voor dat al die AI modellen zo goed zijn dat hij snapt hoe je moet vegen in een huis. dat er iemand in een ander land gaat zitten, zoals er nu drone operators zijn die eh weet je in eh in eh in oorlogsgebieden bommen bommen werpen eh die dan in een container ergens aan de andere kant van de wereld zitten om dat werk te doen. Gaan we datzelfde krijgen met robots? dat er een schoonmaker ergens in een laag lonenland zit die daadwerkelijk een bezem in zijn of haar handen heeft die dan de robot bestuurt die in jouw huis aan het schoonmaken is. Ik bedoel, gaan we dit gaan kan dit technisch zo zijn? Ja, absoluut. Ja. Gaan we dit daadwerkelijk krijgen? Dat weet ik niet. En waarom denk je Waarom twijfel je hierover? Ehm want er zit nog tijd tussen het moment. Want zoals je nu zegt die die robots van €20.000 kan nog niet een kopje vasthouden op dit moment. Ondanks dat het technisch wel. Ik denk dat mijn punt daar was dat dat maakt dat woord teleoperation een beetje complex. Ehm teleoperation, oftewel tele als in telefoon televisie eh via op afstand op afstand dan kan je doen teleoperation by humans of teleoperation by AI. Dat klinkt misschien gek, maar dat is niet zo gek, want zit het is gewoon heel suf om vooralsnog ieder geval die complete hardware voor die AI in die robot te stoppen. Als die heel tijd in jouw huis is, kan je hem net zo goed aan de wifi hangen en het brein buiten de robot brengen. Dat geloof ik. Ja. En dus dit gebeurt nu ook. En daarom worden die robots dus ineens veel beter omdat ze gekoppeld worden aan een beter brein op afstand. Hm hm. Hè, dus eh en dat maakt ook teleoperation zo'n belangrijk feit. Als je namelijk zoals in de presentaties van de Optimus robot van eh Tesla destijds met het event waar de robotxi rondreeden, het waren allemaal fully teleoperated robots. Er was een event een tijd geleden, ik denk een half jaar geleden of iets langer waarbij eh er robots waren die cocktails aan het shaken waren en dat vervolgens inschonken achter een bar en met je spraken. Ja, dat waren robots die hardware allemaal prima onder controle hadden, maar er was een mens die dat ding helemaal fysiek bediende. Ja. En ik heb er nooit beelden van gezien, maar de vraag was: hebben die mensen ook handschoenen aan waardoor ze die cocktail shaker pakken of hè wat teleoperation of begrijpt hij dat deel dat hij dat dat hij dat wel zelf kan? Ja. En dat dat sluit denk ik mooi aan op het punt dat ik eigenlijk wilde maken is dat ehm laten we er even vanuit gaan voor het gemak van de discussie dat de robot die jij thuis gestuurd krijgt een tin is waar alleen maar die alleen maar de hele tijd tegen je zegt: "Connect me to Wi-Fi, scan my QR, connect me to Wi-Fi." Ga ik helemaal van uitwietsen, want dat is mijn iPhone nu ook. Dus dit is voor mij geen nieuws. Top. Het is een cloudbot. Ja. En dan is de vraag: oké, wanneer je hem koppelt aan de cloud, koppel je hem dan aan een mens die daarin eh hè toegang heeft tot jouw robot in een pak zit ergens in een soort telefooncel hè en dan jouw huis begint schoon te maken? En of zeg ik alvast, dus niet of maar en of is het een teleoperation via een omnimodel, namelijk een AI achtig model dat die robot vanuit het datacenter bestuurt. En ik zeg en of omdat je net als wat je nu met zelfrijndende auto's ziet ehm takeovers gaat hebben. Dus op het moment dat er dat de robot er niet dat de AI er niet uitkomt in de cloud, kan een mens het overnemen. En als een mens het overneemt, kijkt de AI weer mee. En als 90% teleoperated is by human hè van jouw robotbedrijf, jouw cloudbot, dat je kan zeggen na een jaar ik haal daar 30% van af. Want er hebben algoritmes meegekeken die hebben de hele nacht liggen dromen over bezems vasthouden en kopjes koffie schenken. En inmiddels hebben die zo lang geoefend in hun evolutionaire broertjes eromheen dat ze het ook kunnen. Want ik heb het over robots omdat dat de eigenlijk het ding is waar we al zijn begonnen met rob eh robots in huis eh die schoonmaken zijn we al mee begonnen. Daarom daar ja daarom daarom denk ik aan de humanoid die een bezem vasthoudt. Ja. En eh het is al voor een paar honderd euro heb je een robotstofzuiger die in je huis rondrijdt en stofzuigt en dan ook nog begrijpt of er katten of hondenkak ligt waardoor je er een rondje omheen maakt. Ehm dat zijn eh dat zijn dus dat is dus een gebied waar wij robots toestaan in ons huis. Die zien er niet uit als mensen, maar ja, ze ruimen wel op en het is een robot. om daar te komen bij een apparaat wat meer kan dan alleen maar de eh vloer schoonzuigen en eh en eh boenen en dat hij meer kan doen, is er waarschijnlijk een tussenfase waarin alleen die AI zelf allerlei dingen doet bij het schoonmaken, maar waarbij die soms dus momenten tegenkomt dat hij het niet begrijpt of iets doet wat niet helemaal goed was. dat dan een mens in een of ander ja, op een of andere plek ergens op de wereld, waarschijnlijk in een laag lonenland, het overneemt en dan die robot op afstand bedient en waarschijnlijk soort van 1000 robots onder zijn of haar supervisie heeft. Ja. En ik denk dat de vraag is dan denk ik is dat eh het is deels live mogelijk hè, technisch mogelijk dat een persoon het overneemt. Dan is de vraag: is het niet handiger om een groep mensen eh de training te laten doen in een soort laboratorium waarin je zegt: "We spelen allemaal na, we trainen daar al die situaties en als we hem down hebben zeg maar." Dus ik moet eerlijk zeg, maar dat zou dus ook kunnen. Dus dan dit gebeurt als in zeg maar eh bijvoorbeeld de handen wat de ledematen worden over het algemeen los ontwikkeld en d is met een auto. Er zijn verschillende fabrikanten. Ik bedoel, het voelt natuurlijk heel logisch om het allemaal in één keer te ontwikkelen, maar neem van mij aan, er zijn handenfabrikanten. Ja. Een een ei oppakken, een ongekookt ei, daar kan je een heel bedrijf omheen bouwen. Zo ongelooflijk goed zijn onze menselijke handen. Ja. En om dat te trainen hebben ze dus een fabriekshal. Ja. plek ieder geval waar mensen waar mensen eien pakken en objecten pakken allemaal naast elkaar eigenlijk die koortstroom die jij net toonde van die 1000 robots naast maar dan mensen naast elkaar dit is hoe dit is wat nu al gebeurt. Mensen ik heb begrepen van de verschillende partijen die handen maken dat zij zeggen we zijn heel veel data aan het verzamelen van mensen die objecten pakken. En omdat we weten welke da data er nog mist in onze datasets, kunnen we mensen heel actief sturen om bepaalde dingen te doen hè. Hendels om te draaien, schroeven vast, schroefbordjes vast te houden, al die eh dat fijne motorgevoel zeg maar na te doen. En dat wordt dan gefilmd ofzo. Ja, opgenomen zoals in Hollywood met die balletjes. Dus doen gewoon talloze stupide taakjes. Zijn mensen nu bezig? Ja, je kan ze stom doen, maar robots konden ze nog niet. Nee. Oké, maar laten we een ei pakken uit een bakje gewoon. Nee, dat daar heb je dus daar heb daar heb je dus hele goede algoritmes voor nodig en hele goede modellen. Ja, maar er zijn dus ook mensen die op dit moment in de tijd dit aan het voordoen zijn aan een aan een bak met sensoren. Nee, maar ik bedoel dit is dit is dit vind ik alleen dit dat vind ik weer zo bizar. Ja, het komt denk ik in de buurt met de mensen die de hele dag kapcha's aan het invullen zijn of de hele dag data aan het aan het labelen zijn of de hele dag eh gekke data in eh meta en YouTube aan het vinden zijn. zijn miljoenen mensen bezig om AI te vertellen hoe de wereld Ja, dit is dit is de wat ze de schaduw noemen van AI is namelijk dat het dat het gesourced wordt uit menselijk eh gedrag en eh eh dat dat het leert van ons. Ja. Vertel ons over die omnimodellen, want die spelen een grote rol in deze in in deze revolutie. Dat er eigenlijk modellen zijn die niet alleen maar goed zijn in het produceren van tekst en produceren of het herkennen en produceren van beeld. maar eigenlijk de wereld begrijpen. Wat is een wereldmodel? Als je een eh wat je het liefst hebt is eigenlijk op het moment dat jij een robot zichzelf laat leren om over een eh stapelrotsen te gaan, dat je eigenlijk iedere stapelrotsen kan neerleggen en dat dan die training op die ene stapel generaliseert naar iedere stapel. Stap één. Dan wil je eigenlijk dat eh een zand op een strand da nou voor de mensen die luisteren nu wel eens op een strand hebben gelopen dat ze anders lopen dan op asfalt of op een boot zijn is wat anders dan aan het land. Wij zijn op é of andere manier bizar goed in het wisselen tussen die ondergronden. Zelfs in één moment, zelfs met één voet in het zand en één voet op asfalt, regelen wij zeg maar. Eh zolang je jong en gezond bent, kan je dat allemaal aan en zelfs hardlopen op het strand van het harde stuk naar dat zachte stuk en heen en weer. Niet normaal. Nou, toen de robots werden gebouwd lang geleden al, kregen wij een soort herwaardering voor onszelf. Want oh wat is het moeilijk om een nietmenselijk wezen die wij zelf hebben ontworpen en zelf proberen eh te configureren op zand te laten lopen. Het lukte gewoon helemaal niet. Dat we nu zien dat op het moment dat je een eh eigenlijk wil je die eh robots dan al niet op afstand, dan al niet in de robot zelf, dat even daar gelaten hebben. Een model geven van de wereld, oftewel, genoeg informatie om te kunnen gaan met een wereld waarin heel veel verschillende dingen gebeuren. Niet alleen maar een ondergrond, maar ook bijvoorbeeld lopen in plaats van zwemmen of zwemmen in plaats van lopen. is me net hoe je het wil zeggen. Of kruipen in plaats van lopen of in een boom klimmen en dan is er een verschil tussen een boom, want die buigt mee als je erin hangt en een stal mast die niet meegeeft, zeg maar. En je wil eigenlijk de onderliggende fundamentele eigenschappen van de wereld in een model vangen, zodat je niet de hele alle scenario's, alle potentiële werelden, alle potentiële eh situaties waarin zo'n robot terecht komt erin moet programmeren, maar iets meegeeft wat zo breed toepasbaar is dat je eigenlijk 99%, het liefst natuurlijk 100%, maar 99% van de situaties die je nog niet eerder hebt gezien toch aankunt. Concreet, je traint een eh wereldmodel. Laten we beginnen met een fabrieksmodel. Dus een de wereld als een fabriek. Dus de robot gaat nooit de fabriek uit. Die blijft binnen de fabriek. Is wat kleiner model dan de hele wereld. Er is geen zand in de fabriek als het goed is. De ondergrond is eh vaak beton. Ja. Ja. Het is makkelijk om in kaart te brengen omdat je een fysieke locatie hebt die gewoon aan beperkingen eh ja, dit heeft beperkingen want je gaat niet naar buiten om maar een voorbeeld te noemen en de ondergrond is altijd hetzelfde. Maar ook weer binnen die fabriek zijn er allerlei dingen die onverwacht is. Er loopt iemand langs met een kopje koffie en da daar moet je niet tegenaan rijden om maar een heel simpel voorbeeld te geven. Het maakt het maakt het allemaal wat meer de scope wordt wat kleiner. Ja. En dan in de praktijk wat je dan bijvoorbeeld kunt doen is zeggen: "We verzamelen heel veel data over heel veel daadwerkelijke fysieke fabrieken, hè. En dan kunnen we de de dat is dan beperkt tot hoeveel toegang we krijgen tot die fabrieken en hoeveel verschillende fabrieken er zijn. Meer hebben we niet. Dit doet Nvidia dus bijvoorbeeld onder andere met hun world model. Absolut. Maar dus die filmen dan in fabrieken. Ja, eigenlijk ja, zoals precies dat zijn na filmen is dan inderdaad ook leidar hè. Dus 3D, de diepte, niet alleen maar beeld eh maar zoveel mogelijk als ze daar kunnen verzamelen zeg maar eh hebben ze uiteraard toestemming toe. En vaak zijn dat dezelfde robots die al wat meer kunnen. Dus die zijn niet die zijn en een soort inzetbaar in de fabriek op een heel simpel niveau. Bijvoorbeeld doosjes heen en weer rijden, maar die zitten ook lekker data te verzamelen, want dan heb je een soort dubbele eh twee vliegen in één klap. H nou, dan heb je allemaal 3D eh eh versies eh digital twins van hè, want digital twinning gaat niet alleen maar over tweelingen maken van humanids, maar ook over tweelingen maken van fabrieken. Dus dan heb je de daadwerkelijke fabriek en de digitale tweeling ervan. Dan heb je op een gegeven moment een hele verzameling van allemaal digital twins die ooit ergens echte fabrieken waren of nog steeds zijn. Dat is top, hè. Dan heb je namelijk een dataset die redelijk schoon is. Die heb je zelf bedacht. Wat je dan gaat doen is uit die eh pool van geverifieerde eh 3D scans van fabrieken. Het liefst ook met beweging erin hè. Dus dat je ook een beetje weet wat daar gebeurt zeg maar. Dus soort door de tijd heen. Dus geen statische modellen maar wat gebeurt er allemaal in een fabriek. Dan ga je daarop doorvalueren. En er nog even voor het gemak van het gesprek. Je hebt 300 digital twins. Die heb je echt opgenomen ergens in de realiteit. 300 fabrieken. Ja. Dan verzin je er nog 700 bij via generatieve AI. Zie daar de koppeling tussen al deze AI-achtige uitvindingen. Zodat je 1000 eh dat je er nu 1000 hebt. Die droom je erbij de rest. Dan ga je daar binnen met tiuizenden robots oefenen. Alles omgooien. maken allemaal geen reed uit, want het is een synthese. Als je dan de juiste doelen eraan hangt, hè, dus de robot die het minst raakt eh of de robot die het minst in de weg loopt, et cetera, die wint en de rest gaat slapen. Dat laat je dan allemaal keer 1000 doordraaien in een datacenter. Dat is waarom al die stoom uit die datacenters komt, want die staan hele tijd te dromen. Dure droom lijk zo. En dan ultieme test zeg je: "We hebben nu in die dataset één fabriek niet gestopt." Namelijk fabriek 301. Hm hm. stiekem. Hm hm. En dan sturen we die robot erin en kijk eens even, het gaat goed. Dat is dan het doel natuurlijk. Hm hm. En dan heb je laten zien dat je zegt: "Nu hebben wij iets wat breder inzetbaar is, want we hoeven niet bijvoorbeeld eerst jouw hele fabriek in te meten voordat de robot bij jou kan rondlopen." En vaak is dat uiteindelijk een combinatie van dat je zegt: "Deze robot komt met een cloud of niet." Heel goed fundamenteel wereldmodel bij jou de kamer in. Maar hè, net als dat je je Sonos speakers even moet instellen op jouw kamer hè, er zit al een heel mooi ruimtelijk geluid in die Sonos, maar als je even een scan doet van jouw ruimte zie je nog net wat mooier. En dit is dan de wereld die de fabriek is, maar is dan de doel om de hele wereld om een soort van digital twin van de hele wereld te maken? Ja, het is het is wel goed om te weten dat eh ja, hoe gaat dat ding anders bewegen in mijn huis of hoe gaat dat ding anders bewegen in op straat? Digital zeg maar even een kleine eh nuance. De digital twin is altijd een eh matige representatie van de daadwerkelijke wereld. Wat het zeg maar de je moet een keuze maken in wat de resolutie is van je scan, hè, als je begrijpt wat ik en de echte wereld is bijzonder complex. De resolutie van de realiteit is een stuk hoger dan die digital twin. Maar wat blijkt hè dat zelfs met alle wetenschappelijke modellen modellen zijn uiteindelijk simplificaties van de realiteit. Is dat zelfs een simplificatie? Als je de juiste dingen in je model stopt is bruikbaar. Kan een auto van WMO 200.000 ritten maken en dan kan je zeggen het model is incompleet. Prima, hij rijdt. Hè, dus dat is de pragmatische waarde van wetenschappelijke modellen. Ook de digital twin heeft een bepaalde resolutie. Heeft ook dingen die er niet de geur van de ruimte bijvoorbeeld niet of wel eh de lichtsterkte. Je moet allemaal keuzes maken daarin. Wat is belangrijk? En dat is ook weer contextafhankelijk, want de geur op een boorplatform is waarschijnlijk heel erg belangrijk. Ja. Dus dat zie je ook vaak bij Spot bijvoorbeeld. Die heeft op zijn rug hè, die robot van Bossnemics, een array. Dat ruggetje is een soort van platform noemen ze dat. Er staan allemaal dingen op sensoren. Ja. En want dat is voor de dus ook daar hè in dat opzicht eh wij hebben best wel zitten eh grapjes gemaakt over Google en hun Gemini en Google heeft de Transformer uitgevonden. Nou gaat op en jij ermee vandoor, hè. Was een beetje ons verhaal. van een jaar geleden van jeetje al al die chat alle innovatie gebeurt grotendeels bij Open en jij en iedereen gebruikt chat GPT terwijl Google zou dat toch moeten doen. Nou vandaag de dag zijn we op een plek waar Google Open en jij voorbij rent. Zo zou je ook kunnen zeggen dat Boston Dynamics, ik blijf ze maar even noemen, met hun spot onderschat ze niet. Eh die zitten gewoon op een veel meer op toepassing nu en op een soort realisme in hun bedrijf. Maar die hebben echt alles in huis om ook gewoon dat hebben ze al gemaakt ook best wel brute humanids neer te zetten en wereldmodellen te ontwikkelen. Noem het allemaal maar op. Ja, maar jouw vraag, gaan we nou een digital twin maken van de wereld? We gaan digital twinnen tot een niveau waarin die robots meer dan alleen nodig is voor die robots om te kunnen functioneren wat ervan zagen. Schoonmaken. Ik denk dat wij Ja. En ik denk dat dat daar dus uiteindelijk de keuze in gaat komen. Ehm dat vond ik wel leuk aan jou. eh Roba voorbeeld hè of de grasmaaier eh de wasvouwen mijn godwietsen. Ik denk dat je je kunt je voorstellen dat die eh de ziekenhuiscontext eh de boorplatform het boorplatform context of de boorplatform context enzovoort enzovoort enzovoort. Gaan we dan op zoek naar het superwereldmodel zodat hij overal ingezet kan worden of zeggen we gewoon zoals ze nu bijvoorbeeld bij Google ook zeggen met hun modellen: "Nee joh, dit is gewoon een model die supergoed in dove talk zijn." En ja, dat dat die hele dove talk informatie hebben we niet nodig op het moment dat we voor die taak bezig zijn. Dus dat je meer een soort expertmodellen krijgt. Maar goed hè, dus heb je een moet die moet die robot van Unitree direct inzetbaar zijn in alle contexten of als die jou als je hem aanzet zegt hij: "Yo, ben ik thuis aan het werk? Wat gaan we doen?" Want ik kan nu datasets inladen voor jou. Ja, de model, maar ik kan ook de health model inladen. Nou ja, ik zag een filmpje van een Chinese vrouw in Shanghai die haar boodschappenmandje op haar robothond zette. En die robothond die wer loopt dan vervolgens die spullen rond eh wandelen. Wat wat is wat denk jij dat er daadwerkelijk gaat gebeuren binnen nu en 3 4 5 jaar? Als je denkt aan al die filmpjes die jij uit China ziet. China en en de Amerikanen moet je ook niet te simpel over doen. Amerikaans eh soort van Amerikaanse humanoid start-ups zijn ook lekker bezig. Maar China is gewoon ook niet te onderschatten. Wat wat voor scenario's denk je dat we binnen nu een 3 tot 5 jaar gaan zien over eh mensachtige of dierachtige robots? Ja, ik denk dat we eerst een soort Segway fase krijgen. Een beetje gek voorbeeld misschien, maar de Segway, de grote technologische innovatie, wat nu niet anders dan stadstours is, hè. De Segway de dook als eerst op en is daar ook vast blijven zitten in de niche van een soort stadstoour. Hm hm. Want het is namelijk een grappige gimmick. Ik zie ze bijna amper meer hoor, maar goed. Een grappige gimmick om een stad door te gaan en het trekt mensen aan. Wauw, ik heb nog nooit op een segway gestaan, hè. Dus dat dat tikte heel veel aan. En dat had een springplank kunnen zijn naar een soort last mile mobility. Dat bleek het stepje te zijn en de vatbike achteraf. Maar goed, de segway deed mee. Wat ik daarmee probeer te zeggen is dat ze een bepaalde entertainment functie hebben, een bepaalde aantrekkingskracht, een bepaalde gimmick. Dat zie je dus nu ook met humanoids, hè. Die worden in pretparker gebruikt. Op conferenties lopen ze daar een beetje te zwaaien iedereen. Krijg je een kopje koffie aangeboden van een van een humanoid. Verwacht daar meer van, hè. Voor de mensen die in eh conferentieircuit zitten door hun werk. Het eerste zien. Ja, als jij ergens een handje gaat geven aan die robotjes van Unit is dat ergens op een beurs in de RA. Want daar daar ga je dus als je ze wil zien, hang daar rond. Ze komen ze lopen er al, maar er worden alleen maar meer. Ja, dan maar dat is dan nog eh soort van kennismaking hè. Eh ze gaan meedoen en een gimmick. Dat heeft geen enkele vi echte waarde. Ja. En hun enige wereldmodel is de beurs. En dat is zat. En niet mensen aanraken zonder dat ze dat vragen, weet je wel. Gewoon geef een hand whatever. En eh dan denk ik dat je wat je zou gaan zien is dat eh dat dat zie je dus nu met Boston Dynamics gebeuren. Dat basistaken in eh distributiecentra bijvoorbeeld waar nu de armen nog vaststaan, de armen gaan rijden hè, de armen op een arm op de rug van een rumba, die zijn er nu. Dat wordt uitgerold. Eh dus dan eh als jij als dat jouw werkplek is, als dat jouw eh eh dagelijkse realiteit is, dan zal jij meer en meer rijdende armen gaan zien. Dan komt er een punt en dat is eh dat zijn rijdende armen. Ja, zo noem ik ze maar even. Dus dat is nog Want we ik denk de reden dat wij het over humanids hebben is om meerdere redenen, maar is omdat het denk ik de vorm van robotica is die het meest bij mensen doet op een hele diepe intuïtie van ons zijn. Dus ik hij helpt om aandacht te trekken naar het onderwerp van robotica. Ik denk dat hij compatible is met de bestaande materiële technische wereld. Daarom is hij ook daadwerkelijk potentieel waardevol voor de tussentijd dat de wereld nog voor ons gemaakt is. Laat ik het dan even zo zeggen. Ehm maar er zijn allerlei vormen denkbaar. Het is zomaar denkbaar dat er nog steeds een roemba is straks. Ja. Dat je dat de stofzu dat het gewoon heel handig is om een heel klein plat schijfje te hebben die jouw huis stofzuigt, hè. Bedoel je, we kunnen een grapje maken dat diezelfde zak in je Siemens apparaat stopt. Je humanoid. Maar misschien zegt die humanoid wel: "Joh, ik heb daar hè ik heb ik heb voor jou een ik heb voor mezelf een Roumbaeld." Nou, ik vind wat dat betreft er is een een bedrijf in Amsterdam dat heet Monumental eh Full Disclosure. Ik ben eh investeerder in dit bedrijf. En zij maken bouwrobots. Dus zij bouwen huizen met robots. En dat is wat jij nu beschrijft, namelijk een arm op hun rijdend platform, letterlijk. En wat die arm doet is eh die eh doet keurig na wat die computer vertelt dat hij moet doen. Namelijk het muurtje bouwen zoals de opdrachtgever dat voor eh zich ziet. En dan pakt die arm vervolgens pakt bakstenen van een stapel, legt die op de juiste plek, doet daar specie overheen en totdat hij daadwerkelijk een muur of een huis gebouwd eh heeft. En dat ding moet rekening houden met de echte wereld in de zin van dat het soms waait en dat het soms regent en dat het ding soms niet helemaal stabiel staat. En hij hij moet zich stabiliseren op de echte wereld en daar wordt een hele bak aan AI voor gebruikt. En dat is in feite wat jij nu beschrijft. namelijk een een arm op een rijdend platform. Dan kan je je afvragen waarom doe je dat in plaats van zo'n humanoid wat ja als jij een mens nadoet namelijk metselaar een metselaar nadoet dan eh weet je als als een soort van drop in replacement is het misschien logischer in de toekomst dat er als een humanoid vorm bestaat dat één generiek ding wat zeg maar in je huis kan schoonmaken ook kan metselen. Maar misschien is het een tussenversie waarin we robotsarmen als oprijdende platforms gebruiken. Of misschien gaan we gewoon altijd allebei blijven zien. Ik denk dat als Ja, dat is dit is puur intuïtie. Maar dat is intuïtie gebaseerd op eh wat er tot nu toe in de technologie gebeurd is in software en in hardware is dat je purpose build software en hardware hebt. Dus context, niche. En heel sterk in die niche. Concreet voorbeeld als het bijvoorbeeld om bouw gaat, wil je niet gewoon een arm die mega sterk is? Ja. Hè, in bepaalde gevallen die die hele muur optilt, ik noem maar wat, hè. Dus dan is die humor nooit helemaal niet handig. Ehm dus hm ik denk dat het ook te maken heeft, kijk net als nu in fabricage en automatisering. Kijk als het een plek is waar eigenlijk heel vaak dezelfde handeling gebeurt en die kan je gewoon de komende jaren daar blijven doen, dan kan het best wel zinvol zijn om te zeggen die humanoid vorm daar gaan we gaan we wegbouwen of of specialiseren. Die krijgen hele grote armen. Dan kan hij eigenlijk niet meer lopen. Maar ja, hij hoeft helemaal niet te lopen. Ik zeg het even andersom nu, hè. En hebben die dingen dan wel iets gemeen? Dus eh wat dan? Nou, precies. Dat dat is dat is heel mooi, want kijk op het moment dat je eh je wilt eigenlijk wanneer je eh eh robotica doet, hè, dus eh fijn motorcontrol eh objecten eh erkennen, oppakken en eh eh het gewicht kunnen begrijpen, voelen, tactiliteit, eh fingerspeed gevoel, al die dingen. Kijk, dat kan jij als eh bedrijf, firma, whatever, allemaal zelf gaan uitvinden iedere keer voor jouw context. Maar het is natuurlijk prettiger als we met elkaar op schouders kunnen staan van algemene wereldmodellen. Hm hm. Hè? En dus dat dat zijn eigenlijk gewoon de frameworks of de SDC's die we beschikbaar hebben. En dan kan eh aan de hand van de specificaties, je ziet het bijvoorbeeld ook in ehm ja, de de de eh quad copters zeg maar. Quadcopters eh die die drones die wereld eh die hebben allemaal pilots. Daar zitten kleine pilootjes in. Hm hm. Nietysiek, maar dat zijn chips en stukjes software. Uiteindelijk gaat het er allemaal om dat je evenwicht moet houden in de lucht, op dezelfde locatie moet blijven, de motors aanstuurt, et cetera. En dan kan je natuurlijk gewoon ingeven als je dat geïnstalleert die piloot van Ardu Pilot bijvoorbeeld. Ik heb zeven motoren of dit is mijn ontwerp, acht motoren. Dit zijn de specificaties, et cetera. En dan gaat Ard Pilot, ik weet wat ik weet genoeg hè. Ik weet wat ik heb als als vorm. En ik ga en dan heb je zelfs ik ga mezelf even ik ga even omhoog en daar ga ik even een paar kunstjes doen en dan weet ik wat ik moet doen. Dan ben ik gekalibreerd zeg maar. En je wil natuurlijk niet voor iedere drone een andere piloot moeten moeten bouwen. Je wil eigenlijk een een basispiloot die dan heel snel de context traint. H en zo wil je eigenlijk ook wereldmodellen hebben die en toepasbaar zijn in het geval van monumental, maar ook toepasbaar zijn op een hele andere plek, maar wel al een heel mooie basis hebben, zeg maar, een hele mooie ondergrond waar je eigenlijk alleen nog maar het liefst in context training doet of digital twin training doet. Ja. En het gaat dan, neem ik aan daardoor ook makkelijker worden om robotbedrijven te starten. Ja. En dat dit zie je dus nu ook al, want zeg maar die armen waar ik het steeds over heb, wat ik denk wel een een prima eh aanknopingspunt is, omdat die hebben we al zo lang. Zo'n zo'n je zo'n arm die in zo'n fabriek staat, dat is geen goedkope arm. Ik weet niet precies wat de prijs is, maar dat is echt flink. Een kleine versie daarvan eh ge3D print en gecalibreerd et cetera, die zijn inmiddels betaalbaar aan het worden. Duizenden euro's, maar oké, volgens mij heb je kleintjes die zitten rond de €1000. Dan zou je kunnen zeggen: "Oké, wat heb je daaraan dan?" Nou, er zijn genoeg taken die helemaal geen zware stevige arm eh vereisen. Eh en je kunt oefenen. Was vouwen, weet je? Ja, jij wil dit, hè? Nou, en de vraag is ook nog eens: is dat allemaal nodig? Want je je kunt ook zeggen, stel dat jij hiermee wil experimenteren, je zegt eh ik heb een hele grote berg Lego thuis en die wil ik sorteren en daar bestaat geen product voor. Ik ga een Lego sorteermachine bouwen. Vet project. Kan je ik niet die is al gebouwd, maar ik zou zeggen oefen oefen oefen lekker. Bouw dat ding gewoon eerst virtueel. Ga nou eerst de digital twinnen. Ik bedoel, je hoeft geen Lego te kopen of een robot arm of whatever. Je kan gewoon een Lego universe maken, daarin oefenen en als het dan werkt misschien zelfs zo'n armpje kopen thuis. Wat is de Wat is de voorspelling die jij gaat doen eh voor waar wij zijn over eh drie tot vi jaar iets? Want daar blijf ik toch een beetje op hangen. Ja. En ik denk dat ehm er gaat dus een segwaychtige introductie komen van die fysieke vorm in een soort gimmicchtige versie. Dat is al gaande. Dat gaan we meer en meer zien. Eh dus op de beursvloer word je geconfronteerd met een espressobot die jou een kopje koffie geeft. Fine. Eh dan ga jij eh op de plek waar jij fysieke arbeid doet geconfronteerd worden met eh collega's die komen trainen, namelijk eh humanids, maar ook eh data recording devices, namelijk eh leidar scanners, dingetjes. Ja, mensen die fysieke arbeid doen gaan merken dat in hun omgeving opeens [&nbsp;__&nbsp;] wordt gemeten. Ja. En ik bedoel, dit zegt genoeg over de bubbel waar ik in leven achter mijn laptop. Eh waarschijnlijk wordt dit allang gedaan eh en weet ik daar gewoon niet genoeg van. Eh dus eh ja, maar goed, dit zouden we ervan kunnen gaan merken. Ja. Ja. En ehm uiteindelijk ga je natuurlijk de eh kijk de wat ik merk en dat is altijd een beetje het puntje van de ijsberg ofzo van dit AI verhaal heeft een puntje van een ijsberg, nu een beetje boven water waar wij dan met elkaar over kunnen praten. En nu kwam VO3 vanochtend eh of gisteravond uit het uit het water met een enorme punt eh ijs omhoog van wow, wat zit daar allemaal onder? Eh die fysieke eh indicaties in de komende 5 tot 10 jaar gaan meer en meer plaatsvinden dat jij één op één geconfronteerd wordt met robots meer dan een Roomba. Echt veel meer dan een Roomba. Waarschijnlijk in eerste instantie in demonstraties eh eh in video's zeg maar. Dan eh in de IKEA waar ze aan het rommelen zijn ermee hè. Soort product demo's. En zo langzaam sluipt dat dan onze fysieke ruimte in. Eh en met eh daarbij natuurlijk ehm de meerdere vraagtekens. Hoeveel van will daarvan willen wij accepteren wij? Welke ruimtes mogen ze wel of niet in? Eh maar wat voor ruimtes verwachten je ze eer als eerste IKEA? Oké. waar het gevaarlijk is. Ja, omdat ik denk dat ehm eh 's nachts op de snelweg eh waar een stukje eh weghersteld wordt of helemaal opnieuw geasfalteerd wordt eh waar ik wel eens eh met de ehm wettelijke snelheid passeer, eh dat is volgens mij niet een plek waar mensen 's avonds eh bezig zouden moeten zijn. Eh of je zou kunnen zeggen waar mensen dichter bij de vangrail bezig zouden moeten zijn terwijl eh machines de plek innemen waar het een stuk gevaarlijker is. Ik noem maar hè. Dus ik wil niet meteen iedereen die daaraan de weg werkt eh naar huis sturen, maar er zijn het is het typische voorbeeld van Boston Dynamics met hun spot is die gaat langs hele zware machines, machines die kunnen exploderen, eh plekken waar gaslekken kunnen ontstaan, et cetera. Ik denk ook precies hetzelfde als met het eh AGI LLM debat. Ehm de wat we daar de [&nbsp;__&nbsp;] jobs noemen, hè. Dus de taken waar mensen over het algemeen eigenlijk verdrietig van worden, laten we die weggautomatiseren in de positieve zin. Dat we in de fysieke ruimte ook [&nbsp;__&nbsp;] jobs hebben. Daar kunnen we mee aan de gang. Maar ook al als aller allereerst gevaarlijke eh jobs, hè. Dit het is niet voor niets dat de explosieve verwijdering bot zijn al rij rumbaas met armen hè. Dus die die lijn kan je vrij makkelijk eh doortrekken. Maar goed, ik ik zie wel nu en dat dat komt gewoon door de ik ga op een aantal signalen baseer ik mijn onderbuik dat het dat het eh de tijd van de robots eh in essentie gekomen is de komende jaren. En dat baseer ik op eh super veel paddenstoeltjes die uit de grond komen in de vorm van kleine laps en bedrijven die met robotica bezig zijn. de verschillende wereldmodellen die aangeboden worden vanuit verschillende laps om die start-ups allemaal een steun in de rug te geven zeg maar of een duw in de rug een stuk stuk fundament te geven onder hun robotica. En ehm daarnaast denk ik dat we eigenlijk een hardware realiteit hebben hè, dus servomotoren et cetera die eigenlijk al vrij op niveau was, maar die nog de spark miste van de intelligentie tussen aanhalingstekens die nodig is om door een fabriek en huis of een ziekenhuis heen te kunnen navigeren zonder dat je daar schade aanbrengt. En er zijn nu gewoon echt een aantal puzzelstukjes die daar op hun eh op hun plek aan het eh vallen zijn. Dat was een wiets hè. Eh wij danken Sam Hengveld voor de edit, Pankra voor de vormgeving. Als je nou meer wieten wil horen in je week, want ja is is 2 uur genoeg wel genoeg. Je kan het 2 uur per week wel genoeg. Je kunt je afvragen. Kun je een lezing van hem krijgen of van mij als je dat wil. Eh mail daarvoor naar lezing@aiirport. Als je op de hoogte wil blijven van het laatste AI nieuws, dan kun je twee keer per week eh tips en tools ontvangen eh via airport. En als je vandaag wil beginnen met AI binnen jouw bedrijf, kun je gaan naar deagency.com/aai report. Volgende week zijn wij hier weer. Tot dan. Tot dan. [Muziek]

---

## Notes


## Key Takeaways
-

## Related
-
