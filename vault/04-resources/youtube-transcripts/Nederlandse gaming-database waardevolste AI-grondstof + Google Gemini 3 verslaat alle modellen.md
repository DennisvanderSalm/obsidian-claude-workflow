# Nederlandse gaming-database waardevolste AI-grondstof + Google Gemini 3 verslaat alle modellen

**Source:** [YouTube](https://www.youtube.com/watch?v=Ytt_j8D6ptY)
**Video ID:** Ytt_j8D6ptY
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie, waar we uitzoeken welke invloed AI heeft op ons werk, ons leven en de [muziek] samenleving. Er is een nieuwe nummer één in de AI race. Google lanceert Geminite 3 en dat model levert enorme vooruitgang op en we gaan je daar uitgebreid over bijpraten. NVIDIA meldt deze week explosieve groei en dat zust de angst weer op de beurzen voor een AI bubbel. En we spreken met Pim de Witte. Dat is een Nederlandse ondernemer die onlangs een overnamebod van Open AI weigerde van een half miljard dollar. Je hebt waarschijnlijk nog nooit van hem gehoord of van zijn bedrijf, maar misschien is hij naast ASML wel de belangrijkste sleutel voor onze Europese en Nederlandse autonomie. Een ongelooflijk interview hoor je straks in deze [muziek] podcast. Dat en meer in IR Award. Veel plezier. [muziek] Ja, weet eindelijk is het er dan. Gemini 3. Je zit er al maanden over het oude [&nbsp;__&nbsp;] Ja, ik [gelach] heb misschien al vier keer aangekondigd dat het ging komen. Nou ja, god, je hebt er geen datum bij gezegd. Eh nee, het kwam wat later dan ik dacht, maar het is er. Ja, het moest nog even doorbakken. We gaan het er uitgebreid over hebben. Eh maar eerst al het AI nieuws in 3 minuten. Ja, het nieuwe AI vlaggenschipmodel van Google neemt de leiding over en het is geen typische modelrelease. Waar Gemini 2.5 Pro alleen beschikbaar was voor ontwikkelaars, rolt Google Gemini 3 meteen uit over alle platforms. De Gemini app, Google search met haar 2 miljard gebruikers per maand. Dus we gaan hier veel van merken. Op vrijwel alle benchmarks, dat zijn de tests die eh prestaties van AI modellen meten, scoort Gemini 3 beter dan alle andere modellen. In sommige belangrijke tests, zoals de beruchte Arc AGI Challenge, bijna de dubbele resultaat van GBT 5.1. Eh Open AI is het nieuwste model en die is nog maar hoe lang oud nu? Een week zoiets. Max twe weken. Ja. Nvidia meldt explosieve groei. Het bedrijf rapporteerde $7 miljard omzet in het afgelopen kwartaal omdat ze stijging van 62% vergelijken met vorig jaar ongelooflijk. De cijfers kwamen op een moment dat beleggers zich zorgen maken over een AI bubbel. Grote investeerders zoalsbank en Peter Theel verkochten recent hun aandelen Nvidia en dat zette de boel behoorlijk onder druk. De CEO van Nvidia probeerde die angst weg te nemen. Hij zegt dat er veel gesproken wordt over een AI bubbel, maar dat we eigenlijk pas aan het begin staan en dat deze cijfers dat supporten. De beurs reageerde direct positief op deze goede resultaten en de verwachtingen van volgend kwartaal met 5% groei van het aandeel na beurs. En Chinese staatshhackers hebben Cloud Code gebruikt om 30 bedrijven en overheidsinstanties te hacken. De AI deed 80 tot 90% van dat werk zelfstandig van network van netwerken scannen tot backdoors installeren. Cloud voerde bijna de hele aanval zelf uit. En dit is volgens Anthropic de eerste gedocumenteerde grootschalige cyberanval zonder substantiële menselijke tussenkomst. De aanvallers hakten de hakten in die aanval eh ja de boel op in kleine taakjes. Kleine hacker eh taakjes zou je kunnen zeggen. Elke subagent kreeg van Claud maar een klein stukje van de puzzel te zien. En Claud dacht dat hij gewoon wat aan het scannen was, maar eh stiekem was dat ding dus allerlei foute dingen aan het doen en daar zijn ze achteraf achter gekomen. En voordat dat paniek oplevert, Claud bleek geen perfecte hacker. Gelukkig de AI verzon regelmatig inloggegevens of beweerde geheime informatie te hebben gestolen die gewoon publiekelijk beschikbaar was. Toch heeft Entropic de accounts natuurlijk geblokkeerd en zijn de maatregelen volgens het bedrijf aangescherpt. Wij gaan het uitgebreid hebben over het hoofdonderwerp van deze aflevering, namelijk de release van Gemini 3. Wat maakt dat model allemaal zo bijzonder en waarom neemt Google nu de leiding? Maar eerst hoor je van Marian en Lucas van Dept. Hi, hier marketing en Tech Brot Dept. Elke week bespreken we hoe wij merken helpen in de wonderenwereld van AI. Deze week hoe we reclameschalen voor de grote retailer zonder de kracht van menselijke creativiteit verliezen. Lucas. Yes. Nou, ik denk dat dit een goed voorbeeld is van the best of both worlds. Want voor een grote retailer hebben we een oplossing gemaakt die hen in staat stelt reclames schlalbaar en relevant te maken zonder dat we de hele commercial met AI hoeven te maken. Wat leuk. Vertel eens. Ja. Nou, zoals je weet eh was het tot nu toe haast onmogelijk om mensen consistent opnieuw te genereren met AI in Hippal character consistency eh noemen ze dat. Ehm maar dankzij nano bananen en Fio 3.1 van Google, een AI image generator en een video creator, is dit nu wel mogelijk? Eh heel concreet betekent dit dat we de hoofdrolpeler van de commercial, wat gewoon acteur van vlees en bloed was, zoals jij en ik, met AI hebben nagemaakt en dat we daardoor oneindig veel eh verschillende producten konden laten zien via hem zonder dat we uren en dagen in de studio hebben gestaan omdat hij iedere keer het volgende productje moest vasthouden wat wij dan weer gingen filmen. En hierdoor kunnen we in hoge kwaliteit merk en performance samenbrengen doordat we de commercial met het meest relevante product naar de juiste doelgroep kunnen pushen. En dit is geen overbodige luxe in een funnel eh die steeds platter wordt. Dat begrijp ik. Hyé. En kunnen merken hier dan makkelijk mee aan de slag? Nou ja, makkelijk. Het vraagt de investering om ervoor te zorgen dat je de AI zo inrichten en trainen dat het NATO voor jouw merk en eh specifiek commercial werkt. Want hier wil je echt op de kwaliteit geen concessies doen. Maar ja, het is zeker ook voor andere merken mogelijk om hiermee aan de slag te gaan. En de schaal en de relevantie die je ermee kunt bereiken is eh echt van een andere orde. Check. Kortom, niet afwachten, maar doen. Wil je weten hoe je jouw commercials kunt schalen met de AI zonder in te leveren op kwaliteit, kijk dan op de.com/idport. Tot volgende week. [muziek] Ja, daar is het dan. Gemini 3, het nieuwe vlaggenschip van eh Google. Open AI werd ooit opgericht als bedrijf omdat de mensen erachter doodsbang waren dat als Google de AI wereld zou domineren er eigenlijk geen alternatief meer zou zijn. En die angst die is misschien een beetje profetisch aan het worden. Want die gigant die lange tijd achter de rest aansukkelde, dan bedoel ik dus Google, pakt nu de leiding. Het is de eerste keer dat er net zoveel hype is over een Gemini release als over chatipt of cloud. En het internet staat vol indrukwekkende demo's. We zagen bijvoorbeeld hoe een programmeur in één prompt een complete 3D Lego editor bouwde waarmee je blokjes heen en weer kan slepen. Is de chief AI scientist van Deep Mind die aan eh Gemini vroeg: "Bau een beautifully simple game that plays itself." En hij deed dat gewoon. Het je hoeft Twitter maar door te scrollen op dit moment en het is één lange brei aan mensen die dat ding allemaal boeiende dingen laten programmeren. Wat wat maakt tot nu toe het meeste indruk op jou van wat mensen ermee gemaakt hebben? Nou, een beetje de front end. Dus dat is eigenlijk de voorkant van het web. Dus de website zelf en dan hoe het eruit ziet. Daarop de andere modellen creëren best wel typische AI uitziende websites. Vaak de kleur roze en paars bijvoorbeeld. Ja, je hebt iets van AI Pink heet dat zelfs volgens mij. Omdat ze een soort van doorgetraind zijn en overgefit zijn op die typische soort blockchain start-up websites. Ja. Ja. En eh je hoeft eigenlijk maar heel weinig te draaien aan Gemini. Je hoeft hem maar heel weinig uit te dagen zeg maar. Hij maakt mooie dingen. Ja. Je kan dan bijvoorbeeld zeggen: "Maak er een brutalist eh eh website van ofzo." En dan dan heeft hij door op é of andere manier: "Oh, oké, jij wil een hele andere kant op qua esthetiek." Dus de het is niet heel moeilijk om esthetisch interessante dingen te maken met Gemini. En dat is wel even een nieuwe stap. En wat ik een bizarre demo vind is vragen aan Gemini. Als je nou naar deze website kijkt en naar deze website kijkt, kan je die dan blenden en nabouwen? Dus eigenlijk dit is wat ik mooi vind. Ja, doe het daarmee. En dan kom je zeg maar wel in een soort nieuw territorium van iets wat veel origineler eruit ziet. In ieder geval unieker dan wat we voorheen uit EI kregen. Ja, precies. Omdat je het meer je smaak eigenlijk kan meenemen erin. Ja. En blijkbaar is de inherente smaak van het model los genoeg om overrued te worden door jou. En dat was ook in het verleden het probleem dat je best wel een magier moest zijn om dat ding uit die AI pink te krijgen, zeg maar. We gaan dadelijk hebben over de benchmarks en ook over eh ja, hoe Google dit gedaan heeft. Maar toch nog even bij wat mensen ermee kunnen. Het model is beter in schrijven geworden, zie ik de hele tijd terugkomen. Wat wat heb jij daarvan gezien? De teksten zijn prettiger om te lezen en voelen professioneler. Het is wel zo dat in de algemene zin Gemini een vrij saai model is. Dat is de Ja, dus weinig persoonlijkheid bedoel ik. En dus daarom zeg ik professioneel schrijven. Eh Google lijkt ervoor te kiezen om in plaats van wat Open en Antropic wel doen, juist weinig persoonlijkheid te geven aan het model en het echt zien als een tool die jou assisteert in plaats van jouw schrijfmaatje die een bepaalde kleur heeft of een bepaalde manier van doen. Eh dus het professioneel schrijven eh dus snel one shot hè, dus in één keer eh vragen en krijgen, komen daar A4tjes uit met stukken tekst erop die blijkbaar prettig weglezen als een soort neutraal professionele teksten. Dus dan hebben we het maken van dingen, het programmeren van dingen, eh het schrijven. Wat zijn nog meer soort van direct zichtbare Nou, wat Google nu eh gedaan heeft is ook kijken naar die agentic tasks, hè. Dus een beetje in in eh kan een model langdurig aan de gang blijven en zelf inzien waar nog data gehaald moet worden, hè, dus hoe vaak het moet in dit geval Google op moet, hè. Gemini gaat natuurlijk zelf Google gebruiken, want het is hetzelfde bedrijf om extra informatie te halen. Toch nog even nakijken, toch nog even die berekening opnieuw en die hele eh dat die stappen van zelf in cirkeltjes blijven draaien en zeggen op een gegeven moment: "Ik heb nu genoeg. Ik ga de conclusie aan de eindgebruiker geven. Dit leerden wij als eerste kennen in de vorm van deep research van Open AI destijds hè. Kan maar 30 minuten duren bijvoorbeeld. Nu kan eigenlijk Gemini ook heel goed in een mooie cirkel blijven. Daar niet uitvallen of wegsla weggaan in een straatje waar die nooit meer terugkomt, maar gewoon mooi in een cirkel blijven en dan stoppen op het juiste moment en ook nadenken wanneer nodig. Want dat blijft natuurlij het moeilijke. Is dit een vraag waar ik in 3 seconden op kan antwoorden of moet ik echt even onderzoek gaan doen? En eigenlijk is die routing hè, waar we het met GPT 5.1 ook over hadden in Gemini ook meegebakken. Hm. Ja, ik zat ik eh je hebt nu soort van bepaald journalistiek genre als het gaat over AI artikelen. Dat zijn een soort vibe checks. Dat zijn dan bekende mensen die wat weten over AI en die dan het gaan gebruiken en dan laten weten hoe het voelt. Wat grappig. Grappig. Ja, maar het zijn eigenlijk hun persoonlijke benchmarks, hè. Ja, zijn mensen die in hun dagelijks veel met AI werken. Dingen hebben waar ze van weten dit kan AI hè, alle modellen samen kunnen dit al versus dit kan het echt duidelijk niet. En dat gaan ze dan meteen weer proberen als die uit is. Ja, precies. Een beroemd voorbeeld is een pelikaan op een fiets. Ja, van Simon Willison is dat. Ja. Hoe Hoe presteert de Gemini 3 in de challenge pelican op een fietstekenen? Nou ja, weer een stukje beter. Nog steeds ziet het eruit als een paint tekening. Nee, het is absoluut lelijk zeg maar. Esthetisch lelijk. Dus daar gaat de esthetiek niet op. Maar één van de dingen die bijvoorbeeld slecht ging ook bij de GPT 5.1 van deze wereld en de zwaardere modellen van Anthropic is dat er geen spaken in de wielen zaten van de fiets of het frame van de fiets kon niet qua zwaartekracht. Ja. Het zweeft gewoon in de ruimte. Ja. Ja. En nu komt daar dus een eh ja een beetje een abstracte hè. Het zou het als een kunstvorm kunnen zien hè. Want even voor de luisteraar die pelk mag alleen getekend worden op basis van basisgeometrie hè. Hè, dus hij mag geen plaatjes eh genereren zoals bijvoorbeeld eh nano banana, dat mag of eh advanced imag wordt uit een ander vaatje getapt. Namelijk dat hij dat hij alleen maar lijnen mag gebruiken. Hij mag geen foto maken, want dat kan hij heus wel, maar mag maar moet een soort van ja, hoe moet je dat? Schematische tekening eigenlijk maken. Dat is moeilijker voor ding blijkbaar. Geef de coördinaten en de radius van de cirkel maar van het wiel en ga daar maar streepjes op leggen en met een bepaalde dikte. Dus je krijgt eigenlijk eh eh soort stokjes en blokjes en balletjes om daar. Daarmee waren we er nog niet als ik dit vergeleek met de vorige plaatjes. Nee, maar ik bedoel het is in dat opzicht op die pelican benchmark. Want dat is het. Die is niet saturated. Oftewel we zijn er nog niet. Maar alle gaatjes die erin zaten bij de eerdere modellen hè. Dus de spaken zitten er niet op of die pelan zit op een vreemde manier op die fiets et cetera. Want het kan natuurlijk eigenlijk niet een pelikaan op de fiets. Voor de duidelijkheid ehm is dit wel weer een stapje vooruit. Maar we zijn ook verwend, want iedere paar maanden komt er een nieuw model uit en iedere iedere paar maanden wordt die pelican weer moeten vergelijken met de pelican van jaar geleden geleden. Ja, precies. Nou, dat is inderdaad niet om aan te zoen. Eh oh Ethan Molic die eh heeft altijd eh die doet altijd dit soort grappige vibe checks en hij had een screenshot van een tweet van zichzelf uit 2022 waarop hij eh waarin die in die tweet schreef hij iets van ik heb het GPT3 nu voor het eerst geprobeerd en het is grappig want het kan een gedichtje schrijven. Het was echt bless to bless from the pastel zo voelt het kan gedichtje schrijven. Het kan een tekst samenvatten en hij kan zelfs uitleggen hoe je En dan had hij een vergelijking of een heel raar idee voor een spelletje. Dus dat is een bedacht bedacht spelletje. Een beetje zoals een pelicaan op een fiets. Gewoon zo'n absurd iets. Idee voor een raar spelletje. En dat had hij uitgeschreven. Dat screenshot had hij gevoerd aan Gemini 3. Dus de het oorspronkelijke screenshot met die tekst daarin en wat de datum erin et cetera. En toen was het prompt daarbij was eh iets van we zijn best ver gekomen sinds eh deze tijd. Doe iets om te laten zien hoe verder hoeveel verder je gekomen bent. En dat ding praat daar op een heel leuke manier op terug. Die zegt dan iets als eh ja, dit was wel gekke tijd in AI, want ja, de ik kon op dat moment echt alleen maar teksten schrijven. Inderdaad. kon wat zinnen achter elkaar construeren. Maar in feite kan ik nu dat spelletje wat ik daar alleen nog maar kan beschrijven kan ik nu maken. Dat ga ik nu voor je doen. En dan vervolgens is dat ding even aan het pruttelen en maakt hij oprecht mooie game die werkt, die precies is wat Ethan Molic in 2022 liet construeren door in tekst door dat ding waarmee hij natuurlijk wil zeggen je we hebben nu de neiging om te kijken naar de pelikaan. ziet er iets zit iets beter op de fiets. Dit is natuurlijk een metafoor voor hoe wij AI gebruiken in ons werk. En we hebben de neiging om nu met een loop te kijken naar de veranderingen per maand. Eh en hij zegt: "Het feit dat dit ding nu dit maakt, deze volledig werkende game eh op basis van deze screenshots van deze tweet zegt iets over de Ja. Ja, het is ook een beetje de moving goal posts, hè. is dat wat dat we iedere keer eigenlijk de lat schuiven eh en kijken vanuit het nu eh terwijl als je nou terugkijkt wat het in 2022 kon eh matige gedichtjes schrijven hebben we zeker niet stilgestaan. Ehm voor de nerds onder ons, laten we het even over de benchmarks hebben. Gemini 3 Pro haalt 37,5% op Humanity's Last Exam. Dat is een test die bedoeld is eh bedoeld was om jarenlang uitduigend te blijven. Een test die mensen goed kunnen maken, maar die voor robots heel lastig was. Eh nou dat is We zijn nu alweer op 375, dus dat kunnen weer een nieuw ding gaan maken. Ja, twee keer zo snel ongeveer dan dat de makers hadden geanticipeerd. Want voor de duidelijkheid, het hele manag. Namelijk, er is een call geweest naar mensen toe. Maak vragen waarvan je weet dat mensen ze goed doen en waarin LM's duidelijk door de band vallen. En betalen jullie ook voor die vraag? Ze hebben een deels een publieke dataset, hè. Dus de vragen die kunnen meegetraind worden in het model, maar ze hebben ook een private onderdeel van de humanity last exam hè. Dus dan stuur jij als het ware het model op als Google zijn en dan ga je in privé dat doen en dan krijgt Google de resultaten terug. En ook daar op het privé deel scoort Gemini 3. Eh Gemini 3 Pro. Ja, dat is niet niet niks. Nee, het scoort 92% op de GPA Diamond Witsen. Ja, dat is Nou, het punt is dat eigenlijk in de grafieken als je even uitzoomt zeg maar dus de de staaf de staafdiagrammen moet ik eigenlijk zeggen, want het is natuurlijk leuk 37,5% of 94 pun zoveel. Het gaat erom dat er ongeveer 10 15 tot 20% hoger dat het model hoger scoort dan de vorige frontier models hè. Dus je ziet eigenlijk op alle gebieden hè waar voorheen we de clouds van de wereld hadden, Opus 4.1 en eh de Gemini 2.5, het vorige model van Google en GPT 5.1 dat eigenlijk alle drie dat daar een blokje van 15 tot 20% bovenop komt in alle benchmarks tegelijk ongeveer. En dat is best wel een ding. En nu de Arc AGI2 test, dat is een beruchte intelligentietest voor AI LAABS, presteert hij dubbel zo goed als GPT 5.1. Ja. Waar dus Ja. En François Colet, de maker van de Arc AGI Challenge, of in ieder geval degene die daar het meeste over publiceert en praat, eh die zei eh een soort een soort eh voorzichtige tweet van: "Ik ben wel onder de indruk, want het idee van Arc J2 was om daarom is het nummer twee en niet meer één." Van die eerste was werd wel heel snel verslagen, hè. Toen waren jij en ik ook een beetje onder de indruk ongeveer een jaar geleden volgens mij iets minder van jeetje, nu gaat het wel heel hard hè als het dan AGI zou moeten zijn. Dus hebben ze een tweede gemaakt waar alle gaatjes uit waren waardoor die zo makkelijk was. En ook die eh schuift nu maar gewoon weer door. En dat is best wel een eh dat was de enige waar ik naar keek is hoe is het met Arc AGI2? En ik ben best wel onder de indruk. Ja, er zijn vrijwel geen benchmarks meer lees ik waar de gemiddelde mens bij textuele taken beter presteert dan Gemini 3 Pro. Wat betekent dat? textuele taken. Nou, je hebt zeg maar in heel veel van de benchmarks heb je een balkje erbij staan, human level, hè. Dus bij Arc AGI is human level dan 89% bijvoorbeeld. En dan zou je kunnen zeggen: "Oké, iedere keer als een benchmark voorbij human level gaat, dus hoeft niet eens 100% te zijn, maar voorbij wat wij kunnen, dan heb dan gebeurt daar iets substantieels." Waar wat hier belangrijk is, is dat je natuurlijk de toppers hebt in benchmarks, hè. Dus de 100 beste wiskundigen van de wereld kunnen dit als human level. Dus human level betekent niet altijd hetzelfde. Je hebt human expert level en human average level. En op textuele taken, dus waar je een tekst gemanipuleerd wordt, hè, dus niet plaatjes maken of plaatjes bekijken of 3D werelden of robots besturen. Nee, tekst bekijken en manipuleren. Dus human humanity's last exam bijvoorbeeld is zitten trouwens ook een paar plaatjes in. Maar goed, dan gaat het heel erg over. Wat is manipuleren? Is dat samenvatten? Is dat nou bijvoorbeeld Arc AGI2? Dat zijn allemaal IQ puzzels. D zijn eigenlijk dat zijn visuele puzzels, hè. Dus dat is niet dat is niet gebaseerd op tekst. Terwijl als er bijvoorbeeld een raadsel, een riddle in tekst geschreven van een A4 lang en daar er waren echt dat daar zat ik ook heel erg op te letten toen die uitkwam. Er waren heel veel raadsels en dan moet je voorstellen Kees heeft twee zussen. Één ervan is arts en die heeft ook een baby. En dan als wij als mens trappen daar niet in. Ja, die zijn ook moeilijk voor ons. Maar omdat het tekstmodellen zijn verliezen die op een gegeven moment het draad en dan kan je ze en zelfs de zwaarste modellen die we hadden vielen door de mand bij dit soort raadseltjes. En Gemini eh 3 blijkt ontzettend goed in die raadsels te zijn. zo goed zelfs dat het beter is dan de gemiddelde mens op die raadsels zolang het de tekst is. En dat is wat anders danel heel veel mensen hebben het vaak als ik het hier zelf ook met mensen over discusseer over PhD level of artificial super intelligence. Terwijl ik denk nou als we systemen hebben die op het die kunnen wat de laat ik even zeggen voor het gemak gemiddelde Nederlander qua intellect kan, dan hebben we ook al iets te bespreken met elkaar, snap je? Dus in plaats van wat de gemiddelde genie kan. Hm hm. Ja. Dus ik moet dat niet zien als de kwaliteit van tekst. Ik moet dat zien als de intellectuele puzzel die een tekst kan zijn. Precies dat. Ja. En ik denk dat dat resulteert nu als een soort bijvangst in dat de teksten die kan genereren over die puzzels of een samenvatting ook beter aan het worden zijn. Dat is natuurlijk wat met deze modellen wel vaker gebeurd is, is dat je traint of A, B en C beter te maken en je krijgt er dan gratis DNA en F bij. Juist. Ja. Ja. Ja. Het blijft een eh dat is een ander ding waar Gemini 3 anders in is dan andere modellen. Eh we zitten in een tijdperk denk ik wel eens wat je het beste kan beschrijven als een soort van commandline interface tijdperk. Het MS DOS tijdperk van AI modellen. Wij kijken naar een knipperende cursor op een wit scherm. We moeten zelf maar gokken wat dat ding kan doen. Ehm Gemini 3 neemt daar een stap in, want die bouwt on the fly interactieve interfaces op basis van wat je vraagt. Dus het model maakt een soort van ja, werkende mini apps terwijl je kijkt. Als je bijvoorbeeld een handgeschreven recept van je oma uploadt in het Chinees, dan kan stel je voor je hebt een Chinees oma, dan eh kan Gemini 3 dat voor je ontciijferen, vertalen en kan er dan een vormgegeven ding van maken. Ja, een 3D kookboekje eigenlijk waar je doorheen kan bladeren zeg maar. Dus dat is dan een websiteje. Het is eigenlijk de clot artifacts feature. Die kennen we al wel. Dus kleine widgets maken. Alleen Google heeft het er hier ingetraind. Dat is sowieso wel een beetje één van de hoofdboodschappen rondom Gemini. Google heeft heel goed gekeken, deepmind heel goed gekeken waar worden modellen nu voor gebruikt en kunnen we eigenlijk die specifieke toepassingen hè dus een mooie stijl voor een website of het creëren van mini apps meetrainen in het model. Hm hm. En daar is hij dus nu ook echt stukken beter in geworden. Wat betekent dat meetrainen in het model? Nou, je kunt Tot nu toe was het eigenlijk zo dat eh bijvoorbeeld als je dan kijkt naar clutty artifacts kan maken, hè. Dus zo'n model kan software maken en op een gegeven moment komt Entropic erachter. Oh, als we dan terwijl jij dat vraagt aan de zijkant alvast dat stukje software laten zien hè in die artifact feature aan de zijkant dan kunnen mensen dashboards maken en widgets. Maar die toepassing was die was niet helder toen het model getraind werd, hè. Dus toen het model eh eh eigenlijk uitgedaagd werd tijdens de training om antwoorden te kunnen geven op bepaalde moeilijke vragen. En wat je kunt doen in de trainingsfase is zeggen: "Joh, jij gaat straks ingezet worden om kleine mini apps te maken. We gaan jou ook 1000 voorbeelden geven van hele smaakvolle goed gelukte mini apps. En we gaan jou daar als het ware punten geven als je dat beter doet tijdens het trainingsproces." Hm hm. Dus het is in plaats van dat je een heel eh breed model traint waar je dan eh als bijvangst mini apps krijgt, ga je zeggen: "Omdat we toch weten dat een groot deel van jouw output dat gaat zijn, gaan we je alvast een beetje helpen om die goed te kunnen doen." En dat daar wordt dus nu ook al gezegd van ja, dehetiek die Gemini nu heeft in het websitejes bouwen, die is er overduidelijk ingestopt omdat de feedback van de eindgebruiker was: "Alles lijkt op elkaar en is lelijk." Ja. Ja. Ja. Ja. Ja. Ja, het is echt een soort van grappige tussenfase waarin we nu dus nog steeds normale dingen kunnen vragen en gewend zijn dat we dan tekst of hooguit een tabel terugkrijgen als we een taalmodel vragen om ons te helpen met iets. En dat we nu met Gemini een soort van tussenstap hebben voordat het een echte volwaardige app is. Dat je in ieder geval een interface krijgt om informatie makkelijker te ja tot je te nemen. Zeg ik dat zo goed? Ja, je zegt het goed. En ik denk dat wat jij begon natuurlijk met MS DOS hè, die metafor van de terminal. We zijn eigenlijk we hebben een soort regressie gemaakt in software dat we ineens weer achter een terminal zitten met z'n allen en wat je nu meer en meer gaat zien en dat gebeurde eerst alleen aan de aan het einde hè. Dus er kwam zat een terminal op de achtergrond en daar werd vlug nog even een dashboardje van gemaakt door Antropic met hun artifacts dat je nu begint te zien dat eigenlijk die modellen steeds meer rijkere resultaten kunnen geven. Dus niet terugpraten in stukjes tekst maar terugpraten in stukjes interface. Ja. Ja. Dus dat als je dingen vraagt met over hypotheek info bijvoorbeeld, dat hij dan gelijk een soort van interactieve calculator erbij maakt omdat dat nou helemaal een betere manier is om iets uit te leggen dan een paar sliders erin. Precies. Dat dat beter is dan een voorbeeldsom eh in tekst laten zien. Ja, het is eigenlijk wat ik iedere week hier met allerlei vage metaforen probeer te Ja, precies dat. Maar dan visueel is erin getraind. Ik las ook film een tenniswedstrijd en dan analyseert het je techniek en verwijst die verbeterpunten aan. Ja, dit heeft ook weer mee te maken dat Gemini dit is allemaal nog een nu gaan we echt wel richting ehm hoe zeg je dat? Eh ehm eh dit dit weten we nog niet hè. Ik ben daarmee bedoel ik er zijn allerlei theorieën aan ontstaan nu over hoe kan het nou dat Gemini 3 zo goed is. Want eh even voor de luisteraar, het was een aantal maanden geleden toen GPT 5 uitkwam, voelt langer geleden zelfs, maar toen GPT 5 uitkwam was het verhaal het idee van LM's doortrainen met meer computerkrachten, hè, meer parameters geven, meer datacenters er tegenaan gooien is eigenlijk tot een soort maximum gekomen, hè. GPT5 is omdat hij tegenviel bedoel je in in prestaties? Ja. GPT5 valt tegen eigenlijk omdat we tegen het plafond zijn gelopen. Want wat je dan in het pretraining paradigmed oftewel tijdens dat bakken van die van die modellen geef je ze zoveel mogelijk data en zoveel mogelijk computerkracht en zo lang mogelijk laat je ze doorgaan en daar zou je dan automatisch betere modellen uit moeten krijgen. Werd toen gezegd de pretraining era is over. Die hebben we uitgespeeld. Alles zit nu in post. Oftewel reasoning, dat kan je nog toevoegen waardoor die langer mag nadenken. Hij kan tool calling gaan doen en dan kan die het internet op. En we moeten eigenlijk alle trucjes nu een beetje als die al getraind is tijdens het uitvoeren van het model gaan doen, hè. Dus eh je hebt het de tijd dat je het traint op een datacenter. Die datacenters kunnen ergens midden in de woestijn staan en dan is het model klaar. Dat wordt gedistribueerd en rest van de datacenters over de hele wereld. Die staan bij jou voor de deur het liefst om de hoek. En daar voer jij dan dat statische broodje wat je gebakken hebt uit. Dus dat is eigenlijk posttraining. Nu blijkt en dat is ook was ook het grote nieuws toen Gemini uitkwam. Het is ze gewoon gelukt om weer in die pretraining eh tijd een model te verbeteren. En het schaalt eigenlijk daar ook nog. Dus wat Google nu heeft is en de voordelen van het doortrainen beter bakken en de voordelen van beter omgaan met wat je gebakken hebt. Dus ze krijgen nu een soort dubbelwinst. Hm hm. Dus de winst die alleen nog aan het halen natinen heeft Google nu ook. Plus dat het hun ook nog gelukt is om te schalen eh tijdens het trainen. En dat en hoe ze dat hebben gedaan is nu nog een beetje zoeken, want dat is natuurlijk de magic hè. Dus er wordt met terugwerkende kracht een beetje geprikt. Maar om een beetje concreter voorbeeld te geven, één van die tekstuele raadseltjes waar ik het net over had is een 3D raadseltje. Dus dat gaat over ik heb een bal op een tafel die rolt er dan af in een mand. Ik draai die mand om, hè. een soort gogeltruachtige tekst. Ja, die tekst dat ga jij niet begrijpen waar die bal nog is. Als jij niet ook eigenlijk een visualisatie kan maken in je hoofd. Eh ik zoals wij mensen dat doen. Om om het trucje te kunnen doen moet je het in je hoofd visualiseren en dan kun je de draadsel oplossen. Noem het een wereldmodelletje wat je dan moet hebben. En dus ik ik zag een eh tweet langskomen van iemand die zei: "You sneaky bastards." Zoiets stond er. één van mijn tests waar ik overduidelijk zoek naar is er een wereldmodel aanwezig? Kan dit taalmodel innerlijk visualiseren hoe de situatie is van de gogeltruck die ik uitleg? Taalmodel kan innerlijk visualiseren. Ja. Oftewel je hebt eigenlijk al je praat al stiekem niet meer over een taalmodel, maar over iets wat breder is. H het kan namelijk visualiseren. Ja. Dus meer dan alleen maar tekst heeft het als het ware visualisatietens. kan het daar binnen binnen een soort wereldje van 3D iets doen. En eh daar is nu dus de suggestie, dit weten we niet zeker, dat Google een stukje wereldmodel aan het meetrainen is in Gemini 3. En dat waar je eigenlijk mee praat inmiddels wel veel meer is dan enkel een multimodaal, omnimodaal, tekst, beeldmodel, maar iets wat ook een beetje kan simuleren. Huh, dus we hebben al, want het is ook echt wel een belangrijke feit wat we wel zeker weten is dit staat namelijk heel trots in de eh model card. Dus dat is de PDF die Google dan ook publiceert met waar ze in een beetje vertellen hè, de benchmarks, maar ook wat ze anders hebben gedaan. Niet teveel, want anders geven ze het weg aan de concurrentie dat ze zeggen: "Dit is een volledig nieuw model. Dit is niet Gemini 2.5 gefineetuned. Dit is niet een oude Gemini doorg. We zijn helemaal opnieuw begonnen met alles wat we nu wisten. En dat is wat Gemini 3 is. Best wel een gok ook, maar het is goed gekomen. En ook op een eigen chips hè. Ja, ook op Google chips. Even een klein klein detail daarnaast. Goed dat je dit aanhaalt. Er is geen gebruik gemaakt van Nvidia hardware. Ik ben dus we weten dat staat namelijk heel trots in die PDF. De volledige training run dit model, dus het bakken van het brood heeft plaatsgevonden op TPU's van Google zelf. Daar komt geen Nvidia chip aan te pas. Dus als je je afvraagt waarom sommige mensen hun aandelen weer hebben verkocht, wie weet zat er [&nbsp;__&nbsp;] Geen idee hè. Pure eh En wat betekent dit dat Google dit kan zonder Nvidia? Ehm nou, ik ben net gaan zoeken, dat kon ik niet goed verifëren, hebben ze hem alleen gebakken op hun TPU's of draait hij nu ook op hun TPU's? Nou, wat ik er publiek over kan vinden is hij draait ook op TPU's van Google. Dus Nvidia is helemaal niet meer betrokken. Daar wordt wel bij gezegd als iemand anders Gemini om premise draait of eh je doet Gemini bij Amazon bijvoorbeeld, slecht voorbeeld, maar je draait Gem&amp;M in een andere cloud, kan het het kan draaien op Nvidia, maar het hoeft niet. Wat betekent dit dan? dat Google eigenlijk binnen hun eigen ecosysteem de hardware onder controle heeft en kan bouwen die capabel genoeg is om een model op een snelheid met intelligentie te kunnen leveren zonder nog afhankelijk te zijn van de chips van Nvidia. Ja, dat is ja, ik denk dat je wel als wat dat betekent. Dat is flink. Ja, dat is echt flink. Ja. Hyé. En je zei je zei net het is eigenlijk een beetje gissen naar wat ze nou precies gedaan hebben, want dat is opnieuw gebakken from the ground up en er eh ze zeggen wel wat dingen in die model card over hoe dit nou zo is gekomen, maar veel is ook geheim. Ehm maar we weten dat het model ehm tientallen zoekopdrachten achter elkaar doet en dan resultaten combineert uit verschillende bronnen en zo analyses maakt zonder de draad kwijt te raken. En waar eerdere modellen dus verdwenen in die langere redeneringen kan Gemini 3 focus eh houden. Heb je een idee hoe het kan dat ze dat dit is gelukt dat langer focus houden of blijft dat dan onderdeel van de soort van secret vraag? Nou, ik denk dat ehm kijk, het was zo, we hadden de GPT's van deze wereld hè, dus open modellen waar we waar toen eigenlijk mensen gingen uitvinden van joh, als je die GPT nou gewoon iedere keer om een nieuw antwoord vraagt en je reigt al die antwoorden aan elkaar, krijg je dan niet een soort agents? Hè, dus er zijn allerlei ehm nieuwe interessante, creatieve eh ideeën gekomen over hoe je taalmodellen kan inzetten. Die creatieve ideeën zijn inmiddels meegetraind in het model hè, waar we het net over hadden. Oftewel, als we weten dat ze gebruikt gaan worden op zo'n manier, kunnen we ze misschien alvast een beetje voorbereiden op die taak. Hm hm. Daar zijn allerlei wetenschappelijke papers over hoe zorg je nou dat een model niet in een death loop komt bijvoorbeeld hè. Dus dat het in de cirkel blijft hangen. Dat het langer in één stuk door kan werken. Want dat is een heel belangrijk voorwaarde om taken van ons over te nemen. Zeker. Zeker. De oud eigenlijk de lange autonomie van zo'n model hè. Dus dat is die meter benchmark waar het vaak over gaat hè. Hoe lang kan zo'n model een menselijke taak doen zonder dat wij hoeven in te grijpen en is het resultaat ervan goed? Allebei belangrijk. Dat wordt nu meegetraind in de modellen. Hoe zij het voor elkaar hebben gekregen, wat hier de magic sal van is, is een goede. Ik weet dat niet. Ik weet wel dat dit ook de trots was van de modellen van Antropic. Eh namelijk dat het hun dat die behavior zo goed was geworden in bijvoorbeeld cloud code was overduidelijk voor programmeurs: Wauw. Waar die vroeger helemaal weg liep of vastliep, kan die nu door? Ja. Langer werken zonder af te dwalen. Ja. En ik denk dat een deel van die magic is wetenschap hè, want er wordt publiek tussen onderzoekers tussen die laps gepubliceerd over check hoe wij onze agents lang kunnen laten draaien en een deel is Secret Sals. Dit is een beetje abstract agents. Voor een programmeur is het heel praktisch dit. Eh want Gemini 3 programmeert ook weer beter. Dus ja, god dat wel interessant dat je dit zegt. Van alle benchmarks scoort Gemini minst spectaculair op Si, de software benchmark. Dus waar Entropic helemaal gekozen heeft om door te optimaliseren op software, heeft Google daar niet per se op door eh hoe zeg je dat? Geoptimaliseerd. Het is wel zo, maar daar gaan we het straks nog heel even over hebben dat hun antigravity scaffold, dus dat is een soort cloud code van Google, een stuk software om Gemini heen, dat als je dat stuk software dat hebben ze tegelijk uitgebracht met Gemini, dus ze hebben een model uitgebracht en een laag om het model heen. Dat heet antigravity. En dat antigravity is soort cursor, soort windsurf is concurrent eigenlijk voor die tools. Ja. En de cursor van Google, dus antigravity in combinatie met Gemini Course wel heel goed op die software benchmark. Oké, dus wacht, er is een dus wat is anti-gravity? Eh het is misschien toch goed om even te Ik moet het niet introduceren als ik het niet uitleg. De Nu is het zo dat veel software ontwikkelaars werken bijvoorbeeld in Visual Studio Code. Dat is een ID. Daar staat je daar staat je code in. Daar typ je normaal, daar typte je steeds minder. We lachen daarom. Ja, je typte je code. Mensen nog typen. En daar hebben mensen dan copilot in. Dat is niet de copilot die de meeste luisteraars kennen, maar de Github Copilot. En die doet mee in jouw software. Ja, dat wordt dus de Word Perfect voor eh voor programmeurs die eh Ja, daar zit ook een copilot in. Daar zit ook een copilot in Word Perfect. Fantastische metafoor. Dat die combinatie van die copilot en Word Perfect wordt ook als een pakketje geleverd door bijvoorbeeld partijen als cursor of winserf. Dan installeer je Word Perfect City Coopilet er meteen in. Het is prettige metafoor om op door te bouwen. Google heeft daarin nu gezegd: "Wijken ook." Eh dat betekent dat je eigenlijk een kopietje maakt van Word Perfect, want dat is open source in dit geval. En eh we brengen een eigen ding uit. Dus er is nu een cursor vanuit eh Google en die heet Antigravity. Een eigen programmeeromgeving omgeving. Absoluut. Ja. Hè alle tools, de hele riem met alle hamers en zagen eraan voor de ontwikkel. Ja. de tool kit. Wat is er speciaal aan antigravity? Twee dingen. Ten eerste is het specifiek gebouwd gebouwd om te praten met Gemini. Dus Gemini weet van Antigravity en Antigravity weet van Gemini, hè. Dat zijn de beste maatjes, hè. Dus het blijkt ook als je die combineert dat duo dat ze krachtiger zijn dan dat het model was, hè. Dus dan scoren ze ineens ook beter op die benchmark. Maar de benchmark ging nou eenmaal over het naakte model, hè. Dus waren allemaal mensen waren val spelen als je daar een app op bouwt op dat model. Mensen waren allemaal verbaasd ontwikkelaars van huh, hoe kan Google nou niet geoptimaliseerd hebben op dat? Nee, je moet eigenlijk die combo gebruiken, de duo en dan krijg je pas eh spectaculaire eh zaken. Wat is er nog meer spectaculair in Antigravity? Dit hadden we al wel in experimenten gezien, maar nog nooit zo diep geïntegreerd als Google het heeft gedaan. Stel jij gaat een website maken waar je kan chatten met een karakter uit Harry Potter in een soort Harry Potter chat. Dan eh typ jij in: "Ik wil een Harry Potter chat hebben." Dan gaat dat ding rondjes draaien. En op een gegeven moment zegt hij: "Nou, klik hier maar." Dan kan je naar je Harry Potter website. Daar ga je dan heen en dan denk je: "Oh, dit ding is gaaf." Jij bekijkt hem als mens. Dit is de oude situatie. Jij bekijkt die Harry Potter chat als mens en zegt dan: "Ik vind hem eigenlijk niet zo mooi. Kun je nog wat leuke gezelligheid toevoegen?" En die knop, ik kan hem amper in aanklikken, man. Wat een klein knopje. Dat moest jij dan doen. Dus jij was de human in the loop die het visuele resultaat kreeg van wat die chat had gemaakt, die AI. En dan moest je aan die AI gaan vertellen wat er niet aan klopte. Wat hebben ze in Antigravity gedaan? Gemini kijkt mee in de browser. Dus Gemini die ziet in die agentic loop hè, dus voor duidelijkheid, jij maakt die chat en dan zegt hij, voordat jij de chat hebt bekeken, zegt hij: "Oh, knopje is een beetje klein, die maken even groter." Maar je zegt chat een beetje verwarrend, maar je zegt dus je bent een website aan het maken van een chat. Ja, slecht. gewoon een website. Dus je bent een Harry Potter website aan het maken met dat ding. Harry Potter soundboard, knopjes. Ja. En normaal gesproken ehm zeg je dan: "Het is lelijk, maak het mooier." Dan genereert dat ding code. Dan druk je op apply en dan kun je dat in de browser zien. Ja. En dan hopen dat het lukt, want jij bent degene die te zien krijgt. Ja, precies. En nu zeg je eigenlijk er is een soort van feedback loop toegevoegd waardoor die naar die website gaat kijken. Dat deed hij niet hiervoor, maar hij gaat naar de website kijken daarop en klik en klikken en klikken door de website. Oh, echt? Ja. En dan Ja. Ja. Dit wat ze dit is wat ze dan noemen full circle agentic development. Oftewel het testen van de applicatie die gemaakt wordt, zowel visueel als interactief. Alle knopjes heb. Ja. En ziet het er een beetje prettig uit, is nu ook toegevoegd aan de cirkel. Ja. Ja. En dus kan je eigenlijk zeggen in jouw initiële prompt kan je een Harry Potter soundboard voor me maken dat er esthetisch prettig uitziet en dat goed te gebruiken is door mensen die het minder makkelijk vinden om te tappen op hun iPad bijvoorbeeld. Ja. En dan ga je dus ook in die: "Oh, ik heb het idee dat de knoppen wel klein zijn, want ik had de opdracht eigenlijk om ze groot, ik ga ze groter maken. Hey, ik zie dat ze groter worden, hè. Dus het dus het visuele resultaat." En dit werd al door andere ontwikkelaars, zoals het gaat zelf aan elkaar geknoopt, hè, die cirkel. Maar Google zegt nu eigenlijk: "Dit zit standaard in antigravity." Ja. Waardoor de eerste versie wat je opgeleverd krijgt alweer beter is dan wat je standaard in loveable ofzo krijgt. Ja. En dat is ook een beetje in de in de in de trend van eh wat je nu bijvoorbeeld even terugkomend op de pelan. Één van de dingen die mensen met die pelican op die fiets gingen doen is tegen eh AI modellen zeggen: "Hier, kijk nou eens naar die pelicanap." Ja, hè, dus screenshot van de pelican erin. En als je nu ziet wat jij gemaakt hebt, wat je dus niet wist, wat zou je dan nog veranderen? Ja, wat denk je er zelf van? Ja, en dan zag je dus dat die pelican 5 tot 10% beter werd als eigenlijk het model niet meer blind is, hè. Het is pretty much hoe het is. Browserblind als het ware. Dit model heeft ogen gekregen om naar de browser te kijken en neemt dat mee. En dat hij was gewoon blind aan het programmeren. Dat is misschien ook wel iets wonderlijks dat het eigen Ja, wij waren zijn ogen. Wij waren zijn ogen. Dat is toch eigenlijk heel knap hoever het lieve lieve computertje is gekomen zonder juist Dit is de juiste conclusie. Ja. Eh er is daarnaast ook Gemini Agent gelanceerd. Dat rolt deze week uit voor ultra abon ultra gebruikers. Dus dat zijn mensen die €200 per maand betalen denk ik. vraag zoiets. Ja, nou in ieder geval hoogbedrag en alleen de Verenigde Staten. Maar ik wil toch even erover hebben, want dit is een agentachtige interface die bijvoorbeeld je dingen kan het ziet eruit als Gemini gewoon. Het is gewoon die chat interface, maar die kan agentachtige taken doen. En het voorbeeld wat Google geeft is organiseer mijn e-mail, je Gmail dus. En dan checkt hij je inbox en dan gaat hij antwoorden voorstellen bij al je e-mails. Drafts maken. Ja, je draft vol loopt eigenlijk vol. Je draft loopt vol. Hij gaat e-mails organiseren, dus labels geven. Hij gaat als er taken zitten in die e-mail, dus je baas heeft je een opdracht gegeven of twee opdrachten gegeven, gaat hij dat opphakken in subtaken. Zeggen: "Klopt dit allemaal zo?" En vervolgens dan acties voorstellen. En dan kan jij met een soort van eh duimpje omhoog of duimpje naar beneden beneden constateren of de stappen die dat ding voorstelt, of je daarmee eens bent. En dan gaat hij het allemaal processen. Ja. En dit is eigenlijk iets wat we in eerste instantie voor het eerst te zien kregen in Open EI deep research agent. Die heette toen nog geen agent, maar gewoon deep research mode. Oftewel ga maar zelf een beetje het internet op zoek naar bronnen en maak een mooie synthese desk research agent was het. Research voor je doen. Ja. Ja. En dat was de eerste agent en ik denk ook de makkelijkste agent met aanhalingstekens voor open AI om te bouwen. Gewoon een beetje research toen. Toen had je aan de andere kant van het spectrum spectrum de computer use agents. Oftewel ga maar een beetje rondklikken op mijn computer. Dat is tot nu toe allemaal een beetje testen beta en loopt vaak een beetje in de soep. H we hebben nu eigenlijk een tussenvorm dat die bedrijven aan het zeggen zijn: "Wacht even, kunnen we niet een soort specialized agents maken die we standaard meeleveren in onze tooling?" Bijvoorbeeld een Gmail agent hè, dus die is goed op de hoogte van hoe Gmail werkt en hoe je Gmail aanstuurt. Dat weet Google, want het is vanuit Google natuurlijk. En dan zeggen: "Oké, wij durven eigenlijk we gaan niet dat ding laten rondklikken in jouw Gmail." Dat is een beetje te grof, hè, op pixel data. Ja, we laten hem met Gmail praten en we geven hem een goede omschrijving van Gmail en dan kan die eigenlijk best wel gave taken oplossen. En je zou kunnen zeggen dat wat nu in eh de Google Maps app hè met Gemini in Google Maps en Gemini in Gemini Home dat je nu steeds meer gaat zien scaffold zoals we dat zo mooi noemen die gespecialiseerd zijn op specifieke taken en software. En dit kan best wel krachtig zijn omdat en dit is een beetje ook de droom van heel veel mensen van kan je mijn mailbox even opruimen? Ja, tuurlijk. Dat is naast de vaatwasser inruimen denk ik de verzoek nummer één wat we hebben aan de AI overlords. Ja. Kun je mijn e-mail oplossen? Ja, los het op alsjeblieft. Het is zo grappig, want wij praten al jaren over Open en Google in de context van eigenlijk het is heel knap wat Open AI doet, maar als dat stoomschip wat Google is wat gewoon heel traag op gang komt al jaren, als ze dan eenmaal op gang zijn, dan moeten we er wel een hoop van verwachten. Want niet alleen hebben ze hun eigen hardware, ze hebben hun eigen cloud infrastructuur, ze kunnen direct in search proppen, in YouTube, in Gmail, in workspace. Miljoenen mensen krijgen het eigenlijk voor hun neus geschoven zonder dat ze een app hoeven te downloaden. Dat is alleen denk ik alleen al een Chrome waar eh Open AI een alternatieve browser voor moet lanceren om dan iets met die browser te kunnen doen. Google heeft dit allemaal al in de hele stack zoals dat dan zo gaaf heet. Ehm nou ja, bezitten ze eigenlijk alles. Ze hebben tijd, ze hebben geld. Ja, wat eh wat is je wat is je gevoel nog bij eh de open alleen heerschappij zoals dat toch nog wel eventjes voelde een paar maanden geleden. Wij openen de aflevering met openen jij is opgezet uit angst voor Google. Ja. En eh en dat die angst misschien een beetje waar bleek. Wat we nu zien gebeuren in ieder geval wat wat ik denk dat er gebeurd is, ik pak even de metafoor van de zelfrijnde auto. Zelfrijnde auto's zijn vooralsnog bestaande auto's van Jaguar, hè. Dus Google eh WMO koopt een auto bij Jaguar en daar plakken ze dan allerlei AI op hè. Dus er wordt een soort skybox op het dak gezet. Aan de zijkant duck tapen ze er nog even een paar leidar sensors en het stuur blijft er ook gewoon in zitten. Het is overduidelijk een oud paradigma auto uitgebreid met nieuwe spulletjes. En AI is er tegenaan geplakt als het ware. Wat je bij andere zelfrijndende autobedrijven ziet hè en Google zal dat zelf met WMO ook gaan doen is dat het een soort eh driving pods worden hè. een soort kleine busjes waar je tegenover elkaar zit, waar geen stuur meer in zit, waar de voor en de achterkant hetzelfde zijn, noem het allemaal maar op. Omdat je eigenlijk zegt: "Ja, als we een auto opnieuw zouden ontwerpen wetende wat we met AI kunnen, dan zit daar op zijn minst geen stuur meer in." Wat we nu een beetje meemaken, denk ik, is we hadden Google met AI erop geplakt, hè, de laatste twee 2,5 jaar. Dus wat toen nog Bart was en later Gemini werd steeds krachtiger, maar de synergie tussen alle verschillende diensten enzo was er overduidelijk niet, hè. Wij hebben daar ook veel grapjes over gemaakt samen de laatste jaren wat voor [&nbsp;__&nbsp;] het allemaal was. Ja. Ja. En nu om maar een voorbeeld te geven, eh Google had al heel lang dus die TPU's hè, dus eigen gespecialiseerde chips specifiek bedoeld om eh eh machine learning op te doen. Waar we dus nu GPU's van Nvidia voor gebruikten, wat eigenlijk gaming eh chips waren, had Google al TPU's liggen, maar de slag maken om die TPU's ook in te zetten voor taalmodellen et cetera was nog niet zo ver. Nu zeggen ze eigenlijk: "Oh, Gemini is klaar." En beide we draait ook op onze eigen hardware. Dus de hele hardware divisie is in sync zou je kunnen zeggen met het Gemini plan. Dan zeggen ze in Google Search heb je de AI modus of ik weet niet hoe dat ding heet. AI mode. AI mode. Dat was een overduidelijker ingehackte Gemini. En dat moest ook nog eens het Gemini 2.5 flash light model zijn. Dus flash betekent al kleiner en light nog kleiner. Eh die over het algemeen dus ook nog eens weinig kennis had. Dus het slechtste model wat je zou inzetten in een search engine waar mensen op zoek zijn naar feiten. Ja, voor de meeste mensen. Maar goed, waarom doe je zo'n klein model? Omdat je niet aan al je x miljard Google gebruikers die zware gave modellen kan geven. Kost te veel geld. Veels te veel geld. En die resources hadden ze gewoon niet. Wat wordt er nu gezegd? Nou, we zetten gewoon Gemini 3 in eh AI mode, hè. Dat het verhaal is nu dat het merendeel van de AI mode antwoorden ineens Gemini 3 zijn. de de full monti zeg maar het hele ding. En blijkbaar is het dus ook gelukt dus om dat het eigen TPU's zijn en en een efficiënte model getraind om te zeggen we gaan een zwaardere Gemini in Google zetten. Dus dat destijds was een beetje paniekvoetbal vind ik hè, want straks gaat iedereen alleen nog maar GPT voor antwoorden. Dus hack alvast maar wat AI in Google. En nu eigenlijk wordt de kwaliteit van het model daachter ook hoger. En zo zie ik dan een beetje voor me hoe langzamerhand al die kartonnen eh plakband oplossingen van van de pre eh Google era nu langzaam naar een professioneel niveau gaan waarop dingen echt goed met elkaar gaan samenwerken. Ja. En ik zeg moet er wel even bij zeggen hopelijk want zo makkelijk is dat niet. Deze Gemini release was wel iets meer dan alleen maar een model release. Namelijk ook de integratie op allerlei vlakken in Google. Nou, zelfs in Google Search dus. Want de Ja, god is eh wij praten graag over allerlei niche dingen, maar dit is natuurlijk de de het feit dat het in Google Search zit gelijk de dit grote model. Dat is wel Ja. En ze hebben ook de interface aangepast. Het kan nu zo zijn dat als jij typt het in de searchbox, maar het systeem heeft door dit is eigenlijk een overduidelijke chat GPT achtig gevraagd. Als in een feiten vraag of uitleg over iets in plaats van dat mensen op zoek zijn naar de website van Coolblue. Precies. Precies. Eh dan verandert de interface in een soort chat GPT achtige interface. Ja. Ja, dat is die AI mode. Die kiest die nu zelf uit bedoel je? Ja, ik bedoel te zeggen dat de AI mode was een beetje een wonky iets en nu is die zit er ook intelligentie van Gemini achter om te bepalen volgens mij wil jij meer een soort AI mode dan een eh klassieke search mode. Wat twee kanten op natuurlijk prettig is hè, want soms wil je gewoon klassieke search mode. Ja, het is best wel een groot een groot ding dus. Nee, ik ik ik eh ik hang aan je lippen wietsen. Eh dat antigravity hebben we deze week trouwens in AI Report getest. Eh we hebben voor de grap gekeken hoever Gemini komt als je hem bijvoorbeeld een website laat nabouwen. En dan zie je dus letterlijk Gemini browsers, zoals jij zegt, schermafbeeldingen maken, zijn eigen werk beoordelen en die code dan aanpassen. En onze redacteur Shan kon dat resultaat in realtime volgen. En die dat eindresultaat was best oké, maar ze is ook kritisch. Dat ding ehm kreeg veel errors, wat misschien te maken heeft maar met de drukte, maar wat misschien ook zegt dat het allemaal nog in testfase zit. En dat was erg frustrerend voor haar. Maar ze had ook door dat ding eh dat ding had door wanneer het errors tegenkwam en pakte na crashes ook de draad weer op. Nou, hoe dat allemaal ging lees je in de nieuwsbrief van deze week en een review van Canvas Gemini interactieve interfaces builder waar het heel goed in is en waar het minder goed in is en hoe je het maximale uit die tools haalt. Als je naar eort. Krijgen. En dan nu iets heel anders. We praten vandaag met Pim de Witte. En Pim die is een 30-jarige Nijmegenaar, oprichter van Medal TV. En dat is één van werelds grootste platformen voor het delen van video's uit computer games. En dan denk je: "Waar hebben we het over?" Maar dit is wezenlijk. En dat zal zo duidelijk duidelijk worden. Medal is dus een ja, een bedrijf wat al heel lang heel populair is, maar onder een hele specifieke groep mensen, namelijk gamers die het leuk. Wij kenden het allebei niet toch? Nee. Nee, nee, zeker niet. Maar ik maak uit de omzetten van dit bedrijf op dat het goed gaat met dat bedrijf eh al heel lang. En dat dus wat gamers willen is als zij eh een spelletje spelen dat ze dan de videobeelden uit die games kunnen delen. Klippen. Clipjes delen. Clipjes delen. Ehm dat doet hij al jaren en stiekem is hij eh doorgestoten naar S'solds grootste plek om beelden uit games te kunnen clippen, om met anderen te kunnen delen. En al die videobeelden die heeft Pim opgeslagen. Ja, die hebben ze bewaard die clipjes. Die clipjes die hebben ze bewaard. En even nog toch nog aan te geven hoor in de orde van grootte en dit verbaast mij dus enorm. Dit is ehm het aantal game clips in minuten aan beeld geüpload naar medal is hoger dan naar YouTube. Juist. Het is een vrij grote database van mensen die spelletjes spelen. Specifiek game beelden zeg ik bij hè. Ja. Juist. En wat blijkt nou? Dit is de missende schakel om world models te bouwen. En dat is een term je al vaker in deze podcast hebt gehoord. Het is iets soort van volgende fase van taalmodellen waar taalmodellen tekst uitschrijven. Zijn world models goed in het begrijpen van alle details van de wereld. Zeg ik dat goed? Jazeker. Ja. Waar je bijvoorbeeld wat je bijvoorbeeld nodig zou hebben om een auto rond te laten rijden. Ja. Dus een auto die zich moet navigeren door Amsterdam en er rolt een bal overstraat dat hij dan begrijpt: "Oh, er komt nu een bal aan, dus ik kan beter remmen, want er komt misschien een kind achteraan." Heb je weinig aan het lezen van Dostojevski? [gelach] Ja, jouw kennis over Dusk Jeevska is daar daar matig eh hulp eh relevant voor. Dus wat een world model doet is getraind op videobeelden om te kunnen dromen over hoe de echte wereld eruit ziet. Om te kunnen voorspellen wat er allemaal kan gebeuren in een wereld zonder dat je daar eerst video van hebt gezien. En dat noemen we generaliseerbare technologie. dingen kunnen voorspellen op basis van beelden. En al die AI bedrijven zijn bezig met world models omdat ze allemaal de vermoedens hebben dat dat nogal belangrijk gaat zijn voor autonomie van robots in de breedste zin. Want je hebt het over auto's, maar dat gaat ook over drones. Het gaat ook over humanids. We hebben het al in deze podcast hier heel vaak over gehad. En met taalmodellen komen we er niet. Dat is niet met taalmodellen komen we er niet. Want je kan wel beschrijven hoe die robot moet lopen in tekst en dat die robot dat dan gaat doen. Maar het blijkt toch beter te werken als die robot kan dromen over de echte wereld en kan voorspellen je hoe je je moet gedragen in onverwachte situaties. Ja, in in een eerdere afleveringen en in eerdere AI Report nieuwsbrief ging het over Butterbot. Namelijk een soort Roomba die een blokje boten moest rondbrengen door een kamer heen. Ja. Met en daar hebben ze toen taalmodellen ingestopt. En die taalmodellen kregen vooral een essentiële crisis, want het lukte allemaal niet. Ja, maar dat botertje werd amper gebracht. Dus dat liet ook zien: "Dit is niet genoeg." Nee. Dus eh ChatGBT en taalmodellen, de de revolutie die eraan te grondslag ligt, zijn niet genoeg, constateren we, om robots autonoom voor te bewegen in de wereld. En dat is wel een droom die de mensheid heeft, zou je kunnen zeggen. Nu is daar dus Pim uit Nijmegen, hecht ik eraan om te zeggen, die toevallig heel veel clipies verzameld heeft. to heel veel clippies heeft verzameld van games. En waarom zijn games gameelden wezenlijk of interessant voor het trainen van die world models? Omdat het heel voorspelbare data is. Ja, het is ook prettig vaak vanuit hetzelfde perspectief opgenomen, namelijk vanuit de speler hè, dus in de game. Heel stabiel camerashot en ehm ja, die games zelf die dat zijn redelijk gecontroleerde werelden hè. Het zijn allemaal andere soort games, maar als je de game naam weet, weet je ook binnen deze game een racing game is heel veel race data aanwezig. En die ziet er ook allemaal ongeveer een beetje hetzelfde uit. Ja. Je moet dus als als mens moeten wij nu accepteren. Dat is iets waar ik altijd moeite mee heb om een to wrap my head around it. Maar dat je dus video's van mensen die racepelletjes aan het spelen zijn heel belangrijk blijken te zijn om straks zelfrijdende auto's beter te kunnen maken. Dat is nou het voelt als kinderspel. Het voelt als soort van oké spelletjes, wat maakt het allemaal uit? Maar stiekem is langs is aan het duidelijk worden dat game beelden een super belangrijke bron zijn voor het maken van die road models waar we hoge verwachtingen bij hebben. En Pim is niet alleen hè, want Demis Hasabis, Demis Hasabis van Deep Mind die heeft zijn hele carrière gegokt en zijn hele wetenschappelijke carrière en zijn zakelijke carrière op het idee dat computer games de sleutel zijn tot een grotere vorm van ja, ik wil het AGI misschien wel, laat ik dan even zo zeggen. Dus Pim is niet alleen in de in deze aanname dat dit belangrijk gaat zijn. Bedoel je? Ja. Waar Pim alleen in is, is dat hij de enige is die zo'n grote database heeft van die game beelden. Beelden van echte mensen die spelletjes spelen, zich gedragen als echte mensen om dingen te doen in spelletjes die we stiekem in de echte wereld ook doen. hebt allerlei spelletjes waarbij mensen eh van racen, maar ook treinsimulatoren en weet ik veel allemaal dingen die wij in het echte leven doen waar heel veel beelden van zijn uitspelletjes die we zouden kunnen gebruiken om banen te automatiseren waar we nu mensen voor gebruiken. Ja. En een belangrijke, dit had ik pas vrij laat door toen ik ging kijken naar wat Pim allemaal aan het doen is. Hij levert niet alleen maar de mogelijkheid om jouw clips te delen. Hij levert ook de video recorder hè. Dus je kunt hoe het het is leuk dat jij clipjes uploadt bij hun, maar die clipjes worden perfect geüpload zoals Metal wil, want je neemt het op metal. Dat is een app die je installeert. Ja, hij heeft allemaal metadata rondom die clipjes waardoor die op een soort van ja eh ja, gestandaardiseerd eigenlijk een hele een hele prettige manier. Het komt allemaal het is allemaal alle videobanden zijn opgenomen met een metal video record. Ja. wat het wat het voorspelbaar maakt, gestandariseerd maakt en daarbij heel goed bruikbaar voor het trainen van die road models. Ehm hij sloeg dit bedrijf dus hij kon dus ja, hij constateerde: "Ik zit op een soort van Groningse gasbel, want dat is wat er is gebeurd. Die komt dus uit Nijmegen en niet uit Groningen." Nijmeg bedoelen we dus dat het niet explosief is, maar een grondstof. Een grondstof. Ja. Op ons grondgebied. Op ons grondgebied, namelijk het land Nederland. Wij hebben de clips. En wij hebben die clips. En eh toen kwam eh naar verluid Open AI die zei eh dit willen wij. Wij geven jou een half miljard, dan geef jij ons jouw bedrijf. Toen zei Pim naar verluid eh n en toen startte hij een nieuw bedrijf genaamd General Intuition, een eh AI start-up met tot nu toe 130 miljoen investering gebouwd op de gok dat hij dus die miljarden uren aan beelden uit games en niet enkel tekst uit boeken de sleutel zijn tot het bouwen van die world models die de fysieke wereld begrijpen. Wat nu volgt is een vrij complex gesprek, zeg ik erbij lieve luisteraar, waar heel veel terminologie in voorkomt, waar het af en toe je zal duizelen. Maar geloof mij als ik zeg dat het je tijd toch waard is. Absoluut. Eh want het is denk ik uiteindelijk eh als het ding rond is wel te begrijpen en dan begrijp je volgens mij ook wat de het belang is eh van niet alleen world models, maar ook het feit dat dit een Nederlander is die tot nu toe vrij onder de radar heeft gevlogen en dat hier allemaal zit te vertellen. Ja. En ik denk dat Alexander en ik intuïtief aanvoelen al vrij vroeg in het gesprek: "Dit is belangrijk, maar het kost ons even om Pim te temmen. [gelach] Ik weet niet of het ons ooit gelukt is, omdat hij zo diep in de materie zit." Hij zit er diep in. Hij zit er diep in. Dus blijf erbij. Eh doe je best. Eh concentreer je op wat er gezegd gaat worden en eh laat je inspireren door Pim de Witte. Ja, zet je auto soms gewoon even langs de weg, joh. Precies. Het is Denk je dat de wereld straks kan met world models? Ja. Ehm world models. Ik denk dat de eerste case is simuleren van dingen eh wat heel hoge kosten heeft voor ehm als je een echte wereld zou moeten simuleren. Dus bijvoorbeeld een een een crash met een auto. Ehm eh een gevaarlijke eh maneuvre in een boot of wat dan ook. So alle dingen die je zeg maar autonoom ehm eh wilt controllen dan eh dat dat dat soort data bestaat niet zeg maar. En ook om het om het te bouwen is is heel duur. Ehm ook bijvoorbeeld ehm als je traditionele simulaties bouwt is het heel lastig om het heet stocasticity om zeg maar onvoorspelbaarheid te simuleren. Hoe mensen echt gaan reageren op dingen voor bijvoorbeeld een zelfrijnde auto. Is dat een goed voorbeeld? Ja. Bijvoorbeeld als je bijvoorbeeld over ehm door een drukke stad rijdt. Hm hm. om om goed zeg maar mensen te simuleren die echt als mensen ehm zich voordoen is heel lastig. Eh ehm en het kost heel veel compute. Eh en en dus wat je wil doen is je wil eigenlijk gewoon een videomodel hebben of wat dan ook die dat die dat dingen al gezien heeft en dan wil je daar een interactieve layer op gooien zodat je dan gewoon daarin kan duiken zeg maar. Ehm en dat dat is dat is een beetje het verschil. Ja. Eh en ehm ja, dus dus eh en het is ook voor robots bijvoorbeeld, het zijn gewoon zoveel dingen waar je gewoon geen goede video op het internet van hebt en waar je ook niet goed van kan leren. Ja, wij verwachten allemaal en daarna gaan we nur dooror, maar wij verwachten allemaal dat je eh dat we robot gaan krijgen of misschien voertuigen of alles wat daar tussenin zit, die gaan snappen hoe ze zich moeten voortbewegen in een onvoorspelbare echte wereld. En de hypothese die jij hebt met jouw bedrijf is games zijn een uitstekende bron h om te leren over de echte wereld. Mensen die spelletjes spelen zijn een hele goede bron om een systeem te laten dromen over de echte wereld. En daarmee wordt de echte wereld voorspelbaarder. En jij bent daar eigenlijk een sleutel in. Zo'n belangrijke sleutel dat blijkbaar Open AI zegt: "Hier is een hier is een eh een half miljard eh voor dit bedrijf." Waarom heb je daar nee tegen gezegd? Eh officieel eh kan ik geen kan ik geen comments geven op openi. Ehm ik kan je wel comments geven op zeg maar hoe we naar de markt kijken. Wij wij zijn erachter gekomen dat we zoveel van dit soort data hebben dat we gewoon world models eigenlijk als tweede kunnen doen. En we kunnen gewoon net zoals LMS kunnen we eerst gewoon zeg maar de de het heet supervised learning wat ik net uitlegde met die masking en de predictions. Ehm je kunt eerst gewoon een hele grote supervised learning pad nemen. Ehm en eh en dan je kunt zeg maar tegelijkertijd die world models bouwen en je kunt en en dus voor ons zeg maar elke elke stard lab die moet nu 2 d jaar lang moet die world models scalen bouwen. Het kost super veel computer want je zit ja als Google wil beginnen dan hebben zij heel wat meer eh in te halen eigenlijk terwijl jij al een enorme database met videogame beelden hebt liggen. Precies. Het is een beetje alsof ik zeg maar bij dat we het internet hebben en niemand anders heeft het internet. Dus we moeten het internet gaan simuleren. Ja. Eh waarom is dit zo'n belangrijke gaat dit zo'n belangrijke rol hebben voor AI agents? Ja, ehm je kunt natuurlijk nu al zien bij chatbt en dat soort dingen eh het is heel goed met met dingen in tekst doen, maar alle computer used agents en dat soort dingen zijn allemaal nog heel slecht. En de reden is omdat die die de ehm de dat de data scaling last van tekst, kijk, dus tekst is heel goed te vinden op internet, maar dat soort zeg maar interaction data niet. Ehm en dus hoe je eerst naar betere computer modellen gaat en dan heb je daar game video voor nodig voor voor een voor een taalmodel dat beter een toetsenbord en een muis kan bedienen. Ja. Ja. Je kunt eh bijvoorbeeld er is een ehm een paper van Bance dat heet UI Tars en dat eh en daar gebruiken ze eh games om te pretrainen. En wat ze dan doen is ehm en de reden is omdat SAS applications zeg maar software is de service ehm die lijken heel veel op elkaar en je wil eh ehm je wil bij het trainen van die modellen wil je juist heel veel het heet enter token, dus heel veel diversiteit hebben. En omdat die SAAS applications zoveel op elkaar lijken, krijg je meer eh learnings van hele diverse game interfaces. Denk denk bijvoorbeeld een Kurbal Space Program of wat dan ook waar je letterlijk een raket in elkaar zet. Ja, dat is een spelletje waarbij je een heel ingewikkelde interface krijgt om een raket te bouwen. Precies. En en bijal zit zijn daarmee kan een AI leren hoe die slack moet gebruiken. Ja, dus maar het gaat maar wat Oké ehm wat je hiervoor moet begrijpen is een LM niet alles zit in de pretraining. Een lm is ook heel goed als je bijvoorbeeld dan later heet expert reasoning change en dat soort dingen toevoegt. Dus het het gaat om de om de transfer. Ehm dus natuurlijk als je alleen op game data traint dan zero shot je niet slack. Maar wat het wel betekent is dan heb je 100 keer minder slack data nodig om slack te doen. Ja, ik ga dit even vertalen. Als je alleen maar eh kijkt naar hoe iemand eh Slack gebruikt, heb je niet genoeg om Slack helemaal te kunnen bedienen automatisch door een computer. Je hebt er meer aan door te kijken naar heel veel spelletjes die niks met slecht te maken hebben, maar die wel mensen zijn. die spelletjes aan het gebruiken zijn om om ingewikkelde dingen in elkaar te zetten. Ja, dat is een fascinerend idee. Ja. En het gaat om de diversiteit eh van de interfaces. Ja. Eh gaming interfaces lijken minder op elkaar dan SAS. En dat is goed voor een AI goed voor AI model, want dan is hij generalistischer en kan hij verschillende dingen doen. Niet alleen Slack, maar ook Microsoft Word en ook Microsoft Excel et cetera. Oké. En je zegt eigenlijk zijn het is een tweestapraket, want je hebt dan eerst die eerst computer use als je dat noemt. Dus het het een AI die eigenlijk eh ja, programma's op je computer automatisch bedient en zo automatisch voor jouw complexe taken uitvoert. Daar kun je game data bij gebruiken. Dus die video's voor jou zijn daar heel waardevol voor. En ten tweede krijg je die uitgebreidere world models die gebruikt gaan worden om robots door de de wereld. En en daarin zeg jij: "Mijn bedrijf brengt daar versnelling aan voor groot bedrijven." Ja, dat is de in algemene zin waarom AI bedrijven misschien half een half miljard bieden voor een bedrijf zoals dat van jou. Ja. Ja, ik denk dat door ons dat wat mensen dachten dat in de volgende vi jaar kon dat nu misschien de komende é tot 2 jaar kan. Juist. Waar ik me over verbaas is eh Google heeft YouTube en ik heb ben er eigenlijk altijd een beetje naïef van uitgegaan dat eh dat zij daarmee hun treasure trove wel hadden, hè. Ja, de meeste labs waardoor die modellen nu ook op elkaar lijken allemaal hè. Dus de taalgebaseerde modellen. Er is geen common craw voor video zeg maar. Geen video common craw. En YouTube is dat ook niet. Ja. Ehm hele goede vraag. De ehm paar dingen. Één, Metal heeft eh qua games meer uploads dan YouTube. We hebben een miljard uploads per jaar ongeveer. Ehm YouTube heeft geloof ik vorig jaar ook zoiets ik 900 miljoen ofzo. Eh en dat is in alles ik ik denk niet dat er shorts in zitten, maar ik denk dat de de de public upload ehm ehm met YouTube data heb je drie problemen. É als het op een mobiele telefoon opgenomen is, zit je niet in in de perceptie van de persoon die de acties neemt. Dus dat toestel zit niet aan iemands bril geplakt. Zit je niet in de ogen hand. Precies. Dus dan moet je iets gebruiken dat heet post estimation. Post estimation is waar je zeg maar probeert vanuit een ander ehm eh punt zeg maar de ander camerastandpunt bijna ja andere te te genereren. En dat doe je ook met AI. probleem daarvoor is nou je gaat een heleboel dingen simuleren die oude distribution zijn. Dus het is niet, het is zeg maar, het generalized niet supergoed. Dus je kunt zeg maar als je hele complexe dingen eh ziet, dan werkt dat niet heel goed. Het feit dat mensen zelf de camera vasthouden maakt dat het eigenlijk hele rommelige data oplevert. Ja, precies. Want wij hebben gewoon ogen die zeg maar goed zeg maar vastzitten. Ehm en en het tweede ehm eh dus dus en daarom zijn point of view beelden die in games normaal zijn veel beter om op te trainen. En en het tweede is omdat je omdat je die supervised learning methode moet gebruiken die ik uitlegde, moet je dan human labelers zeg maar mensen die die videobeelden gaan labelen met de acties. Maar ehm fysieke mensen die naar een video kijken en dan eigenlijk op het toetsenbord gaan nadoen dat als dit een game zou zijn, dan zou de camera zo bewegen bijvoorbeeld. Ja. Ja, maar dat kunnen mensen helemaal niet. Dat het is echt de En niet op die YouTube beelden, want die zijn veels te vaag. Nee, nee. Ja, ze zijn vaag. En ook ehm eh zeg maar je moet het eigenlijk met milliseconden precisie dat soort dingen kunnen doen. En dat kan dat kunnen laberschaltjure weet je als je €10 per uur hiermee verdient of wat dan ook dan ja hoe goed ga je dat zeg maar doen weet je. Ik denk ehm eh dus dus dus dus je hebt de acties niet. En de derde en dit is denk ik de belangrijkste is ehm ook al heb je alle twee die dingen, de echte eh special temporal zeg maar beslissing die is meestal een resultaat van zeg maar waar je ook je ogen naartoe beweegt. Dus de optical dynamics heet dat. En ehm dat kun je zelfs met post estimation, dat soort dingen kun je dat niet echt inschatten. Dus je je hebt zeg maar drie information loss events. Pose estimation, actions, optical dynamics. En daardoor kun je die supervised bed niet goed nemen. Ehm dus je kunt zeg maar eh weet je ehm ik ik denk natuurlijk weet je ze ze proberen het en maar ik denk daarom denk ik dat we ook zeggen want het gaat vijf gaat voor hun vif jaar duur ze moeten al problemen oplossen met AI ehm ja om eigenlijk hun bestaande datet geschikt te maken. Want zou ik zou ik je zou ik het zo kunnen interpreteren. Ja net over Saas applicaties. Als je allemaal opnames van Slack maakt dat is eigenlijk niet divers genoeg hè. Dus die opnames van al die sleken rondklikken en eh eh OneDrive, dat is niet genoeg. Dat is divers genoeg. Maar eigenlijk zijn die beelden die YouTube heeft te divers. Als ik je zo hoor, hè, in een soort diversity slider. Nee, je wil diversiteit hebben, maar je wil ook wat heet ground truth hebben. Dus je wil zeg maar ehm eh je wil geen variatie hebben in the observations and the perception, maar je wil je wil eh je wil variatie hebben in wat je waarneemt. Ja. Dus je standpunten moeten vast zijn. Ja, en daar mag best diversiteit met hetelfde standpunt. En wat YouTube niet heeft is een vast standpunt om het even voorbeeld te noemen. Preci precies vast standpunt en de acties en en als als en die optical dynamics dus als resultaat kun je die lm bed gewoon niet nemen. Ehm en eh en alles het nemen. Kijk je je kunt in AIQ kun je heel veel met veel computer oplossen. Ehm dus dus maar ja, het gaat ze gewoon veel langer duren en het gaat veel duurder zijn. Ja. En want jullie dataset is dus en divers en heeft die vaste standpunten hè om het even plat te slaan. En dat maakt het zo'n ontzettend waardevolle dataset. Ja. En en ook omdat die die optical dynamics, dat special reasoning is heel belangrijk. Want in games is alle informatie die die tot een beslissing eh waar je eh op basis van waar je beslissing neemt is op het scherm. Dus je weet 100% zeker dat er zeg maar geen information los is tussen wat je ziet en wat je beslist. Ehm en eh zelfs daarnaast eh met de muis eh simuleer je die optical dynamics, want je daarmee daarmee zeg maar zeg maar ehm eh doe je de ogen stimuleren een beetje, weet je wel, want je zeg gewoon links, rechts kijken, dat soort dingen. Dus dus je stimuleert met je hand dat soort dingen. Ehm eh en daardoor he is het gewoon een hele goede data op space reasoning. Dus het het is de beste representation van space reasoning. Dus wat daarom zeggen we ook we doen ehm eh general agents for environments require deep space and poor reasoning omdat wij we wij willen een beetje zeg maar de anthropic code bad nemen is heel hard gefocust op code. Ja. Dus met Antropic cloud die zijn helemaal aan het specialiseren binnen die software niche omdat zij daar ook tokens verkopen en dat gaat goed hè. En jij zegt wij gaan ook een niche kiezen. Wij wij wij verkopen vision tokens in action tokens uit. Heel simpel. Hm. Dit is de wereld en als je die wereld wil manipuleren zoals jij dat zegt, zoals een een auto die naar rechts moet rijden, dan is dit de Ja. actie die je moet ondernemen. Ja, precies. Maar waarom vraag je het over over YouTube iets? Hè? Nou, ik denk dat ehm Kijk, ik ben wel nieuwsgierig van Medal, hè. Dus voor de luisteraar, er is een bestaand bedrijf Medal. Dat dat is jouw bedrijf en en een nieuw bedrijf waar we het zo over gaan hebben, wat eigenlijk uit Medal geboren is, toch? Hè? En maar toen jij Medal startte of toen je toen jullie medal starten, wist je dit al of is dit zeg maar Nee, dit dus in alle eerlijkheid hè, je bent het niet gestart met het idee met een soort soort Demis hasabis achtige gaming AI visie. Nee, nee, het is het is nog erger zelfs. Toen ik eh eh ik ik werkte in eh 2015 2016 op hetzelfde eh etage als Deep Mind eh bij Google. Ik werkte voor arts zonder grenzen, maar ik werk toen aan Ebola. Ehm en eh en Google had had ons project overgenomen daar en ik had het met die deepminders over deze soort experimenten. Ik zeg: "Ah, dat is echt dom. Wat zijn jullie aan het doen met die games?" J. [gelach] Dus ik had ik had ik had voorkennis en daarna ben ik Menel gestart. Ik had zelfs toen nog geen idee. En het was eigenlijk toen eh Maar ik ik weet je, ik ben altijd Wat vond je dom dan dat ze spelletjes aan het spelen waren? Echt, want zij gebruikte toen games om hun modellen te trainen. Ik dacht van ja, je heb je kunt nooit je kunt er nooit genoeg data uithalen zeg maar van individuele spelletjes en dat soort dingen, weet je wel. Dan en je en het is ook niet echt je speel niet tegen mensen en dat soort dingen, want dat kun je niet doen, want dan heb dan word je geband vanwege anticheat en dat soort dingen. Dus ik had alle al die reden waarom het niet zou werken. En ehm eh en toen toen toen ben ik medal gestart en ik heb er nooit aan gedacht. De de link nooit aan gedacht. Ehm ik heb ik heb wel zeg maar 2016 2017 met Tensor Flow en dat soort dingen heb ik toen voic modellen gebouwd. Ik ben ik ben al mijn hele leven redelijk technisch, maar ik heb die link nooit gemaakt. Ehm eh toen dat het bedrijf wat je gebouwd had stiekem een cruciale factor zou kunnen zijn in Ja. Ja. Ja. En ehm en het is wel grappig, want Deepmind die heeft toen ook die van papers gepublished over he zeg maar over ehm eh creating like the episodic memory eh om ehm om modellen te trainen. En ehm eh en ik heb nooit wij legden metal altijd uit als zeg maar het episode geheugen van mensen in simulatie. Ehm want het zijn zeg maar de highlights, weet je wel, de dingen die eh die heel belangrijk zijn die wil die je wil onthouden. Ehm en we hebben we we hebben zelfs toen die link nooit gemaakt. Eh en toen het was het was na 2000 het was na GPT2 of GPT3 waar ik had ik weet je ik begreep een beetje hoe die dingen getraind zijn. Eh en toen uiteindelijk heeft Deep Mind heeft Genie heeft de originele Genie paper een Simma paper toen gepublished. Dat is het basis idee over hoe je een world model kan bouwen, de echte wereld kan simuleren in een Toen begonnen mensen ook een beetje te zien dat het dat het werkt, dat het kan. Ja, op die schaal inderdaad. En ehm ja en toen heb to het eerste wat ik heb toen heb gedaan is heb ik eigenlijk dem een e-mail gestuurd. Eh en eh ja dat was een beetje het het begin van eh van alles wat er daarna gebeurd is. Ja, want misschien kijk jij jij begint dus eigenlijk metal met niet die intentie, maar je zit hier nu met allerlei machine learning eh generative AI jargon waar Alexander en ik best wel ons best doen ook voor de luisteraar om ze een beetje te helpen hè. Ja, hoe hoe is dat dan zo gekomen dat je er nu eigenlijk wel zoveel van weet en zoveel mee bezig bent terwijl dat eigenlijk niet je achtergrond is, toch? Ja. Ehm ik denk een paar dingen. Één, ik heb eh hele slimme co-founders die en ik vraag heel veel vragen. Eh en ik heb ik heb ook eh van de zomer heb ik ehm eh deep learning eh courses gedaan. Ik voor die announcement. Eh want ik ik ik heb toen een beetje deze zomer. Ja. Ja. Ik gewoon om de basis te versterken, weet je. Ik had ik had ik ik heb ehm eh dus ik heb toen tegen mijn couer gesag van: "Hey, als ik zeg maar heel heel goed hierin moet zijn, het zijn allemaal PhD's, weet je wel, welke courses moet ik deze zomer doen om zeg maar op jullie niveau en ik kan nooit op hun niveau komen Nee, maar wel met ze te kunnen praten." Ja. Ja, maar kijk, mijn achtergrond is zeg maar infrastructure engineering en en low level system zijn ook GPU's. Ik heb ik heb de hele transcoding video transcoding stack van Metal geschreven. Dus een heleboel van de dingen waar ze mee bezig zijn was ik al redelijk goed in. Maar het eh het modellen bouwen zelf is is één heel wiskundig eh zoals je weet. Ehm en ehm eh en en dit is het is een hele dit is zeg maar diepe specialiteit. Dus ik ik ik zeg ook niet ik ben zelf geen expert in het bouwen van modellen. Ik maar ik begrijp wel hoe alles werkt. Ehm en eh ja, dus ja, dus ik ik heb toen ook een beetje eh de cultuur gezien beschill in verschillende AI bedrijven en eh het verschil tussen bedrijven met eh waar ze eh goede AI kennis op de top hadden en niet en zeg maar demis natuurlijk die kan dit allemaal heel goed. Ehm en dus ik dacht van ja, ik moet voordat ik die announcement doe moet ik heel goed studeren en zeg maar echt het begrijpen. Want op het moment dat ik die announcement doe, dan gaat het heel hard en dan heb je daar geen tijd meer voor. Ja, het is inderdaad ongelooflijk hoe recent dit allemaal is. Deze zomer heb je een nog een aantal cursussen gedaan. Het geld ophalen is ook deze is ook pas een paar maanden geleden. Ja, dat is insane eigenlijk, want daarvoor was jouw wereld was was echt het is een heel heel vet bedrijf wat je had gebouwd, maar het was geen AI bedrijf. En dit is allemaal gewoon het afgelopen half jaar gebeurd. Ja. Ja. van het feit dat het ook een best wel een bizarre turn is hè, want iemand komt eigenlijk aan jouw deur en zegt wat jij wat jullie in handen hebben, wat jullie hebben opgebouwd met elkaar. Als wij dat zouden hebben hè, dat zullen meerdere partijen zijn geweest, dan kunnen wij daar heel mooi op doorbouwen en jij zegt: "Nee, maar ik word gewoon zoals jullie dan. Ik ga doen wat jullie doen of k ik ik zeg maar ik doe het zelf wel in ieder geval." Deze guys die werken al vif jaar lang models voor voordat het cool was. Eh welke guys bedoel je dan? eh Vincent en Cofounders. Ja, die werken die werken al. Die hebben ook die hebben zelf die hebben zelf die papers schreven waar eh Genie deels op gebaseerd was. Dus dus die zijn Kijk ehm het het e ik zou hoe zou ik het kunnen uitleggen? Ehm eh ik ben een beetje een 18-jarige die in die auto stapt, weet je. Ik heb net mijn rijbewijs gehaald. Ik weet hoe het beetje werkt, maar ik hoef ook niet ik ik hoef niet zeg maar alles te weten. Ik moet ook een bedrijf natuurlijk operaten. En zij zijn de de Formule 1 drivers. Ja, maar je hebt hun er je hebt hun erbij maar je hebt hun erbij gehaald toch? Ik bedoel recent omdat je dacht: "Ik wil het zelf doen." Want toch nog even terugkomen op je vraag hè. Bedoel je had ook kunnen zeggen en dit doen volgens mij de meeste schat ik zo in. Ik verkoop het. Wat een mooie exit voor medal. Ja, ik ga lekker eh wat is het Demis en Sams videootjes en boeken lezen in mijn eigen tijd en ik begin helemaal niet een nieuw bedrijf. Ik vind dat gewoon een interessante keuze van je. Ja, ik ja, ik ben ik ben 30. Ik heb ik ik weet je, ik alle AI leaders zijn allemaal veel ouder zeg maar. Mijn generatie is denk ik één van de meest zeg maar affected bij dit soort dingen. En en ik dacht van ja, weet je wel, als we de kans hebben en d is ook in Europa is er niet veel. Ja, zeg maar wat zeg maar kijk naar andere bedrijven gaat niet heel goed. Ehm en dus ik dacht van ja, als we de kans hebben moeten we het gewoon doen. En ik wist natuurlijk niet 100% zeker dat die kans er echt was. Het duurde echt weet je en en het ik het is meer anderhalf jaar zou ik het zeggen. Want we hebben natuurlijk ehm ehm ja de mid 2024 is zeg maar echt allemaal heel hard gegaan. Ehm en ehm eh ja eh en toen ja we geloof het zelf eerst ook niet. Eh het het was echt toen ik de toen ik die researchers gerecruit had dat we het echt allemaal doorgenomen zijn en van ja oké kun bedoel je geloofde niet dat mensen op dat niveau geïnteresseerd zouden zijn. Nee, nee. Eh dat dat we dat we dat we zo belangrijk zijn voor AI weet je het het is het is ehm juist ja, er zijn echt een paar rare dingen hier bij elkaar gekomen. Namelijk jouw enorme datet, het feit dat je mensen kent die al heel lang met die world models bezig zijn. Het zijn allemaal en dat dan vervolgens dat een missend puzzelstukje blijkt te zijn voor de grootste techbedrijven ter wereld op dit moment. Dat al die dingen tegelijkertijd samenvallen. Verklaar. Hyé. En als je dan dit pitch jij dus bij investeerders waarschijnlijk de hele tijd. Wat is als je als je nu jouw bedrijf pist bij investeerders? Dat is forward looking. Dat is dan kijk je in de toekomst. Wat wat pitch je ze dan? Ja. Ehm en je ziet hoe goed het is gegaan bij Anthopic om gewoon te focussen op code. En daar hebben ze ze hebben dus eerst code heel goed gedaan met die lms en toen hebben ze dat gebruikt om meer dingen binnen bedrijven op te lossen. En wij doen gewoon precies dat maar voor eh special temporal agents. Dus alle eh workloads zeg maar ehm eh mensen simuleren in eh Self driving car simulations. Eh bot voor video games. We werken met de weken al met de grootste game developers voor bots eh binnen de spellen die meer als mensen spelen. Ehm en eh dus wij willen gewoon heel erg gefocust zijn op op zeg maar deze use case. En we denken dat je dan als je dat goed doet, dan kun je binnen die bedrijven veel meer doen. Eh want hoe hoe langer een een een workload is zeg maar eh hoe meer special het wordt, snap je? Dus eh en wat bedoel je dan met meer doen? Veel meer doen? Eh ja, dan kun je natuurlijk dingen zoals computer use en dat soort dingen gaan doen. Will willen nu heel erg gefocust zijn op 3D en heel erg gefocust op eh op simulatie en dan zeg maar uitbreiden naar computer use en robotics en dat soort dingen. Als jij zegt: "Ik ga we gaan eh die specialiteit in zeg maar, want toch nog weer weer even een stapje terug, want wij hebben het nu Alexander stuurde mij eh medal door eh een aantal weken geleden van joh weet je, kijk even mee wat gebeurt hier allemaal." En ik ik dacht op een gegeven moment Alexander en ik maken hier wekelijks grapjes over Mist en onze Europese trots als het gaat om het trainen van taalmodellen grotendeels hè. En eh maar wereldmodellen zijn de volgende stap na taalmodellen hè. Er zijn heel veel experts met je eens. Ook John Lecoon is weggegaan bij Meta omdat hij zei dat hele LM paradigma heb ik wel een beetje gehad. Het gaat naar wereldmodellen toe hè. Bij deep mind wordt er enorm geïnvesteerd et cetera. Dus die validatie dat wereldmodellen de volgende stap zijn is er. zitten wij hier dan nu te praten met een de wereldmodellen mistral van Europa? Je zit te knikken. Ja, ik denk dat we ik denk dat we de beste kans hebben ook zelfs tegen Google en tegen Jan Lecoon. Ik denk dat we ze echt met drie jaar kunnen inhalen. Anders had ik het niet gedaan. Anders had ik er verkocht, [gelach] weet je. Eh het het is zo ja ehm het wat het het ziet er één ding wat je ook even moet beseffen is dat elke robot van de wereld heeft een game controller. Elke arm robotic arm heeft een game controller. Ja. Zelfs in een in een autofabriek of zelfs in zelfs een robotstofzuiger kun je allemaal bedienen met een PlayStation controller. Precies. Dus dat is dat is ook het grote inzicht wat we nog niet over niet over gehad hebben. Je hoeft je hoeft niet zeg maar een bed te maken op een gok te maken op ehm op dat je input space transfer hebt. Zeg maar dat je dat het van in dat je van input space naar andere input space naar zeg maar robotic hand of wat dan ook, weet je wel. Maar ehm eh maar je hoeft alleen de observatie de de observation de environment zeg maar te ehm iemand komt met de video erin en jij stuurt de game controller acties terug. Precies. Jullie hebben jullie hebben de modellen al gezien waar je zeg maar de de labels gewoon kunt genereren op de video die mensen die die naar ons sturen. Ja. En als je nou dit voor computer use wil gebruiken, wat is dan de Laten we hier eens op inzoomen, want je hebt eigenlijk uit elkaar gezet: "Dit zijn de twee eh grofweg gezien twee use cases. Computer use, wat is nu de stand van zaken van computer use? Wat zie jij nu als cutting edge? Wat wat is een een toepassing of een voorbeeld of een demo die je zelf hebt gezien waar je van onder de indruk bent?" Ja, de model wat ik jullie ook eh even liet zien was ook een Voor de uitzending heb je ons kort wat video laten zien. Ja, was er letterlijk een wat was een computer model met computer inputs. Ehm ehm en ehm ja, dus kijk alles wat je alles wat je in tekst kunt oplossen, heel goed. Dat kun je met LMS goed doen. Ehm maar eh alles wat je zeg maar ehm eh bijvoorbeeld een Excel spreadsheet, dat is heel lastig, weet je wel. eh of ehm eh of meerdere applicaties zeg maar bij elkaar gebruiken om om iets om iets te produceren. Heel lastig. Ehm als je iets ehm eh kijk, je je wilt ook niet constant voor elke taak eh integratie met LM moeten doen, weet je wel. Je je wil gewoon dat je dat dat je letterlijk gewoon tegen een een computer model zegt van oké ehm eh vind voor mij de eh weet je ehm eh goedkoopste tickets naar eh weet ik wat eh jainky ehm en eh ja ik ik wil het alleen eh als er deze ehm stoelen beschikbaar zijn, weet je. En en dus ehm je kijkt er gewoon op een andere manier naar. Je je kunt alle interfaces van de websites en dat soort dingen zien wat je gewoon in tekst allemaal niet kunt doen. En dan hoef je niet al die systemen die voor elms te bouwen. Dan kun je gewoon hoe het internet nu al is gebouwd gebruiken. En specialiseer je je nu ook hierin of is het meer toekomstmuziek? Dat jij zelf wij focussen nu op 3D. Ehm en en de reden is dat 3D moeilijk robots de de echte wereld dat is eigenlijk een moeilijkere toepassing. Dus de de focus op het moment is in engine simulation. Dus zeg maar ehm bots voor videogames. En bijvoorbeeld als je in eh als je Nvidia bent en je en je bent van die ehm simulaties aan het doen van fabrieken eh dan moet je simuleren hoe mensen gedragen binnen ehm eh binnen fabrieken. En dan zet je ons model stream the vision en dan predict je actions. En dan heb je zeg maar eh onvoorspelbaar gedrag van mensen die je gewoon met tekst kunt ehm eh eh sturen. En dus het is eh op het moment da want daar zit het meeste geld op het moment. Dus zie je ja, het is gewoon een commerciële beslissing om die twee dingen in te zoomen. Dus aan de ene kant lever je aan gamers het idee dat je NPC's kan leveren. Dus van die karakters in spellen die zich mensachtig dragen en veel beter gaan worden door jouw technologie. En aan de andere kant in fabrieken eh waar Nvidia robotiseringstechnologie levert of in ieder geval op de achtergrond eh ja waardoor die robot beter kunnen werken. Dat zijn nu de twee. Ja, daar daar zijn we het meest gefocust. Ja. Ehm en de manier waarop je naar moet kijken is je hebt zeg maar eh die die game engines of simulatie engines dat zijn allemaal gewoon 3D environments en daar kun je gewoon een poppetje inzetten, camera opzetten en dat streamt dan naar onze systemen zeg maar die frames en wij predicten dan gewoon die actions, snap je? Dus je kunt tussen elke engine, welke engine ook gebruikt, kun je onze systemen gebruiken om eh gedrag te simuleren. En wat bedoel je dan dat je dan dat je dan kijkt naar iemand die in een keuken staat en een pan oppakt? En dat je dat jij dan kan stimuleren dat als je datzelfde ding als een humanoid zou neerzetten en die humanoid zou te bedienen zijn met een PlayStation controller om die pan op te pakken, dat jij eigenlijk van die beelden van die kok die die pan oppakt de vertaling kan maken naar de signalen voor die PlayStation controller waardoor die humanid die pan kan pakken. Dat is wat jij dat is de video eh manier. Maar je kunt ook zeg maar als je gewoon een eh simulatie hebt van een keuken met die met die pannen pakken h ehm dan kun je dat gewoon ook al heb je er geen video van kun je het gewoon in de simulatie zelf proberen in 3D weet je wel dan dan ben je gewoon het model van die robot en dan kun je het gewoon uitproberen. Dus ehm eh dus daarom focus ook simulatie. Je hebt met simulatie heb je ook heb je geen gevaar dat eh weet je kijken wat er bijvoorbeeld bij Cruise en San Francisco gebeurt. De velf zelfrijende auto's. Ja. En er is toen eh zelfrijdende auto is toen iemand dood gegaan. Hm hm. Ehm en eh en dat was het einde van het bedrijf. Dus je je hebt met ehm fysieke situaties heb je gewoon zero tolerance eh voor air, weet je wel. Ehm dus daarom focussen we nu heel erg op simulatie. Ehm eh en dan kun je al die systemen bouwen, scalen en dan ga je naar de fysieke wereld toe. Ja, wat misschien wat de luisteraar misschien ook zou kunnen helpen en mij ook trouwens is dat Alexander en ik heb het hier een beetje gek schierend gehad over Neo, de robot van X1 Labs. De robot met een soort grijs pak aan wat door je huis heen gaat. En toen bleek uit de demo bij Joh Stern dat het eigenlijk een teleoperated robot is hè. Dus een robot die is in jouw huis, maar eens er iemand anders met een VR headset op afstand bezig om jouw vaatwas eruit te ruimen met een PlayStation controller. Met een met een controller in de hand en de en de bril op. Ehm daar zegt het bedrijf van: "We moeten wel, want we hebben niet genoeg videodata om onze robot al die vaatwasser leg te laten ruimen." En wat jij nu eigenlijk zegt is: "Als zij dat beeld naar ons toe zouden streamen, dan zouden wij die vaatwasser mogelijk wel kunnen uitruimen. Maar we beginnen nog even dat die robot niet bij iemand thuis is, maar in een simulatie is, omdat we niet in een huis kopjes op de grond willen gaan gooien, et cetera." Ja, voor jullie bed is eerst in simultie daar de juiste actions naar de simulator sturen en vervolgens de stap gaan maken naar de fysieke wereld uiteindelijk wel toch? Ja. Ja. En dus wel voor ons, ik denk dat ehm de focus is niet echt op zeg maar huishouden, robots en dat soort dingen. Het is het is meer fabrieken en dat soort dingen. Want er zijn zoveel bedrijven gefocust op de use cases dat het ehm en dus ik dat soort dingen zijn in games niet heel goed zeg maar. Dat dat zie zie je niet heel vaak voorkomen. Simulator bedoel. Ja, precies. Eh je hebt power simulator dat heel [gelach] leuk. Heel leuk. Eh en ehm eh maar inderdaad je je wil een beetje bijvoorbeeld navigatie wil dingen hebben die die redelijk ehm eh general zijn op begin ehm en eh ja keuken en dat soort dingen die dingen komen later. Ik denk dat het begint met eh Robotic arms en eh ja, voor gevaarlijk werken als ik je goed begrijp in een in een famie. Ja, bijvoorbeeld ehm ja ehm eh ja, ook ehm drones en dat soort dingen bijvoorbeeld voor eh ehm voor delivery services en dat soort dingen. Eh dat dat soort dingen worden de eerste used cases. En onze modellen zijn zo klein dat je die ook gewoon op de drone kunt. Ja, want dat zeg jij nu leuk. was ook wel nieuwsgierig naar van wat verkopen jullie dan uiteindelijk hè, want je zei net heel mooi een aantal minuten geleden videokens in, actietens uit. Wij doen wij doen de vertaling naar wat wat je ziet op je drone of in je simulatie en wij komen wat hoe je je moet bewegen daarna. Maar betekent dat ik dacht meteen dat is dan een service hè in een cloud ergens wat draait, maar je zegt eigenlijk ook nee, onze modellen zijn te licen of in ieder geval aan te schaffen om in jouw hardware te stoppen als hardware bouwer. Ja. Ja. Dus je weet je weet dat eh kijk je moet bijvoorbeeld dat soort je moet dan dat heel ehm eh moet je niet veel doen, want je hebt dan weights exposure, snap je? Dan kunnen mensen die weights expen. Ja. Dus je wil je wil eigenlijk ehm eh zeg maar kleinere versies van de base model eh heet de stille. Ehm en ehm en dan kun je dan heb die heeft dan mindere actie is minder actie is dan de bas specifiek voor die klant voor de context van de klant. Base model heeft 100duizenden combinaties van acties en dan heeft die heeft er misschien weet ik al 50 100 of wat dan ook. Ehm en dan kun je niet zeg maar eh een competitief product bouwen eh op eh op op de weights. Eh als ik nu game developer ben, voor mijn specifieke game zouden jullie dan een model distillen wat in mijn en die dat model wordt dan meegeleverd met die game hè, omdat die NPC dra Ja, die zit dan inderdaad in Ja, want anders heb je een constante cloud connectie nodig naar jullie eh centrum. Ja, maar ook meeste games werken op dat op die manier. Ehm ik denk dat het voor drones en dat soort dingen belangrijker is dat je dat je ze lokaal eh kunt runnen. Bijvoorbeeld moeten heel snel dingen reageren bijvoorbeeld. Wat vind je zelf vetter eigenlijk als het zeg maar de rol want je bent een game je bent een gamer in de in je hart zo te horen. Dus is het vind je het vind je het heel vet om naar een punt toe te werken dat games exponentieel veel vetter zijn over 5 jaar of denk je aan die drones die rondvliegen en die robots die rondlopen? Ehm voor mij meer de drones en de robots. Ik denk de games, het is heel belangrijk omdat de data natuurlijk ook uit games komt dat je heel veel doet met de game developers. Machine that fiets unto itself. Je hebt een belang games beter te maken, want dat maakt de echte wereld beter. Preci precies. En het is het is ook we weten dat dat die modellen in games heel goed zijn, want waar de data vandaan komt, snap je? Dus dus we weten gewoon dat in games dat moeten we gewoon 100% goed kunnen doen. Ja. Ehm dus eh maar ja daar is niet waar de meeste omzet. Maar robot dus Ja. Ja. En wat wat waar waar denk je dan aan? Wat wat vind je zelf een vet idee? Ja. Waar hoop je op? Waar hoop je op? Ja, we zijn we zijn bijvoorbeeld eh bezig met ehm eh in in ehm eh warehouses, dus zeg maar eh waar je drones hebt. Ja. Warehouses waar je drones hebt. Oké. Ja. Ja. Eh en ehm ja, dit dit bestaat in Amerika. Waarom? Don't ask me niet. Dus eh ja, maar vooral als je als je lichte pakketjes hebt, dus is het heel heel snel. Eh en dan kun je vertical bouwen. Ja. Ja, dat bestaat. Oké, dus dat zijn dat zijn dan distributiecentra voor pakketten. Ik zag RoBA Roomba robots op de grond vorm waar je over vliegende drones in dat heb je one zeg maar. Two dimensional plane heb je in de grond. Maar als je drones hebt heb je die pakt dan gewoon een pakketje en die vliegt dan door die door die pakkethal. Oké. Maar het probleem is dat ze heel veel tegen elkaar aanbotsen bijvoorbeeld en je en je hebt in games heb je heel veel data van zeg maar drones die zeg maar tegen elkaar in gaan en dat soort dingen. En dan kun je daar heet negative eventuction op doen. Dus daar zijn we bijvoorbeeld heel goed in. Ehm en dan kan dat is die hebben één actie dat is stop en dan pause is pauze. En dan precies dat is één één voorbeeld bijvoorbeeld. En elke drones die heeft die heeft gewoon een game controller, weet je wel. Dan kun je gewoon met game controller en ook ehm de physical transfer, dus zeg maar de ehm eh hoe leg je dat uit? Eh de manier waarop je van de actie naar zeg maar de motor controls gaat. Dat is natuurlijk ja, je gaat natuurlijk van move left XY. Ja, zo zoals drone heeft vier motoren en die moet je op een bepaalde manier combineren in hun snelheid waardoor ze gaan bewegen. Ja, precies. Maar maar dat is een hele andere prediction dan de high level, snap je? Dus dan moet je heel specifiek tork en dat soort dingen gaan eh gaan gaan producen. Maar maar omdat de game omdat ze met game wat ze game controllers hebben hoef je dat dus niet te doen. En omdat ze een flight controller hebben ze al stabilization en dat soort dingen. Dus dan kun je gewoon met de game controller kun je gewoon boem stoppen. Weet je wat ik best verwarrend vind aan dit allemaal? Dat we dus naar dit soort voorbeelden aan het zoeken zijn. Naar ja, wat wil je dan met drones en wat wil je dan met zelfrijnde auto's? En omdat het voor mij eerlijk gezegd best lastig is om deze generaliseerbaarheid van technologie, het feit dat je ehm dat je heel veel videobeelden van heel veel verschillende soorten games in een zwarte doos kan gooien en dat kan gebruiken om Excel te bedienen en om een robot in een warehouse wat ik net voor het eerst heb geleerd eh kan bedienen, zodat ze niet op elkaar botsen. Het is het maakt het gewoon zo lastig om te bevatten als mens. Heb jij dit ooit? Ja. Ja, dat is ook de reden dat we die modellen gebouwd hebben die ik liet zien waar je gewoon ook gewoon van video naar controls kan. Want wij pretrainen niet alleen met game staten, hè, want je kunt ook gewoon dat soort video's in je pretraining gooien. Ehm eh het gaat meer omdat je één inputspace hebt. Ik bedoel meer het bevatten wat dit voor impact gaat hebben. Ja, maar dat wisten we onwaarschijnlijk breed. Ja, maar duizelt je dat wel eens of denk je: "Ja, god, dit is gewoon wat ik doe en ik zit op een soort abstracte laag en wat mensen daar dan vervolgens mee moeten gaan doen, moeten ze lekker zelf weten." Ja. Ja. Soms word ik wakker en ik denk echt van: "How did I get here?" Weet je wel? En wat denk je dan? Wat of wat nopt je tot die gedachte? Ehm ja, het het is ik als ik met mijn team praat waar we bang voor zijn is wat er gaat gebeuren met de wereld als alles goed gaat. Snap je? Zeg maar hoe snel dingen gaan veranderen. Ehm die zin is wel een bijzondere zin hè die je nu uitspreekt. Je bent bang voor de wereld waar alles goed gaat. Als alles goed gaat. Ja. Als nou al zeg maar als je als je Space of Natural Reasoning unlocked dan kijk je hebt LMS die hebben natuurlijk al een hele grote impact gehad op mensen en en ik denk dat studenten bijvoorbeeld hebben is wel lastiger op dit moment om banen te vinden dat soort dingen. En eh ik denk dat als je als je zeg maar de Space Bor reasoning Unlock hebt, dat is dat is ook denk ik zo'n zo'n wave weet je wel waar heel veel mensen ehm eh niet op de goede kant uitkomen. Ik denk dat aan de andere kant natuurlijk, kijk, er worden ook heel veel banen gecreëerd, maar niemand weet zeg maar weet echt hoeveel dat is, weet je wel. Ehm en ehm ja, dus dus ik denk eh ja, net zoals met LMS, je je wist niet waar je allemaal die chatt uiteindelijk voor ging gebruiken. Eh we weten er een paar games bijvoorbeeld eh daar hebben we al hele grote klanten, maar ehm ja, het is inderdaad zo breed en het het is het is zo toepasselijk voor verschillende dingen dat het dat het heel moeilijk voorspellen is precies wat er allemaal gebeurt als alles goed landt. En goed betekent dat het lukt om een soort chat GPT moment te hebben in de tijd en ruimte, oftewel in 3D, oftewel uiteindelijk in de fysieke wereld waarin mensen nu voelen als ze een rapport laten samenvatten door de laatste Gemini dat ze denken: "Jeetje menetje, wat een goede samenvatting." En dat jij zegt: "Wacht maar tot dingen zich gaan bewegen in de wereld op een manier dat je datzelfde gaat voelen." En wat jij nu aan het bouwen bent eigenlijk is dat in potentie. Ja. En ik denk de reden de de naam General Intuition komt van ehm Demis en Alpa Volt. Ehm en dat is ook de originele inspiratie. Die hebben wat ze nu hebben gedaan is ze hebben een AI gebouwd proberen om folder te spelen om die ehm pro zeg maar eh om die protein structures in in 3D eh te kunnen voorspellen. En daar hebben ze de mensen hebben gewoon Volit gespeeld. Die hebben toen data gegenereerd. Foldit is een spelletje. Volit was een computerspelletje en die heeft data gegenereerd om dan uiteindelijk 11 vol te doen. Ja. En daar heb je natuurlijk een hele grote biologische medische doorbraak. En ehm dus dat was ons dat was onze originele inspiratie. Eh Damit heeft een quote waar zegt ehm wouldn't it be amazing if you could mimic the intuition of these gamers who are by the way only amateur biologists en ehm LM zijn op dit moment al zeg maar amateur biologists weet je wel. Dus als je zeg maar space reasoning en dat soort krachten samen kunnen doen, dan kun je denk ik ooit in 5 jaar 11 ft for x doen waar je gewoon heel waar je gewoon een een eh een probleem in threedimensional space uitlegt met data en dan heb je zo'n space board agent die er oplossingen voor gaat genereren. Dus ik denk dat aan de ene kant inderdaad is het heel lastig wat er allemaal gaat gebeuren. Aan de andere kant is het ook heel belangrijk voor medische doorbraken en dat soort dingen. En zeg maar de wat er wat er allemaal tussen zit is is wordt gewoon heel moeilijk naviger denk ik. Maar maar weet je, het het komt soms lees ik wel van die dingetjes als en ja en dan over een paar jaar dan hebben we natuurlijk meer compute nodig. Dus dan hebben we meer datacentra nodig. Maar tegen die tijd dan bouwen de robots eigen datacentra en dan denk ik altijd ja ja. Nee, ik denk dat ik denk dat we inderdaad eh kijk de de longizon zeg maar eh hoe langer de taak hoe moeilijker is om het te doen, snap je? Dus een datacenter bouwen. Ja, een jaar weet je. Ik denk dat we ehm ik ik denk dat het misschien meerdere jaren voor mensen, weet je, ik denk echt dat dat eh ja, daar dat duurt nog wel even lang. Kunt die je kunt die kortere subtaken doen, maar die het orgaken bij elkaar in een soort zwerm, daar zit dan nog nu nog mensen en het goed doen. Dat is het probleem, want het zijn generative models die zijn prediction machines, weet je wel. Ze ze maken fouten en eh en dus het is ik denk eerlijk gezegd, ik denk dat het dan weer de eerste use cases worden gewoon navigatie zeg maar, simpel manipulation ehm eh drones, auto's eh robot. Ja, met game controllers. H ehm en ehm eh search and rescue bijvoorbeeld eh bij Arts zonder gens dan eh eh zeg maar ehm drones om zeg maar mensen op te sporen en dat soort dingen voor mensen die op zee vermist zijn om ze te zoeken geutomiseer na de of wat dan ook. Ja, een heleboel mensen op het team hebben ook zeg maar eh humanitarian achtergrond. Dat dat is ook dat is één van onze eerste use case met drones. Ehm en ehm eerst ga je heel veel in simulatie zien en in simula wat er in simulatie kan wordt een beetje de benchmark van wat er dan daarna in de echte wereld kan. Zo dank Ja. Dus waar we filmpjes van kunnen kijken, dat gaat de eerste stap zijn. Ja. Dus op het moment dat je zeg maar ehm maar waar je naar moet kijken is of die robots dezelfde input hebben als mensen. Dus dat ze zeg maar alleen kunnen zien en aanraken en dat ze niet zeg maar een beetje Elon Musk verhaal hè, dat hij zegt als een mens kan rijden met twee camera's, namelijk je twee ogen, dan vind ik eigenlijk of George Hots hè met AI, ik vind eigenlijk dat we met twee camerasensors achter het stuur een auto zouden moeten kunnen besturen en niet liidars en andere radars en weet ik veel. Ja, vals spelen. Ja, dus je moet je moet kijken wat kunnen AI modellen in simulatie zonder vals te spelen en hoe lang kunnen ze dat soort dingen doen? Ja, daar moeten we op letten, bedoel je? Daar moet je op letten. En hoe onvoorspelbaar zijn de eh omgevingen waarin ze dat doen. Hm hm. En dat wordt een beetje voorspellend van hoe snel dingen gaan. Hm hm. Ehm ja, dus de benchmark is dan een jouw één van jouw modellen rijdt 80 uur lang in Truck Simulator zonder crash of wint Lem ofzo, weet je wel dat soort maar allemaal in simulatie nog toch hè? Lem in de game toch? En dan op een gegeven moment zeg jij als als we die allemaal gaan maxen zeg maar dus al die benchmarks gaan we beaten, 800 uur lem whatever dan ga je zeggen kan dan kunnen we een transfer doen zoals het woord dat jij gebruikt hè en een overgang naar Leman het Ja daadwerkelijke circuit. Ja, nou de transfer is zelfens ook heel lastig natuurlijk, maar in principe qua intelligentie ja ehm maar je moet het bijvoorbeeld vals spelen hier is bijvoorbeeld dat je eh kijk je kunt natuurlijk met een eh met een AI model kun je kun je precies de motor bij zeg maar elk wiel kun je zeg maar de alle dingen precies aansturen als je perfecte bocht neemt. Een mens heeft alleen een stuur. Hm. Weet je wel. Ehm dus val spelen is echt dat je alleen vision en het stuur hebt. Snap je? Mooi voorbeeldje. Ehm eh dus daar moet je op letten. Dat is dat is de special reasoning. Heyé je zei ik word soms wel eens dit vul ik nu in maar badend van het zweet wakker als ik nadenk over wat de implicaties hiervan zijn. Maar er dat is ook een andere kant van de medaille waarschijnlijk waarin je heel optimistisch bent over wat dit kan veroorzaken. Het is niet zweet. Kijk, ik het het is voor mij ehm dit komt eraan die die dit is weet je, we wonen in een kapitalistische eh wereld en en het komt eraan. Ehm het probleem is dat eh op dit moment lijkt het eraan dat het dat er dat het eraankomt door weet je miljarden bedrijven die eh ja die die misschien minder open zijn bijvoorbeeld qua ehm eh qua hoeveel ze met game developers werken en dat soort dingen. En dat is voor weet je en dat is voor ons heel belangrijk is ook waar ik in opgegroeid ben. Ehm maar ik denk ja voor mij is het echt de science waar zeg maar mijn mijn longterm goal is is om dat te doen. Maar maar ook kijk kijk naar mijn vrienden bijvoorbeeld. Ik ben 30 weet je ik heb gewoon vrienden die geen banen kunnen vinden vanwege AI d weet je. Dus dus het is je moet je moet er gewoon ook heel eerlijk naar kijken van ja dit is gewoon een iets wat veel dingen verandert en maar dus er zijn beide zijn waar. Het komt eraan en veel dingen veranderen. En wat bedoel je met ik ben uit ik doe het voor de science? Wat bedoel je daarmee? Ja, mij mijn ehm mijn doel is om om om weet je echt over vi jaar zoiets van 11v for x zo een generalized approach naar scientific problems in 3D en dan swit or agents aan de andere kant. Ja, d is even je zegt het heel snel maar het is het eigenlijk de wetenschappelijke uitdagingen die er nu liggen die waar mensen tot nu toe niet opgelost hebben. Bijvoorbeeld omdat we protein folding doen om als te genezen. Ik roep even wat dingen nu heel makkelijk. En dat jij zegt wat wij aan het bouwen zijn om is omdat het zo eh general is ook kan de general intuition van onze modellen zeggen, maar is zo general dat we mogelijk zelfs iets rondom wetenschap en mogelijk gezondheid kunnen gaan doen. Ja. Maar wat je daar ook mee moet beseffen is het is niet alleen ons modellen hè. Je hebt ook gewoon die LM's die hier heel goed in worden in in dus maar maar die LM's die kunnen niet dat soort programma's besturen die de threedimensional predictions doen. Dat is een verschil. Dus je moet niet alleen kijken naar wat wij doen. Je moet ook kijken naar de reason capit in text van LMS. Want je kunt die dingen samen trainen, snap je? Je kunt gewoon een eh een chain of thought loop zeg maar bootstrappen op basis van die acties. Ja, want dat is misschien ook nog wel een belangrijke vraag, hè. Want je zegt nu eh we hebben het een beetje gehad over lms en dat leen bij Meta weg is en dat je mogelijk de world model van Europa aan het bouwen bent hier et cetera. Maar is het dan de bedoeling om met jullie modellen in een ensemble met andere modellen samen te gaan werken, hè? Dus dat jouw dat jullie model aangeroepen wordt door een LM van een Google en dat hij eigenlijk daar zijn eh special reasoning uithaalt. Ja. Of is en en of is het ook het idee dat jullie wereldmodel uiteindelijk de taak kan overnemen van een LM? Ja, het is het is meer dat gewoon net zoals wij één van onze acties die wij als mensen kunnen nemen is praten of schrijven. Dat wordt hetzelfde. Dus één van de acties die voorspeld gaat worden is gewoon language generation of Oh, echt? Ja. Dus daar krijg je schrijven in een Het is bijna alsof je kijkt naar iemand die een brief aan het schrijven is en we kijken wel even wat die wat het wat het world model getypt heeft. Ja, dan dan dit is dit is op dit moment is het een is het een een action model. Je hebt zeg maar je hebt twee verschillende modellen. Je hebt de world model. Dat is waar je waar je waar ehm waar je van acties naar frames gaat. Dus je hebt zeg maar eh een initial frame, weet je wel, op deze kamer en dan druk je op op s of wat dan ook en dan gaat hij een beetje naar links of je muis gaat hij een beetje naar rechts. En die frames die worden gegenereerd door de world model. Ja. Ehm maar inderdaad daar kun je dat dan in de wereld eh schrijven, maar de action policy dat is zeg maar de andere kant en dan heb je frames en dan genereer je acties, snap je? Dus dat zijn twee kanten. Maar je kunt maar die die actiemodellen daar worden gewoon ehm eh internal world models gebouwd door die modellen. Dus het is het is heel de modellen zijn heel similar. Er zijn er zit niet heel veel verschil tussen qua techniek. Ehm eh maar het probleem is eh world models hebben een hele grote ehm eh zeg maar output degree of freedom. Hoe la ik dit uit? Je hebt heel veel pixels die kunnen voorspeld worden waar je ehm waar er heel veel fout kan gaan met actie is dus veel minder. Snap je? Kunnen maar een paar dingen doen. Eh dus dus het is het is een beter het is ook weer een vorm van compressie eigenlijk hè. Ja, het is een beter probleem. En en eh en je kunt acties kun je controleren. Pixels zijn heel moeilijk en heel duur om te controleren. Maar we gaan dus naar één model toe wat ook tekst gaat genereren. Wat wij nu uit chat trekken dus gewoon praten is gewoon dan één van de acties. En hoe verhoudt zich dit dan tot het idee van soort van general gegenaliseerde intelligentie? Ja, ik ik vind eh Hi en dat soort dingen een intelligentie. Ik vind het ik vind het een beetje een moeilijk woord, want het is heel lastig om zeg maar eh definition Geef je er Geef je eigen definitie eraan. Ja, ik vind het ik vind het heel lastig om er ik kijk ik kijk waar het voor gebruikt wordt en ik denk ehm ik ik ja dus dus want dan krijg je ook van die ja predictions, when wat ik ik ik moet eerst ja ik wil eerst zien wat er uit deze kijk wat er uit de modellen komt. Ehm en we hebben natuurlijk een heleboel hebben we bewezen op het moment, maar weet je de tekst is voor ons nog niet bewezen dat dat we dat we tekst als actie weet je. Dus voor voordat ik eh een definition als erop gooi, wil ik eerst zien hoe het gaat. En misschien kan ik, want je zegt heel vaak in dit gesprek vandaag, eh Demis hè, alsof het je buurman is hè, Demis Hasabis van Deep Mind van Google die eh recent in een interview gezegd heeft met Hardfk: "Ik zit nog steeds op 5 tot 10 jaar met AJI hè. Gemini 3 is net uit. Iedereen wow, zie je er wel, dan gaan we weer." En hij zeg: "Oh nee hoor, ik ben nog steeds heel cool. 5 tot 10 jaar." Zit je dan een beetje in het Damis Hassabis kamp misschien? Ja. Ja. Ja, want die is redelijk conservatief hè, als je kijkt naar de stemmen die er zijn in de in de in Ja, ik ben misschien Demmes en dan min 2 jaar omdat omdat we dit denk dit kan. We weten dat dit kan. Ehm maar ehm ja, ik wil nog ik wil nog ik ben nog benieuwd en dan gaan we een beetje afronden van jij jij hebt bij arts zonder grenzen gewerkt en je zegt ook de mensen die in mijn team zijn aangesloten hebben iets met humanitaire eh doelen. Dat dat werd net gezegd. Betekent dat ook dat er iets verankerd zit binnen jouw bedrijf dat het niet overal voor gebruikt mag worden? Ja, we zijn ook een PBC net zoals Tropic. Wat betekent dat? Ja, public benefit corporation. Dus dat dat je zeg maar de ehm eh de de de social mission van de company en wat het waarvoor gebruik worden. Dus dit zeg maar in de ehm ja, hoe doe zeg je dat goed uit? Ehm en misschien ik maar kan heel concrete vraag stellen. Dit is allemaal heel erg geschikt voor militaire doeleinden natuurlijk wat je aan het maken bent. Zit daar een soort muur tussen? Is daar een soort iets verankerd? Ja, de manier waarop ik er naar kijk is eh ik wil die dingen gewoon general eh we willen een compute platform zijn voor intelligentie, weet je. En als het ooit heel fout gaat in Europa, dan denk ik dat het heel goed is dat we een Europees bedrijf zijn. Nederlands bedrijf zelfs toch? Nederlands bedrijf. Ja. Ja. Ja. Ja. Dus eigenlijk is het bijna metahumanitair dat je zegt: "Ja, onze modellen zouden daar potentieel voor gebruikt kunnen worden, maar het is dan wel een Europees bedrijf." Ja, het is een vorm van detrance als ik je goed begrijp. Ja, we zijn we zijn Ja, zo zou ik er inderdaad naar kijken. Maar ehm wij bouwen voor eh general compute. We hebben geen zeg maar specifieke offensive of dat dat doen we gewoon niet in de modellen. Ehm eh in simulatie met bot kan natuurlijk wel, dat maakt niet uit. Maar voor physical deployments gaat er niet in. Ehm en omdat we die acties gelabeld hebben kunnen we dat bewijzen. Snap je? dat dat dat er acties er ook echt niet in zitten. Ehm ehm maar maar weet je, als het dan ooit een keer heel fout gaat, weet je, dan kunnen we hopelijk heel snel met die transfer kunnen we dan systeem bouwen om om defensie en dat soort zit een soort potentie in wanneer nodig. Ja, maar maar dat als je de research goed doet dan dan kan dat. Dan hoef je daar niet nu op te focussen zeg maar. Als het dan ooit heel fout gaat, dan hopelijk dat dan kunnen we dat binnen week of maanden kunnen we dat omzetten om dat soort dingen te kunnen doen als het eh ja als eh Poetin een keer eh op onze trainen op onze tenen trapt. Ja, ontzettend ehm bedankt voor je tijd. Ik vond dit een eh zeer wonderlijk gesprek en dat is misschien ook omdat eh ja, je je schetst ongelooflijk eh verre lijnen met heel veel impact in de echte wereld potentieel. En ik had nog nooit van jou gehoord terwijl dit is een BV. En eh zeg maar dit is on Nou, Alexander hebben ons hardop zitten verbazen van gaan we deze jongen nou uitnodigen? Want het is zo bizar wat hij allemaal doet. En hè ik ben interviews van jou gaan kijken en ik zei tegen Alexander: "Ja, ik denk dat we hem gewoon gaan uitnodigen, want dit dit is dit is gewoon helemaal echt." En die jongens en meiden die die om zich heen verzameld heeft, die zijn ook allemaal echt. Ja, maar misschien is het ook een soort van moet jij niet af en toe lachen over hoe wij in Nederland praten over of in Europa eigenlijk praten over hoe wij nou om het even heel plat te zeggen AI doen in Europa en we hebben de neiging om onszelf de put in te praten. Ik denk dat Europa je bent daar gewoon helemaal niet mee bezig. Ik denk Europa heeft het voor Worldming heeft Europa het beste talent. Echt mijn hele Worldming team zijn Europese mensen. Dat is Ik denk echt dat eh ik denk echt dat dat eh dat dat de andere kant op gaat in de komende paar jaar. Waarom denk je waarom ben je hier zo verzekerd over? Ehm ja, ik we proberen mensen in Amerika aan te nemen voor dit soort dingen. Alle goede mensen zitten in Europa. En ja, hoe kan dit? Eh universiteit eh in eh in in Frankrijk bijvoorbeeld heeft hele goede opleidingen voor dit soort dingen. Geneva een heleboel van Geneva. Ehm ehm eh het is ook veel wiskundiger dan LM's. Eh en je moet ook heel veel meer physe dan dat soort dingen. Ehm maar wordt Europa dan een beetje wakker nu in een soort poëtische eh zin bedoel ik hè van een soort dat het is er wel maar dat moest even bij elkaar gehaald worden allemaal. Ja, en ik denk ook dat je door LM zoveel meer kan doen met minder mensen dat het gewoon een equalizer is. Dat je gewoon veel meer impact kan hebben als je gewoon een paar experts hebt. Ook al is het een kleine groep genes in Europa, een kleine groep genies plus AI is alsnog capabel genoeg om mee te kunnen doen in de wereld in het wereldspel. Ja, ik denk het wel. Ja, dankjewel dat je hier wilde zijn. Ja, bedankt man. [muziek] Jewet, wat een gesprek weer. Zit nog een beetje bij te komen, merk ik. Maar eigenlijk zegt hij: "Taalmodellen waren fase 1. World models wordt fase 2. Europa heeft [&nbsp;__&nbsp;] goede mensen op het gebied van Worlds. [&nbsp;__&nbsp;] goede data." Ja. En eigenlijk stiekem heeft hij onbedoeld de grondstof soort van ontdekt zou je kunnen zeggen. Ja. Ja. Als je dan kijkt naar een een wereld waarin grondstoffen zo'n groot hè de daadwerkelijke grondstoffen. Je bedoelt in de echte wereld olie olievelden olievelden, gaspellen onder Groningen, dat soort dingen. Daar is van alles om te doen. Ja, we hebben een nieuw gasveld onder Groningen ontdekt, maar deze kwam uit Nijmegen. Ja. En het is een En dat zijn video game beelden. Ja. En die video game beelden dat dat die zijn echt de grondstof om die dat die tweede stap te maken na taalmodellen. En het dat is gebleken, want de de biedingen vlogen hun om de oren blijkbaar. Ja. Ja. Ja. Ja. Ja. Ja. Het is gevalideerd dat dat ze de grondstoffen ook echt te pakken hebben. En er is ook maar één bedrijf die zo'n uitgebreide dataset heeft van videogame beelden, wat blijkbaar dus zo belangrijk is. En dat bedrijf is Nederlands. Maar hoe ik ik daar mijn vraag op het einde, het klinkt misschien wat arrogant. Hoezo heb ik niet van jou gehoord? Maar ik bedoel echt hoe kan hoe hoe kun ik Nee, maar omdat hij het zelf pas net door heeft eigenlijk. Zei hij tegen wij zeiden wij hoe kan het dat we niet van jou hebben gehoord? Toen zei hij bijna ik heb ook pas net van mezelf gehoord. [gelach] Ik heb deze zomer een cursus gedaan. Ja, ik eh ja, je bent hij ook hij is er eigenlijk ineens achter dat hij op op goud gestuit is. Letterlijk. Nee, niet letterlijk, maar je op de grondstof gestuit is. Dat dat deel is letterlijk. Dat is bizar. En wat ik wel wat ik er interessant aan vind is want we hebben het natuurlijk over ASML gehad. Je hebt het bij Eva over ASML gehad. Nederlands trots en ook een sleutel in autonomie. Ja. En dan hebben we blijkbaar nog één. Ja. En dat ja, ik heb ja, ik had dit niet door. Ik heb het idee dat heel veel mensen dit niet doorhebben dat er een Nederlands bedrijf is die blijkbaar een versnelling in deze in deze hype een versnelling van een aantal jaar veroorzaakt en dat daar een 30-jarige Nijmegenaar achter zit. Ja, ik en ik de luister mag best weten. Ik heb dit dus drie keer, vier keer, vijf keer getrippel kradroepel checkt omdat ik eigenlijk niet helemaal kon geloven van jeetje dit hoe kan dit nou weer een BV zijn in Nederland waar die data in zit? Ja, ik word er ook wel een beetje vrolijk van. Ja, zeker. We hebben iets we hebben iets heel positiefs ontdekt voor ons allemaal. Eh ik zou zeggen laten we dit beschermen. Ja, ik weet niet wat we kunnen doen om hem te helpen, maar eh waarschijnlijk heeft hij meer computer nodig zoals iedereen. Ja. En misschien ook nog wel meer talent. Ja. Dus wie weet als je luistert en eh je zit in die in die hoek. We hebben nu in eh in Europa en dus in Nederland een eh bedrijf waar eh genoeg mensen nodig zijn. Heb je nog stichtelijke woorden aan het eind van deze podcast? Wieen? [gelach] Ja, dit is jouw moment jongen. Pak hem nu moet je Nee, je kan ook zeggen: "Nee, dit is een prima moment in de tijd en dan gaan we gewoon door." Ik vind het heel gaaf dat wij eh dit interview hebben gedaan en ehm ik heb een beetje het gevoel dat dit best wel een eh een belangrijk interview was. Ja. Nee, ik ben ook een beetje giddy over. Nou, over hem hè, over dat dat het feit dat je in het Nederlands kan praten met iemand die zoiets belangrijks doet is gewoon heel cool. Ja, ben je eens. Goed, wij danken Sam Hengeveld voor de edit, Pankra voor de vormgeving. Als je een lezing wil van de heer Hagen of van mij over AI, dan kan dat. Milen ons op lezing@ai report. En als je op de hoogte wil blijven van het laatste AI nieuws twee keer per week en die tips en tools kunt ontvangen, eh dan eh kun je naar onze nieuwsbrief gaan op airport. Wil je vandaag nog beginnen met AI binnen jouw bedrijf, dan ga je naar onze vrienden van Dept via deagency.com/aai report. Tot volgende week. Tot volgende week. M.

---

## Notes


## Key Takeaways
-

## Related
-
