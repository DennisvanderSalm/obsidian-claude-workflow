# GPT 5.1 is een sycofant + Chinees model verslaat ChatGPT en is gratis + photoshoppen door te praten

**Source:** [YouTube](https://www.youtube.com/watch?v=9ejysbezX9A)
**Video ID:** 9ejysbezX9A
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie, waar we uitzoeken welke invloed AI heeft op ons werk, ons leven en de [muziek] samenleving. Tegenover mij zit Wietse Haagen. Hallo, van harte welkom. Ik ben Alexander Klupping en deze week gaan we het hebben over Open AI die afgelopen nacht GPT [muziek] 5.1 lanceerde. De nieuwe versie van ChatP. Wij bespreken wat er nieuw is. Maar ook wie ze al op de hielen zitten. Een Chinees AI Lab lanceerde een model dat Chatpt inhaalt. Gratis beschikbaar voor iedereen. En het komt dichter bij de prestaties van westerse topmodellen dan ooit tevoren. En dat is dus open source. Google maakt een variant van Photoshop waar je tegen kunt praten. Je kan bijvoorbeeld zeggen verwijderen flexies, verander een foto van jezelf in een schilderij. Gewoon door te typen wat je wil. Dat bespreken we. Dat en meer in AI Report. Veel plezier. [muziek] Wet, we hebben weer een eh item bij televisieprogramma Eva voorbereid voor vanavond. Ja, jij en ik samen zeker. Eh de opkom of de tenminste het uitkomen van Sora 2 was de aanleiding, want eh dat kwam nu anderhalve maand geleden ofzo kwam dat uit. Zoiets. Ehm en wij dachten, wij zaten een beetje te spelen met die cameo functie waar je jezelf kan clonen door jezelf even te filmen en dan drie getallen uit te spreken. Ja. Heb je een digital twin van jezelf. Precies. Die je van alles kan laten doen. Dus ik heb video's van mezelf gemaakt dat ik drones boven Schiphol eh oplaat en dan huilend bij ASML. Precies. Uitend voor een high en EUV machine en eh die gingen heel hard op ehm op mijn eh social kanalen en toen dacht: "Ja, dat heb je gerepost dan. Ja, door naar Ja, precies. Precies. En ik dacht dat daar moeten we iets mee, want volgens mij is dit dit is te automatiseren. Zullen we dit gewoon eens zullen we eens een soort flow bedenken waardoor we een soort van AI influencer kunnen maken waarbij we automatisch posten. Dus wat we wat nou ja, wat jij gemaakt hebt is een simpel flootje mag gezegd worden. Zo toch? Ja, zeker. Is niet zo heel spannend. Waarin we een aantal scriptjes ehm ja, een soort van formatjes voor eh TikTok video's of social video's. prompt generator eigenlijk prompjes die mooi passen in Sora juist maar gekoppeld aan het nieuws. Dus je pakt de NOS feed. Ja eh en dan die zet die die scriptjes eroverheen en dan vervolgens komen daar Sora prompts uit. Ja enige stapje ertussen is nog dat ik even vraag eerst aan een AI model: is dit waardig om iets voor te maken? Want dat maken kost natuurlijk een beetje geld. Ja, precies. Niet al het nieuws worden scripts bij gegenereerd. Jij doet een soort Ja, zeker nog negen van de 10 niet. Precies. Moet een beetje mogelijk zijn om er iets interessants van te maken. Ja. En het is nu ook dan nog nodig dat je handmatig dat in Sora invoert, want de API die beschikbaar is, heeft weer niet toegang tot die Cameio functie. Dus je kunt wel video's via de API, dat zou het mooist zijn natuurlijk, dat je nieuwsbericht van de NOS komt uit. Er worden drie scripts gegenereerd, drie prompts gegenereerd. Al die drie promps worden automatisch video's van gemaakt en dan met of zonder menselijke tussenstop gewoon in die TikTok API knallen. Jij zegt mooi. Voor mij is het natuurlijk [gelach] alleen maar reuzen spannend, maar ik snap technisch mooi zou zijn als we niet die menselijke stap erin hebben om hem in de app te plakken. Maar het maakt Ja, goed. Dit is zoals met alle items die we tot nu toe doen eh bij Eva is ook om te laten zien van als wij dit al aan elkaar kunnen klussen. Ja, kan je voorstellen hoe dan een beetje de toekomst eruit ziet? Dat is natuurlij een beetje het spelletje. Ja, ja, dit is waarschijnlijk bij Open AI letterlijk nog een vinkje wat ze moeten aanzetten om Cameo in de API ja, soort van mogelijk te maken. Ja, want in essentie praat je tegen open AI om de promps te maken voor open AI hè. Dat is ook een beetje het gekke van. Dus wij kunnen die cirkel natuurlijk zelf ook gaan verbinden. Ja. Ja. Ja. dat je dat je een Sora account hebt die je niet eens zelf gaat vullen, maar waarbij dat gewoon je kan gewoon eh engagement maximizer aanzetten en dan kijken ze zelf wel even wat posten. Maar heb je gelachen? En het idee is natuurlijk wel een beetje dat we er een het moeten een beetje luchtige video's zijn ook. Heb je gelachen? Ik heb heel hard gelachen. Het echt heel hard gelachen. En de Ik moet ook wel zeggen we die die promptgenera mensen kunnen dit kijken op eh op televisie want dan zie je de ehm video's die dat ding gegenereerd heeft. We hebben wel een beetje zitten spelen met eh hoe hoe neem je het hele prompt over of neem je een deel van het prompt over? Ik moet wel zeggen, Sora is uit zichzelf echt best wel grappig. Dus hoe meer ehm eh detail je het meegeeft in het prompt, op een bepaalde manier hoe minder goed de eh video wordt. Want dan gaat hij het echt precies proberen na te doen. Terwijl als je het meer openhoudt, dan vind ik hem eigenlijk grappiger. Wat alweer veel zeggend is, hè. Ja, boeiend wat zij dus weer aan hun kant aan het doen zijn voordat het een video wordt. Waarschijnlijk hebben zij ook weer een tussenstapje waar ze hem opleuken hè, om een soort viraliteit eraan te geven. Dat is helder. Dat dat niet alleen maar is maak een ja, een soort van heel realistische video. Beetje wat wat meer een VO3 zit van Google. Dit is meer waarheidsgetrouw zou ik zeggen van wat je invoert. En bij Sora merk je het is bedoeld voor een ja stand alone video app die gewoon een TikTok concurrent moet worden. Er zit een system prompt in Sora zeg maar. Waarschijnlijk hebben zij ook zo'n VO-achtig ding ergens hè die veel rauwer veel meer instructies volgt. Maar er zit overduidelijk iets met een mening en een hogere temperatuur op creativiteit van ja geef doe een beetje de hoofdlijnen dan ga ik dat wel vullen. Wat hoop je nou na dit? Want dit item gaan we doen met Jord Kelder. Die hebben we eigenlijk gecame en daar gaan we tuurlijk, want dat moet ook want hij moet die getallen voorlezen waardoor zijn stem gekloond kan worden. Ehm maar dit gaan we dus doen met Jord Kelder. We hebben de afgelopen week hebben we zijn Instagram account gevuld met deze AI slop. Eh de best bekeken video is kwart miljoen keer bekeken. Vind ik toch grappig met AI slop. Ik vind het grappig. Ik vind het ook verschrikkelijk hè. Begrijp me niet verkeerd. Maar nee, zeker. De combinatie van die twee. Nee, ik denk wat ik net zei hè. Dat dus als je net je vraagt eigenlijk wat is dan een soort doel hiervan, hè? Behalve dat het dan grappig is, wat hoop je dat blijft plakken? Want dan dan heb ik ook nu nog input voor wat ik vanavond aan tafel kan vertellen. Nee, uiteindelijk is het een soort public service announcement hè, zo'n PSA wat mij bestaat. Ja, dit bestaat. Dit kan nu. Ehm net als dat we de vorige keer hebben geprobeerd voor Carisle een soort van bureautje te maken om een campagne rondom haar boek te maken, hebben we nu weer een dingetje aan elkaar. Een soort rop goldberg machine met touwtjes en plakband. En dan zetten wij dat in elkaar. En dat knutstofproject van ons, dat levert dan iets op wat een kwart miljoen views krijgt. En ik denk dat de boodschap vooral is als als wij dat op een zolderkamer kunnen doen, dan zijn er meer mensen die dit kunnen nu al en waarschijnlijk gaan doen. En daar hebben we wat mij betreft mee te dealen nu. En we in de breedste zin van we, dat is gewoon de consument die achter de tv zit, maar ook de redacties. Wat bedoel je? Ja, maar wat bedoel je dan? Daar hebben we mee te dealen. Wat hoop je dat mensen nou uiteindelijk, want dit is dit is een beetje zoals ja, ik hoop dat het awareness oplevert, maar dan denk ik altijd awareness voor wat dan? Ja, nou ik zou zeggen de eh vervaging tussen echt en nep eh de de in de hoe zeg je dat? Ja, ik noem dat informatieinflatie of een soort van het uit elkaar vallen van alles wat er achter het glas gebeurt op jouw telefoon. met uit elkaar vallen bedoel ik gewoon dat het vertrouwen daarvan en en een soort van eh en ook de soort van kwaliteit van dat medium zeg maar de betrouwbaarheid van van dat digitale medium dat dat valt dat stort eigenlijk langzaam in nu zie je doet alles wat je op je telefoon ziet ja zie je een soort oude kathedraal voor je waar heel dat stenen afvallen dat is nu gewoon aan het gebeuren met met het soort digitale media en eh of alle digitale media zou je kunnen zeggen. En ik denk dat om dit een soort van ja, ik geloof een beetje in het idee als je een paracetamol aan een kind wil geven, moet je dat in een in een in een hapje vla doen hè. Want dan zit die paracetamol moet je wel overleggen met je kind. Niet stiekem, maar van joh, doe er een beetje zoetigheid omheen, dan kan je die boodschap brengen, zeg maar. Dus dat wij er nu een beetje een viral dingetje met Jord Kelder van maken is de ja, de vla de wat serieuzere boodschap is denk ik ehm ja, let op dit gebeurt nu. En ik denk ook ehm dat we dat je dan met elkaar moet gaan kijken en dat en dat is dus niet alleen consumerend hè dus nieuwsconsumerend of media consumerend Nederland, maar ook mediaend Nederland vind ik eigenlijk ook [gelach] een hele belangrijke groep van hoe hier nu mee om te gaan. Want om een voorbeeld te geven, nu is het zo dat ook in de Sora 2 video's zit een eh watermark hè. Er zit een soort stenografie in waardoor eigenlijk platforms die deze weer gerepost krijgen, hè. Dus jij pakt een Sora 2 video, Alexander Clupping huilend bij ASML. Die zet je door op TikTok. En TikTok kan dan nu een label toevoegen met generated content. Want zij zien gewoon dat doet Open. En jij heeft het afgesproken, die stoppen ze daarin. Daarin kunnen we met elkaar synthetische content labelen. Maar als jij dit zou hebben gemaakt met een open soort model van GitUP, dan kan die stenografie eruit, hè. Dus dan dus daarmee is het niet opgelost nu dat we een soort van synthetisch label hebben. Je kunt natuurlijke label hebben, hè. Dus dit moet je erop zetten, hoe je het ook technisch doet, dat dat gaat helpen. Maar ook daar we hebben geen ehm hoe zeg je dat? Eh gesloten technische oplossing om die synthetische content te herkennen. Het zijn afspraken tussen de grote model providers nu en de social media netwerken dat ze zeggen: "Jij geeft het aan mij door en dan geef ik het door aan de eindgebruiker." En ik denk dat hierin ja nog wel wat op allerlei vlakken debat te voeren is over hoe dwing je dat dan af? Hoe gaan we om met open source? bij wie ligt de verantwoordelijkheid et cetera et cetera, et cetera. Allemaal een beetje gebracht die boodschap in een soort leuk luchtig iets. Eh er gebeurde veel deze week en ik ga dat nu in 3 minuten met je doornemen. Open jij lanceerde vannacht GPT 5.1, de nieuwe versie van ChatPT en die update rolt nu uit naar betalende gebruikers. GPT 5.1 komt in twee smaken. Instant en thinking, eigenlijk hetzelfde als nu. Met de manier waarop hij kiest welke van de twee eh gebruikt wordt veranderd. Het model beslist niet middels een of andere router, maar zelf wanneer het moet nadenken voordat het antwoord geeft en wanneer die gewoon snel antwoord geeft. Daarnaast is instant volgens openi warmer en gezelliger geworden. Er zit meer speelsheid in en het model volgt volgens open instructies nu ook beter. De instructies die je geeft dus. En zelfs je voorkeur voor gedachtestreepjes wordt nu onthouden. Fiets, wat een ongeloofelijke vooruitgang krijgen we hier toch weer. Eh we gaan het er dadelijk meer over hebben. Een Chinees AI Lab lanceert op dit moment ook een open source model dat ChatBT op zijn beurt weer inhaalt. Het heet Kimy K2 thinking. En dat model scort op belangrijke AI benchmarks beter dan betaalde alternatieven van Westerlap, zoals sommige versies van Jetpt. Bijzondere is dat dit monster van 1 biljoen parameters voor iedereen gratis beschikbaar is. En ook hier gaan we dadelijk meer over hebben. Google bankt Photoshop waarmee je kunt praten. De Google Foto app krijgt nano banana ingebouwd en dat is hun beste beeldbewerkingsmodel. Je kunt voortaan in Google foto's tegen je foto's praten door ze om ze aan te passen. Dan kan je bijvoorbeeld zeggen verwerwijder die zonnebril of open mijn ogen en laat mijn vriend lachen of zet me in een high fashion fotoshoot. Eh dat gaat allemaal kunnen. Eh kleine kanttekening. Je voelt hem al aankomen. Dit is niet beschikbaar in Europa. We kijken wel even wanneer dat gaat gebeuren. En McKinzie publiceerde deze week hun State of AI 2025 report. En die cijfers zijn een beetje ongemakkelijk. 88% van de bedrijven gebruikt AI volgens dit rapport. En dat klinkt goed zou je denken. Maar slechts 33% heeft daadwerkelijk breed uitgerold. En nog schijnender slash 39% ziet een klein beetje positieve impact op de bedrijfswinst. De meeste organisaties zitten gevangen in eindeloos experimenteren, maar komen nooit tot doorpakken. Er is een kleine groep die het wel voor elkaar krijgt, ongeveer 6%. Dat zijn een soort AI koplopers. En zij zien meer dan 5% van hun bedrijfswinst direct eh toerekenbaar aan AI gebruik. 6% dus. Eh en die zien dan 5% van hun bedrijfswinst. Nou, dat is aanzienlijk. Wat doen die 6% anders dan de rest? McKinzie testte 31 verschillende werkwijzen en heeft allerlei best practices uitgewerkt en die vind je onze nieuwsbrief airport. Tenslotte Jan Lecoon verlaat Meta om zijn eigen start-up te beginnen. Hij is nu chief AI scientist bij Meta en hij wordt gezien als één van de AI pioniers. Hij kwam onder andere met technieken die cruciaal zijn geweest voor de doorbraak van modellen zoals we die vandaag de dag kennen. En hij is in gesprek met investeerders voor een bedrijf dat zich richt op world models. AI systemen die slimmer worden door niet eindeloos data te verwerken, maar door in de echte wereld te leren hoe dingen werken en wat de gevolgen zijn van acties. Een beetje zoals wij mensen leren. Dus eigenlijk die timing die die eh nu aanhoudt is veelzeggend. Meta heeft recent zijn AI strategie volledig omgegooid. Een nieuwe divisie is opgericht. Alexander Wang is binnengehaald en meer dan 50 engineers zijn van concurrenten binnengehaald voor onwaarschijnlijke bedragen. En er zijn signalen dat het een chaos is binnen met AI afdeling. Niet zo gek dus dat Leon al die drama zat is en denkt ik ga lekker iets nieuws bouwen. Straks gaan wij het hebben over al die dingen die ik beloofde zoals dat Chinese AI LAAB en wat kunnen we merken van ChatBT 5.1. Maar eerst hoor je Marian en Lucas van Dept. Hi, [muziek] hier marketing en techbrood Dept. Elke week bespreken we hoe wij merken helpen in de wonderwereld van AI. Deze week, hoewel iedereen zijn mond vol heeft over AI, zien we dat bij veel klanten de uitdagingen om hiermee aan de slag te gaan echt ergens anders liggen. Lucas, vertel. Ja, en dit klinkt misschien gek, maar voor de meeste merken is de AI transformatie uiteindelijk vooral een dataformatie. En wij praten veel met klanten over de kansen hoe die AI kan bieden. Maar we zien ook in die gesprekken en in de projecten die we doen dat de fundamenten vaak gewoon niet genoeg op orde zijn om echt aan de slag te kunnen gaan om impact te maken. En hierbij is vooral het en dan vooral het gebrek aan de kwaliteit en de beschikbaarheid ervan eh meestal de grootste bottelnek. Ai wat nu? Ja, sorry. Dit is niet het bericht wat we hier normaal eh verspreiden, maar eigenlijk net zoals bij de Good old digitale transformatie hè, die kennen we allemaal nog wel, moeten de randvoorwaarden kloppen om AI echt voor te laten werken. Dus naast data hebben het bijvoorbeeld ook over de manier van werken, talent wat je nodig hebt of de benodigde technische infrastructuur. Oké. En wat kunnen merken dan doen om dit op orde te krijgen? Nou, het begint in de basis met een hele duidelijke visie op wat moet AI jouw organisatie de komende jaar gaan brengen. En op het moment dat we dat weten, kunnen we in kaart gaan brengen ehm wat er nodig is om dit te realiseren. Dit zorgt ervoor dat we eigenlijk wat meer uit die point solutions komen. Dus nu op dit moment zie je gewoon vaak dat er oplossingen bedacht en ook geïmplementeerd die heel goed werken in een bepaalde eh eh workflow bijvoorbeeld, maar niet schaalbaar zijn in impact eh binnen de organisatie. Eh uiteraard kunnen wij hierbij helpen hè, maak je geen zorgen. We hebben een aanpak die we al eh vaker hebben ingezet onder andere bij klanten als eh Luft Hansza en Saintbs. Kortom, neem een stap terug om er straks twee vooruit te kunnen zetten. Wil je weten hoe je een duidelijk langer termijn plankt voor AI binnen jouw organisatie? Kijk dan op de.com/aaiort en tot volgende week. Wie? Heb je met GPT 5.1 gespeeld? Ja, even snel. En viel je iets op? Ja, is een beetje een sikofant geworden weer. Oh ja, echt? Ja, we zijn nou ja, kijk GPT eh moet even uitleggen wat dat is. Een hielenlikker. Ja, iemand die de hele tijd met je meelult. Ja, niet best man. Nee. Nou ja, het is het is iets wat toch ook wel Ik bedoel we hebben op een gegeven moment gehad dat GPT4 dus voordat GPT5 uitkwam een soort tussenupdate kreeg waardoor mensen zeiden: "Oké, dit is een teveel een sikofant geworden." Toen hebben ze na een knoppen gedruk. Alles gaaf wat je doet. Ja, dat was hem was helemaal dus hebben ze ook zelfs een blogpost over gedaan op de jij toen van woeps sorry sorry. Nou dan hebben ze al die knoppen weer teruggedraaid. Toen kwam GPT 5 uit zeiden mensen: "Ja, dit ding heeft helemaal geen persoonlijkheid meer. Waar zijn waar die Ja, dat is dan de de keerzijde van de medaille is Sik is weggedraaid, maar daarna voelde die een beetje als copilot." Ja. Door eigenlijk die nou ja [&nbsp;__&nbsp;] met GPT4O die te ernstig werd toen terugdraaien kwam GPT5 uit waar zij dat eigenlijk mee hebben getraind. Eh het meetrainen van niet van persoonlijkheid. Ja. En dan dat bleek weer een soort van niet de de sfeer te zijn, niet het karakter te hebben. Ik moet even deze woorden gebruiken. Ja. Ja, ik snap het. Stel de persoonlijkheid. Het maakt toch uit dat je het gevoel hebt met wie je praat. Ja. En wat ze nu bij 5.1 hebben gedaan is, ik bedoel, we we zijn er nog niet helemaal achter wat 5.1 precies is. Ik bedoel, 5.1 is een versienummer waarmee je laat zien dat je een kleine update hebt gedaan hè. Anders had je hem zes genoemen genoemd. Is een een minor update. Ja. Maar is het nou ook wel echt een nieuw model? Dat is nog een beetje vaag, zeg maar. Zijn ze echt opnieuw dat brood terug in de oven bakken en er weer uit of hebben ze vooral system promps getweakted en in die scaffolding wrapper eromheen heel veel dingen gedaan? waarschijnlijk een beetje van alles. Het model is een beetje opnieuw gebakken, maar heel kort. Eh de system prompt is duidelijk aangepast, want die hebben ze inmiddels alweer uitgetrokken, zeg maar. Die kan je eh terughalen als je slim rommelt, kan je de oer oerprompt uit die modellen trekken, zeg maar. En daar staat staat overduidelijk andere opdrachten in dan in die eerdere. Veel meer dat je joh eh wees een beetje wees het gewoon een beetje meer eens, hè. Wees een beetje vriendelijk. Eh probeer een beetje vriendschappelijk te zijn. Dus het zit er duidelijk in. praat een beetje mee, maar niet teveel. Niet teveel. D ze hebben ze hebben weer geprobeerd aan die knoppen te draaien. Ja. Ehm nou, de eerste tekst die ik een beetje lees van mensen is dat ze zeggen: "Ja, nu zijn we weer waar we waren toen met het gedoe dat het teveel was." Hè, dus er is ook best wel een flinke groep online die nu zegt: "Het is weer teveel. Dit en dit is gevaarlijk teveel." Want er zijn stel je zeg maar eh beetje maffe vragen over rare plannen die je hebt en dan zegt hij: "Top idee, man." Ja, het is niet per se goed als een taalmodel de hele tijd alles gaaf vindt wat je zegt. Nee, omdat je ook in een soort van eh ja, echop terecht komt van je eigen ideeën. En dit is al een probleem nu. En als ze die knop dus nu harder hebben aangezet, lijkt me onverstandig. Ehm tegelijkertijd hebben ze wel de mogelijkheid nu dat je persoonlijkheden kan kiezen, hè. Dus ze hebben ze Ik had persoonlijk zou ik gezegd hebben: "Mak dat ding nou wat meer vanille. Geef, maak hem nou weer zo neutraal als het de originele vijf gewoon was. Laat dat gewoon zo en los het op door die persoonlijkheden te kiezen, hè. Dus je krijgt een soort van neutraal wat kouder model voor iedereen. En als iemand een persoonlijkheid kiest waar ook een karakteromschrijving bij staat, bijvoorbeeld eh Heal Liende Leo. Ja, [gelach] als je dat wil dan krijg je dan klik je daarop en dan krijg je het. Heyé en wat is dat adaptive reasoning? Ja, wat toen GPT5 uitkwam was eigenlijk de roddel. Dit is het model waarbij ze thinking en instant gecombineerd hebben tot één supermodel die kan switchen on demand. Dat is toen niet gelukt. Dus ze hadden een soort goedkoop goedkoop dun makkelijk gemaakt trucje tussen die heel snel probeerde nog te gokken. Moet ik de zware of de lichte aanroepen? De router zat ertussen. Dat is ook heel veel van de controversie rondom GPT5. Want heel veel mensen kregen dus heel de tijd de GPT5 Mini waardoor ze dachten: "Dit ding is nog dommer GPT4O." Nee, de routing is niet goed gegaan. Nu zit die keuze tussen zwaar en licht in het model zelf. In ieder geval dat is de belofte. Waardoor dus eigenlijk met een heel heel korter verhaal het wisselen tussen zwaar denkwerk en licht denkwerk hè dus snel antwoorden licht en langzaam antwoorden met zwaar denkwerk gemaakt wordt door het model zelf in plaats van een blokje ervoor. Dat je die beslissing dan kan nemen op een veel intelligentere wijze aanhalingstekens dan dat die router daarvoor dat komt. Ja. Dus in de praktijk zou het zomaar kunnen dat ehm het slimmer gaat voelen omdat voor ingewikkeldere vragen waarbij het ding eh constateert: "Hier moet ik even wat langer bij stilstaan voordat ik gewoon uit de losse mols eh losse pols een antwoord schud uit de mouw." Eh dat gaat nu beter voelen als het goed is. Ja. En ik moet wel zeggen wat ik ook vooral las is is het niet gewoon vooral een update voor eh in het voordeel van Open AI eh die namelijk enorme infrastructuur moet draaien om die zijn het inmiddels 8 900 miljoen gebruikers eh blij te houden. Als je die routing verkeerd doet heb je aan de ene kant het probleem dat je mensen doorstuurt naar een te licht model terwijl ze een moeilijke vraag sturen. Ja teleurgesteld zijn. Maar ook dat je mensen met een makkelijke vraag waarschijnlijk per ongeluk doorstuurt naar een te zwaar model. weer heel veel geld kosten. Ja, dus het is voor Open heel belangrijk om dit goed te krijgen. Dus ik zie dit eigenlijk als 5.1 de bugs fix op vi om de router ertussen uit te slopen. En ze zeggen: "Madel volgt instructies beter. Is dat nog wezenlijk?" Hm. Ja. Goed, er wordt een beetje mee getest en gerommeld nu, maar omdat er geen benchmarks bij zitten, over het algemeen zijn wij gewend dat als een LAP of commerciële partij of beide een nieuw model uitbrengt, dat er dan meteen een PDF'je bij zit en vaak ook een hele website met dat ze even flexen van kijk wat die allemaal kan. Dat zit hier nul van bij, hè. Dus dat moet nu door mensen zelf getest gaan worden. Dat doet velen van ons denken dat het eigenlijk een bugfix is vanuit Open AI. dat ze hem 5.1 hebben genoemd, zodat wij het verschil snappen dat we met iets anders aan het praten zijn, maar dat we niet moeten verwachten dat dit een een echt intelligenter model is op de achtergrond. Je hoorde het net al even. Het Chinese AI lab Moonshot AI komt met een model dat Anthropics Cloud en Open Chpt naar de kroon steekt op belangrijke benchmarks voor zover die dan wel gereleased worden. Voor wie niet dagelijks met AI bezig zijn. Benchmarks zijn gestandaardiseerde tests waarmee je AI modellen met elkaar kunt vergelijken. En Humanity's Last Exam is bijvoorbeeld zo'n test over hoe goed een model complexe problemen kan oplossen die normaal gesproken menselijke expertise vereisen. En Kimy 2, Kimy K2 scoort eh buiteng goed op exact die test. 44.9% als je precies wil zijn. Dat is één van de hoogste scores tot nu toe. En het bijzondere is vooral dit. Het model is voor iedereen gratis beschikbaar. Je kunt het dus nu uitproberen. Heb je dat gedaan? Ja. Ja, het was het voelt een beetje het is wel een soort subtiel deepziek dingetje. Alsin toen Deepzeek R1 destijds uitkwam, kon je het ook gratis gebruiken. Met daar natuurlijk de kanttekening bij. Let even op wat je allemaal vraagt en wat je er allemaal inplakt aan data. Maar dan kan je even voelen hoe dat dan gaat zeg maar. En want dat woord gratis is natuurlijk een beetje tricky, want eh eigenlijk ja, in het Nederlands hebben we daar wat minder last van. In het Engels heb je free en free. Dat is namelijk zeg maar free als zin het is vrij of free als zin het is gratis. En hier is hij eigenlijk een beetje dubbel. Namelijk het model wordt gehost door Moonshot zelf waardoor jij het kunt gebruiken als eindgebruiker. En het model is vrij in de vorm van het is te downloaden en te draaien op de infrastructuur naar keuze hè. Dus het is het is het is dubbel dubbel free. Maar dat is twee keer goed nieuws. Maar je hebt het geprobeerd en wat viel je op? Nou, wat je merkt is dat het uiteindelijk best wel voelt als O3 eigenlijk. Dus GPT's of open is O3 ziet er ook precies zo uit, hè. D ziet eruit als een visuele kloon van Chat PT. Ja. En dat lijkt dan misschien dat je denkt: "Nou, oké, grappig is dit dan zo innovatief ofzo?" Maar omdat het dus een vrij te downloaden model is wat je dan zelf kan draaien met zelfdraaien wil ik wel even de de luisteraar een soort reality check doen. Ehm twee Mac ultra's, €10.000 per machine van Apple. Als je twee Mac ultra's op elkaar stapelt, M4 ultra's zijn dat, met het maximale intern geheugen, dan kan je met ongeveer 20 tokens per seconde, hè, dus 20 stukjes woord per seconde, dit hele model, dus wat zo zwaar is eigenlijk en zo intelligent is op de test als wat Open en jij aan jou aanbiedt met een maandbedrag in hun datacenter thuisdraaien. Maar dat is dus €20.000 een investering voor nodig. Dus als er ergens staat: "U kunt dit downloaden en thuis draaien." Besef je even wat je daarvoor nodig hebt. Tegelijkertijd in de tests hè. Je zei net Humanity's last exam. Eh het laatste examen van de mensheid. Eh er zijn nog meer andere benchmarks, deentic benchmarks hè. Dus kan zo'n model zelf door eh denken zonder dat jij hoeft in te grijpen. Al dat soort dingen. Daar scoort dit model ook heel erg goed op. En het is wel typisch omdat ik vorige week nog een beetje onderzoek aan het doen was naar de staat van open modellen, hè. Hoe zitten de frontier closed lab zeg maar hè, dus de clouds eh eh de GPT's, noem maar op, versus de eh eh open eh lab zeg maar. Wat veel Wat is nu de stand van zaken? Dat natuurlijk de hele tijd eh de vraag hoe groot is het gat van de voornamelijk Chinese bedrijven die open source modellen uitbrengen en de Amerikaanse bedrijven die voornamelijk de closed source modellen aanbieden. Hoe groot is dat gat? En dat was een tijd geleden zei jij de hele tijd dat is een jaar. Ja, het was op een gegeven moment 6 maanden geworden al, hè. Dus je hebt van die mooie grafiekjes van artificial analysis doen dat die kan je hebben hele die hebben hele mooie brede benchmarks, soort met benchmarks en die laten dan zien van oké, dit is de lijn met gesloten modellen en hoe slim zij zorden en het lijntje erachteraan hè, als een soort marathonrace met iemand die dan letterlijk op eh z maanden achterloopt zeg maar, komt dan daar op dezelfde tempo achteraan zeg maar. Alleen zit een zit een gat tussen. Nu is eigenlijk het gat tussen even grof gezegd tussen GPT 5 eh Gemini 2.5 Pro van Deepmind en eh Cloud eh 4.1 Opus redelijk ingelopen. De Frontier models nu, maar ook allemaal alweer een paar maanden oud hè. In AI tijd is dat een hele lange tijd hè. Ik bedoel het klinkt als voelt als gister, maar die modellen zijn Gemini 2.5 is denk ik ook alweer vier of vi maanden oud. Weet niet uit mijn hoofd. Maar goed, dat zijn nu de beste modellen als je betaalde abonnementen hebt op van die AI. En eigenlijk is dit model loopt op veel vlakken nu gelijk op wat daar gebeurd is. Alleen ja, de deze ik zeg er wel meteen bij, als Google dan ooit nog voor het eind van het jaar Gemini 3.0 dropt, dan zijn ben je dan ben je weer op die zes maanden denk ik ongeveer. Dus dit is ongeveer natuurlijk hoe zo'n race werkt. Als straks een stokje weer overgegeven wordt aan de nieuwere frontier gesloten modellen, dan schuiven die weer even op. Maar het is wel Ik had persoonlijk denk ik ja, eigenlijk niet verwacht gezien eh hoe krachtig eh de frontier gesloten modellen zijn. En dan vooral de grote modellen hè, dus de Pro, de Opus hè, de de thinking eh en ook wat je daarvoor dataacenter computation infrastructuur voor nodig hebt. Dat we nu eigenlijk iets kunnen downloaden op het niveau van ja hè en dus met een investering van €20.000 €000 en dat voor een bedrijf een andere investering voor een particulier is te halen. Ja. Ja. Dus dat is wel een eh dus in dat opzicht is het ik vind het geen seek R1 momentje, maar het laat wel zien eh die race tussen open en gesloten modellen die is gewoon nog gaande en ze en ze ze komen elkaar toch iedere keer weer tegen. En dan iets praktischer, want dit dit zeg maar je kunt dit model dus gebruiken door naar kimi.com te gaan en dan zie je gewoon een chatptbt cloon waar je mee kan praten in het Nederlands en hij heeft diep research en eh eh weet je, je kunt dus modellen switchen, ifter vision. Ehm betekent dat dat mensen hun chatpt abonnement op kunnen zetten in op kunnen zeggen in de meeste gevallen en gewoon dit kunnen gebruiken? Goed, dat is je je voelt mijn antwoord dan een beetje aankomen. Dat dat is maar net aan wat voor data je erin stopt en waar je comfortabel mee bent. Ehm ja, ik zou zeggen hè wat die treingesprekken die je al niet in de trein zou voeren doe je wat mij betreft met Lechat hè, met Mistraal. Dan loop je ook zes maanden achter eh ongeveer op de frontier modell het dan op Europese service gebeurt bedoel je? Ja. En als je dan gesprekken voert eh even vanuit het individu gezien hè, gesprekken voert over het samenvatten van je VVE notleen. Da zou ik lekker eh GPT voor gebruiken, maar in die VV notuule zitten wel mogelijk adressen en namen, dus die zou ik niet zo snel in in ieder andere online gratis AI gooien. Kijk, gratis is natuurlijk enkel en alleen mogelijk als je wat je ervoor terugkijkt trainingsdata is. Dus ik ga ervanuit hè aanname van mij. Geen idee. Maar dat Kimi zegt: "Joh, prima dat je dit gratis gebruikt." Maar dat geeft ons wel heel veel data om ons model op te fine tunen, zeg maar. Ja. Ja. En voor dingen waarbij het absoluut niet uitmaakt dat het op straat komt te liggen, kun je dus prima als je dat voornamelijk gebruikt voor chpt pt, dan kun je dat dus prima opzeggen en dit gebruiken gratis. Ja, de vraag is natuurlijk wel een beetje eh ik zou het dan meer door elkaar heen gebruiken. Ik zou sowieso altijd meerdere agents gebruiken of wat is het? Interfaces gebruiken, want de modellen zijn gewoon niet gelijk. Wel benchmarks komen, maar uiteindelijk voelen ze toch anders, hè. Ik gebruik zelf ook nog steeds ieder geval drie modellen door elkaar heen. Eh je kunt hem toevoegen aan je ensemble, aan je aan je boeket. Ja. Al is het alleen maar om eens om eens te kijken hoe dat dan nu gaat, hè. Technisch gezien zou je kunnen zeggen: "Ik maak software waarin ik AI stop." Dan zou ik zeggen: "Hou Kimy in de gaten om te kijken of die je hem kan verwerken in je flow." Hè, desnoods kies je voor om te draaien in je op je eigen infra. En als eind eindgebruiker, gewoon de particulier zeg maar, eh kan je spelen en reasoning tharces lezen hè. Dus het reflectie eh momentjes in de interne dialoog van Ja, die zijn veel uitgebreider in die in die Chinese open source modellen, want die zijn gewoon eerlijk in plaats van al die AI van Amerikaanse bedrijven die dat hele gedachteproces eigenlijk censureert. Ja. en verstoppen ook of zodat het niet gestolen kan worden. Ja. Ja. Ehm dit model heeft 1 biljoen parameters. Dat zegt me in principe niet zo heel veel. Maar wat me wel opviel dat er per vraag maar 32 miljard gebruikt worden. Dus hij gebruikt maar een deel van zijn parameters. Hoe zit dat? Ja, dat is eigenlijk ehm wat je je verdeelt het model eigenlijk intern in een soort experts in allemaal stukjes van het model. Dus die het model bestaat uit verschillende experts. Ja. Dus dit is wat Mistral bijvoorbeeld al best wel lang doet ook. Dat is één van de dingen waar zij vrij vroeg bij waren. Kijk, uiteindelijk in een datacenter en trouwens ook op een laptop doet even niet toe. Als je zo'n model hebt, word je eigenlijk niet het hele model in je geheugen hoeven laden. Want zolang het geheugen bezet is, is dat duur. Eh en je moet gewoon meer je moet ook meer hardware hebben om zo'n groot model in te kunnen laden. Dus het is veel mooier als je zegt: "Ik ik stel een vraag over wiskunde." Dan kan eigenlijk het hele deel wat over geschiedenis gaat. Even als voorbeeld zeg maar. Zo'n model is heel breed hè. een soort brede savant zou je kunnen zeggen met allerlei expertdomeinen. En uiteindelijk als je die experts slim definieert hè, dus waar eigenlijk weinig overlap is, want als je experts defineert met veel overlap, worden ze constant allemaal geladen, want ze hebben allemaal elkaar nodig. Maar als je meer wiskundige of bijvoorbeeld programmeervragen stelt over software, heb je als je software aan het maken bent met een taalmodel de complete historie van Europa nodig? Nee. Dus dan kan eigenlijk dat deel van het model. Ja. Dus het mooie is dat je de vraag stelt en dan eigenlijk wordt alleen het deel van het model dat nodig is om dat die vraag te beantwoorden warm hot in het geheugen geladen en de rest staat zeg maar koud klaar. En dat is dat is sowieso een nog een klein puntje over eh Kimica 2 is dat eh de training zoals gezegd, dus we moeten even geloven dat dat waar is, volgens mij gebeurt is voor iets van iets meer dan miljoenar dollar. Dat is extreem goedkoop. Extreem goedkoop. Ja. Dus dat is dat maakte het een soort semi diepziek momentje, hè. Want wat er toen met diepziek gebeurde, dat was dat de Nvidia aandelen daalden omdat er werd gedacht: "Jeetje, als jij kan trainen van Deep Seek R1 op zo'n kleine infrastructuur hè, want zij hadden het echt over een miljoen maar ofzo, toen bleek later iets meer, maar niet honderden miljoenen." Is dit met Kimy K2 verhaal weer zeggen zij heel trots in hun press release erbij. 4.1 miljoen volgens mij. Joh, wij hebben op een paar aardappels hè even in de metafoor iets getraind wat eh waar jullie training runs hè jullie als in de gesloten. Zorg dat dit nu dan niet weer tot het instort van de aandelenbeurzen. Want want al die al die koersen zijn nu gebaseerd op de verwachting die enorme investeringen in infrastructuur gaat opleveren. Maar hier zeg je dus eigenlijk ja, met een fractie van de infrastructuur krijgt Kimy het voor elkaar om even slim te zijn als het beste model van opening. Wat wat begrijp ik hier dan niet? Nou, het is wel zo dat in ieder geval dit was destijds tijdens deepziek R1 saga ook het verhaal dat er vooral door de laps gereageerd werd met ja, als je de handleiding eenmaal hebt eh die wij hebben uitgevonden hoe je zoiets maakt, dan is makkelijker. Maar ja, iemand moet hem wel de eerste keer maken zeg maar hè. Dus zij waren ook een beetje gefrustreerd natuurlijk. Nou, doen wij die diepte investering. Jij doet kopieeron. Ja, je maakt een cover van die track. Dat wordt ook een hit. En dan ga je zeggen: "Kijk, dan kan ik echt met een heel klein beentje." Ja, maar maak het originele nummer maar eens, hè. Eh dat dus ehm daar zit eigenlijk was de interpretatie destijds van de reactie van de markt op R1 klopte eigenlijk niet helemaal. Dat is en dus nu is die reactie niet nog een keer, want er is een soort van wijsheid nu, hè. Dit neem ik even aan. Het is wel en het is zo dat de mode hè, dus de eh de de slotgracht eh het eh unieke selling point wat Nvidia heeft eh slash op je moet Nvidia chips hebben, want anders kan je niet zoveel rondom een AI. Dat is eigenlijk steeds minder waar. Eh Entropic heeft nu een heel stuk infrastructuur aangekocht bij Amazon, een gigantische miljoenen deal. En dat gebeurt allemaal op de wat zij noemen hun tranium chips heet dat volgens mij. En je moet altijd een soort klinken als het als het een soort element is, hè. een soort uranium en heet tranium ofzo uit mijn hoofd. Maar goed, dat zijn Amazon chips. Ja. En die die zijn dat is niet een of andere press release over fake Amazon chips. Nee, dit is gewoon server datacenters gebouwd waarop nu de volgende cloud getraind wordt. En dat zijn geen Nvidia chips. En zo zijn er eigenlijk nog wel meer hè. Voor Inference heb je grok met de Q, Cerebrus, dat zijn ook geen Nvidia chips hè. Dus aan zowel de trainingkant van het AI infrastructuurverhaal als de uitvoer van de AI en het hosten van de AI kant word komen nu allerlei alternatieve chips op de markt en chipmakers. Dus en dat is ook maar goed ook hè denk ik voor een soort gezonde markt en ook en afhankelijkheid van één bedrijf moet je eigenlijk helemaal niet die monopolie willen. Dus ik denk dat de klap wat minder hard is omdat inmiddels wel duidelijk is dat de mode van Nvidia langzaam maar zeker eh aan het verdwijnen is of in ieder geval aan het verkleinen is. Dan onze vriend van de showja Nadella zat vannacht bij Duar Cash. Eh heb je die podcast geluisterd? Ja, ik heb hij was anderhalf uur wat heel kort is voor een jammer. Ja, ik dacht wel wij hadden hem maar een kwartier. Maar een kwartier. Dit is toch baas boven baas. [gelach] Absoluut een baas bovenbaas. Nee, ik wil ik wil toch heel even over heeft die dingen gezegd. Ja, een beetje. Eh ik moet wel zeggen ehm het begin is ze ze hebben een wij weten ook hoe dit werkt, jij en ik. Er zit een toertje door een nieuw datacenter van Microsoft bij. Dat is natuurlijk ook een beetje de afspraak hè van een interview doen, maar kom ook even een rondje lopen. En dus maar dan dan lopen ze dus heel casual door een mega datacenter heen wat en dan ja, dat zeg ik goed. Wat dat is één enkel datacenter met 10 keer de capaciteit waarop GPT 5 getraind is. Even een soundbite van Satanaadella. Dus de infrastructuur die nodig was om heel GPT5 te trainen, hebben ze daar keer 10 staan in één gebouw. Terwijl GPT5 ook nog eens getraind is in meerdere datacenters tegelijk. Het is een groot datacenter. Ja, even de flex. Ja. Oké. Eh leg hem even op tafel. Maar goed, dan komt meteen de vraag van Dra Cash. Oké. Eh zijn die modellen zo belangrijk dan? Eh betekent dat zijn jullie hier dan je eigen MS GPT1 aan het trainen ofzo? En dan zegt eigenlijk eh Satje Nadella: "Nou ehm wij geloven helemaal niet zo in de mode van modellen." D is best wel een het is best wel juicy. Gezien de zit inmiddels hebben ze nog 27% aandeel in. Hoe tree? dat eigenlijk nou dat de antropics van deze wereld en de open van deze wereld en de Googles van deze wereld met hun modellen ieder geval wat hen betreft niet zoveel in handen hebben. Dit moet je natuurlijk dit komt uit de CEO's de mond van de CEO van Microsoft hè. Dus die een jaar geleden of nou ja iets langer dan 2 jaar geleden nog eh ja de beurskoers was een beetje gebaseerd op hun aandeel in Open AI. Ja. Maar goed, het gaat dus echt over de discussie op een gegeven moment is tijdens het interview waar zit de waar zit de waarde in de modellen of in de scaffolds? Dat is gewoon de heldere vraag, hè. Dus ja, scaffolds betekent dan de manier waarop het zit de waarde in, de manier waarop het in Windows en in Excel zit geïntegreerd of zit het in dat jij ja, de secret source hebt die eronder zit. Ja, en nu is het nou, hij neemt dan hij noemt dan het voorbeeld Excel dat eh ik kan het voorbeeld even gebruiken van vandaag. We hebben Google Photo's heeft nu integratie met nano bananana. Ehm dat eigenlijk voor de eindgebruiker willen wij natuurlijk alleen maar zeggen tegen de luisteraar. Je kan n je kan nu praten tegen Photoshop. Ja. En dat heet Google foto's. En als jij nu die zonnebril weg wil, dan kan jij letterlijk zeggen: "Haal die zonnebril weg." En dan is die weg. Daar zeggen wij dan nog achteraan. Dat is trouwens nano banana. Ja. Wat met alle respect alleen nerds vinden dat interessant hè. Wij noemen het toch, want we proberen een beetje een dubbel publiek aan te spreken tijdens deze podcast. Maar wat eigenlijk Shatja Nadella zegt is Google foto's is wat waard. Ja. Nano banana niet. Hm hm. Want is zijn punt en ik ga wel een klein beetje mee in die gedachte. Yo, dat nano banana is over 6 maanden op source nagebouwd. Dus ja. En mijn Google Photo's is niet over 6 maanden op source nagebouwd. Ja, wel de interface, maar niet alle mensen die erop zitten met hun foto's en hun pixel telefoons. Dus de mode, de slotgracht hè, de unique selling point, de waarde zit hem in die scaffold. Namelijk hoeveel gebruikers heb jij die binnen Excel, die binnen Google foto's opereren, die in jouw ecosysteem infrastructuur zitten. Want dan ben jij Microsoft, dan heb jij niet je eigen nano banana. Nou, dan wacht je 6 maanden pak je de nano eh het is het eh heet waarschijnlijk eh micro eh lemon, want zo is dan het open source project genoemd. En die pak je dan als Microsoft en die stop je in je Microsoft foto's. En dan kan je alsnog zeg maar je OneDrive photo gallery ook praten met je foto's. En zijn punt is dus eigenlijk dat de modellen worden constant open source nagemaakt. Is een beetje zijn verhaal. Eh dus daar heb je gewoon het is onverdedigbaar. Maar dus het antwoord op de vraag waar gebruik je dit voor? Gebruik je het voor het trainen van grote modellen of gebruik je het van voor AI gebruik van eindconsumenten? Dan is dat het laatste of het is een typische Steve Jobs opmerking die zegt: "Natuurlijk gaan wij nooit een telefoon maken en een en een pen bij een iPad zullen we nooit doen en dan dat zes maanden later alsnog doen." Ik denk dat er natuurlijk kleine modellen die zijn er ook hè binnen Microsoft zijn. Tuurlijk heeft Microsoft hun eigen beds op specialized models blab bla bloei. Maar ik vond het een interessante eh focus. Dan komt natuurlijk ook daarna de vraag hè, want jij zei net al Excel mooi als voorbeeld. Daar zegt Satanadella dus van ja, wij kunnen eigenlijk meerdere modellen in Excel aan de gang zetten. En dat model krijgt dan toegang tot Excel te knopjes te binnen zodat hij kan rondklikken, die kan kijken naar jouw sheet. En het model krijgt heel veel context mee vanuit Microsoft om te helpen om met Excel te werken. Hè, dat noemt hij de middle tier. Hebben wij het vorige week volgens mij over gehad van waar zit die AI dan? Hè, zit hij dan in jouw hele OS alleen in Excel of in een website waar je Excel screenshots uploaden? hè, een soort van op de verschillende lagen. Heel laag of heel hoog. Nou, hij heeft het dus nu over de middle tier application van AI. Oftewel, alle Microsoft producten enhancen met een specialized AI, hè, dus een Excel agent noemt hij dat dan. Dus gewoon een foundational model met allemaal hulp eromheen van hoe kan je met Excel werken. Een handleiding voor Excel als het ware plus toegang. Also jept eerst Excel voor dummies voert en daarna screenshots van jou Excel sheet waar jij in aan het werk bent en dan zeg je doe even wat ik wil. Ja. En weet je wat? Ga maar op de achtergrond in Excel zitten. Ik wil gewoon met Excel praten. Regel het hè. Dus een beetje de nou ja wat met wat Google met hun Google Maps gedaan heeft eh vorige week met Gemini. Ja. Dat vind ik dus een interessante strategie. Dan is alleen natuurlijk wel de vraag, waar blijft Excel uiteindelijk als die Excel agent echt heel goed wordt? Ja. Wanneer zie je nog de spreadsheet? Bedoel je als gebruiker van je? Ja, want niemand Oké, bijna niemand wil spreadsheets maken. Je hebt een doel. Ja. En je hebt een berekening die je wil maken. Je hebt een bedrijf te runnen. Je wil iets. Ja. Ja. En als op een gegeven moment die agent jou gewoon de antwoorden geeft in een sexy dashboard. Ja. Misschien ook nog met een screenshot van hoe het dan eruit ziet, zodat je als je wil er nog even naar kan kijken. Ja. Mag ik even onder de motorkap kijken? Maar die verhouding gaat veranderen. Ja. Nou, daar was ik kan ook echt wel de mensen met de tijd aanraden om in ieder geval een goed uur van dit interview te kijken. Eh want er zit een hele strategie. Kijk, je kunt je kunt natuurlijk denken dat er nu een soort van heen en weer gerend wordt binnen de hoofdkantoor van Microsoft van oh nee, oh nee, wat moeten we nu? Hè, daar gaat onze mode. Nou, als je Sat Nadella hoort praten heb je zoiets nee. Toen GPT2 uitkwam is er waarschijnlijk een certificzon geweest en zijn ze helemaal gaan nadenken hoe positioneren we Microsoft in een wereld waarin mensen geen software meer nodig hebben? En wat is daarop het antwoord? Het gaat ons niet om software. Wij gaan ervoor zorgen dat die agent zo magisch kan voelen omdat hij eigenlijk stiekem ergens een Windows machine kan draaien die jij niet ziet bij Microsoft. waarin Excel draait van Microsoft en waarin een Excel agent ontworpen op maat door Microsoft draait op open modellen gratis door Microsoft gedownload, snap je? Dus en ja, je merkt dus eh in zijn verhaal dat dat zij wel redelijk klaar zijn voor een wereld waarin jij geen Windows meer hebt. Heeft hij nog AGI voorspellingen gedaan? Om dat een beetje Hij zei hetzelfde als bij ons. Dat is wel grappig, want wij hebben het er ook over gehad dat we ons best wel zorgen maakt zorgen maken eh om AGI. En daar heeft hij eigenlijk een beetje een standaard soundbite op. Ehm het is een tool. Het is een iets wat ons eh ondersteunt en niet vervangt. Dat is waar het nu is. Hij zegt het wel Hij zegt het wel slim hoor. Dat is waar het nu is. Dat is waar ik de focus ook nu op leg. Om te zorgen dat AI een goede hulp is, hè. Hij noemt het volgens mij een guardian angel zelfs. Dat vind ik best wel een statement. Ehm en wat er daarna allemaal nog komt en dat noemt hij een soort van the almost spiritual way of talking about AI noemt hij dat in het interview. Eh ja, dat is een dat is een interessant gesprek, maar niet eh eh niet relevant op dit moment. Dus hij schuift gewoon eigenlijk die AGI timeline weer even 5 jaar vooruit, zegt 10. Goed, in de nieuwsbrief viel mij nog één ding op wat ik wel boeiend vond. Een eh ding wat ook over Microsoft eh PowerPoint eh een concurrent van Microsoft PowerPoint, namelijk de AI presentatietool eh Gamma Gamma. Gamma. Ik weet eigenlijk niet hoe ik het moet uitspreken. Ik denk Gamma. Een start-up van 5 jaar oud met 52 medewerkers. Eh dat is er niet zoveel als ze waarschijnlijk a PowerPoint werken, maar die winstgevend is en een waardering van 2.1 miljard dollar krijgt. Ehm dus dat is aardig in vergelijking met wat Microsoft eh doet. En wat dit doet is eigenlijk hoe de toekomst van PowerPoint eruit zou kunnen zien. Eh namelijk presentaties maken met tekstprompts. Dat is toch nog niet iets? Ja, het sluit ook een beetje aan op ons vorige verhaal, hè. Dus dan bestaat mij bestaat PowerPoint straks nog als je als je gamma hebt. Precies. Ja, dus dit soort tools bestaan en die eh die vallen natuurlijk keihard Microsoft met haar enorme jaaromzet van eh nou hun jaaromzet aan. En eh deze tool kan dus met AI complete presentaties eh maken op basis van eh promps die er echt goed uitzien. Ehm en onze redacteur Shan testte het met een campagne voor minimalistische sneakers. Je moet het maar je moet maar ergens beginnen. Ze gaf een prompt. Ontwerp een campagne voor de lancering van deze sneakers. Doelgroep genziers. Eh doel 10.000 pre-orders. Dus oftewel doe een beetje je best. Focus op samenwerking met influencers en betaal de social media. En die hele eh die AI nam haar door dat hele proces heen van automatisch gegenereerde conceptslides, dat kiezen van layouts. Ehm en eh die AI paste de hele tijd kleuren, fonds, nou ja, heel visueel aan op basis van eh wat ze prompten. Dan druk je uiteindelijk druk je op generate en dan leun je achterover en dan gaat dat ding dus die presentatie voor jou in elkaar flansen. Dat is best iets bizars. En is er ook nog een eh soort van extra tool, een knopje die luidt convert to website. En met één klik transformeer je dan je presentatie in een live website die meteen via het internet te raadplegen is. Of het genoeg is eh om daadwerkelijk in professionele context te gebruiken, we hebben een link in de showotes gezet, dan kun je het zelf eh oordelen over hoe je in ieder geval die sneaker eh sneakers eruit ziet. En in de nieuwsbrief van deze week lees je meer over scamma's beste functies, zoals een functie om diagrammen te maken, gedachten omzetten in eh flow charts en zelfs een eh presentation analytics tool die wil laten zien wanneer je publiek waarschijnlijk afhaakt in je presentatie. Nou, dat moet ik toch echt in mijn lezing doorheen gooien. Als je daar meer over wil lezen, ga je naar aiirport. En als je denkt van oké, kan ik dit dan zo gebruiken als ik geef die prompt, dan komt een presentatie uit en dan ga ik die presentatie dan geven ofzo ergens. Wat ik doe met dit soort tools is een ik zie het meer als een soort ideation prototyping tool. Ik laat hem 10 presentaties maken, die bekijk ik en denk: "Oh, dat is die slide is wel grappig." En daar begin ik dan zelf mee in mijn eigen. Dus ik zie het meer als kan je wat ideetjes voor me genereren en dan sporadisch zit daar ineens een slide bij dat ik denk jeetje. En dat is in het laatste half jaar meer komt het steeds meer voor dat ik denk er zitten wel meerdere slides in. Het gaat mij vaak om hoe iets gevisualiseerd is of hoe iets teruggebracht is tot een paar bullet points dat ik denk ja nou nou je het zo laat zien aan mij is wel prettig. Ja. En je bent duszelfde de de dirigent van al deze van dit orkest. En ik laat ook wel eens moeilijke dingen uitleggen door gamma, wat niet helemaal de bedoeling is van hun eh idee, hun hun software, maar dan zeg ik gewoon: "Oké, dit boek leg uit in een slideshow omdat ik over het algemeen makkelijker door een dek heen tik." Ja. Dan door een paar paragraven chat GPT summarization. Nou, wij vinden het dus de moeite waard om deze tool eh te testen eh voor jezelf en dat hebben we voor je gedaan en dat kun je lezen in AR Report. Wij danken Sam Hengevild voor de edit van deze podcast en Pankra voor de vormgeving. Als je een lezing wil over AI van Wietse Haag of van mij, dan kan dat. Mail ons op lezing@aaireport. Als je op de hoogte wil blijven aan het laatste AIs twee keer per week en dus tools en tips wil ontvangen over tools als gamma, dan abonneer je op onze nieuwsbrief via AIport. En als je vandaag nog wil beginnen met AI binnen jouw bedrijf, dan ga je naar deagency.com/aiort, onze gewaardeerde sponsor. Tot volgende week. Tot dan. [muziek]

---

## Notes


## Key Takeaways
-

## Related
-
