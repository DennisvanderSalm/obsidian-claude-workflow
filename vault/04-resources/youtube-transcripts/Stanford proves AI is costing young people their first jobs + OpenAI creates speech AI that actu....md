# Stanford proves: AI is costing young people their first jobs + OpenAI creates speech AI that actu...

**Source:** [YouTube](https://www.youtube.com/watch?v=3_3sTZ9uxHA)
**Video ID:** 3_3sTZ9uxHA
**Tags:** #youtube #transcript #ai-report

---

## Transcript

Welkom bij AI Report, de Nederlandse podcast over kunstmatige intelligentie, waar we uitzoeken welke invloed AI gaat hebben op ons werk, ons leven en de samenleving. Tegenover mij zit Wietse Hagen en ik ben Alexander Lupping. Deze week kwam er onderzoek uit van Stanford wat laat zien dat jonge werkzoekende de eerste zijn die de pineut zijn door AI. Zij onderzochten miljoenen loonstrookjes van de afgelopen jaren en zagen hoe banen van 22 tot 25-jarige in AI gevoelige beroepen, zoals de klantenservice een daling van 13% hebben in de werkgelegenheid voor die leeftijdscategorie. Ze ontdekten nog meer dingen over de impact van AI op de arbeidsmarkt. Ehm daar gaan we het over hebben en ook over wat er in het FD stond deze week over hoe advocaten op de Zuidas hiermee omgaan. Spoiler alert. Ook daar zetten ze een rem op het aannemen van jonge mensen. Maar we gaan het ook nog over andere dingen hebben. Open AI heeft een zogenaamd speech to speech model gemaakt. Eh lang verhaal kort. Het komt erop neer dat ze betere spraakinterfaces gaan maken waardoor we nog beter met onze computers kunnen gaan praten met onze stem en dat ze ook gaan terugpraten en dat ze dingen kunnen doen. Runway gaan we het over hebben. Een bedrijf wat normaal gesproken alleen maar mooie video's maakt, maar nu ook in de robotica terechtkomt. En zoekt Microsoft ruzie met Open AI met de lancering van hun laatste modellen die niet door open gemaakt zijn, maar door Microsoft zelf. Wat zegt dit over de relatie tussen Sam Altman en de baas van Microsoft? Blijf luisteren. Dit is AI Report. [Applaus] [Muziek] Weet je dat ik me af en toe afvraag waarom ik nog voor Cloud betaal? Dit was altijd mijn lievelingsmodel. Ik deed alles met Claud. Dat is mijn vriend. En sinds GPT5 uit is en sinds Anthropic, mijn lievelingsmodel, Cloud 3.7 Zonit heeft gekilld zonder ritueel afscheid, eh denk ik. Ik ik merk dat ik het gewoon eigenlijk heel weinig wou en ik programmeer niet. Voor sommige mensen zal CL code nog de belangrijke reden zijn om te gebruiken. Maar ik vraag me opeens af: "Waarom heb ik nog cloudwitsen?" Ik vind dit nogal een moment. Ja, we gingen altijd naar cloud, want ik toen jij het eh nu net zei, zat ik ook te denken: "Waarom ga ik eigenlijk veel minder vaak naar Antropic?" Dat gewoon in dat was eigenlijk mijn standaard eh ding geworden. Ja, voor mij ook. Als mensen Ja, als het wat dan chat heet wastropic eigenlijk met cloud. Precies. Ja, ik denk ook omdat GPT5 eigenlijk oké genoeg is qua schrijven ook niet. Dus ja, dat is wel tricky, want ik bedoel, ik gebruik die modellen in allerlei andere tools, dus dat is een kwestie van switchen. Maar de echte webinface van Antropic, dat bruine ding van hun zeg maar, die zie ik gewoon in hun week nu steeds minder. En dat is eigenlijk heel geleidelijk gegaan. Ja. Ja, ik denk omdat ik intuïtief daar niet meer naartoe hoef. Ja, dat is best wel gek eigenlijk. Nou, en open schrijft ook gewoon die of eigenlijk de vier, hoe zeg je dat nu? De 4.1 modellen. Ze schrijven gewoon veel minder goed in mijn voor mijn gevoel. Als ze de 3.7 nog aan je aan zouden bieden, dan zou je misschien nog twijfelen om heen en weer te klikken. Ja, misschien. Maar dan zou ik ook wel weer geërgerd raken door het feit dat hij niet zo slim is als wat ik inmiddels verwacht van een van een taalmodel. Ja, het kan ook zijn dat jij nu een soort vertekende herinnering hebt aan jouw oude vriend, hè? Ja, ik mythologiseer nu eh 3.7 sonnets. Dat zou heel goed kunnen. Ik droom er nog wel eens over. Dan denk ik was hij er nog maar mijn vriend, maar hij is overleden. Is hij wel beschikbaar via de EPI? Eh goede vraag. Bij elkaar kunnen hacken? Ja, dan goede vraag. Dat moeten we even gaan checken, want 3.5 is dus wel nog beschikbaar in de interface ook. Waarom ze die dan hebben gekozen als baseline? Want je kunt dat is nog één van hun oude modellen om een soort tegemoet te komen aan die mensen met dat eh nostalgische gevoel. Nou, misschien moet ik daar maar met mijn mijn vriendje dan maar gaan praten en daar eh enige soas in vinden. Oké. Ehm er was deze week een grote nieuwe studie van Stanford waarin werd aangetoond dat jonge werkzoekende nu wel echt eerst als eerste de pineut zijn eh door AI. Het onderzoek analyseerde miljoenen loonstrookjes tot juli 2025 en de onderzoekers keken per leeftijdsgroep en beroep over het effect van AI op eh werk. En het resultaat was best wel schokkend. Namelijk sinds de brede adoptie van Generatieve AI eind 222 aka de introductie van chatpt zagen eh banen in de categorie van 22 tot 25 jaar in AI gevoelige beroepen eh een 13% daling in werkgelegenheid. Dat hebben ze proberen te verklaren door allerlei dingen die tussendoor gebeurd zijn, zoals thuiswerken, covid, allerlei dingen natuurlijk in de tussentijd gebeurd. Eh maar dat was allemaal zij kregen dat niet dus zij kregen die daling niet verklaard door dat soort omstandigheden. En AI leek dan als ehm ja leek lijk de boosdoener. In minder AI gevoelige sectoren dan noemen ze zorgondersteuning bijvoorbeeld tegen juist het aantal banen. En bij oudere werknemers is er nauwelijks verschil zichtbaar. Maar jonge werknemers die kennis uit boeken eh en documentatie halen, maar niet jarenlange praktijkervaring hebben die oude werknemers wel waardevol maakt, zijn de pineut met dus een daling van 13%. en de onderzoekers adviseren we dat beleidskeuzes nodig zijn rondom onderwijs en ehm ja, startersbanen hoe we dat gaan vormgeven. Ik ben benieuwd of we meer eh van dit soort onderzoeken eh die onderzoeken zullen zeker komen, maar die ook iets significants laten zien in al die data. Omdat het voelt ook wel alsof er best wel een delay op zit, hè. Ik bedoel, anekdotes zijn niet wetenschappelijk, daarom doen we die onderzoeken. Maar ik spreek in wandelgangen ook allerlei mensen en daar hoor ik wel over. Ja, dat de IT-opleidingen minder aanmeldingen zien dit jaar en dat het best wel eh ja, junior programmeurs minder aangenomen worden bij IT partijen, hè. Dus er is best wel wat daar zit wel een soort, laat ik zo zeggen, er is daar een reactie. Hm hm. Of dat een korte termijn ding is, hè, uit een soort schrik moeten we nog maar zien. Maar er zijn wel wat tekenen om mij heen. Alleen echt hele goede onderzoeken vinden waarin duidelijk eh naar voren komt dit is het effect van AI op de arbeidsmarkt. Nog niet heel denderend. Het is een beetje bij elkaar sprokkelen van dit soort databronnen en ze spreken elkaar soms ook tegen. Maar het is niet het enige rapport wat uit is gekomen wat eh jongen eh waar wat de focus ligt op startersbanen. Oké. Eh dus daar dacht ik toch moet dat even noemen. Ehm daarnaast was er nog een tweede artikel deze week dat stond in het FD en die krant maakte een rondgang langs grote advocatenkantoren op de Zuidas. En daaruit blijkt dat de instroom van junioren de komende jaren waarschijnlijk zal gaan afnemen omdat veel van hun werkzaamheden door AI worden overgenomen. AK hetzelfde verhaal als wat we net hoorden. Ja, voor de duidelijkheid die instroom is dus aan de beperkende kant van de actor of de kantoren. Ja. Hè, het is niet omdat die instroom beperkt wordt door de door het aanbod. Nee, nee, nee, nee. De vraag neemt af. De vraag neemt af. dicht. Die kantoren zeggen: "Wij gaan minder mensen aannemen." Eh junioren, juist het eenvoudige repetatieve werk is essentieel om het vak in de praktijk te leren, stelt de krant. En het is zorgelijk, zegt één van die grote kantoren in het FD: "We verwachten dat de impact van AI op junioren op korte termijn heel groot zal zijn." Bedrijven kiezen er steeds vaker voor om problemen waarvoor ze normaal een junior zouden inhuren zelf op te lossen met AI tools. Dus de klanten van die advocatenkantoren gaan zelf [&nbsp;__&nbsp;] fixen met GPT5 stel ik me zo voor in plaats van dat ze de bruilen. Experts zien deze ontwikkeling als een groot probleem voor de opleiding van jongetje uristen omdat zij de noodzakelijke vlieguren niet meer kunnen maken die onmisbaar zijn om het vak onder de knie krijg te krijgen. Wat is dan de situatie? In het buitenland zien we dat kantoren het risico opvangen met virtual learning programma's. Ha je vastwitsen. Daarin oefenen jonge advocaten met realistische gesimuleerde zaken. Soms met en soms zonder AI ondersteuning. En zo kan AI juist helpen met het gat eh wat in de opleiding als praktijk ervaring eh wordt geopend. Ik zat dit te lezen. Nou, er gebeurt een hoop tegelijkertijd, want dit zijn natuurlijk kantoren die eigenlijk zeggen: "In de toekomst verwachten we minder junioren te gaan eh ophalen." Nou, of aannemen. Dat is een signaal om serieus te nemen als die kantoren dat zeggen. Maar ik denk ook, is dit nu al niet het geval dan? En ik heb ook veel eh start-up vrienden die zeggen dat het verschil zo groot is tussen Amsterdamse advocatenkantoren of Nederlandse advocatenkantoren waarbij amper AI wordt gebruikt. Dit is dit is anekdotisch hoor wat ik nu vertel. En dat het juist zo opvalt als Amerikaanse advocaten die dan de fundraising helpen of wat dan ook voor ehm specialistische dingen voor Amerikaanse situaties dat die juist heel zichtbaar wel AI gebruiken en dat echt zien als een fundamenteel deel van hun ehm ja ding wat ze aanbieden. Dat vond ik een opvallend verschil. En ik vond deze reactie namelijk dat je met gesimuleerde eh ja, gesimuleerde zaken eigenlijk dat je een soort van een medewerker in een AI simulator zet om dan een senior ervan te maken met het idee dat senioradvocaten straks wel nog een baan hebben. Ik weet niet, men ik weet niet zo goed wat ik daarvan moet denken. Ergens voelt het een beetje vreemd, toch? Ja, dat is een beetje vreemd. Dat is natuurlijk heel vreemd, want als ik het goed begrijp is je heb je dus een is deze techniek in 2 jaar zo ontwikkeld dat junioren straks minder snel er binnenkomen bij die bedrijven. En staat in hetzelfde artikel dat senioradvocaten nauwelijks niet vrezen dat eh kunstmatige intelligentie hun baan overneemt. Terwijl die nieuwe mensen die binnenkomen, die gaan dan nu in een simulator zitten. Zo stel ik me dat dan even voor. En dan zijn ze opeens senior geworden. Denken zij nou echt dat de senioren dan niet daarna aan de beurt zijn als die als de technologie doorontwikkelt blijkbaar. Ja, goed. Daar zit natuurlijk een soort eh aanname van een bepaalde eh ja barrière die niet doorbroken gaat worden op de korte termijn. Een unieke eigenschap of eigenschappen bij een groep mensen die zeggen wij niet, want wij kunnen x, y en z. Ja. Maar als je dan helemaal gaat uit specificeren wat X, Y en Z is en hoe die barrière dan opgebouwd is, dan wordt het vaak wel een beetje een spannend gesprek omdat heel veel werk uiteindelijk toch informatiewerken is. Input, output, vervormen, omvormen en doorsturen zeg maar. En dus ik tegelijkertijd kan ik me voorstellen dat er een bepaalde natuurlijk fysieke aanwezigheid is, hè. We hebben een hele aflevering over arbeid opgenomen waar je een soort ehm veilige ruimte hebt in de fysieke, hè, de premium reality zoals het dan genoemd wordt, hè. Dus als jouw rol ergens in een rechtszaal eh of op een bepaalde manier doet doet dat jij mens bent, dan is als senior ben je wel oké. Alleen zang een rechter nog eh eh overtuigd moet worden met argumenten. Flits flitsrecht krijgen met agents. Maar goed, dan werkt dat allemaal niet meer. Maar ik vind eigenlijk aan dat trainingsverhaal sowieso vind ik het wel boeiend eh hoe los je dan die soort van junior senior gap op, hè? Want daar praten we nu eigenlijk over. Als de junioren vroeger een senior werden door de door de rotklusjes te doen ook om vlieguren te maken om vervolgens op te groeien hè. Dus eh net als in de in de luchtvaart dat je de stad naar stad kleine vluchtjes in kleine private jets doet en dan pas daarna overstapt denk ik trouwens. Dat weet ik helemaal niet maar ik kan me zo voorstellen dat het hier is. Nee, we automatiseren eigenlijk al die eh dat werk wat we minder prettig vinden weg. Wat het werk was wat je ook kon gebruiken om op te trainen, zeg maar als mens. Ja. Ehm en daarom moeten we simulators gaan bouwen. In eerste instantie toen ik jouw verhaal dacht ik wat dubbel, want dan ben je dus aan de ene kant AI aan het inzetten en daarmee dus ook de GPU's en de computertijd om studenten een nepwereld voor te schoten, zodat ze kunnen oefenen. En aan de andere kant ben je diezelfde GPU's aan het inzetten om die taken te doen die je die studenten ook had kunnen geven om te oefenen. Toen dacht ik alleen wel van waarschijnlijk kan je die taakjes die studenten normaal doen of eh de stagiair slash junioren eh die gaan natuurlijk veel sneller. eh dan dat ze zouden gaan als jij die taak aan een junior geeft. Wat je ook nog die junior moet begeleiden, terugsturen, het klopt niet. Daar zit het leerproces. Terwijl als je natuurlijk een legertje van een swarm van agents hebt en dan eind van de dag heb jij alsof eh 100 junioren 100 keer zo snel zonder fouten jouw werk hebben gedaan, daar zit het hem denk ik in. Dat het toch wel logisch is om AI in te zetten in een soort simulatieomgeving. Maar wat zei je? Kijk, ergens moet ik dus een beetje om lachen denk ik. Wat is dit voor naïef? Wat wat wat een na Ja, voor die senioren bedoel jij. Ja, wat een naïef eh gedoe is dit. En die mensen weten niet wat er wat er op ze afkomt daar op de zuid als dat is een deel van mij denkt dat en een ander deel van mij denkt: "Ja, je zal er maar zitten en een partner zijn bij dat bedrijf en nu beslissingen nemen over hoe je in godsnaam met deze storm omgaat." Ja, wat ga je anders doen dan dan als je dan zegt van nou oké kosten besparen en dan maar mensen in de simulator stoppen. Wat is het alternatief? Ik weet voor de korte termijn. Nee, we gaan sowieso natuurlijk nu allemaal van die soort vreemde tussenoplossingen krijgen. Rare maffe tijdelijke situaties die als we er nu al naar kijken raar zijn. Ja. Eh goed, wij hebben het al eerder over gehad. Als je de lang lange termijn gaat pakken wordt het natuurlijk alleen maar een gekker verhaal met hoe Ja, maar zelfs binnen nu een vi jaar denk ik is het een interessante Ja. Ja. Ja. Ja, zeker. Ja, je kan maar een rechtopleiding doen nu. Ja. Maar goed, en dat dat dit geldt natuurlijk voor veel meer vakgebieden hè, want en ik zit ook te denken of die die simulator zou je natuurlijk op veel meer plekken ook in kunnen zetten. Het is een metafor voor en dit zijn duur betaalde uren, dus die kop gaat er al eerste af en dan zullen ze langzaam gaan doorwerken naar minder duurbetaalde uren, dus andere beroepen. Maar advocaten zijn dan een prettig startpunt. Ja. En ik denk dat zit eigenlijk ook nog een beetje in jouw vraag. Eh als jij een junior bent die is klaargestoomd door middel van een simulatie, een simulatie die veel breder is en veel meer veel mooier kan zijn. Mooier als in rijker. Hm hm. Dan waar je eh met rijk bedoel ik er zitten de grootste edge cases ingebakken. Dat is in een vliegsimulator. Ja. Je zou het bijna echter kunnen maken dan het dan het origineel. Ja. Statistisch zou je kunnen zeggen als jij een klassieke junior eh senior avontuur beleeft, dan heb jij een kans van 3% om een zaak mee te maken die Europees recht benoemt, whatever. En nu zet je gewoon die schuiv omhoog en dan zeg je: "Nou, klap er maar even zo'n moeilijke zaak in in die simulatie." Dus er is natuurlijk ook een kans dat de nieuwe senioren die ontstaan zijn door middel van simulatie uiteindelijk ook sterkere collega's zijn. Kan je eh in het taalmodel in je hoofd de contrace case genereren? De hoe de contracase? Dat het wel meevalt. Ja, soms denk ik wij zitten hier met zijn twee maar een beetje te oude [&nbsp;__&nbsp;] z van ja geen baan meer op de zuidas over een paar jaar. Ze hebben het nog niet door, maar het komt eraan hoor. Wat is de wat is als er hier een derde lalm bij aanwezig zit en die heeft al systeemp me ga er tegen taalmodellen te simuleren. Ja, heel graag. Ehm nou, ik denk dat wat ik veel terugkrijg als ik het hier met mensen over heb na lezingen en dan ga even discussiëren, want dit krijg je altijd ongeveer dit gesprek hè, van we merken al dat we minder junioren aannemen. Hoe komen dan nog aan senioren? Hoe zit het eigenlijk met onszelf? Dat kwartje begint langzaam wel een beetje te vallen. Ehm er is zo iets als tas knowledge. Dus dat is de kennis die niet op papier staat. Dat is de kennis die niet opgenomen wordt, hè. De Wij hebben wel het grapje gemaakt, misschien moet dan straks iedereen met een plate, zo'n kleine recorder of een watch met altijd een eh microfoontje gaan rondlopen om alsnog die hele eh eh kennis die niet eh papier is of eh het bits en bites op te zuigen uit zo'n organisatie, hè. Dus ook de gesprekken bij de watercooler in de auto naar een afspraak. De vergelijking met dit eh met deze podcast is ik lees een artikel ergens over, dan vervolgens praten wij misschien over het artikel buiten de opname om en dan vervolgens hebben we een gesprek in de opname. Dat gesprek buiten de opname nemen wij niet op en daardoor kan die AI niet A naar B krijgen. Dat is wel degelijk nog relevante context voor de dingen. De meeste mensen nemen dat nu niet op. Dus daar kan die AI zich niet op baseren. Ja, precies. En eigenlijk alle modellen die we nu hebben, als het dan even om taalmodellen gaat, zijn taalmodellen getraind op alles wat we daadwerkelijk vastgelegd hebben. Dat is natuurlijk ergens denk je wat je zegt bijna niks nu, maar dat is toch wel heel erg een relevant inzicht, want er wordt zoveel niet vastgelegd. Ja, ik ben dus echt begonnen met alles vastleggen voor jouzelf. Ja, omdat je dit door hebt van ik heb een mijn papier realiteit. iken heb gewoon eh brainstorms en eh en meetings. Ik ben echt een punt van aan het maken om alle gesprekken die ik heb voor mijn werk dan hè even laten we wel wezen niet dat je nu denkt eh wat gebeurt er allemaal thuis maar eh je houdt weinig vrienden over zeg. Ja, precies. Maar op werk ben ik alles aan het opnemen omdat ik gewoon ervanuit ga dat dit dit gaat mijn dat gaat die suggesties van dat ding beter maken op een gegeven moment. Ja. Ja, en ik kan me dus voorstellen dat die move die jij nu maakt dat bedrijven die dan ook steeds meer gaan doen. Eh ehm eh ja, hopelijk op een beetje een ethische manier, want alle alle personeel iets eh natuurlijk, ik doe mijn best, ik hoop het. Eh maar dat je uiteindelijk eh zo is dat er heel veel aanwezig is waar we achter gaan komen. Er zit een beetje misschien de soort eh als ik dan het eh een soort van eh advocaat van de duivel eh mag steel mannen denk ik dat we nog moeten gaan zien. En daar kan je best wel wat hoop op vestigen, denk ik, als jij nu senior bent. Hm hm. Eh hoeveel er gevangen kan worden in die modellen, zelfs als we meer microfoontjes plaatsen en meer e-mailtjes inlezen zeg maar. Eh en wat er toch nog allemaal gebeurt tussen mensen en aan intuïtie plaatsvindt. Er vanuitgaande dat die modellen dan ook niet stiekem iedere 18 maanden beter worden. Was het bijna nog een positief verhaal. Wist hij toch nog een eh staartje eraan te Nou ja, goed. Oké, we gaan door. Opener. Ja, lanceerde GPT Real Time, een speech to speech model. Toen moest ik even achter mijn oren krabben. Toen dacht ik: "Wat the [&nbsp;__&nbsp;] is dit nou weer?" Wat is een speech to speech model iets? Nou, die haalt eigenlijk eh de tussenstapjes ertussenuit. Dus het is gewoon prettig dat je niet door al die modaliteiten hoeft. Dus anders ga je van speech naar tekst en dan ga je weer tekst genereren en dan moet je weer speech genereren. Dit moet je even beter uitleggen. Dit snap ik niet. Nou, als jij nu eh met een gemiddelde app praat, bijvoorbeeld die van eh Mistral Lechat, dan eh ik heb echt nog nooit gedaan. Moet ik dat doen? Ja, absoluut. Ja, zij draaien op grok met een Q is best wel prettig, want die antwoorden komen gewoon met A4 binnen. Dat is echt eng. Gewoon bam bam bam. Ik denk iedere keer dat die appstuk is. Ja, dit is oké. Dit is mijn mijn mijn wekelijkse herinnering om Leut te installeren, maar oké. Ja. Ja. Eh en eh moet je wel betalen hè, anders krijg je niet die instant feature natuurlijk. Ehm prima. Ik heb Claot toch al opgezegd, maar je gaat je gaat dan precies stap even over naar een nieuwe vriend, een kat. Een Europese vriend. Neem een kat. En dan ga je eh ga je eh ga je kletsen en dan wordt die audio teruggebracht naar tekst. En die tekst gaat weer een taalmodel in en die geeft dan weer tekst terug en die moet dan weer van een tekst naar speechmodel. En zo heb je een soort pipeline van allerlei stukjes die met elkaar moeten samenwerken. Dus is het verschil tussen als ik in chat GPT dat microfoonicoontje gebruik, dan schrijft hij het op in tekst en komt het in het chatfenster terecht. of dat ik advanced voice mode gebruik en ik zie die die soort van blauwe blop eh mee bewegen als ik praat dat die gelijk antwoord geeft. Dan wordt hij niet geconverteerd naar tekst voordat hij antwoord geeft. Ja. En dit merk je in ieder geval als het goed is heb je dit gemerkt. Ja. Want die is aan de ene kant snel maar die heeft dan wel zwaar moeten inleveren op intelligentie helaas. Juist. Juist hè. Want om die modellen vlot te kunnen draaien zijn het vaak kleinere modellen. En dit zijn modellen die eh ook audio in zich meedragen en in audio fonetische tokens kunnen reageren, namelijk hè van geluid naar geluid. Eh en dat heeft nadelen. Maar wat is er dan nieuw nu? Nou, dat het eh eigenlijk Open en jij gelukt is om ze hebben natuurlijk ook gemerkt dat die eh advanced voice mode, daar worden mensen wel blij van, want het is best wel een bizarre manier om met AI te interacteren. Zeker als je gaat zeggen: "Lees een kinderverhaal voor. Doe een scheepskapitein na." Nou ja, we hebben allerlei leuke testjes gedaan eh een aantal maanden geleden, maar als je dan zegt: "Lees even deze PDF door van mijn werk en trouwens roep even die en die API aan via een MCP calling." Nee, want het is eigenlijk een soort van een paar stappen terug in de tijd. Ja. Hè, er zijn een hoop offers gebracht om te zorgen dat die eh latency die reacties zo ontzettend laag is. Ja, maar zij merken natuurlijk ook dat het gebruik daarvan best wel hoog is. Dat mensen het gaaf vinden dat het wordt gewaardeerd. En dan is het ook nog eens zo dat ontwikkelaars het willen kunnen gebruiken. Die zeggen: "Ja, eh jullie hebben Advance Voice Mode in jullie mobiele app zitten onder andere, maar wij willen dit ook als ontwikkelaars in onze apps stoppen, hè." Ja. Zodat je bijna een soort assistent, een spraakassistent in een app kan integreren. Ik zag voorbeelden op de site van Open AI waar ze ja, bijna een soort van Sirichtige blop rechtsboven in beeld op de Amerikaanse funda hadden geplakt. En dan zag je een kaart van Manhattan met daarop alle huizen die beschikbaar waren op de Amerikaanse funda. En dan stelde die meneer een vraag in de trand van ik wil iets doe me een huis met uitzicht op het water en met meer dan eh bla en met een eh nou nog een raar verzoek erbij. En dan ging die stem zeggen: "Oké, nou dit ga ik voor je filteren." En dan zoomde die kaart zoom in en dus het was een combinatie van beeld en audio eh met die snelheid en die persoonlijkheid snelheid. Ja, want ik dat en dat kan dus nu omdat één van de dingen hè, dus tool calling wat eigenlijk inhoudt dat je API/MCP achtige bruggen kan bouwen naar andere diensten waaronder eh de kaart kan laten bewegen, want er is kennis van een kaart. Dit konden we al, maar we konden niet nou ja, noem ik wou het bijna de holy grill noemen, maar dat is een beetje overdreven. Maar het zou toch zo gaaf zijn als je en die low latency interactie hebt met een stem die heel erg overtuigend is, maar ook al die voordelen die inmiddels in die niet speech modellen zitten. Ja. Zoals dat hij een actie kan uitvoeren op je scherm. Exact. En dit is eigenlijk nu en is advance mode eh voice mode eh ja geüpdate en eh ontwikkelaars kunnen ermee werken. Dat konden we al, maar was meer een beetje een demo modus en de meeste ontwikkelaars zeiden al: "Ja, ik ben gewend dat ik als ik met taalmodellen praat veel meer kan." Hm. Eh dus ik kan nu niet jouw advanced voice mode even in mijn app zetten. Ja, daarom zit het ook nergens in denk ik. Nee, want het is eigenlijk je hebt er niet zoveel aan. Want het enige wat je dan zou krijgen is ja, een scheepskapitein in de Funda app. Het schiet niet op, zeg maar. En denk je dat het nu wel gaat gebeuren? Dat alle apps waar je op é of andere manier filtering hebt, want dat is natuurlijk de dat is een heel aantrekkelijke use case, dat je in de Airbnb app hoef je dan niet te zeggen: "Nou, appartement, vier personen, wc, we zijn heel erg gewend om lijstjes af te werken als we naar dingen zoeken." Denk je, denk je dat we nu gaan zien dat je in dat soort apps en dat zijn er heel veel van Marktplaats tot eh nou ja eh noem maar op, denk je dat dat die functie snel ingebouwd gaat worden? dat je ja, er zitten een aantal aannames in, want sowieso het idee willen mensen praten met apparaten. Dat is ook nog cultureel afhankelijk. Eh ik vast wel ergens op de wereld. Ik zelf denk steeds dat ik dat wil, maar dan doe ik dat niet. Ik bedoel, ik doe wel transcriberen en soms een uur praten in een memo recorder en dat samenvatten. Dat is echt wel een killer use case voor wat we nu allemaal kunnen. Maar ik heb mezelf nog weinig achter een computer zien zitten en praten en ga maar doen ofzo. Dat voelt dat is niet mijn interface merk ik. Maar misschien omdat hij nog niet zo goed is. Ja, het is grappig, want misschien is mijn voorbeeld eigenlijk ook niet goed dat ik zeg doe mij een Stel je nou voor thuisbezorgd, de thuisbezorgd app. Hoe vaak denk je wel niet: "Ik heb zin in een taco, maar hij moet wel vega zijn." Eh en dat je geen zin hebt om van om dan die die ehm eh die zoek die zoekbalkjes, die filters zou instellen, dan krijg je een bak met restaurants. Terwijl wat je misschien wel wil is een ja, door AI samengesteld lijstje van alle ehm ja, alle dingen die niet per se aan zo'n filter voldoen. Die die meer fine grained is, zal ik maar zeggen. Dus ik zoek altijd Airbnb, zoek altijd vakantiehuisje met een trampoline. Vind ik fijn. Slim. Dat is een lekkere. Dan klik je meteen 1000 dingen weg, toch? Ja. Ja. Ja. En ehm eh dat is dat is geen standaard vinkje. En dat is wel iets wat ik zou willen. En met spraak heb je dus de vrijheid om dat te doen. Wat ik niet geloof is dat mensen zelf gaan typen. Dus ik geloof niet dat er een soort chatpotachtig Nee, dat voelt als gedoe. Maar voor dat soort specifieke requests als ze maar gewend gaan raken aan het feit dat wij heel fijnmazig eigenlijk verzoeken kunnen doen aan apps die feitelijk gewoon lijstjes zijn. Ja, dan ik vind spraken opeens best een logische manier om het te verzoeken aan dat ding. Ja, ik denk ook omdat als je een operator zou bellen, een mens die voor jou achter een computer zit, dan is dat op zich een prima interactie, hè. Dus die persoon gaat voor jou rondklikken. Is ook nog eens iemand die al vier jaar in dat systeem werkt, hè. Stel van eh ik heb wel eens eh moest ik met de of moest ik wilde graag met de boot eh ergens in Zweden en dan moest je die ticket voor die boot moest je een beetje bellen gewoon naar een soort agency. Dat was gewoon hoe het was toen. En dan bel ik en dan hoorde ik op de achtergrond klik klak klik iemand die gaat over een toetsenbord heen mega snel. Ja, zit helag datelfde te doen. En dan toen dacht ik: "Oh, mijn soort van fuzy input hè, wat diealmodellen zo lekker kunnen." En een soort van en dan ook nog een persoon aan de andere kant die al zoveel requests heeft gehad dat zelfs al vertel jij het in de verkeerde volgorde met allemaal rare en jij laat hij weet hoe je dat moet invoeren en je laat even vallen. Ik heb kinderen, dan wordt er meteen nog een kajuitje bij geregeld. Ju n al die en ik denk dat dus eh soort van eh eh chaotische fusie menselijke input omzetten in wat eigenlijk die software van jou verwacht. Dat ben ik met je eens. Eh dus kan ik me voorstellen dat tegen grote interfaces waar je anders op 20 vinkjes moet klikken, je op een gegeven moment cognitief de keuze maakt. Denkt ik zou het eigenlijk liever zeggen als het kon dat je dat gaat doen, geloof ik. Ik zat alleen dan nog technisch te denken: de plek eh voor die voice agent daar? Omdat ik ehm lokaal even los nog van privacy, lokaal heeft low latency hè, dus als het lokaal omgezet wordt op jouw toestel, daarom doet Google dat bijvoorbeeld ook. Die houden van data, maar die doen ook heel veel lokaal, want dan is het gewoon veel sneller. dat ik persoonlijk het heel gaaf zou vinden als in mijn Android/ios toestel een agent zit die met mij praat in Safari en Chrome mag meekijken en daar dan even en in de thuisbezorgd app ook even alle dingen aanklikt voor mij dat ik eigenlijk gewoon Siri maar dan goed. Ja. En dit ding begrijpt ook plaatjes hè, dus dat zit in het model. Ja, daarom. Dus het kan en en misschien is jouw punt, want ik wilde mijn punt was dus moet je dit als ontwikkelaar nou inbouwen of mag je ervuitgaan dat je ondersteuning kan bieden voor de agent van Apple of Google. Dat ik me ook kan voorstellen dat thuisbezorg zegt: "Nee, wij willen graag een eigen agent, want die gaan we helemaal fijn tunen op dat zie je ook eh je ziet openheid dat stimuleren dat mensen niet het OS eh systeem gebruiken, maar dat Nee, goed. Open jij vindt dat natuurlijk prettig, hè, laat dat duidelijk zijn." Maar het is ook prettig omdat je dan vanuit thuisbezorg misschien gaan ze met een stemacteur werken en is degene die de reclamespotjes van thuis doet ook wel die stemry doet alles dat dat soort van idee van verschillende kwaliteiten in je stem dat hebben ze in ieder geval ingebouwd. Er stond een demonstratie op de website waarbij ze ding verschillende emoties meegeven. Luister even mee. Yes, I can hear you clearly. How can I help you today? I want you to tell me a story about a lost roba in five sentences. And I want you to use different emotions for each sentence in this order. First fear, then sadness, then curiosity, then joy, and finally excitement. Go ahead. Oh no, the little robot wandered into the dark forest trembling. It sat down. Circuit wimpering, feeling so alone and forgotten. But wait, what's that strange glow over there in the bushes? Nou, zo gaat dat nog even door. Ik vind het ook wel grappig dat we het ook heel casual vinden dat het verhaal ook even bedacht wordt. Snap je? Maar goed, snap je de inhoud los van de vorm. We're becoming jaded man. Het Amerikaanse Runway is vooral bekend om haar videogeneratiemodellen Runway ML waarmee eh ja, dat was toch al een tijd lang waren dat de coolste video's en nog ja, voor Vio was dit waar we allemaal naar keken. Ja, maar goed, nog steeds doen ze komen ze steeds snel uit met nieuwe nieuwe dingen. Interessant bedrijf. Maar ze gaan nu achter een nieuwe markt aan die op het eerste gezicht heel vreemd lijkt, maar die bij even iets meer nadenken toch eigenlijk best logisch is. Namelijk robotica. Eh ze krijgen inkomsten inkomende belangstelling van robotica zelfrijde autobedrijven om world models als simulatieomgeving te gebruiken. Wie ze legt het even uit aan de mensen. Ja. Nou de sprong runway oftewel tekst naar video, wat we nu kennen als Vio 2 en 3 van Deep Mind. Ehm Google. Ja. Eh in ieder geval en als ik dan zeg kennen, die lopen een beetje voorop nu. Ik volg Runway ook nog. Die zijn nu aan het specialiseren dus hè. Want je moeten natuurlijk Ja de investeerders in Runway zullen we ook wel vragen. Ja. Ja, wij zien ook die videoilmpjes. Wat gaan wij hier dan nog mee runway doen? Want dat is Google jongens hè. Dat is best wel een eh flinke en ze heel veel concurrentie van Chinese videogeneratiebedrijven. Ja, natuurlijk. Eh kling enzo wat allemaal langskomt. Dus er is dit ook daar bloeit nu een hele markt op van allerlei eh initiatieven. En dan moet je natuurlijk gaan zoeken oké waar zit ook geld? Want er moet een soort return on investment komen. Dus kunnen wij ons gaan specialiseren. En de CEO van Rumway die zei een interview eh ook al hebben wij dit nooit in ons pitch gehad destijds hè, want wij gingen natuurlijk geld ophalen in rondes. Daar stond niet in robotics. Nee. Dat hij dat toch even uit wilde leggen van nou, we zijn serieuze gesprekken aan het voeren met partijen die eigenlijk naar ons toe zijn gekomen. Wij hebben ze nog niet eens benaderd eh van dus het is een eh ze worden er naartoe getrokken zeg maar. Die zeggen: "Ja, wij hebben best wel wat hiaten in onze trainingsdata zitten hè. Als het dan om zelfrijende auto's gaat of fabriekbog. Precies. Wat voor bedrijven zijn dat dan? Ja, dat zijn eigenlijk eh bedrijven die apparaten hebben die in ruimtes rondlopen waarin eh veilig gehandeld moet worden of eh eh je apparaten moet kunnen gebruiken. En we hebben dus humanid robots en zelfrijende auto's. Zijn nog andere dingen denkbaar? Nee, ik zou niet Oké, dat zijn de twee categorieën. Gewoon generalistische Absoluut robots. Ja. Waar die eigenlijk het liefst eh de hele wereld hebben gezien en alles wat daarin gebeurt, hè. Dus daar heb je een wereld voor nodig. Dan krijg je eigenlijk de zogenaamde zogenoemde world models hè, wat eigenlijk Vio ook doet. En nu eh genie, het live dromen waar we het eerder over hebben gehad hè, dat je ook nog kan bewegen door die video's van Google. Wat maakt dan zo'n videogenatiemodel als eh Vio 3 een world model? Dat je Waarom is dat niet gewoon er heeft heel veel YouTube gekeken. Mo mooi. Je zou ook eigenlijk kunnen zeggen is het die zijn klopt dat label nu al? Want het idee van World Models is er namelijk een model waarin je de wereld kunt simuleren tot in detail. Dus het heeft te maken dat als er een glas water omvalt op een bepaald stuk textiel bij een bepaalde temperatuur en er zit bijvoorbeeld ook nog eens chocomel in. Dat doet ook weer iets met de eh vloeibaarheid van kan ik je vertellen, want ik heb heel wat chocomel omgegooid in mijn leven. Dat dat dan als dat omvalt dat en je zou het daarnaast nog een keer doen in het echt dat dat dan in de buurt komt van elkaar. genoeg in de buurt dat je er wat aan hebt. Het hoeft niet perfect te zijn, maar je moet er wat aan hebben. Nou, je kan je voorstellen en zo niet, ga er nog even goed over nadenken. Een glas chocomel opgooien op een bepaalde ondergrond waar dan ook nog textiel in zit. Want hier ligt een matje voor me waar ik nu naar zit te kijken. Dat is best wel een moeilijke. Da zit best wel wat natuur Ja, daar moet je de wereld voor begrijpen om om dan een realistische weergave te schetsen. Ja. En dan eh dan moet je dus gaan voorspellen eigenlijk wat daar gebeurt. Nou en dan blijkt eigenlijk zeg maar het is het Carl Segan heeft ooit gezegd om het om een appeltaart te maken moet je het hele universum hebben. Want die appeltaart impliceert zeg maar een appel een appelboom, grond, water, voor het weten heb je de hele aarde moeten maken om tot die appeltaart te komen hè. Dus eh die kan je niet maken in een vacuü. Dus om daarom is ook vermazen mensen zich wel eens ik ben dan best wel enthousiast of verbaasd of bezorgd over video's die uit zo'n videomodel kunnen ook komen. Ook bij runway had ik dat destijds al omdat daar dan ineens een explosie was op de achtergrond of een auto rolde over de grond op é of andere rally trck met zand eromheen dat ik zat te kijken. Ik denk hoe weet dat ding dat allemaal? Ja. Hoe weet hij dat er zand moet meevliegen? Ja. En dat het dan daarheen vliegt. En ik bedoel zelfs als je dan vraagt zet de ventilator ernaast dan kan die nog daar effect op hebben enzo. Ja, want in het spelletje vinden we het heel normaal. Maar daar weten we dat mensen eindeloos hebben ze de klooi op al die ziet hebben moeten schrijven zelfs die routines. Ja. Van als er een auto uit de bocht vliegt dan vliegt hij zo en dan gaat het dan mee. En hier begrijpt dat ding dat gewoon. Ja, je zou het mooi kunnen vergelijken met de early AI zeg maar. Dus dat is eh hoe computers vroeger slim leken. Dat was dan rulebased AI. Dus het is eigenlijk voorgeprogrammeerd op basis van als je dit tegenkomt moet je dat zeggen. Hè, ik had bijvoorbeeld heel lang geleden een soort psycholoog op mijn computer in DOS nog. En die psycholoog dat die zei gewoon vooral terug wat je zelf zei. Dat was de regel. Leg gewoon een spiegel toe aan je cliënt zeg maar. En er stonden zoiets van het zal het zijn geweest misschien 100 routines in. En daar kon hij dan ook nog een beetje random doorheen. Ja, d is al heel lang geleden kon je het gevoel geven aan aan computergebruikers dat ze met iets slim zat praten. Ja, een soort gogeltruc. En dat dat viel dan door de mand en daarom konden die dingen ook de touring test nooit halen. Want uiteindelijk vielen ze toch op tijd door de mand. En als ze dan vallen was het echt gewoon ineens stond je achter de schermen en zag je alles zeg maar. Dat was niet best. Maar uiteindelijk wil je dus niet systemen die op regels gebaseerd zijn, maar die op statistieken gebaseerd zijn en dan heel veel statistieken kunnen herleiden eigenlijk in gewichten in zo'n model. En dan krijg je waar we vandaag zijn. Even heel cru. Ehm een wereldmodel dan zou je eigenlijk zeggen: "Ja, eh als je dan als je daar taal aan gaat vragen, kan die ook nog taal." Maar dat is dan een soort van submodaliteit in zo'n wereldmodel, hè. Dus wat we nu met taal bedoel ik tekst. Hm hm. Dus dan zou je bijvoorbeeld zeggen: "Oké, maak een video van iemand die nieuwe stukken Shakespeare Shakespeare aan schrijven is en zoom in op de pagina." Wat voor woorden komen daar dan te staan, hè? Nou, in een serieus goed wereldmodel staan daar ook nog eens goede zinnen. Ja. Hè? Kijk, nu zou je natuurlijk kunnen zeggen: "Laat dat wereld laat dat videomodel even op de achtergrond praten met een taalmodel. die fietsvlug even wat goede zinnen erin en die schrijft hij alsnog op dat papier hè van zo'n zo'n ensemble krijg je dan daar kan je stiekem al heel ver mee komen nu dat je ze allemaal combineert. Maar ja, een true world model zou in essentie een realiteitssimulator moeten zijn. En wat zegt het jou dat Runway wat toch best veel aandacht krijgt met haar videogeneratiemodellen nu deze specialisatie doet? Zegt dat iets over de wereld van videogeneratiemodellen en de de soort van dat het gebrek aan doelstellingen zoals we die oorspronkelijk verwachten, namelijk binnen entertainment of reclame, dat gewoon minder is dan verwacht of verzadigd. Of zegt dat vooral iets over robotica en andere autonome technologie? Eh toch beide. Kijk, cynisch zou ik zeggen runway heeft er wel een beetje een probleem, want ze waren heel erg verop in de markt. Heel lang. En Google is ingehaald Chinezen. Ja, ik wou zeggen er gebeurt nog veel meer wat je al zei. Dus dan moet je wel op een gegeven moment gaan uitleggen wat de de twe jaar roadmap van Runway is. Nou, als je die roadmap gaat tekenen en je ziet eigenlijk al dat Google expliciet zegt: "Wij zien VO als iets heel geschikt als world model potentieel en we gaan onze auto's misschien ook wel trainen met die precies. Oké, wij gaan er ook robots mee maken." Ja, het is al bekend. Nou, dan heb je daar ook weer antwoord op geven. En wat ik me wel kan voorstellen is, kijk, uiteindelijk hebben we gelukkig een een eh e een markt waarin allerlei spelers zijn over het algemeen binnen verschillende domeinen hè. Je hebt allemaal verschillende partijen die meedoen in de markt. Dus ik hoop eigenlijk dat Runway een manier vindt om om een soort ja, wat hè die mode, die slotgracht te graven rondom runway waardoor zij enig veiligheid hebben tegenover al het geweld wat nu eh op ze afkomt. We hebben natuurlijk allemaal nieuws van deze week, maar uiteindelijk wil je natuurlijk ook dingen horen over hoe AI in de praktijk wordt toegepast. En daarover praten Marian en Lucas van Dept je nu bij. Hi, hier Marketingen Tech Prodept. Elke week bespreken we hoe wij merk helpen in de wonderwereld van AI. En wist je dat het mogelijk is om AI in te zetten om je fotomodellen te genereren die vervolgens je producten op wel duizenden verschillende manieren kunnen laten zien? Wij hielpen Orium om hun kosten voor modelfotografie te verminderen met wel 40% en conversie met 15 tot 50% te verhogen. Alles met behulp van AI. Lucas, vertel. Yes. En dat is niet onbelangrijk, want de missie van oium is om dat alle kleren die gemaakt worden uiteindelijk ook iemand gedragen moeten worden. En dit doen ze door eh restpartij te verkopen van grote bekende fashion merken. Helaas hebben ze niet van ieder ontvangen ook fotografie op een model. En zoals jij net al aangaf is dit erg belangrijk, want de conversie stijgt daarmee eh aanzienlijk. Ehm door de kleine oplages die Otum aanbiedt eh is het echter niet rendabel om altijd ook deze fotografie zelf te verzorgen. Check. Maar gelukkig was daar AI to the rescue. Absoluut. Eh wat hebben we gedaan? We zijn samen met OD aan de slag gegaan om diverse groepen AI fashion models te ontwikkelen om modellen die dus allemaal eh inspelen op hun verschillende doelgroep. En daar hebben we heel veel tijd in gestopt om te zorgen dat die super consistent zijn. Want je wil ze gebruiken in duizenden assets met termijn 1000 verschillende item die ze aannemmen. Dat moet er altijd hetzelfde uitzien. Ja. Ehm toen dat eh eh gedaan was eh zijn we het proces opgestart en hoe dat werkt is we fotograferen we in de studio op een paspop. Die wordt vervolgens automatisch op een fashion model geplaatst waarbij we zorgen dat het helemaal in de juiste pasvorm is. Dat we weten zeker in e-commerce hoe belangrijk het is dat het item wat je thuis ontvangt ook echt zo staat als dat je op de video of de afbeelding hebt gezien. En eh als dat is gedaan kunnen we het renderen in naar een breed scala aan assets van video's eh die heel inspirationeel zijn ondergaande zon op een strand eh tot afbeeldingen eh of voor de product detailpagina waar mensen kunnen inzoomen op verschillende eh onderdelen van een item. Duidelijk. Dankjewel Lucas. Niet afwachten maar doen dus want wie vandaag begint loopt straks voorop. Wil jij weten hoe we jou kunnen helpen? Ga dan naar de.com/aai report. Tot volgende week. [Muziek] Nog twee dingen. Eh want er is er was gewoon deze week niet zo heel veel nieuws. Hij zitten te vringen hier. Hij zitten te vringen op. Nou ja, het is ook niet dat we het hoeven vol te maken hè. Dit uur het is een podcast. Nee, we zitten te vingen met een glimlach. Ja. Ja, en ik moet ook zeggen als je dan eenmaal gaat praten, dan blijf ik ook gewoon luisteren. Zo is het ook wel weer. Maar de er zijn nog twee dingen waar van tevoren in ieder geval bedacht hebben dat we erover wilde hebben. Laat ik het dan zo zeggen, want ik weet ook kan uit de hand lopen. Eh is dat Open een acquisitie heeft gedaan die jij opvallend vond. Ik moet zeggen, ik las het bericht en ik dacht who cares? Maar er is een overname gedaan van een of andere analytics en eh experimentatieplatform. Een AB test service. [&nbsp;__&nbsp;] saai. Maar wat voor 1.1 miljard gekocht is door Open AI toch ineens minder saai. Dat is best een bedrag. Dat is wel veel geld geef ik toe. Maar alsnog dacht ik toen ik las over het bedrijf Stadzig. Ik had er ook nog nooit van gehoord dacht ik who gives a [&nbsp;__&nbsp;] Maar you give a [&nbsp;__&nbsp;] Waarom? Nou ik had dus in eerste instantie moet ik ook toegeven dat ik dacht oh grappig. Ze hebben een soort analytics matrix eh telemetrix bedrijf overgenomen. Heel kort. Nou heel kort jij maakt een applicatie. Daarbinnen heb je allerlei ideeën en je wil die ideeën eigenlijk kunnen testen op je eindgebruikers. Nou hè om AB testen te doen, maar dat wil je doen in die applicatie. Dus dat betekent dat je een deel van je gebruikers interface A laat zien en een deel van je gebruikers interface B. Je wil ook nog eens een soort groep van early testers hebben. Dus dan moet je feature verleing gaan doen. Dus dat is een vlaggetje zetten bij bepaalde features en zeggen in die interface eh die nieuwe manier van sorteren is alleen beschikbaar voor early testers. Ja. nieuwe functionaliteit die je niet in één keer naar alle gebruikers eh beschikbaar maakt, maar voor een klein groepje zodat als het fout gaat eh niet de hele tent in de fik staat. Dat is op zich netjes. Daarnaast wil je Wie wordt er emotioneel van? Daarna daarnaast ja AB test snap ik ook. Ja, dat ga dat gaat typ dat gaat aan jouw hart. Dat is ook mooi in jouw. Ja, dankjewel. Ja, het is gewoon telemetrix, weet je wel, telemetry. Ja. Ehm maar uiteindelijk wil je natuurlijk ook weten hoe er binnen je applicatie als een soort Google Analytics achtig heen en weer geklikt wordt in dat ding. Hebben bepaalde mensen op bepaalde toestellen last van vertraging. Oké. En ik snap dat dit nuttig is en ik weet ook dat Open dit heeft, want ik bedoel ik word de hele tijd eh met AB test van antwoorden geconfronteerd. Ja. En natuurlijk als jij als gebruiker staat er dan ben jij bereid om anonieme gebruikersdata met ons te delen? Nou, dat is dat vind je zodat ze deze partijen kunnen inschakelen. Ja, maar waarom hebben ze het gekocht? Wat zegt jou dat nou? Ehm er is een beetje onderzoek gedaan. Niet door mij. Ik ben ik ben onderzoek gaan doen. Toen vond ik mensen die onderzoek gingen doen. Die dachten: "Wat een random bedrijf om over te nemen als er zijn er zoveel." Ja, maar die waren ook nieuwsgierig. Ja. Van dit wat wat wat is de play hier? Dit moet een soort vierdimensionaal test zijn. Ja, dan is een miljard wel vier veel toch? Want dit is niet soort van rocket science. No fans. Nou, wat blijkt? Zij doen hele specifieke matrics voor AI clients eh en AI rappers, hè. Dus eigenlijk al die scaffolding, al die heel concreet Cloud Code van Antropic gebruikte dit bedrijf om alle telemtry op te slaan wat betrekking tot wat software ontwikkelaars met cloud code doen. Hoe ze cloud code gebruiken, wat er misgaat in Cloud code et cetera. En waarop ik wil leren over hoe mensen Cloud code gebruiken om het weer terug te voeden in de volgende trainingsrun om Cloud code daar gebruiken ze een third party bedrijf voor. Dat heet Stadzig. Ja. Oké. Nou, en dan is nu de vraag: oké, zit er dan waarde? Dit kan allemaal tegelijk waar zijn hoor. Zit er waarde in stad zich omdat het hun gelukt is om heel knappe telemityerty te doen voor deze specifieke use case. Namelijk lm's erachter of ieder geval AI modellen hè. Want je kunt natuurlijk iets bouwen wat je in iedere applicatie kan hangen. Maar blijkbaar heeft Entropic gekozen voor hun eh omdat ze waarschijnlijk waardevolle informatie geven op een manier dat hun concurrenten niet kunnen. Dat dus één optie kan zijn dat Open AI dacht: "We gaan die hele markt bekijken. Wie werkt het best met al die wrapping achtige applicaties?" Want als wij dat bedrijf dan bezitten, kunnen we van al die ontwikkelaars die hun ook gebruiken al die data naar binnen halen. Stap één, hè. Dus je je zou kunnen kijken, het is een kijkje in de keuken bij Anthropic. Ja, als Antropic het er nu niet uithaalt uit cloud code, dan heeft Open in essentie een tunneltje naar binnen. Eh dus dat is denk ik wel ja, ga ervanuit dat het eruit gaat halen, vermoeden, maar misschien historische data ofzo waar ze dan bij kunnen. Precies. Absoluut. En daarin dit maakt bijvoorbeeld ook bedrijven als Windsurf en Curser en dat soort forks van een ander stuk software van Visual Studio Code toch waardevol omdat eigenlijk alle knohow die ze binnenhalen aan telemetry van hun gebruikers plus wat zij leren over hoe ze dit moeten bouwen door feedback gewoon op de mail je uiteindelijk toch een soort ja eh chest een schatkistje aan het opbouwen van telemity data plus eh expliciete data van gebruikers. Ja, wat je niet kijk Open AI heeft nu inmiddels wel, maar had eigenlijk ook geen coding tools. Ja, dan weet je het dus gewoon niet. Het is wel grappig, hè? De soort van de mate van dirty business die die AI bedrijven zichzelf eh eigenlijk toe toestaan. Dus het begint al met het trainen op data waar ze geen copyright op hebben en zich in allerlei bochten moeten vringen om zich daar uit te houden [&nbsp;__&nbsp;] Het zit hem in eh in het kopen van bedrijven om elkaar dwars te zitten. Hebben we al situatie gehad dat ze bijvoorbeeld van elkaar jatten? Eh mensen sowieso. Nou mensen wel, maar ik bedoel kennis eh bij elkaar hacken. Nou ja, ik bedoel de thought traces hè, dus als jij eh in een reasoning model zit, staat er zo thinking en dan kan je dan openklikken en dan kan je die interne metacognitie zien. En je kan zijn gedachtegang lezen. Ja, die zijn allemaal al gefilterd al lang geleden, omdat het bleek dat ze die reasoning traces aan het stelen waren van elkaar. Van elkaar. Ja, daarom kijken wij naar gecomprimeerde versie ervan. Ja. Ja. Het is een parafraseren van de metacognitie, want anders wordt het gestolen. Ja, dit is dit is de wereld waarin ik leven. Ehm maar en dus dat dat gebeurde. Ik bedoel maar dat vind ik nog niet echt hacken, want ik zat namelijk te denken ja jij bedoelt echt gewoon naar binnen gaan op een zondag zeg maar 's nachts met een kijk als je eenmaal als je eenmaal kijk en nu we zitten nu in de weet je we hebben we zijn onderwerp aan het uitspringen. Dus nu gun ik mez, ik weet dat de helft ons heeft verlaten na na dat verhaal over robotica. Maar de nu ik nu we zijn, denk ik we vinden het voorkomen normaal dat Amerika en eh en eh en China de dat die dat die geheime diensten elkaar aan het hekken zijn. Ja, we vinden het ook volkomen normaal. Tenminste we accepteren het natuurlijk niet, maar we weten dat het gebeurt dat die Chinezen bij AZML proberen allerlei ehm ja dingen te te jatten. Ja. Ja. Bedrijfspionage. Bedrijfspionage, dat is niet nieuw. En eh ik heb dat nog nooit gehoord van eh ik heb dat nog nog niet echt gehoord over AI bedrijven. Terwijl in hetzelfde land tussen bedrijven bedoel jij? Nou, ik ik in in eerste instantie we accep we weten dat het aan bedrijfspioners gebeurt tussen China en Amerika bijvoorbeeld. Ik we in die toekomstvoorspelling al zei IC 27 gebeurt het dat de volgens mij de Chinezen inbreken bij de Amerikanen of andersom. Dus dan is er opeens een versnelling in die hele wapenwedloop. Dus daar wordt het voorspeld. Maar dit is volgens mij voor zover ik weet nog niet uitgekomen dat eh landen elkaars AI technologie proberen te stelen. Maar ja, dan is het een beetje een dunne grens inmiddels tussen wat een land is die [&nbsp;__&nbsp;] en wat een bedrijf is die [&nbsp;__&nbsp;] Omdat die twee nou best wel in één aan het gaan zijn. Je hebt letterlijk basen van AI bedrijven die bij het Amerikaanse leger werken nu. die gewoon een titel en een pakje hebben gekregen. Als jij hier zeg maar een netwerkdiagram van tekent, zo'n graf zeg maar social graph, dan dan de de ja, de verstrengelde belangen en onderlinge belangen zijn te bizar natuurlijk. Ik denk alleen wel dat, kijk, ik ben wel benieuwd hoor, want dit zal nog wel een stage krijgen die overname van dit bedrijf of het inderdaad zo is dat je daarmee ook de data van die klanten overneemt. Ik mag toch hopen dat de user agreement dat dat niet mee zou gaan. Dat is ook een beetje gek, toch? Zou gek zijn. Dat zou een beetje gek zijn. Ik kan me ook voorstellen dat het open en jij gewoon zegt: "Nee joh, wij doen al heel veel toemity zelf in onze eigen apps. We gebruiken hun ook. Dit is gewoon fantastisch." Maar we willen heel veel meer controle hierover hè, hoe we dat inzetten. Dus we gaan gewoon die ontwikkelaars, het is een soort equy higher. Er zitten gewoon een paar hele slimme mensen daar. Die willen wij binnenhalen en dat het nog een paar weken doordraait bij de concurrenten. Ik snap er niks van. Het is een beetje gek. Snappen ook naar jouw uitleg nog steeds niks van. Maar ik wil nog wel zeggen, het is wel een boeiende, want vroeger deed ik vaak eh patentjes in de gaten houden van bedrijven. Maar om te zien dat is leuk, hè. Tuurlijk tuurlijk. Maar ehm acquisities in de gaten houden is ook leuk, want dan kan je daarna soort complotterig samen zoals wij nu doen erachter komen waarom. Maar dit complot kan nog veel dieper. Dat dat voel ik aan alles. Dit ik vind deze uitleg te simpel, want Antropic trekt natuurlij stekker eruit. Wat wat is het nou voor? Dan is het een duur geintje. Ja, wat waar betaal je nou een miljard voor? Maar goed, misschien onderschat ik de business van AB testing eh SAA software. Daar moet ik moet ik misschien niet lichtzinnig over doen. En werken daar ontzettend slimme getrouwe mensen. Eh nee, ik vind gewoon dat wij als Europa wij moeten gewoon Amerikaan en de Chinesen helaal de moeder hacken om hun e stelen. Dit zie ik als het als het grote voorland. Start ik nu nog een een jingletje in. Microsoft heeft eigen AI modellen gelanceerd, twee stuks en ze hebben geweldige namen. De ene heet My Voice 1 en de andere heet My A preview. My Preview werd getraind op 15.000 Nvidia H100 GPU's. NMI Voice levert natuurlijke spraak en zit in copilot daily en podcasts. Ja, wat een pizze. Ik ik schrik hiervan. Ja, ik zie jou ook bij emotioneel. Maar ik doe wel klaar. Er zijn twee modellen van Mar. Het is natuurlijk saant, want hoezo maken zij hun eigen modellen als ze ook zo vuisdiep in open AI zitten en open AI nu eigenlijk overal toepassen. Ja, dus ze zijn daar zijn grotere modellen of is dit meer in de categorie van die F modellen? Nee, dat precies. Dat dacht ik dus eerst ook. Dus ik was eigenlijk voorbij dit nieuws gescroll eerder deze week omdat ik dacht: "Ja, Microsoft is een lang model aan het maken. Ze hebben een hele mooie kleine kleine modelletjes die je heb een soort nich nich gevonden in die eh miniellen zeg maar. Wa gebruiken ze het ook weer voor? Vai eh on device, kleine embedded devices ehm pinnen hun eigen infrastructuur om kleine AI toepassingen te doen. Is best het is een soort heel klein elektromotortje wat ze hebben uitgevonden wat je natuurlijk op heel veel plekken kan doen om een ram omhoog te doen in een auto maar niet te laten rijden. Dat is een grotere motor. In de auto zitten veel motors. Die zijn kle ah zo. Jeetje ik deze metor ging die maar oké. Ja. Ja. En ehm dus maar nu dus ik zat door te lezen. Ik dacht: "Nee, nee, dit is model wat ze in copilot gaan gebruiken. Een model wat in copilot gaat praten." Ja, precies. Dat is opvallend, want eh daarvan zijn we gewend dat ze open modellen gebruiken. Ik bedoel, het is een het is een eh gezonde eh professionele beslissing als bedrijf om natuurlijk te zeggen: "Ja, eh ook al hebben we 49 punt zoveel procent aandeel in één van onze toeleveranciers, Open AI, dat geeft ons niet eh genoeg garantie eh dat wij intern niet moeten gaan ontwikkelen." Ik bedoel, zij werken ook in in GitHub hè, ook Microsoft werken ze ook gewoon met Antropic samen hè. Dus er waren en met Grok met een K van eh Musk. Dus er waren allang openingen in dat een soort van er was wel geen explosiviteit meer. Zo moet ik het even zeggen. Maar je hebt een stukje er is geen excessiviteit en we gaan meedoen in de arena. Hè dit ik zie dit als een potentieel eerste stapje naar nou misschien kunnen die modellen wel groter en kunnen we wel eh want zijn ze groot of vooral dat preview model? Niet niet spectaculair. Want is dat dit is getraind op 15.000 H100s. Is dat veel? Ja. Ja. Nou wel om daar doe je niet een vaatje op trainen zeg maar. Dus zo zo'n minije Nee. Dus ze zijn aan het ze bewegen langzaam toe naar modellen die inzetbaar zijn op de plekken waar nu open en jij eigenlijk de default was. Juist en nog is op veel plekken. Dus ik wilde hem even benoemen als Het is voor Microsoft ook interessant om talent binnen te halen op deze manier hè. Onderzoekers willen werken aan niet alleen maar aan miniodellen. Dus je wil ook een beetje iets te bieden hebben. Ja, maar het is opvallend dat ze het gelijk in copilot integreren. Dat is best wel een stap toch van een soort we zijn in een lap een beetje aan het rommelen om te zorgen dat we een plan B hebben versus het zit nu in Copiland. Ja. Ja. Dus ik ik het was een soort nieuwsbericht. Ik las er eerst overheen. Toen las ik het nog een keer. Toen dacht ik: "Wat is hier eigenlijk allemaal voor verschuiving gaan?" Omdat ik merk eh en dat zou jij ook hebben tijdens lezingen. Ja. Coopilot zeg maar range supreme hè. Ik bedoel, dat is wat voor heel veel mensen die nu luisteren ook AI is. Ja. Eh dus als daar dan het standaardmodel vervangen wordt door iets wat Microsoft zelf aan het bakken is, vind ik dat toch wel een beetje een big deal. Ja. Nou en er is eh eh in de afgelopen maanden hoor je met echt de regelmaat van de trom over het gedoe tussen Open en Microsoft. Dus heel veel is geen prettige relatie. Nee, dat is inmiddels een beetje verzuurde relatie geworden. Ze proberen heel erg positief erover te doen de hele tijd over en weer. Maar aan alles is merkbaar dat ze elkaar eh toch ook wel hier en daar de tent uitvechten. Dus dit is een Ja, misschien als we nog een haakje of een bruggetje kunnen maken naar die telemetry AB EB testing AB testing Staas waar we het net over hadden. Ja, al die telemetry wat betreft Windows hè, het desktop operating system van Microsoft en trouwens hun hele webomgeving met Office 365 en noem het allemaal maar op. Die heeft Microsoft hè, die heeft Open AI niet die tol. Dus als jij modellen wil maken hm dan kan jij binnen Microsoft modellen maken op basis van trainingsdata waar open en jij helemaal niet bij kan. Je bedoelt hoe mensen office gebruiken om bijvoorbeeld die droom waar te maken? Dit klinkt als een hele wou ik wou het jouw droom noemen, maar dat je wel kan praten met Excel en dat die hele applicatie wel begrijpt en dat je ineens daar magische Excel sheets uitfietst wat mensen nu verwachten van copilot. Coopilot inmiddels ook een beetje beter kan. Dus ja, of misschien wel in de toekomst. Ik ben nu echt aan het aan het ehm eh beetje vrij aan het praten, maar de hoe mensen tot een document komen bijvoorbeeld die bij een advocaatbedrijf werken en in eh Word werken online, dat de manier waarop dat document tot stand komt ook iets is waarmee ze modellen kunnen trainen. Dat de tot standkoming van het document zelf en niet alleen maar de output van het niet alleen maar doorkasie af bijvoorbeeld. En ik denk dat kijk destijds met de overname van Winserf hè, één van die code editing IDE's dacht ik, ik was echt een beetje cynisch. Hoe kan er nou zoveel geld geboden worden voor iets wat nagenoeg een kopie is met een ander logo erop? Totdat je gaat beseffen dat er dus heel veel data verzameld wordt in die applicatie. Dan wordt er een data verzamelingsapplicatie overgenomen, hè. Dus een service die die verzameling doet. Ook geen hele gekke move. Ook al snappen wij hem nog niet helemaal. Dan vind ik het eigenlijk vanuit Microsoft best logisch dat gezien het feit dat zij zoveel data hebben. Want als je Windows tegenwoordig installeert, dan geef je best wel wat ehm hoe zeg je dat? Toestemming om de de anonymous user statistics te eh doen. Ja, dan heb je eigenlijk als data het nieuwe goud is, heb je goud in handen en dan moet je misschien toch dat goud gaan omsmelten naar je eigen modellen. Jezus, deze metafoor, ik vind het echt heel knap hoe je dat doet. met goud en goud van maken en door je handen laten van dat motortje in die auto neem. Die motor in die auto die dat die Goed, dit was Pok eh AI report. Wij heten AI Report. Wij danken Sam Hengeveld voor de edit en Pankra voor de vormgeving. Als je een lezing wil over AI van Wiets of van mij, dan kan dat. Mail ons op lezing@aaireport. Wil je op de hoogte blijven van het laatste AI nieuws en twee keer per week tips en tools ontvangen om het meeste uit AI te halen, abonneer je dan op onze nieuwsbrief via Airport. En wil je vandaag nog beginnen met AI binnen jouw bedrijf? Ga naar deagency.com/aai report. Alle linkjes staan in de showotes. Tot volgende week. [Muziek] Ja.

---

## Notes


## Key Takeaways
-

## Related
-
